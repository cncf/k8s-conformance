Conformance test: not doing test setup.
I1214 08:40:15.240369    6248 e2e.go:116] Starting e2e run "d784b4f6-5b92-4d47-8c5f-aec0e1a12994" on Ginkgo node 1
Dec 14 08:40:15.258: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /go/src/k8s.io/kubernetes/platforms/linux/amd64
=====================================================================================
Random Seed: 1671007215 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Dec 14 08:40:15.353: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:40:15.354: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 14 08:40:15.413: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
Dec 14 08:40:15.482: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 14 08:40:15.482: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Dec 14 08:40:15.482: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 14 08:40:15.499: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-disk-plugin-alicloud' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'egress-filter-applier' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-1-v1.25.4' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-host' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-pod' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec 14 08:40:15.500: INFO: e2e test version: v1.25.4
Dec 14 08:40:15.519: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Dec 14 08:40:15.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:40:15.531: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.178 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec 14 08:40:15.353: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:40:15.354: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Dec 14 08:40:15.413: INFO: Waiting up to 10m0s for all pods (need at least 1) in namespace 'kube-system' to be running and ready
    Dec 14 08:40:15.482: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Dec 14 08:40:15.482: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
    Dec 14 08:40:15.482: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Dec 14 08:40:15.499: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-disk-plugin-alicloud' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'egress-filter-applier' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-1-v1.25.4' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-host' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'network-problem-detector-pod' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
    Dec 14 08:40:15.500: INFO: e2e test version: v1.25.4
    Dec 14 08:40:15.519: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Dec 14 08:40:15.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:40:15.531: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:15.554
Dec 14 08:40:15.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:40:15.555
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:15.589
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:15.61
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-83497f37-6a5b-4592-970b-8ec893bdbba0 12/14/22 08:40:15.63
STEP: Creating a pod to test consume configMaps 12/14/22 08:40:15.642
Dec 14 08:40:15.671: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05" in namespace "projected-1885" to be "Succeeded or Failed"
Dec 14 08:40:15.681: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 10.73027ms
Dec 14 08:40:17.693: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022878739s
Dec 14 08:40:19.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024421027s
Dec 14 08:40:21.694: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Running", Reason="", readiness=false. Elapsed: 6.023413411s
Dec 14 08:40:23.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023998048s
STEP: Saw pod success 12/14/22 08:40:23.695
Dec 14 08:40:23.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05" satisfied condition "Succeeded or Failed"
Dec 14 08:40:23.707: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 container projected-configmap-volume-test: <nil>
STEP: delete the pod 12/14/22 08:40:23.737
Dec 14 08:40:23.753: INFO: Waiting for pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 to disappear
Dec 14 08:40:23.764: INFO: Pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:40:23.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1885" for this suite. 12/14/22 08:40:23.786
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":1,"skipped":16,"failed":0}
------------------------------
• [8.245 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:15.554
    Dec 14 08:40:15.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:40:15.555
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:15.589
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:15.61
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-83497f37-6a5b-4592-970b-8ec893bdbba0 12/14/22 08:40:15.63
    STEP: Creating a pod to test consume configMaps 12/14/22 08:40:15.642
    Dec 14 08:40:15.671: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05" in namespace "projected-1885" to be "Succeeded or Failed"
    Dec 14 08:40:15.681: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 10.73027ms
    Dec 14 08:40:17.693: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022878739s
    Dec 14 08:40:19.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024421027s
    Dec 14 08:40:21.694: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Running", Reason="", readiness=false. Elapsed: 6.023413411s
    Dec 14 08:40:23.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023998048s
    STEP: Saw pod success 12/14/22 08:40:23.695
    Dec 14 08:40:23.695: INFO: Pod "pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05" satisfied condition "Succeeded or Failed"
    Dec 14 08:40:23.707: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:40:23.737
    Dec 14 08:40:23.753: INFO: Waiting for pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 to disappear
    Dec 14 08:40:23.764: INFO: Pod pod-projected-configmaps-78e70c57-5e77-45f0-86b2-234863cedf05 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:40:23.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1885" for this suite. 12/14/22 08:40:23.786
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:23.799
Dec 14 08:40:23.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:40:23.8
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:23.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:23.857
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 12/14/22 08:40:23.878
STEP: Creating a ResourceQuota 12/14/22 08:40:28.89
STEP: Ensuring resource quota status is calculated 12/14/22 08:40:28.903
STEP: Creating a Service 12/14/22 08:40:30.915
STEP: Creating a NodePort Service 12/14/22 08:40:30.936
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/14/22 08:40:30.958
STEP: Ensuring resource quota status captures service creation 12/14/22 08:40:31.017
STEP: Deleting Services 12/14/22 08:40:33.03
STEP: Ensuring resource quota status released usage 12/14/22 08:40:33.066
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:40:35.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6269" for this suite. 12/14/22 08:40:35.099
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":2,"skipped":17,"failed":0}
------------------------------
• [11.313 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:23.799
    Dec 14 08:40:23.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:40:23.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:23.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:23.857
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 12/14/22 08:40:23.878
    STEP: Creating a ResourceQuota 12/14/22 08:40:28.89
    STEP: Ensuring resource quota status is calculated 12/14/22 08:40:28.903
    STEP: Creating a Service 12/14/22 08:40:30.915
    STEP: Creating a NodePort Service 12/14/22 08:40:30.936
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 12/14/22 08:40:30.958
    STEP: Ensuring resource quota status captures service creation 12/14/22 08:40:31.017
    STEP: Deleting Services 12/14/22 08:40:33.03
    STEP: Ensuring resource quota status released usage 12/14/22 08:40:33.066
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:40:35.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6269" for this suite. 12/14/22 08:40:35.099
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:35.113
Dec 14 08:40:35.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 08:40:35.114
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:35.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:35.17
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 12/14/22 08:40:35.19
STEP: wait for the container to reach Succeeded 12/14/22 08:40:35.209
STEP: get the container status 12/14/22 08:40:41.295
STEP: the container should be terminated 12/14/22 08:40:41.306
STEP: the termination message should be set 12/14/22 08:40:41.306
Dec 14 08:40:41.307: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 12/14/22 08:40:41.307
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 08:40:41.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5324" for this suite. 12/14/22 08:40:41.353
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":3,"skipped":19,"failed":0}
------------------------------
• [6.253 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:35.113
    Dec 14 08:40:35.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 08:40:35.114
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:35.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:35.17
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 12/14/22 08:40:35.19
    STEP: wait for the container to reach Succeeded 12/14/22 08:40:35.209
    STEP: get the container status 12/14/22 08:40:41.295
    STEP: the container should be terminated 12/14/22 08:40:41.306
    STEP: the termination message should be set 12/14/22 08:40:41.306
    Dec 14 08:40:41.307: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 12/14/22 08:40:41.307
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 08:40:41.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5324" for this suite. 12/14/22 08:40:41.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:41.367
Dec 14 08:40:41.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:40:41.369
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:41.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:41.424
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9359.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9359.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 12/14/22 08:40:41.444
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9359.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9359.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 12/14/22 08:40:41.444
STEP: creating a pod to probe /etc/hosts 12/14/22 08:40:41.445
STEP: submitting the pod to kubernetes 12/14/22 08:40:41.445
Dec 14 08:40:41.463: INFO: Waiting up to 15m0s for pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe" in namespace "dns-9359" to be "running"
Dec 14 08:40:41.473: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.778595ms
Dec 14 08:40:43.485: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022791375s
Dec 14 08:40:45.485: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022767446s
Dec 14 08:40:47.486: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023839634s
Dec 14 08:40:49.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024492456s
Dec 14 08:40:51.486: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023866901s
Dec 14 08:40:53.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Running", Reason="", readiness=true. Elapsed: 12.024683103s
Dec 14 08:40:53.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:40:53.487
STEP: looking for the results for each expected name from probers 12/14/22 08:40:53.5
Dec 14 08:40:53.633: INFO: DNS probes using dns-9359/dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe succeeded

STEP: deleting the pod 12/14/22 08:40:53.633
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:40:53.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9359" for this suite. 12/14/22 08:40:53.67
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":4,"skipped":40,"failed":0}
------------------------------
• [12.318 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:41.367
    Dec 14 08:40:41.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:40:41.369
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:41.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:41.424
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9359.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9359.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     12/14/22 08:40:41.444
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9359.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9359.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     12/14/22 08:40:41.444
    STEP: creating a pod to probe /etc/hosts 12/14/22 08:40:41.445
    STEP: submitting the pod to kubernetes 12/14/22 08:40:41.445
    Dec 14 08:40:41.463: INFO: Waiting up to 15m0s for pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe" in namespace "dns-9359" to be "running"
    Dec 14 08:40:41.473: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.778595ms
    Dec 14 08:40:43.485: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022791375s
    Dec 14 08:40:45.485: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022767446s
    Dec 14 08:40:47.486: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023839634s
    Dec 14 08:40:49.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024492456s
    Dec 14 08:40:51.486: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023866901s
    Dec 14 08:40:53.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe": Phase="Running", Reason="", readiness=true. Elapsed: 12.024683103s
    Dec 14 08:40:53.487: INFO: Pod "dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:40:53.487
    STEP: looking for the results for each expected name from probers 12/14/22 08:40:53.5
    Dec 14 08:40:53.633: INFO: DNS probes using dns-9359/dns-test-1317fca5-fc82-440c-9799-0ee80f579ebe succeeded

    STEP: deleting the pod 12/14/22 08:40:53.633
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:40:53.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9359" for this suite. 12/14/22 08:40:53.67
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:40:53.686
Dec 14 08:40:53.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 08:40:53.687
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:53.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:53.741
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 in namespace container-probe-3371 12/14/22 08:40:53.762
Dec 14 08:40:53.780: INFO: Waiting up to 5m0s for pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24" in namespace "container-probe-3371" to be "not pending"
Dec 14 08:40:53.791: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24": Phase="Pending", Reason="", readiness=false. Elapsed: 11.245898ms
Dec 14 08:40:55.803: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24": Phase="Running", Reason="", readiness=true. Elapsed: 2.022814367s
Dec 14 08:40:55.803: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24" satisfied condition "not pending"
Dec 14 08:40:55.803: INFO: Started pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 in namespace container-probe-3371
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:40:55.803
Dec 14 08:40:55.814: INFO: Initial restart count of pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 is 0
Dec 14 08:41:46.137: INFO: Restart count of pod container-probe-3371/busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 is now 1 (50.322747137s elapsed)
STEP: deleting the pod 12/14/22 08:41:46.137
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 08:41:46.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3371" for this suite. 12/14/22 08:41:46.173
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":5,"skipped":48,"failed":0}
------------------------------
• [52.500 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:40:53.686
    Dec 14 08:40:53.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 08:40:53.687
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:40:53.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:40:53.741
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 in namespace container-probe-3371 12/14/22 08:40:53.762
    Dec 14 08:40:53.780: INFO: Waiting up to 5m0s for pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24" in namespace "container-probe-3371" to be "not pending"
    Dec 14 08:40:53.791: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24": Phase="Pending", Reason="", readiness=false. Elapsed: 11.245898ms
    Dec 14 08:40:55.803: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24": Phase="Running", Reason="", readiness=true. Elapsed: 2.022814367s
    Dec 14 08:40:55.803: INFO: Pod "busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24" satisfied condition "not pending"
    Dec 14 08:40:55.803: INFO: Started pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 in namespace container-probe-3371
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:40:55.803
    Dec 14 08:40:55.814: INFO: Initial restart count of pod busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 is 0
    Dec 14 08:41:46.137: INFO: Restart count of pod container-probe-3371/busybox-0c3ec883-2259-49ef-9c3e-89c6dc3b5b24 is now 1 (50.322747137s elapsed)
    STEP: deleting the pod 12/14/22 08:41:46.137
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 08:41:46.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3371" for this suite. 12/14/22 08:41:46.173
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:46.188
Dec 14 08:41:46.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 08:41:46.189
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:46.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:46.245
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 12/14/22 08:41:46.266
Dec 14 08:41:46.282: INFO: Waiting up to 5m0s for pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0" in namespace "containers-6241" to be "Succeeded or Failed"
Dec 14 08:41:46.293: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.516541ms
Dec 14 08:41:48.305: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022485563s
Dec 14 08:41:50.306: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023314126s
STEP: Saw pod success 12/14/22 08:41:50.306
Dec 14 08:41:50.306: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0" satisfied condition "Succeeded or Failed"
Dec 14 08:41:50.317: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:41:50.34
Dec 14 08:41:50.357: INFO: Waiting for pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 to disappear
Dec 14 08:41:50.369: INFO: Pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 08:41:50.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6241" for this suite. 12/14/22 08:41:50.389
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":6,"skipped":91,"failed":0}
------------------------------
• [4.213 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:46.188
    Dec 14 08:41:46.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 08:41:46.189
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:46.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:46.245
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 12/14/22 08:41:46.266
    Dec 14 08:41:46.282: INFO: Waiting up to 5m0s for pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0" in namespace "containers-6241" to be "Succeeded or Failed"
    Dec 14 08:41:46.293: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.516541ms
    Dec 14 08:41:48.305: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022485563s
    Dec 14 08:41:50.306: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023314126s
    STEP: Saw pod success 12/14/22 08:41:50.306
    Dec 14 08:41:50.306: INFO: Pod "client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0" satisfied condition "Succeeded or Failed"
    Dec 14 08:41:50.317: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:41:50.34
    Dec 14 08:41:50.357: INFO: Waiting for pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 to disappear
    Dec 14 08:41:50.369: INFO: Pod client-containers-4444e82b-b3ef-4376-a713-fc5b9ac301f0 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 08:41:50.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6241" for this suite. 12/14/22 08:41:50.389
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:50.402
Dec 14 08:41:50.403: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:41:50.403
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:50.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:50.458
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 12/14/22 08:41:50.478
STEP: Getting a ResourceQuota 12/14/22 08:41:50.49
STEP: Updating a ResourceQuota 12/14/22 08:41:50.501
STEP: Verifying a ResourceQuota was modified 12/14/22 08:41:50.521
STEP: Deleting a ResourceQuota 12/14/22 08:41:50.532
STEP: Verifying the deleted ResourceQuota 12/14/22 08:41:50.544
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:41:50.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2862" for this suite. 12/14/22 08:41:50.568
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":7,"skipped":107,"failed":0}
------------------------------
• [0.178 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:50.402
    Dec 14 08:41:50.403: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:41:50.403
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:50.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:50.458
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 12/14/22 08:41:50.478
    STEP: Getting a ResourceQuota 12/14/22 08:41:50.49
    STEP: Updating a ResourceQuota 12/14/22 08:41:50.501
    STEP: Verifying a ResourceQuota was modified 12/14/22 08:41:50.521
    STEP: Deleting a ResourceQuota 12/14/22 08:41:50.532
    STEP: Verifying the deleted ResourceQuota 12/14/22 08:41:50.544
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:41:50.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2862" for this suite. 12/14/22 08:41:50.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:50.582
Dec 14 08:41:50.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sysctl 12/14/22 08:41:50.582
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:50.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:50.637
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/14/22 08:41:50.658
STEP: Watching for error events or started pod 12/14/22 08:41:50.675
STEP: Waiting for pod completion 12/14/22 08:41:52.688
Dec 14 08:41:52.688: INFO: Waiting up to 3m0s for pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68" in namespace "sysctl-8381" to be "completed"
Dec 14 08:41:52.700: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 11.433926ms
Dec 14 08:41:54.712: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024102197s
Dec 14 08:41:54.712: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68" satisfied condition "completed"
STEP: Checking that the pod succeeded 12/14/22 08:41:54.724
STEP: Getting logs from the pod 12/14/22 08:41:54.725
STEP: Checking that the sysctl is actually updated 12/14/22 08:41:54.747
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:41:54.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8381" for this suite. 12/14/22 08:41:54.768
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":8,"skipped":131,"failed":0}
------------------------------
• [4.199 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:50.582
    Dec 14 08:41:50.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sysctl 12/14/22 08:41:50.582
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:50.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:50.637
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 12/14/22 08:41:50.658
    STEP: Watching for error events or started pod 12/14/22 08:41:50.675
    STEP: Waiting for pod completion 12/14/22 08:41:52.688
    Dec 14 08:41:52.688: INFO: Waiting up to 3m0s for pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68" in namespace "sysctl-8381" to be "completed"
    Dec 14 08:41:52.700: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 11.433926ms
    Dec 14 08:41:54.712: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024102197s
    Dec 14 08:41:54.712: INFO: Pod "sysctl-534b149c-34b3-40e8-ba51-bb19cb19bc68" satisfied condition "completed"
    STEP: Checking that the pod succeeded 12/14/22 08:41:54.724
    STEP: Getting logs from the pod 12/14/22 08:41:54.725
    STEP: Checking that the sysctl is actually updated 12/14/22 08:41:54.747
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:41:54.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-8381" for this suite. 12/14/22 08:41:54.768
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:41:54.781
Dec 14 08:41:54.781: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:41:54.782
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:54.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:54.836
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-98181be1-0769-4892-9145-dbe67a2894cc 12/14/22 08:41:54.868
STEP: Creating the pod 12/14/22 08:41:54.88
Dec 14 08:41:54.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc" in namespace "projected-3080" to be "running and ready"
Dec 14 08:41:54.907: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.465927ms
Dec 14 08:41:54.907: INFO: The phase of Pod pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:41:56.920: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc": Phase="Running", Reason="", readiness=true. Elapsed: 2.023364187s
Dec 14 08:41:56.920: INFO: The phase of Pod pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc is Running (Ready = true)
Dec 14 08:41:56.920: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-98181be1-0769-4892-9145-dbe67a2894cc 12/14/22 08:41:56.955
STEP: waiting to observe update in volume 12/14/22 08:41:56.967
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:43:24.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3080" for this suite. 12/14/22 08:43:24.235
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":9,"skipped":133,"failed":0}
------------------------------
• [89.467 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:41:54.781
    Dec 14 08:41:54.781: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:41:54.782
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:41:54.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:41:54.836
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-98181be1-0769-4892-9145-dbe67a2894cc 12/14/22 08:41:54.868
    STEP: Creating the pod 12/14/22 08:41:54.88
    Dec 14 08:41:54.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc" in namespace "projected-3080" to be "running and ready"
    Dec 14 08:41:54.907: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.465927ms
    Dec 14 08:41:54.907: INFO: The phase of Pod pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:41:56.920: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc": Phase="Running", Reason="", readiness=true. Elapsed: 2.023364187s
    Dec 14 08:41:56.920: INFO: The phase of Pod pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc is Running (Ready = true)
    Dec 14 08:41:56.920: INFO: Pod "pod-projected-configmaps-f504bd34-f5af-4916-b52b-a8332e85cfbc" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-98181be1-0769-4892-9145-dbe67a2894cc 12/14/22 08:41:56.955
    STEP: waiting to observe update in volume 12/14/22 08:41:56.967
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:43:24.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3080" for this suite. 12/14/22 08:43:24.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:43:24.249
Dec 14 08:43:24.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:43:24.25
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:24.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:24.305
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 08:43:24.387: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 08:44:24.501: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 12/14/22 08:44:24.521
Dec 14 08:44:24.569: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 14 08:44:24.586: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 14 08:44:24.626: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 14 08:44:24.643: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/14/22 08:44:24.643
Dec 14 08:44:24.643: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8873" to be "running"
Dec 14 08:44:24.654: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.171936ms
Dec 14 08:44:26.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023803109s
Dec 14 08:44:28.668: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02477248s
Dec 14 08:44:30.666: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022765078s
Dec 14 08:44:32.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024430702s
Dec 14 08:44:34.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.02386963s
Dec 14 08:44:34.667: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec 14 08:44:34.667: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
Dec 14 08:44:34.678: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.491457ms
Dec 14 08:44:34.678: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:44:34.678: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
Dec 14 08:44:34.690: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.479596ms
Dec 14 08:44:36.703: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.024735044s
Dec 14 08:44:36.703: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:44:36.703: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
Dec 14 08:44:36.715: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.608295ms
Dec 14 08:44:36.715: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/14/22 08:44:36.715
Dec 14 08:44:36.733: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8873" to be "running"
Dec 14 08:44:36.745: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.545761ms
Dec 14 08:44:38.757: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024201897s
Dec 14 08:44:40.758: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.024490229s
Dec 14 08:44:40.758: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:44:40.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8873" for this suite. 12/14/22 08:44:40.836
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":10,"skipped":144,"failed":0}
------------------------------
• [76.676 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:43:24.249
    Dec 14 08:43:24.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:43:24.25
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:43:24.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:43:24.305
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 08:43:24.387: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 08:44:24.501: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 12/14/22 08:44:24.521
    Dec 14 08:44:24.569: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec 14 08:44:24.586: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec 14 08:44:24.626: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec 14 08:44:24.643: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/14/22 08:44:24.643
    Dec 14 08:44:24.643: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8873" to be "running"
    Dec 14 08:44:24.654: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.171936ms
    Dec 14 08:44:26.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023803109s
    Dec 14 08:44:28.668: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02477248s
    Dec 14 08:44:30.666: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022765078s
    Dec 14 08:44:32.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024430702s
    Dec 14 08:44:34.667: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.02386963s
    Dec 14 08:44:34.667: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec 14 08:44:34.667: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
    Dec 14 08:44:34.678: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.491457ms
    Dec 14 08:44:34.678: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:44:34.678: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
    Dec 14 08:44:34.690: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.479596ms
    Dec 14 08:44:36.703: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.024735044s
    Dec 14 08:44:36.703: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:44:36.703: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8873" to be "running"
    Dec 14 08:44:36.715: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.608295ms
    Dec 14 08:44:36.715: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 12/14/22 08:44:36.715
    Dec 14 08:44:36.733: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-8873" to be "running"
    Dec 14 08:44:36.745: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.545761ms
    Dec 14 08:44:38.757: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024201897s
    Dec 14 08:44:40.758: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.024490229s
    Dec 14 08:44:40.758: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:44:40.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8873" for this suite. 12/14/22 08:44:40.836
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:44:40.927
Dec 14 08:44:40.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:44:40.928
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:40.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:40.983
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Dec 14 08:44:41.021: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f" in namespace "kubelet-test-7738" to be "running and ready"
Dec 14 08:44:41.032: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.975434ms
Dec 14 08:44:41.032: INFO: The phase of Pod busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:44:43.045: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f": Phase="Running", Reason="", readiness=true. Elapsed: 2.023993988s
Dec 14 08:44:43.045: INFO: The phase of Pod busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f is Running (Ready = true)
Dec 14 08:44:43.045: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 08:44:43.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7738" for this suite. 12/14/22 08:44:43.104
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":11,"skipped":188,"failed":0}
------------------------------
• [2.190 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:44:40.927
    Dec 14 08:44:40.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 08:44:40.928
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:40.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:40.983
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Dec 14 08:44:41.021: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f" in namespace "kubelet-test-7738" to be "running and ready"
    Dec 14 08:44:41.032: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.975434ms
    Dec 14 08:44:41.032: INFO: The phase of Pod busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:44:43.045: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f": Phase="Running", Reason="", readiness=true. Elapsed: 2.023993988s
    Dec 14 08:44:43.045: INFO: The phase of Pod busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f is Running (Ready = true)
    Dec 14 08:44:43.045: INFO: Pod "busybox-readonly-fsd24342f6-d6df-43cf-9b0e-35a4cbda843f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 08:44:43.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7738" for this suite. 12/14/22 08:44:43.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:44:43.118
Dec 14 08:44:43.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 08:44:43.118
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:43.152
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:43.173
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 12/14/22 08:44:43.193
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:43.228
STEP: Creating a pod in the namespace 12/14/22 08:44:43.249
STEP: Waiting for the pod to have running status 12/14/22 08:44:43.266
Dec 14 08:44:43.266: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-2878" to be "running"
Dec 14 08:44:43.277: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.773157ms
Dec 14 08:44:45.290: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023351643s
Dec 14 08:44:45.290: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 12/14/22 08:44:45.29
STEP: Waiting for the namespace to be removed. 12/14/22 08:44:45.302
STEP: Recreating the namespace 12/14/22 08:44:56.326
STEP: Verifying there are no pods in the namespace 12/14/22 08:44:56.362
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:44:56.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1983" for this suite. 12/14/22 08:44:56.394
STEP: Destroying namespace "nsdeletetest-2878" for this suite. 12/14/22 08:44:56.406
Dec 14 08:44:56.418: INFO: Namespace nsdeletetest-2878 was already deleted
STEP: Destroying namespace "nsdeletetest-8737" for this suite. 12/14/22 08:44:56.418
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":12,"skipped":193,"failed":0}
------------------------------
• [13.314 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:44:43.118
    Dec 14 08:44:43.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 08:44:43.118
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:43.152
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:43.173
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 12/14/22 08:44:43.193
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:43.228
    STEP: Creating a pod in the namespace 12/14/22 08:44:43.249
    STEP: Waiting for the pod to have running status 12/14/22 08:44:43.266
    Dec 14 08:44:43.266: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-2878" to be "running"
    Dec 14 08:44:43.277: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.773157ms
    Dec 14 08:44:45.290: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023351643s
    Dec 14 08:44:45.290: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 12/14/22 08:44:45.29
    STEP: Waiting for the namespace to be removed. 12/14/22 08:44:45.302
    STEP: Recreating the namespace 12/14/22 08:44:56.326
    STEP: Verifying there are no pods in the namespace 12/14/22 08:44:56.362
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:44:56.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1983" for this suite. 12/14/22 08:44:56.394
    STEP: Destroying namespace "nsdeletetest-2878" for this suite. 12/14/22 08:44:56.406
    Dec 14 08:44:56.418: INFO: Namespace nsdeletetest-2878 was already deleted
    STEP: Destroying namespace "nsdeletetest-8737" for this suite. 12/14/22 08:44:56.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:44:56.434
Dec 14 08:44:56.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ephemeral-containers-test 12/14/22 08:44:56.435
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:56.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:56.49
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 12/14/22 08:44:56.511
Dec 14 08:44:56.539: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4420" to be "running and ready"
Dec 14 08:44:56.550: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.924652ms
Dec 14 08:44:56.550: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:44:58.563: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023842232s
Dec 14 08:44:58.563: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Dec 14 08:44:58.563: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 12/14/22 08:44:58.575
Dec 14 08:44:58.596: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4420" to be "container debugger running"
Dec 14 08:44:58.608: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.691486ms
Dec 14 08:45:00.621: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024715632s
Dec 14 08:45:02.620: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023992614s
Dec 14 08:45:02.620: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 12/14/22 08:45:02.62
Dec 14 08:45:02.621: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4420 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 08:45:02.621: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 08:45:02.621: INFO: ExecWithOptions: Clientset creation
Dec 14 08:45:02.621: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/ephemeral-containers-test-4420/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Dec 14 08:45:02.985: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:45:03.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-4420" for this suite. 12/14/22 08:45:03.107
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":13,"skipped":238,"failed":0}
------------------------------
• [6.685 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:44:56.434
    Dec 14 08:44:56.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ephemeral-containers-test 12/14/22 08:44:56.435
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:44:56.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:44:56.49
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 12/14/22 08:44:56.511
    Dec 14 08:44:56.539: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4420" to be "running and ready"
    Dec 14 08:44:56.550: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.924652ms
    Dec 14 08:44:56.550: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:44:58.563: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023842232s
    Dec 14 08:44:58.563: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Dec 14 08:44:58.563: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 12/14/22 08:44:58.575
    Dec 14 08:44:58.596: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4420" to be "container debugger running"
    Dec 14 08:44:58.608: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.691486ms
    Dec 14 08:45:00.621: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024715632s
    Dec 14 08:45:02.620: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.023992614s
    Dec 14 08:45:02.620: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 12/14/22 08:45:02.62
    Dec 14 08:45:02.621: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4420 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 08:45:02.621: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 08:45:02.621: INFO: ExecWithOptions: Clientset creation
    Dec 14 08:45:02.621: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/ephemeral-containers-test-4420/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Dec 14 08:45:02.985: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:45:03.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-4420" for this suite. 12/14/22 08:45:03.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:03.121
Dec 14 08:45:03.121: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:45:03.122
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.158
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.178
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:45:03.199
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-rmt9 12/14/22 08:45:03.223
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:45:03.223
Dec 14 08:45:03.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rmt9" in namespace "subpath-4674" to be "Succeeded or Failed"
Dec 14 08:45:03.252: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.798104ms
Dec 14 08:45:05.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 2.023637376s
Dec 14 08:45:07.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 4.023421679s
Dec 14 08:45:09.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 6.023447003s
Dec 14 08:45:11.272: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 8.030559359s
Dec 14 08:45:13.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 10.022856467s
Dec 14 08:45:15.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 12.023578724s
Dec 14 08:45:17.266: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 14.024090175s
Dec 14 08:45:19.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 16.022574957s
Dec 14 08:45:21.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 18.023225917s
Dec 14 08:45:23.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 20.02367625s
Dec 14 08:45:25.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=false. Elapsed: 22.022998455s
Dec 14 08:45:27.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.02320184s
STEP: Saw pod success 12/14/22 08:45:27.265
Dec 14 08:45:27.265: INFO: Pod "pod-subpath-test-secret-rmt9" satisfied condition "Succeeded or Failed"
Dec 14 08:45:27.276: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-secret-rmt9 container test-container-subpath-secret-rmt9: <nil>
STEP: delete the pod 12/14/22 08:45:27.304
Dec 14 08:45:27.319: INFO: Waiting for pod pod-subpath-test-secret-rmt9 to disappear
Dec 14 08:45:27.329: INFO: Pod pod-subpath-test-secret-rmt9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-rmt9 12/14/22 08:45:27.329
Dec 14 08:45:27.330: INFO: Deleting pod "pod-subpath-test-secret-rmt9" in namespace "subpath-4674"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:45:27.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4674" for this suite. 12/14/22 08:45:27.362
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":14,"skipped":263,"failed":0}
------------------------------
• [24.254 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:03.121
    Dec 14 08:45:03.121: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:45:03.122
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:03.158
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:03.178
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:45:03.199
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-rmt9 12/14/22 08:45:03.223
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:45:03.223
    Dec 14 08:45:03.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rmt9" in namespace "subpath-4674" to be "Succeeded or Failed"
    Dec 14 08:45:03.252: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.798104ms
    Dec 14 08:45:05.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 2.023637376s
    Dec 14 08:45:07.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 4.023421679s
    Dec 14 08:45:09.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 6.023447003s
    Dec 14 08:45:11.272: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 8.030559359s
    Dec 14 08:45:13.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 10.022856467s
    Dec 14 08:45:15.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 12.023578724s
    Dec 14 08:45:17.266: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 14.024090175s
    Dec 14 08:45:19.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 16.022574957s
    Dec 14 08:45:21.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 18.023225917s
    Dec 14 08:45:23.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=true. Elapsed: 20.02367625s
    Dec 14 08:45:25.264: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Running", Reason="", readiness=false. Elapsed: 22.022998455s
    Dec 14 08:45:27.265: INFO: Pod "pod-subpath-test-secret-rmt9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.02320184s
    STEP: Saw pod success 12/14/22 08:45:27.265
    Dec 14 08:45:27.265: INFO: Pod "pod-subpath-test-secret-rmt9" satisfied condition "Succeeded or Failed"
    Dec 14 08:45:27.276: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-secret-rmt9 container test-container-subpath-secret-rmt9: <nil>
    STEP: delete the pod 12/14/22 08:45:27.304
    Dec 14 08:45:27.319: INFO: Waiting for pod pod-subpath-test-secret-rmt9 to disappear
    Dec 14 08:45:27.329: INFO: Pod pod-subpath-test-secret-rmt9 no longer exists
    STEP: Deleting pod pod-subpath-test-secret-rmt9 12/14/22 08:45:27.329
    Dec 14 08:45:27.330: INFO: Deleting pod "pod-subpath-test-secret-rmt9" in namespace "subpath-4674"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:45:27.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4674" for this suite. 12/14/22 08:45:27.362
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:27.376
Dec 14 08:45:27.377: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 08:45:27.378
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:27.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:27.432
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Dec 14 08:45:27.484: INFO: Waiting up to 5m0s for pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814" in namespace "svcaccounts-5187" to be "running"
Dec 14 08:45:27.495: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814": Phase="Pending", Reason="", readiness=false. Elapsed: 10.944363ms
Dec 14 08:45:29.508: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814": Phase="Running", Reason="", readiness=true. Elapsed: 2.023197729s
Dec 14 08:45:29.508: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814" satisfied condition "running"
STEP: reading a file in the container 12/14/22 08:45:29.508
Dec 14 08:45:29.508: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 12/14/22 08:45:30.098
Dec 14 08:45:30.098: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 12/14/22 08:45:30.706
Dec 14 08:45:30.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Dec 14 08:45:31.281: INFO: Got root ca configmap in namespace "svcaccounts-5187"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 08:45:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5187" for this suite. 12/14/22 08:45:31.313
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":15,"skipped":290,"failed":0}
------------------------------
• [3.949 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:27.376
    Dec 14 08:45:27.377: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 08:45:27.378
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:27.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:27.432
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Dec 14 08:45:27.484: INFO: Waiting up to 5m0s for pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814" in namespace "svcaccounts-5187" to be "running"
    Dec 14 08:45:27.495: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814": Phase="Pending", Reason="", readiness=false. Elapsed: 10.944363ms
    Dec 14 08:45:29.508: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814": Phase="Running", Reason="", readiness=true. Elapsed: 2.023197729s
    Dec 14 08:45:29.508: INFO: Pod "pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814" satisfied condition "running"
    STEP: reading a file in the container 12/14/22 08:45:29.508
    Dec 14 08:45:29.508: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 12/14/22 08:45:30.098
    Dec 14 08:45:30.098: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 12/14/22 08:45:30.706
    Dec 14 08:45:30.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5187 pod-service-account-23083155-3b4a-461e-9aac-e57c80d4d814 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Dec 14 08:45:31.281: INFO: Got root ca configmap in namespace "svcaccounts-5187"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 08:45:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5187" for this suite. 12/14/22 08:45:31.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:31.328
Dec 14 08:45:31.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 08:45:31.329
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:31.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:31.383
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-1f9e07f0-a58b-4267-948e-2e1a2b39c222 12/14/22 08:45:31.403
STEP: Creating a pod to test consume secrets 12/14/22 08:45:31.414
Dec 14 08:45:31.432: INFO: Waiting up to 5m0s for pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89" in namespace "secrets-9133" to be "Succeeded or Failed"
Dec 14 08:45:31.443: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Pending", Reason="", readiness=false. Elapsed: 10.597578ms
Dec 14 08:45:33.455: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023321072s
Dec 14 08:45:35.456: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023417823s
STEP: Saw pod success 12/14/22 08:45:35.456
Dec 14 08:45:35.456: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89" satisfied condition "Succeeded or Failed"
Dec 14 08:45:35.467: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 08:45:35.49
Dec 14 08:45:35.506: INFO: Waiting for pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 to disappear
Dec 14 08:45:35.518: INFO: Pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 08:45:35.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9133" for this suite. 12/14/22 08:45:35.541
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":16,"skipped":339,"failed":0}
------------------------------
• [4.226 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:31.328
    Dec 14 08:45:31.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 08:45:31.329
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:31.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:31.383
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-1f9e07f0-a58b-4267-948e-2e1a2b39c222 12/14/22 08:45:31.403
    STEP: Creating a pod to test consume secrets 12/14/22 08:45:31.414
    Dec 14 08:45:31.432: INFO: Waiting up to 5m0s for pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89" in namespace "secrets-9133" to be "Succeeded or Failed"
    Dec 14 08:45:31.443: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Pending", Reason="", readiness=false. Elapsed: 10.597578ms
    Dec 14 08:45:33.455: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023321072s
    Dec 14 08:45:35.456: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023417823s
    STEP: Saw pod success 12/14/22 08:45:35.456
    Dec 14 08:45:35.456: INFO: Pod "pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89" satisfied condition "Succeeded or Failed"
    Dec 14 08:45:35.467: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:45:35.49
    Dec 14 08:45:35.506: INFO: Waiting for pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 to disappear
    Dec 14 08:45:35.518: INFO: Pod pod-secrets-fb924118-2971-4c52-a7a7-303a6c7cca89 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 08:45:35.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9133" for this suite. 12/14/22 08:45:35.541
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:35.554
Dec 14 08:45:35.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:45:35.555
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:35.589
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:35.61
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 12/14/22 08:45:35.631
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:36.235
Dec 14 08:45:36.261: INFO: Pod name wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8: Found 0 pods out of 5
Dec 14 08:45:41.301: INFO: Pod name wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:45:41.301
Dec 14 08:45:41.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:41.314: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht": Phase="Running", Reason="", readiness=true. Elapsed: 12.204652ms
Dec 14 08:45:41.314: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht" satisfied condition "running"
Dec 14 08:45:41.314: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:41.326: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8": Phase="Running", Reason="", readiness=true. Elapsed: 11.852873ms
Dec 14 08:45:41.326: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8" satisfied condition "running"
Dec 14 08:45:41.326: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:41.337: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8": Phase="Running", Reason="", readiness=true. Elapsed: 11.836273ms
Dec 14 08:45:41.337: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8" satisfied condition "running"
Dec 14 08:45:41.337: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:41.349: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m": Phase="Running", Reason="", readiness=true. Elapsed: 11.920901ms
Dec 14 08:45:41.349: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m" satisfied condition "running"
Dec 14 08:45:41.349: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:41.361: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88": Phase="Running", Reason="", readiness=true. Elapsed: 11.958172ms
Dec 14 08:45:41.361: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:41.361
Dec 14 08:45:41.436: INFO: Deleting ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 took: 12.942698ms
Dec 14 08:45:41.537: INFO: Terminating ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 pods took: 100.467175ms
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:42.55
Dec 14 08:45:42.590: INFO: Pod name wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f: Found 0 pods out of 5
Dec 14 08:45:47.630: INFO: Pod name wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:45:47.63
Dec 14 08:45:47.630: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:47.642: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl": Phase="Running", Reason="", readiness=true. Elapsed: 11.673001ms
Dec 14 08:45:47.642: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl" satisfied condition "running"
Dec 14 08:45:47.642: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:47.654: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm": Phase="Running", Reason="", readiness=true. Elapsed: 11.937572ms
Dec 14 08:45:47.654: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm" satisfied condition "running"
Dec 14 08:45:47.654: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:47.666: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg": Phase="Running", Reason="", readiness=true. Elapsed: 11.832237ms
Dec 14 08:45:47.666: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg" satisfied condition "running"
Dec 14 08:45:47.666: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:47.678: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5": Phase="Running", Reason="", readiness=true. Elapsed: 11.604358ms
Dec 14 08:45:47.678: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5" satisfied condition "running"
Dec 14 08:45:47.678: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:47.706: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4": Phase="Running", Reason="", readiness=true. Elapsed: 28.388313ms
Dec 14 08:45:47.706: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:47.706
Dec 14 08:45:47.783: INFO: Deleting ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f took: 13.341276ms
Dec 14 08:45:47.884: INFO: Terminating ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f pods took: 100.920501ms
STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:49.396
Dec 14 08:45:49.427: INFO: Pod name wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b: Found 0 pods out of 5
Dec 14 08:45:54.468: INFO: Pod name wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b: Found 5 pods out of 5
STEP: Ensuring each pod is running 12/14/22 08:45:54.468
Dec 14 08:45:54.469: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:54.480: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh": Phase="Running", Reason="", readiness=true. Elapsed: 11.679184ms
Dec 14 08:45:54.480: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh" satisfied condition "running"
Dec 14 08:45:54.480: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:54.492: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg": Phase="Running", Reason="", readiness=true. Elapsed: 11.886424ms
Dec 14 08:45:54.492: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg" satisfied condition "running"
Dec 14 08:45:54.492: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:54.504: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9": Phase="Running", Reason="", readiness=true. Elapsed: 11.609886ms
Dec 14 08:45:54.504: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9" satisfied condition "running"
Dec 14 08:45:54.504: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:54.523: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw": Phase="Running", Reason="", readiness=true. Elapsed: 18.678161ms
Dec 14 08:45:54.523: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw" satisfied condition "running"
Dec 14 08:45:54.523: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp" in namespace "emptydir-wrapper-4600" to be "running"
Dec 14 08:45:54.534: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp": Phase="Running", Reason="", readiness=true. Elapsed: 11.721981ms
Dec 14 08:45:54.534: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:54.534
Dec 14 08:45:54.611: INFO: Deleting ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b took: 13.113535ms
Dec 14 08:45:54.712: INFO: Terminating ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b pods took: 100.581143ms
STEP: Cleaning up the configMaps 12/14/22 08:45:56.513
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec 14 08:45:57.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4600" for this suite. 12/14/22 08:45:57.162
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":17,"skipped":342,"failed":0}
------------------------------
• [21.621 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:35.554
    Dec 14 08:45:35.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 08:45:35.555
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:35.589
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:35.61
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 12/14/22 08:45:35.631
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:36.235
    Dec 14 08:45:36.261: INFO: Pod name wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8: Found 0 pods out of 5
    Dec 14 08:45:41.301: INFO: Pod name wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:45:41.301
    Dec 14 08:45:41.301: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:41.314: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht": Phase="Running", Reason="", readiness=true. Elapsed: 12.204652ms
    Dec 14 08:45:41.314: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-c4kht" satisfied condition "running"
    Dec 14 08:45:41.314: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:41.326: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8": Phase="Running", Reason="", readiness=true. Elapsed: 11.852873ms
    Dec 14 08:45:41.326: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-f5fk8" satisfied condition "running"
    Dec 14 08:45:41.326: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:41.337: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8": Phase="Running", Reason="", readiness=true. Elapsed: 11.836273ms
    Dec 14 08:45:41.337: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-jhnr8" satisfied condition "running"
    Dec 14 08:45:41.337: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:41.349: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m": Phase="Running", Reason="", readiness=true. Elapsed: 11.920901ms
    Dec 14 08:45:41.349: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-nhc9m" satisfied condition "running"
    Dec 14 08:45:41.349: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:41.361: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88": Phase="Running", Reason="", readiness=true. Elapsed: 11.958172ms
    Dec 14 08:45:41.361: INFO: Pod "wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8-rch88" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:41.361
    Dec 14 08:45:41.436: INFO: Deleting ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 took: 12.942698ms
    Dec 14 08:45:41.537: INFO: Terminating ReplicationController wrapped-volume-race-caff0dae-88ad-444f-a3e5-28379d60eab8 pods took: 100.467175ms
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:42.55
    Dec 14 08:45:42.590: INFO: Pod name wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f: Found 0 pods out of 5
    Dec 14 08:45:47.630: INFO: Pod name wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:45:47.63
    Dec 14 08:45:47.630: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:47.642: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl": Phase="Running", Reason="", readiness=true. Elapsed: 11.673001ms
    Dec 14 08:45:47.642: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-45mgl" satisfied condition "running"
    Dec 14 08:45:47.642: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:47.654: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm": Phase="Running", Reason="", readiness=true. Elapsed: 11.937572ms
    Dec 14 08:45:47.654: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-5dlsm" satisfied condition "running"
    Dec 14 08:45:47.654: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:47.666: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg": Phase="Running", Reason="", readiness=true. Elapsed: 11.832237ms
    Dec 14 08:45:47.666: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-h52lg" satisfied condition "running"
    Dec 14 08:45:47.666: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:47.678: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5": Phase="Running", Reason="", readiness=true. Elapsed: 11.604358ms
    Dec 14 08:45:47.678: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-mcqt5" satisfied condition "running"
    Dec 14 08:45:47.678: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:47.706: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4": Phase="Running", Reason="", readiness=true. Elapsed: 28.388313ms
    Dec 14 08:45:47.706: INFO: Pod "wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f-wswv4" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:47.706
    Dec 14 08:45:47.783: INFO: Deleting ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f took: 13.341276ms
    Dec 14 08:45:47.884: INFO: Terminating ReplicationController wrapped-volume-race-bd3558a6-ab99-4d85-aa09-4609f768a37f pods took: 100.920501ms
    STEP: Creating RC which spawns configmap-volume pods 12/14/22 08:45:49.396
    Dec 14 08:45:49.427: INFO: Pod name wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b: Found 0 pods out of 5
    Dec 14 08:45:54.468: INFO: Pod name wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b: Found 5 pods out of 5
    STEP: Ensuring each pod is running 12/14/22 08:45:54.468
    Dec 14 08:45:54.469: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:54.480: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh": Phase="Running", Reason="", readiness=true. Elapsed: 11.679184ms
    Dec 14 08:45:54.480: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-5whgh" satisfied condition "running"
    Dec 14 08:45:54.480: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:54.492: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg": Phase="Running", Reason="", readiness=true. Elapsed: 11.886424ms
    Dec 14 08:45:54.492: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-ggszg" satisfied condition "running"
    Dec 14 08:45:54.492: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:54.504: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9": Phase="Running", Reason="", readiness=true. Elapsed: 11.609886ms
    Dec 14 08:45:54.504: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-gvvx9" satisfied condition "running"
    Dec 14 08:45:54.504: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:54.523: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw": Phase="Running", Reason="", readiness=true. Elapsed: 18.678161ms
    Dec 14 08:45:54.523: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-n7rpw" satisfied condition "running"
    Dec 14 08:45:54.523: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp" in namespace "emptydir-wrapper-4600" to be "running"
    Dec 14 08:45:54.534: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp": Phase="Running", Reason="", readiness=true. Elapsed: 11.721981ms
    Dec 14 08:45:54.534: INFO: Pod "wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b-pqphp" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b in namespace emptydir-wrapper-4600, will wait for the garbage collector to delete the pods 12/14/22 08:45:54.534
    Dec 14 08:45:54.611: INFO: Deleting ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b took: 13.113535ms
    Dec 14 08:45:54.712: INFO: Terminating ReplicationController wrapped-volume-race-2599549b-66da-4138-accc-a89fd2868e9b pods took: 100.581143ms
    STEP: Cleaning up the configMaps 12/14/22 08:45:56.513
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:45:57.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4600" for this suite. 12/14/22 08:45:57.162
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:45:57.175
Dec 14 08:45:57.175: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:45:57.176
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:57.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:57.231
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:45:57.259
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-9mzs 12/14/22 08:45:57.283
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:45:57.283
Dec 14 08:45:57.302: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9mzs" in namespace "subpath-9072" to be "Succeeded or Failed"
Dec 14 08:45:57.313: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Pending", Reason="", readiness=false. Elapsed: 11.073787ms
Dec 14 08:45:59.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 2.023256183s
Dec 14 08:46:01.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 4.023340977s
Dec 14 08:46:03.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 6.023448511s
Dec 14 08:46:05.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 8.02390435s
Dec 14 08:46:07.327: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 10.024771239s
Dec 14 08:46:09.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 12.02302619s
Dec 14 08:46:11.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 14.023156803s
Dec 14 08:46:13.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 16.024384744s
Dec 14 08:46:15.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 18.023731228s
Dec 14 08:46:17.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 20.023768974s
Dec 14 08:46:19.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=false. Elapsed: 22.023270312s
Dec 14 08:46:21.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023397543s
STEP: Saw pod success 12/14/22 08:46:21.325
Dec 14 08:46:21.325: INFO: Pod "pod-subpath-test-configmap-9mzs" satisfied condition "Succeeded or Failed"
Dec 14 08:46:21.337: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-configmap-9mzs container test-container-subpath-configmap-9mzs: <nil>
STEP: delete the pod 12/14/22 08:46:21.36
Dec 14 08:46:21.377: INFO: Waiting for pod pod-subpath-test-configmap-9mzs to disappear
Dec 14 08:46:21.388: INFO: Pod pod-subpath-test-configmap-9mzs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9mzs 12/14/22 08:46:21.388
Dec 14 08:46:21.388: INFO: Deleting pod "pod-subpath-test-configmap-9mzs" in namespace "subpath-9072"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:46:21.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9072" for this suite. 12/14/22 08:46:21.42
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":18,"skipped":344,"failed":0}
------------------------------
• [24.258 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:45:57.175
    Dec 14 08:45:57.175: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:45:57.176
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:45:57.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:45:57.231
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:45:57.259
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-9mzs 12/14/22 08:45:57.283
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:45:57.283
    Dec 14 08:45:57.302: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9mzs" in namespace "subpath-9072" to be "Succeeded or Failed"
    Dec 14 08:45:57.313: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Pending", Reason="", readiness=false. Elapsed: 11.073787ms
    Dec 14 08:45:59.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 2.023256183s
    Dec 14 08:46:01.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 4.023340977s
    Dec 14 08:46:03.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 6.023448511s
    Dec 14 08:46:05.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 8.02390435s
    Dec 14 08:46:07.327: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 10.024771239s
    Dec 14 08:46:09.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 12.02302619s
    Dec 14 08:46:11.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 14.023156803s
    Dec 14 08:46:13.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 16.024384744s
    Dec 14 08:46:15.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 18.023731228s
    Dec 14 08:46:17.326: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=true. Elapsed: 20.023768974s
    Dec 14 08:46:19.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Running", Reason="", readiness=false. Elapsed: 22.023270312s
    Dec 14 08:46:21.325: INFO: Pod "pod-subpath-test-configmap-9mzs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023397543s
    STEP: Saw pod success 12/14/22 08:46:21.325
    Dec 14 08:46:21.325: INFO: Pod "pod-subpath-test-configmap-9mzs" satisfied condition "Succeeded or Failed"
    Dec 14 08:46:21.337: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-configmap-9mzs container test-container-subpath-configmap-9mzs: <nil>
    STEP: delete the pod 12/14/22 08:46:21.36
    Dec 14 08:46:21.377: INFO: Waiting for pod pod-subpath-test-configmap-9mzs to disappear
    Dec 14 08:46:21.388: INFO: Pod pod-subpath-test-configmap-9mzs no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-9mzs 12/14/22 08:46:21.388
    Dec 14 08:46:21.388: INFO: Deleting pod "pod-subpath-test-configmap-9mzs" in namespace "subpath-9072"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:46:21.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9072" for this suite. 12/14/22 08:46:21.42
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:21.433
Dec 14 08:46:21.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 08:46:21.434
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:21.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:21.489
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-9363 12/14/22 08:46:21.51
STEP: creating replication controller nodeport-test in namespace services-9363 12/14/22 08:46:21.528
I1214 08:46:21.542508    6248 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9363, replica count: 2
I1214 08:46:24.595540    6248 runners.go:193] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 08:46:27.595764    6248 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 08:46:27.595: INFO: Creating new exec pod
Dec 14 08:46:27.612: INFO: Waiting up to 5m0s for pod "execpodzz7rt" in namespace "services-9363" to be "running"
Dec 14 08:46:27.623: INFO: Pod "execpodzz7rt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.690448ms
Dec 14 08:46:29.635: INFO: Pod "execpodzz7rt": Phase="Running", Reason="", readiness=true. Elapsed: 2.023429771s
Dec 14 08:46:29.635: INFO: Pod "execpodzz7rt" satisfied condition "running"
Dec 14 08:46:30.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 08:46:31.265: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 08:46:31.265: INFO: stdout: ""
Dec 14 08:46:32.266: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 08:46:32.793: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 08:46:32.793: INFO: stdout: ""
Dec 14 08:46:33.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 08:46:33.818: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 08:46:33.818: INFO: stdout: ""
Dec 14 08:46:34.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Dec 14 08:46:34.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 14 08:46:34.822: INFO: stdout: "nodeport-test-vfbbj"
Dec 14 08:46:34.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.27.11.114 80'
Dec 14 08:46:35.374: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.27.11.114 80\nConnection to 172.27.11.114 80 port [tcp/http] succeeded!\n"
Dec 14 08:46:35.374: INFO: stdout: "nodeport-test-zvlqn"
Dec 14 08:46:35.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 31623'
Dec 14 08:46:35.853: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 31623\nConnection to 10.250.18.71 31623 port [tcp/*] succeeded!\n"
Dec 14 08:46:35.853: INFO: stdout: "nodeport-test-vfbbj"
Dec 14 08:46:35.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31623'
Dec 14 08:46:36.461: INFO: stderr: "+ nc -v -t -w 2 10.250.18.72 31623\n+ echo hostName\nConnection to 10.250.18.72 31623 port [tcp/*] succeeded!\n"
Dec 14 08:46:36.461: INFO: stdout: ""
Dec 14 08:46:37.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31623'
Dec 14 08:46:38.062: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 31623\nConnection to 10.250.18.72 31623 port [tcp/*] succeeded!\n"
Dec 14 08:46:38.062: INFO: stdout: "nodeport-test-zvlqn"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 08:46:38.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9363" for this suite. 12/14/22 08:46:38.082
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":19,"skipped":344,"failed":0}
------------------------------
• [16.661 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:21.433
    Dec 14 08:46:21.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 08:46:21.434
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:21.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:21.489
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-9363 12/14/22 08:46:21.51
    STEP: creating replication controller nodeport-test in namespace services-9363 12/14/22 08:46:21.528
    I1214 08:46:21.542508    6248 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-9363, replica count: 2
    I1214 08:46:24.595540    6248 runners.go:193] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 08:46:27.595764    6248 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 08:46:27.595: INFO: Creating new exec pod
    Dec 14 08:46:27.612: INFO: Waiting up to 5m0s for pod "execpodzz7rt" in namespace "services-9363" to be "running"
    Dec 14 08:46:27.623: INFO: Pod "execpodzz7rt": Phase="Pending", Reason="", readiness=false. Elapsed: 10.690448ms
    Dec 14 08:46:29.635: INFO: Pod "execpodzz7rt": Phase="Running", Reason="", readiness=true. Elapsed: 2.023429771s
    Dec 14 08:46:29.635: INFO: Pod "execpodzz7rt" satisfied condition "running"
    Dec 14 08:46:30.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 08:46:31.265: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 08:46:31.265: INFO: stdout: ""
    Dec 14 08:46:32.266: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 08:46:32.793: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 08:46:32.793: INFO: stdout: ""
    Dec 14 08:46:33.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 08:46:33.818: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 08:46:33.818: INFO: stdout: ""
    Dec 14 08:46:34.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Dec 14 08:46:34.822: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Dec 14 08:46:34.822: INFO: stdout: "nodeport-test-vfbbj"
    Dec 14 08:46:34.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.27.11.114 80'
    Dec 14 08:46:35.374: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.27.11.114 80\nConnection to 172.27.11.114 80 port [tcp/http] succeeded!\n"
    Dec 14 08:46:35.374: INFO: stdout: "nodeport-test-zvlqn"
    Dec 14 08:46:35.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 31623'
    Dec 14 08:46:35.853: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 31623\nConnection to 10.250.18.71 31623 port [tcp/*] succeeded!\n"
    Dec 14 08:46:35.853: INFO: stdout: "nodeport-test-vfbbj"
    Dec 14 08:46:35.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31623'
    Dec 14 08:46:36.461: INFO: stderr: "+ nc -v -t -w 2 10.250.18.72 31623\n+ echo hostName\nConnection to 10.250.18.72 31623 port [tcp/*] succeeded!\n"
    Dec 14 08:46:36.461: INFO: stdout: ""
    Dec 14 08:46:37.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9363 exec execpodzz7rt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31623'
    Dec 14 08:46:38.062: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 31623\nConnection to 10.250.18.72 31623 port [tcp/*] succeeded!\n"
    Dec 14 08:46:38.062: INFO: stdout: "nodeport-test-zvlqn"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 08:46:38.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9363" for this suite. 12/14/22 08:46:38.082
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:38.095
Dec 14 08:46:38.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ingress 12/14/22 08:46:38.096
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:38.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:38.151
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 12/14/22 08:46:38.172
STEP: getting /apis/networking.k8s.io 12/14/22 08:46:38.192
STEP: getting /apis/networking.k8s.iov1 12/14/22 08:46:38.202
STEP: creating 12/14/22 08:46:38.212
STEP: getting 12/14/22 08:46:38.249
STEP: listing 12/14/22 08:46:38.26
STEP: watching 12/14/22 08:46:38.272
Dec 14 08:46:38.272: INFO: starting watch
STEP: cluster-wide listing 12/14/22 08:46:38.282
STEP: cluster-wide watching 12/14/22 08:46:38.294
Dec 14 08:46:38.294: INFO: starting watch
STEP: patching 12/14/22 08:46:38.304
STEP: updating 12/14/22 08:46:38.316
Dec 14 08:46:38.339: INFO: waiting for watch events with expected annotations
Dec 14 08:46:38.339: INFO: saw patched and updated annotations
STEP: patching /status 12/14/22 08:46:38.34
STEP: updating /status 12/14/22 08:46:38.352
STEP: get /status 12/14/22 08:46:38.375
STEP: deleting 12/14/22 08:46:38.387
STEP: deleting a collection 12/14/22 08:46:38.421
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Dec 14 08:46:38.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-4288" for this suite. 12/14/22 08:46:38.461
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":20,"skipped":351,"failed":0}
------------------------------
• [0.379 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:38.095
    Dec 14 08:46:38.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ingress 12/14/22 08:46:38.096
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:38.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:38.151
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 12/14/22 08:46:38.172
    STEP: getting /apis/networking.k8s.io 12/14/22 08:46:38.192
    STEP: getting /apis/networking.k8s.iov1 12/14/22 08:46:38.202
    STEP: creating 12/14/22 08:46:38.212
    STEP: getting 12/14/22 08:46:38.249
    STEP: listing 12/14/22 08:46:38.26
    STEP: watching 12/14/22 08:46:38.272
    Dec 14 08:46:38.272: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 08:46:38.282
    STEP: cluster-wide watching 12/14/22 08:46:38.294
    Dec 14 08:46:38.294: INFO: starting watch
    STEP: patching 12/14/22 08:46:38.304
    STEP: updating 12/14/22 08:46:38.316
    Dec 14 08:46:38.339: INFO: waiting for watch events with expected annotations
    Dec 14 08:46:38.339: INFO: saw patched and updated annotations
    STEP: patching /status 12/14/22 08:46:38.34
    STEP: updating /status 12/14/22 08:46:38.352
    STEP: get /status 12/14/22 08:46:38.375
    STEP: deleting 12/14/22 08:46:38.387
    STEP: deleting a collection 12/14/22 08:46:38.421
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Dec 14 08:46:38.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-4288" for this suite. 12/14/22 08:46:38.461
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:38.476
Dec 14 08:46:38.476: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename certificates 12/14/22 08:46:38.477
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:38.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:38.54
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 12/14/22 08:46:39.056
STEP: getting /apis/certificates.k8s.io 12/14/22 08:46:39.08
STEP: getting /apis/certificates.k8s.io/v1 12/14/22 08:46:39.09
STEP: creating 12/14/22 08:46:39.1
STEP: getting 12/14/22 08:46:39.136
STEP: listing 12/14/22 08:46:39.147
STEP: watching 12/14/22 08:46:39.161
Dec 14 08:46:39.161: INFO: starting watch
STEP: patching 12/14/22 08:46:39.171
STEP: updating 12/14/22 08:46:39.185
Dec 14 08:46:39.197: INFO: waiting for watch events with expected annotations
Dec 14 08:46:39.197: INFO: saw patched and updated annotations
STEP: getting /approval 12/14/22 08:46:39.197
STEP: patching /approval 12/14/22 08:46:39.209
STEP: updating /approval 12/14/22 08:46:39.223
STEP: getting /status 12/14/22 08:46:39.236
STEP: patching /status 12/14/22 08:46:39.248
STEP: updating /status 12/14/22 08:46:39.261
STEP: deleting 12/14/22 08:46:39.274
STEP: deleting a collection 12/14/22 08:46:39.31
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:46:39.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-1338" for this suite. 12/14/22 08:46:39.369
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":21,"skipped":387,"failed":0}
------------------------------
• [0.908 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:38.476
    Dec 14 08:46:38.476: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename certificates 12/14/22 08:46:38.477
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:38.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:38.54
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 12/14/22 08:46:39.056
    STEP: getting /apis/certificates.k8s.io 12/14/22 08:46:39.08
    STEP: getting /apis/certificates.k8s.io/v1 12/14/22 08:46:39.09
    STEP: creating 12/14/22 08:46:39.1
    STEP: getting 12/14/22 08:46:39.136
    STEP: listing 12/14/22 08:46:39.147
    STEP: watching 12/14/22 08:46:39.161
    Dec 14 08:46:39.161: INFO: starting watch
    STEP: patching 12/14/22 08:46:39.171
    STEP: updating 12/14/22 08:46:39.185
    Dec 14 08:46:39.197: INFO: waiting for watch events with expected annotations
    Dec 14 08:46:39.197: INFO: saw patched and updated annotations
    STEP: getting /approval 12/14/22 08:46:39.197
    STEP: patching /approval 12/14/22 08:46:39.209
    STEP: updating /approval 12/14/22 08:46:39.223
    STEP: getting /status 12/14/22 08:46:39.236
    STEP: patching /status 12/14/22 08:46:39.248
    STEP: updating /status 12/14/22 08:46:39.261
    STEP: deleting 12/14/22 08:46:39.274
    STEP: deleting a collection 12/14/22 08:46:39.31
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:46:39.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-1338" for this suite. 12/14/22 08:46:39.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:39.384
Dec 14 08:46:39.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 08:46:39.385
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:39.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:39.441
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 08:46:39.488
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:46:40.368
STEP: Deploying the webhook pod 12/14/22 08:46:40.381
STEP: Wait for the deployment to be ready 12/14/22 08:46:40.407
Dec 14 08:46:40.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 08:46:42.462
STEP: Verifying the service has paired with the endpoint 12/14/22 08:46:42.479
Dec 14 08:46:43.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/14/22 08:46:43.491
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:43.491
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/14/22 08:46:43.647
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/14/22 08:46:44.671
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:44.671
STEP: Having no error when timeout is longer than webhook latency 12/14/22 08:46:45.752
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:45.752
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/14/22 08:46:50.933
STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:50.933
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:46:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-146" for this suite. 12/14/22 08:46:56.061
STEP: Destroying namespace "webhook-146-markers" for this suite. 12/14/22 08:46:56.074
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":22,"skipped":394,"failed":0}
------------------------------
• [16.757 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:39.384
    Dec 14 08:46:39.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 08:46:39.385
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:39.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:39.441
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 08:46:39.488
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 08:46:40.368
    STEP: Deploying the webhook pod 12/14/22 08:46:40.381
    STEP: Wait for the deployment to be ready 12/14/22 08:46:40.407
    Dec 14 08:46:40.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 8, 46, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 08:46:42.462
    STEP: Verifying the service has paired with the endpoint 12/14/22 08:46:42.479
    Dec 14 08:46:43.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 12/14/22 08:46:43.491
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:43.491
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 12/14/22 08:46:43.647
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 12/14/22 08:46:44.671
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:44.671
    STEP: Having no error when timeout is longer than webhook latency 12/14/22 08:46:45.752
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:45.752
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 12/14/22 08:46:50.933
    STEP: Registering slow webhook via the AdmissionRegistration API 12/14/22 08:46:50.933
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:46:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-146" for this suite. 12/14/22 08:46:56.061
    STEP: Destroying namespace "webhook-146-markers" for this suite. 12/14/22 08:46:56.074
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:46:56.142
Dec 14 08:46:56.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 08:46:56.143
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:56.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:56.197
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Dec 14 08:46:56.236: INFO: Waiting up to 5m0s for pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d" in namespace "security-context-test-5651" to be "Succeeded or Failed"
Dec 14 08:46:56.247: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.73997ms
Dec 14 08:46:58.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022603942s
Dec 14 08:47:00.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022791628s
Dec 14 08:47:00.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:47:00.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5651" for this suite. 12/14/22 08:47:00.28
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":23,"skipped":399,"failed":0}
------------------------------
• [4.151 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:46:56.142
    Dec 14 08:46:56.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 08:46:56.143
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:46:56.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:46:56.197
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Dec 14 08:46:56.236: INFO: Waiting up to 5m0s for pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d" in namespace "security-context-test-5651" to be "Succeeded or Failed"
    Dec 14 08:46:56.247: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.73997ms
    Dec 14 08:46:58.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022603942s
    Dec 14 08:47:00.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022791628s
    Dec 14 08:47:00.259: INFO: Pod "busybox-user-65534-742af0c7-c4e9-4443-9b57-d850a6a8988d" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:47:00.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-5651" for this suite. 12/14/22 08:47:00.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:47:00.295
Dec 14 08:47:00.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 08:47:00.296
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:00.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:00.35
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 in namespace container-probe-6657 12/14/22 08:47:00.37
Dec 14 08:47:00.389: INFO: Waiting up to 5m0s for pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477" in namespace "container-probe-6657" to be "not pending"
Dec 14 08:47:00.401: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477": Phase="Pending", Reason="", readiness=false. Elapsed: 11.14248ms
Dec 14 08:47:02.412: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477": Phase="Running", Reason="", readiness=true. Elapsed: 2.023064702s
Dec 14 08:47:02.412: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477" satisfied condition "not pending"
Dec 14 08:47:02.413: INFO: Started pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 in namespace container-probe-6657
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:47:02.413
Dec 14 08:47:02.424: INFO: Initial restart count of pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is 0
Dec 14 08:47:22.646: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 1 (20.221442865s elapsed)
Dec 14 08:47:42.771: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 2 (40.346656496s elapsed)
Dec 14 08:48:02.896: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 3 (1m0.47226807s elapsed)
Dec 14 08:48:23.028: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 4 (1m20.603724888s elapsed)
Dec 14 08:49:31.454: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 5 (2m29.029530345s elapsed)
STEP: deleting the pod 12/14/22 08:49:31.454
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 08:49:31.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6657" for this suite. 12/14/22 08:49:31.49
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":24,"skipped":436,"failed":0}
------------------------------
• [151.208 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:47:00.295
    Dec 14 08:47:00.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 08:47:00.296
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:47:00.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:47:00.35
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 in namespace container-probe-6657 12/14/22 08:47:00.37
    Dec 14 08:47:00.389: INFO: Waiting up to 5m0s for pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477" in namespace "container-probe-6657" to be "not pending"
    Dec 14 08:47:00.401: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477": Phase="Pending", Reason="", readiness=false. Elapsed: 11.14248ms
    Dec 14 08:47:02.412: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477": Phase="Running", Reason="", readiness=true. Elapsed: 2.023064702s
    Dec 14 08:47:02.412: INFO: Pod "liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477" satisfied condition "not pending"
    Dec 14 08:47:02.413: INFO: Started pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 in namespace container-probe-6657
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 08:47:02.413
    Dec 14 08:47:02.424: INFO: Initial restart count of pod liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is 0
    Dec 14 08:47:22.646: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 1 (20.221442865s elapsed)
    Dec 14 08:47:42.771: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 2 (40.346656496s elapsed)
    Dec 14 08:48:02.896: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 3 (1m0.47226807s elapsed)
    Dec 14 08:48:23.028: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 4 (1m20.603724888s elapsed)
    Dec 14 08:49:31.454: INFO: Restart count of pod container-probe-6657/liveness-92fe1c7e-9094-4bd1-a6b6-479883ced477 is now 5 (2m29.029530345s elapsed)
    STEP: deleting the pod 12/14/22 08:49:31.454
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 08:49:31.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6657" for this suite. 12/14/22 08:49:31.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:31.503
Dec 14 08:49:31.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 08:49:31.504
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:31.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:31.561
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Dec 14 08:49:31.609: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068" in namespace "security-context-test-3232" to be "Succeeded or Failed"
Dec 14 08:49:31.620: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Pending", Reason="", readiness=false. Elapsed: 10.598659ms
Dec 14 08:49:33.633: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023486469s
Dec 14 08:49:35.632: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022839867s
Dec 14 08:49:35.632: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 08:49:35.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3232" for this suite. 12/14/22 08:49:35.654
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":25,"skipped":443,"failed":0}
------------------------------
• [4.163 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:31.503
    Dec 14 08:49:31.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 08:49:31.504
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:31.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:31.561
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Dec 14 08:49:31.609: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068" in namespace "security-context-test-3232" to be "Succeeded or Failed"
    Dec 14 08:49:31.620: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Pending", Reason="", readiness=false. Elapsed: 10.598659ms
    Dec 14 08:49:33.633: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023486469s
    Dec 14 08:49:35.632: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022839867s
    Dec 14 08:49:35.632: INFO: Pod "busybox-readonly-false-f942e7b6-a896-4189-810a-752729503068" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 08:49:35.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-3232" for this suite. 12/14/22 08:49:35.654
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:35.667
Dec 14 08:49:35.667: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 08:49:35.668
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:35.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:35.723
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-6de0d5ce-39b0-4e36-ac4d-08ed1ff9b348 12/14/22 08:49:35.743
STEP: Creating a pod to test consume configMaps 12/14/22 08:49:35.756
Dec 14 08:49:35.776: INFO: Waiting up to 5m0s for pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e" in namespace "configmap-5746" to be "Succeeded or Failed"
Dec 14 08:49:35.787: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.809507ms
Dec 14 08:49:37.799: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022761686s
Dec 14 08:49:39.800: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024597517s
STEP: Saw pod success 12/14/22 08:49:39.801
Dec 14 08:49:39.801: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e" satisfied condition "Succeeded or Failed"
Dec 14 08:49:39.812: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:49:39.875
Dec 14 08:49:39.891: INFO: Waiting for pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e to disappear
Dec 14 08:49:39.902: INFO: Pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 08:49:39.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5746" for this suite. 12/14/22 08:49:39.923
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":26,"skipped":447,"failed":0}
------------------------------
• [4.269 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:35.667
    Dec 14 08:49:35.667: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 08:49:35.668
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:35.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:35.723
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-6de0d5ce-39b0-4e36-ac4d-08ed1ff9b348 12/14/22 08:49:35.743
    STEP: Creating a pod to test consume configMaps 12/14/22 08:49:35.756
    Dec 14 08:49:35.776: INFO: Waiting up to 5m0s for pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e" in namespace "configmap-5746" to be "Succeeded or Failed"
    Dec 14 08:49:35.787: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.809507ms
    Dec 14 08:49:37.799: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022761686s
    Dec 14 08:49:39.800: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024597517s
    STEP: Saw pod success 12/14/22 08:49:39.801
    Dec 14 08:49:39.801: INFO: Pod "pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e" satisfied condition "Succeeded or Failed"
    Dec 14 08:49:39.812: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:49:39.875
    Dec 14 08:49:39.891: INFO: Waiting for pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e to disappear
    Dec 14 08:49:39.902: INFO: Pod pod-configmaps-d974ae73-904c-4c7e-bcaf-9e40f084053e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 08:49:39.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5746" for this suite. 12/14/22 08:49:39.923
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:39.936
Dec 14 08:49:39.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 08:49:39.937
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:39.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:39.992
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273 12/14/22 08:49:40.013
Dec 14 08:49:40.036: INFO: Pod name my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273: Found 1 pods out of 1
Dec 14 08:49:40.036: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273" are running
Dec 14 08:49:40.036: INFO: Waiting up to 5m0s for pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" in namespace "replication-controller-2827" to be "running"
Dec 14 08:49:40.047: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96": Phase="Pending", Reason="", readiness=false. Elapsed: 10.795758ms
Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96": Phase="Running", Reason="", readiness=true. Elapsed: 2.023508879s
Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" satisfied condition "running"
Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" is running (conditions: [])
Dec 14 08:49:42.060: INFO: Trying to dial the pod
Dec 14 08:49:47.199: INFO: Controller my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273: Got expected result from replica 1 [my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96]: "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 08:49:47.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2827" for this suite. 12/14/22 08:49:47.22
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":27,"skipped":463,"failed":0}
------------------------------
• [7.297 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:39.936
    Dec 14 08:49:39.937: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 08:49:39.937
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:39.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:39.992
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273 12/14/22 08:49:40.013
    Dec 14 08:49:40.036: INFO: Pod name my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273: Found 1 pods out of 1
    Dec 14 08:49:40.036: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273" are running
    Dec 14 08:49:40.036: INFO: Waiting up to 5m0s for pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" in namespace "replication-controller-2827" to be "running"
    Dec 14 08:49:40.047: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96": Phase="Pending", Reason="", readiness=false. Elapsed: 10.795758ms
    Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96": Phase="Running", Reason="", readiness=true. Elapsed: 2.023508879s
    Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" satisfied condition "running"
    Dec 14 08:49:42.060: INFO: Pod "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96" is running (conditions: [])
    Dec 14 08:49:42.060: INFO: Trying to dial the pod
    Dec 14 08:49:47.199: INFO: Controller my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273: Got expected result from replica 1 [my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96]: "my-hostname-basic-03c7f78f-4752-420a-8faf-a1367ecb1273-hjl96", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 08:49:47.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2827" for this suite. 12/14/22 08:49:47.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:47.234
Dec 14 08:49:47.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 08:49:47.235
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:47.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:47.29
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Dec 14 08:49:47.310: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8891 version'
Dec 14 08:49:47.394: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Dec 14 08:49:47.394: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 08:49:47.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8891" for this suite. 12/14/22 08:49:47.406
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":28,"skipped":482,"failed":0}
------------------------------
• [0.185 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:47.234
    Dec 14 08:49:47.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 08:49:47.235
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:47.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:47.29
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Dec 14 08:49:47.310: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8891 version'
    Dec 14 08:49:47.394: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Dec 14 08:49:47.394: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:29:58Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 08:49:47.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8891" for this suite. 12/14/22 08:49:47.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:49:47.42
Dec 14 08:49:47.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:49:47.421
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:47.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:47.477
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 12/14/22 08:49:47.51
STEP: waiting for Deployment to be created 12/14/22 08:49:47.523
STEP: waiting for all Replicas to be Ready 12/14/22 08:49:47.539
Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.554: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.554: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.586: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:47.586: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Dec 14 08:49:48.765: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 14 08:49:48.765: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Dec 14 08:49:48.964: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 12/14/22 08:49:48.964
W1214 08:49:48.980632    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 08:49:48.990: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 12/14/22 08:49:48.99
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.008: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.008: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.011: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.011: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:49:49.971: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.971: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:49:49.983: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
STEP: listing Deployments 12/14/22 08:49:49.983
Dec 14 08:49:49.995: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 12/14/22 08:49:49.995
Dec 14 08:49:50.022: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 12/14/22 08:49:50.022
Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:50.052: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:50.781: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:55.993: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:56.020: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:49:56.026: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Dec 14 08:50:02.809: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 12/14/22 08:50:02.825
STEP: fetching the DeploymentStatus 12/14/22 08:50:02.85
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3
STEP: deleting the Deployment 12/14/22 08:50:02.872
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.898: INFO: observed event type MODIFIED
Dec 14 08:50:02.899: INFO: observed event type MODIFIED
Dec 14 08:50:02.899: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:50:02.909: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:50:02.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8586" for this suite. 12/14/22 08:50:02.932
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":29,"skipped":495,"failed":0}
------------------------------
• [15.525 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:49:47.42
    Dec 14 08:49:47.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:49:47.421
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:49:47.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:49:47.477
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 12/14/22 08:49:47.51
    STEP: waiting for Deployment to be created 12/14/22 08:49:47.523
    STEP: waiting for all Replicas to be Ready 12/14/22 08:49:47.539
    Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.549: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.554: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.554: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.586: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:47.586: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Dec 14 08:49:48.765: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec 14 08:49:48.765: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Dec 14 08:49:48.964: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 12/14/22 08:49:48.964
    W1214 08:49:48.980632    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 08:49:48.990: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 12/14/22 08:49:48.99
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 0
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.001: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.008: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.008: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.011: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.011: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:49:49.971: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.971: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:49:49.983: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    STEP: listing Deployments 12/14/22 08:49:49.983
    Dec 14 08:49:49.995: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 12/14/22 08:49:49.995
    Dec 14 08:49:50.022: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 12/14/22 08:49:50.022
    Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:50.046: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:50.052: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:50.781: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:55.993: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:56.020: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:49:56.026: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Dec 14 08:50:02.809: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 12/14/22 08:50:02.825
    STEP: fetching the DeploymentStatus 12/14/22 08:50:02.85
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 1
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 2
    Dec 14 08:50:02.872: INFO: observed Deployment test-deployment in namespace deployment-8586 with ReadyReplicas 3
    STEP: deleting the Deployment 12/14/22 08:50:02.872
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.898: INFO: observed event type MODIFIED
    Dec 14 08:50:02.899: INFO: observed event type MODIFIED
    Dec 14 08:50:02.899: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:50:02.909: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:50:02.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8586" for this suite. 12/14/22 08:50:02.932
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:02.946
Dec 14 08:50:02.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 08:50:02.947
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:02.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.002
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 12/14/22 08:50:03.023
STEP: get a list of Events with a label in the current namespace 12/14/22 08:50:03.06
STEP: delete a list of events 12/14/22 08:50:03.072
Dec 14 08:50:03.072: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/14/22 08:50:03.092
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec 14 08:50:03.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2195" for this suite. 12/14/22 08:50:03.117
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":30,"skipped":502,"failed":0}
------------------------------
• [0.184 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:02.946
    Dec 14 08:50:02.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 08:50:02.947
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:02.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.002
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 12/14/22 08:50:03.023
    STEP: get a list of Events with a label in the current namespace 12/14/22 08:50:03.06
    STEP: delete a list of events 12/14/22 08:50:03.072
    Dec 14 08:50:03.072: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/14/22 08:50:03.092
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec 14 08:50:03.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-2195" for this suite. 12/14/22 08:50:03.117
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:03.131
Dec 14 08:50:03.131: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 08:50:03.132
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.188
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-f91bed61-67d6-4b9c-b00a-f86bd74d8b9b 12/14/22 08:50:03.208
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 08:50:03.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-512" for this suite. 12/14/22 08:50:03.231
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":31,"skipped":509,"failed":0}
------------------------------
• [0.113 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:03.131
    Dec 14 08:50:03.131: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 08:50:03.132
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.188
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-f91bed61-67d6-4b9c-b00a-f86bd74d8b9b 12/14/22 08:50:03.208
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 08:50:03.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-512" for this suite. 12/14/22 08:50:03.231
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:03.246
Dec 14 08:50:03.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:50:03.247
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.302
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 12/14/22 08:50:03.323
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/14/22 08:50:03.333
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 08:50:03.333
STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/14/22 08:50:03.333
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/14/22 08:50:03.343
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:50:03.344
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:50:03.353
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:50:03.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6512" for this suite. 12/14/22 08:50:03.366
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":32,"skipped":560,"failed":0}
------------------------------
• [0.132 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:03.246
    Dec 14 08:50:03.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:50:03.247
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.302
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 12/14/22 08:50:03.323
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 12/14/22 08:50:03.333
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 08:50:03.333
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 12/14/22 08:50:03.333
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 12/14/22 08:50:03.343
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:50:03.344
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 12/14/22 08:50:03.353
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:50:03.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6512" for this suite. 12/14/22 08:50:03.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:03.379
Dec 14 08:50:03.379: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:50:03.38
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.415
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.437
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 12/14/22 08:50:03.458
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:03.47
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:03.47
STEP: creating a pod to probe DNS 12/14/22 08:50:03.47
STEP: submitting the pod to kubernetes 12/14/22 08:50:03.47
Dec 14 08:50:03.490: INFO: Waiting up to 15m0s for pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252" in namespace "dns-3011" to be "running"
Dec 14 08:50:03.501: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252": Phase="Pending", Reason="", readiness=false. Elapsed: 10.977503ms
Dec 14 08:50:05.515: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252": Phase="Running", Reason="", readiness=true. Elapsed: 2.02433822s
Dec 14 08:50:05.515: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:50:05.515
STEP: looking for the results for each expected name from probers 12/14/22 08:50:05.535
Dec 14 08:50:05.718: INFO: DNS probes using dns-test-49bee1c1-0881-4673-8261-6bdbf5337252 succeeded

STEP: deleting the pod 12/14/22 08:50:05.718
STEP: changing the externalName to bar.example.com 12/14/22 08:50:05.733
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:05.756
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:05.756
STEP: creating a second pod to probe DNS 12/14/22 08:50:05.757
STEP: submitting the pod to kubernetes 12/14/22 08:50:05.757
Dec 14 08:50:05.774: INFO: Waiting up to 15m0s for pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d" in namespace "dns-3011" to be "running"
Dec 14 08:50:05.785: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.142587ms
Dec 14 08:50:07.800: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d": Phase="Running", Reason="", readiness=true. Elapsed: 2.02605106s
Dec 14 08:50:07.800: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:50:07.8
STEP: looking for the results for each expected name from probers 12/14/22 08:50:07.812
Dec 14 08:50:07.931: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:07.981: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:07.981: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:13.005: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:13.064: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:13.064: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:17.999: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:18.048: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:18.048: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:23.002: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:23.049: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:23.049: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:27.999: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:28.052: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:28.052: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:33.002: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:33.048: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 14 08:50:33.049: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

Dec 14 08:50:38.048: INFO: DNS probes using dns-test-89cb8894-170e-468c-9e33-628824139a0d succeeded

STEP: deleting the pod 12/14/22 08:50:38.048
STEP: changing the service to type=ClusterIP 12/14/22 08:50:38.065
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:38.092
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
 12/14/22 08:50:38.092
STEP: creating a third pod to probe DNS 12/14/22 08:50:38.092
STEP: submitting the pod to kubernetes 12/14/22 08:50:38.104
Dec 14 08:50:38.123: INFO: Waiting up to 15m0s for pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563" in namespace "dns-3011" to be "running"
Dec 14 08:50:38.134: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563": Phase="Pending", Reason="", readiness=false. Elapsed: 10.979351ms
Dec 14 08:50:40.147: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563": Phase="Running", Reason="", readiness=true. Elapsed: 2.023627973s
Dec 14 08:50:40.147: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:50:40.147
STEP: looking for the results for each expected name from probers 12/14/22 08:50:40.158
Dec 14 08:50:40.324: INFO: DNS probes using dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563 succeeded

STEP: deleting the pod 12/14/22 08:50:40.324
STEP: deleting the test externalName service 12/14/22 08:50:40.34
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:50:40.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3011" for this suite. 12/14/22 08:50:40.377
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":33,"skipped":565,"failed":0}
------------------------------
• [37.011 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:03.379
    Dec 14 08:50:03.379: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:50:03.38
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:03.415
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:03.437
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 12/14/22 08:50:03.458
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:03.47
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:03.47
    STEP: creating a pod to probe DNS 12/14/22 08:50:03.47
    STEP: submitting the pod to kubernetes 12/14/22 08:50:03.47
    Dec 14 08:50:03.490: INFO: Waiting up to 15m0s for pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252" in namespace "dns-3011" to be "running"
    Dec 14 08:50:03.501: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252": Phase="Pending", Reason="", readiness=false. Elapsed: 10.977503ms
    Dec 14 08:50:05.515: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252": Phase="Running", Reason="", readiness=true. Elapsed: 2.02433822s
    Dec 14 08:50:05.515: INFO: Pod "dns-test-49bee1c1-0881-4673-8261-6bdbf5337252" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:50:05.515
    STEP: looking for the results for each expected name from probers 12/14/22 08:50:05.535
    Dec 14 08:50:05.718: INFO: DNS probes using dns-test-49bee1c1-0881-4673-8261-6bdbf5337252 succeeded

    STEP: deleting the pod 12/14/22 08:50:05.718
    STEP: changing the externalName to bar.example.com 12/14/22 08:50:05.733
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:05.756
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:05.756
    STEP: creating a second pod to probe DNS 12/14/22 08:50:05.757
    STEP: submitting the pod to kubernetes 12/14/22 08:50:05.757
    Dec 14 08:50:05.774: INFO: Waiting up to 15m0s for pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d" in namespace "dns-3011" to be "running"
    Dec 14 08:50:05.785: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.142587ms
    Dec 14 08:50:07.800: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d": Phase="Running", Reason="", readiness=true. Elapsed: 2.02605106s
    Dec 14 08:50:07.800: INFO: Pod "dns-test-89cb8894-170e-468c-9e33-628824139a0d" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:50:07.8
    STEP: looking for the results for each expected name from probers 12/14/22 08:50:07.812
    Dec 14 08:50:07.931: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:07.981: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:07.981: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:13.005: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:13.064: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:13.064: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:17.999: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:18.048: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:18.048: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:23.002: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:23.049: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:23.049: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:27.999: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:28.052: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:28.052: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:33.002: INFO: File wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:33.048: INFO: File jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local from pod  dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Dec 14 08:50:33.049: INFO: Lookups using dns-3011/dns-test-89cb8894-170e-468c-9e33-628824139a0d failed for: [wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local]

    Dec 14 08:50:38.048: INFO: DNS probes using dns-test-89cb8894-170e-468c-9e33-628824139a0d succeeded

    STEP: deleting the pod 12/14/22 08:50:38.048
    STEP: changing the service to type=ClusterIP 12/14/22 08:50:38.065
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:38.092
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3011.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3011.svc.cluster.local; sleep 1; done
     12/14/22 08:50:38.092
    STEP: creating a third pod to probe DNS 12/14/22 08:50:38.092
    STEP: submitting the pod to kubernetes 12/14/22 08:50:38.104
    Dec 14 08:50:38.123: INFO: Waiting up to 15m0s for pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563" in namespace "dns-3011" to be "running"
    Dec 14 08:50:38.134: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563": Phase="Pending", Reason="", readiness=false. Elapsed: 10.979351ms
    Dec 14 08:50:40.147: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563": Phase="Running", Reason="", readiness=true. Elapsed: 2.023627973s
    Dec 14 08:50:40.147: INFO: Pod "dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:50:40.147
    STEP: looking for the results for each expected name from probers 12/14/22 08:50:40.158
    Dec 14 08:50:40.324: INFO: DNS probes using dns-test-c7d37b1c-fc56-4dd4-a50e-88c3c9917563 succeeded

    STEP: deleting the pod 12/14/22 08:50:40.324
    STEP: deleting the test externalName service 12/14/22 08:50:40.34
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:50:40.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3011" for this suite. 12/14/22 08:50:40.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:50:40.391
Dec 14 08:50:40.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:50:40.392
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:40.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:40.45
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 08:50:40.506: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 08:51:40.626: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 12/14/22 08:51:40.637
Dec 14 08:51:40.685: INFO: Created pod: pod0-0-sched-preemption-low-priority
Dec 14 08:51:40.700: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Dec 14 08:51:40.736: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Dec 14 08:51:40.752: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 12/14/22 08:51:40.752
Dec 14 08:51:40.752: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2853" to be "running"
Dec 14 08:51:40.763: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.027418ms
Dec 14 08:51:42.775: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.023248963s
Dec 14 08:51:42.775: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Dec 14 08:51:42.775: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
Dec 14 08:51:42.787: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.748246ms
Dec 14 08:51:42.787: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:51:42.787: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
Dec 14 08:51:42.799: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.51556ms
Dec 14 08:51:42.799: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Dec 14 08:51:42.799: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
Dec 14 08:51:42.810: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.504126ms
Dec 14 08:51:42.810: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 12/14/22 08:51:42.81
Dec 14 08:51:42.839: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Dec 14 08:51:42.850: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.949473ms
Dec 14 08:51:44.864: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025797066s
Dec 14 08:51:46.873: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03448213s
Dec 14 08:51:46.873: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:51:46.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2853" for this suite. 12/14/22 08:51:46.978
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":34,"skipped":576,"failed":0}
------------------------------
• [66.678 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:50:40.391
    Dec 14 08:50:40.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 08:50:40.392
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:50:40.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:50:40.45
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 08:50:40.506: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 08:51:40.626: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 12/14/22 08:51:40.637
    Dec 14 08:51:40.685: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Dec 14 08:51:40.700: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Dec 14 08:51:40.736: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Dec 14 08:51:40.752: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 12/14/22 08:51:40.752
    Dec 14 08:51:40.752: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2853" to be "running"
    Dec 14 08:51:40.763: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.027418ms
    Dec 14 08:51:42.775: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.023248963s
    Dec 14 08:51:42.775: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Dec 14 08:51:42.775: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
    Dec 14 08:51:42.787: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.748246ms
    Dec 14 08:51:42.787: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:51:42.787: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
    Dec 14 08:51:42.799: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.51556ms
    Dec 14 08:51:42.799: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Dec 14 08:51:42.799: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2853" to be "running"
    Dec 14 08:51:42.810: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 11.504126ms
    Dec 14 08:51:42.810: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 12/14/22 08:51:42.81
    Dec 14 08:51:42.839: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Dec 14 08:51:42.850: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.949473ms
    Dec 14 08:51:44.864: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025797066s
    Dec 14 08:51:46.873: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03448213s
    Dec 14 08:51:46.873: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:51:46.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2853" for this suite. 12/14/22 08:51:46.978
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:47.074
Dec 14 08:51:47.074: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 08:51:47.075
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:47.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:47.13
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 12/14/22 08:51:47.151
STEP: listing events in all namespaces 12/14/22 08:51:47.163
STEP: listing events in test namespace 12/14/22 08:51:47.185
STEP: listing events with field selection filtering on source 12/14/22 08:51:47.197
STEP: listing events with field selection filtering on reportingController 12/14/22 08:51:47.209
STEP: getting the test event 12/14/22 08:51:47.22
STEP: patching the test event 12/14/22 08:51:47.232
STEP: getting the test event 12/14/22 08:51:47.249
STEP: updating the test event 12/14/22 08:51:47.26
STEP: getting the test event 12/14/22 08:51:47.274
STEP: deleting the test event 12/14/22 08:51:47.285
STEP: listing events in all namespaces 12/14/22 08:51:47.299
STEP: listing events in test namespace 12/14/22 08:51:47.319
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Dec 14 08:51:47.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1255" for this suite. 12/14/22 08:51:47.343
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":35,"skipped":581,"failed":0}
------------------------------
• [0.281 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:47.074
    Dec 14 08:51:47.074: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 08:51:47.075
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:47.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:47.13
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 12/14/22 08:51:47.151
    STEP: listing events in all namespaces 12/14/22 08:51:47.163
    STEP: listing events in test namespace 12/14/22 08:51:47.185
    STEP: listing events with field selection filtering on source 12/14/22 08:51:47.197
    STEP: listing events with field selection filtering on reportingController 12/14/22 08:51:47.209
    STEP: getting the test event 12/14/22 08:51:47.22
    STEP: patching the test event 12/14/22 08:51:47.232
    STEP: getting the test event 12/14/22 08:51:47.249
    STEP: updating the test event 12/14/22 08:51:47.26
    STEP: getting the test event 12/14/22 08:51:47.274
    STEP: deleting the test event 12/14/22 08:51:47.285
    STEP: listing events in all namespaces 12/14/22 08:51:47.299
    STEP: listing events in test namespace 12/14/22 08:51:47.319
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Dec 14 08:51:47.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1255" for this suite. 12/14/22 08:51:47.343
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:47.356
Dec 14 08:51:47.356: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:51:47.357
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:47.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:47.412
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Dec 14 08:51:47.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:51:49.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1974" for this suite. 12/14/22 08:51:49.191
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":36,"skipped":582,"failed":0}
------------------------------
• [1.847 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:47.356
    Dec 14 08:51:47.356: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 08:51:47.357
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:47.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:47.412
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Dec 14 08:51:47.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:51:49.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1974" for this suite. 12/14/22 08:51:49.191
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:51:49.204
Dec 14 08:51:49.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 08:51:49.205
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:49.239
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:49.259
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Dec 14 08:51:49.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 08:51:58.088
Dec 14 08:51:58.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 create -f -'
Dec 14 08:51:58.779: INFO: stderr: ""
Dec 14 08:51:58.779: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 14 08:51:58.779: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 delete e2e-test-crd-publish-openapi-4790-crds test-cr'
Dec 14 08:51:58.887: INFO: stderr: ""
Dec 14 08:51:58.888: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 14 08:51:58.888: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 apply -f -'
Dec 14 08:51:59.153: INFO: stderr: ""
Dec 14 08:51:59.154: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 14 08:51:59.154: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 delete e2e-test-crd-publish-openapi-4790-crds test-cr'
Dec 14 08:51:59.269: INFO: stderr: ""
Dec 14 08:51:59.269: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/14/22 08:51:59.269
Dec 14 08:51:59.269: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 explain e2e-test-crd-publish-openapi-4790-crds'
Dec 14 08:51:59.496: INFO: stderr: ""
Dec 14 08:51:59.496: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4790-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 08:52:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2806" for this suite. 12/14/22 08:52:02.27
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":37,"skipped":585,"failed":0}
------------------------------
• [13.079 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:51:49.204
    Dec 14 08:51:49.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 08:51:49.205
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:51:49.239
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:51:49.259
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Dec 14 08:51:49.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 08:51:58.088
    Dec 14 08:51:58.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 create -f -'
    Dec 14 08:51:58.779: INFO: stderr: ""
    Dec 14 08:51:58.779: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec 14 08:51:58.779: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 delete e2e-test-crd-publish-openapi-4790-crds test-cr'
    Dec 14 08:51:58.887: INFO: stderr: ""
    Dec 14 08:51:58.888: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Dec 14 08:51:58.888: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 apply -f -'
    Dec 14 08:51:59.153: INFO: stderr: ""
    Dec 14 08:51:59.154: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Dec 14 08:51:59.154: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 --namespace=crd-publish-openapi-2806 delete e2e-test-crd-publish-openapi-4790-crds test-cr'
    Dec 14 08:51:59.269: INFO: stderr: ""
    Dec 14 08:51:59.269: INFO: stdout: "e2e-test-crd-publish-openapi-4790-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/14/22 08:51:59.269
    Dec 14 08:51:59.269: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2806 explain e2e-test-crd-publish-openapi-4790-crds'
    Dec 14 08:51:59.496: INFO: stderr: ""
    Dec 14 08:51:59.496: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4790-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 08:52:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2806" for this suite. 12/14/22 08:52:02.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:02.283
Dec 14 08:52:02.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:52:02.284
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:02.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:02.339
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 12/14/22 08:52:02.361
Dec 14 08:52:02.391: INFO: Waiting up to 5m0s for pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c" in namespace "downward-api-6409" to be "Succeeded or Failed"
Dec 14 08:52:02.402: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.835108ms
Dec 14 08:52:04.414: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023551542s
Dec 14 08:52:06.414: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023603778s
STEP: Saw pod success 12/14/22 08:52:06.414
Dec 14 08:52:06.415: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c" satisfied condition "Succeeded or Failed"
Dec 14 08:52:06.427: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c container dapi-container: <nil>
STEP: delete the pod 12/14/22 08:52:06.454
Dec 14 08:52:06.478: INFO: Waiting for pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c to disappear
Dec 14 08:52:06.490: INFO: Pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 08:52:06.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6409" for this suite. 12/14/22 08:52:06.511
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":38,"skipped":592,"failed":0}
------------------------------
• [4.240 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:02.283
    Dec 14 08:52:02.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:52:02.284
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:02.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:02.339
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 12/14/22 08:52:02.361
    Dec 14 08:52:02.391: INFO: Waiting up to 5m0s for pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c" in namespace "downward-api-6409" to be "Succeeded or Failed"
    Dec 14 08:52:02.402: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.835108ms
    Dec 14 08:52:04.414: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023551542s
    Dec 14 08:52:06.414: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023603778s
    STEP: Saw pod success 12/14/22 08:52:06.414
    Dec 14 08:52:06.415: INFO: Pod "downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c" satisfied condition "Succeeded or Failed"
    Dec 14 08:52:06.427: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c container dapi-container: <nil>
    STEP: delete the pod 12/14/22 08:52:06.454
    Dec 14 08:52:06.478: INFO: Waiting for pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c to disappear
    Dec 14 08:52:06.490: INFO: Pod downward-api-392c13cb-710a-4696-83d1-a6f9ccbaf29c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 08:52:06.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6409" for this suite. 12/14/22 08:52:06.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:06.525
Dec 14 08:52:06.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:52:06.526
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:06.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:06.582
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-b2c83662-2ca4-4de6-98d5-06de70e48bff 12/14/22 08:52:06.602
STEP: Creating a pod to test consume secrets 12/14/22 08:52:06.615
Dec 14 08:52:06.634: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe" in namespace "projected-1723" to be "Succeeded or Failed"
Dec 14 08:52:06.645: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.179633ms
Dec 14 08:52:08.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024237527s
Dec 14 08:52:10.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023712637s
STEP: Saw pod success 12/14/22 08:52:10.658
Dec 14 08:52:10.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe" satisfied condition "Succeeded or Failed"
Dec 14 08:52:10.670: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 08:52:10.692
Dec 14 08:52:10.707: INFO: Waiting for pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe to disappear
Dec 14 08:52:10.718: INFO: Pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 08:52:10.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1723" for this suite. 12/14/22 08:52:10.738
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":39,"skipped":622,"failed":0}
------------------------------
• [4.226 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:06.525
    Dec 14 08:52:06.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:52:06.526
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:06.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:06.582
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-b2c83662-2ca4-4de6-98d5-06de70e48bff 12/14/22 08:52:06.602
    STEP: Creating a pod to test consume secrets 12/14/22 08:52:06.615
    Dec 14 08:52:06.634: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe" in namespace "projected-1723" to be "Succeeded or Failed"
    Dec 14 08:52:06.645: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.179633ms
    Dec 14 08:52:08.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024237527s
    Dec 14 08:52:10.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023712637s
    STEP: Saw pod success 12/14/22 08:52:10.658
    Dec 14 08:52:10.658: INFO: Pod "pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe" satisfied condition "Succeeded or Failed"
    Dec 14 08:52:10.670: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 08:52:10.692
    Dec 14 08:52:10.707: INFO: Waiting for pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe to disappear
    Dec 14 08:52:10.718: INFO: Pod pod-projected-secrets-98adfd15-4cff-49c5-8485-2f488c62d8fe no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 08:52:10.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1723" for this suite. 12/14/22 08:52:10.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:10.752
Dec 14 08:52:10.752: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:52:10.753
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:10.786
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:10.807
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 12/14/22 08:52:27.84
STEP: Creating a ResourceQuota 12/14/22 08:52:32.853
STEP: Ensuring resource quota status is calculated 12/14/22 08:52:32.865
STEP: Creating a ConfigMap 12/14/22 08:52:34.877
STEP: Ensuring resource quota status captures configMap creation 12/14/22 08:52:34.893
STEP: Deleting a ConfigMap 12/14/22 08:52:36.907
STEP: Ensuring resource quota status released usage 12/14/22 08:52:36.919
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:52:38.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2917" for this suite. 12/14/22 08:52:38.951
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":40,"skipped":652,"failed":0}
------------------------------
• [28.212 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:10.752
    Dec 14 08:52:10.752: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:52:10.753
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:10.786
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:10.807
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 12/14/22 08:52:27.84
    STEP: Creating a ResourceQuota 12/14/22 08:52:32.853
    STEP: Ensuring resource quota status is calculated 12/14/22 08:52:32.865
    STEP: Creating a ConfigMap 12/14/22 08:52:34.877
    STEP: Ensuring resource quota status captures configMap creation 12/14/22 08:52:34.893
    STEP: Deleting a ConfigMap 12/14/22 08:52:36.907
    STEP: Ensuring resource quota status released usage 12/14/22 08:52:36.919
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:52:38.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2917" for this suite. 12/14/22 08:52:38.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:38.966
Dec 14 08:52:38.966: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:52:38.967
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:39.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:39.023
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-e668ea64-13de-42a9-904b-be0d540bd003 12/14/22 08:52:39.043
STEP: Creating a pod to test consume configMaps 12/14/22 08:52:39.056
Dec 14 08:52:39.073: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17" in namespace "projected-8890" to be "Succeeded or Failed"
Dec 14 08:52:39.084: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Pending", Reason="", readiness=false. Elapsed: 10.998398ms
Dec 14 08:52:41.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023509122s
Dec 14 08:52:43.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023161693s
STEP: Saw pod success 12/14/22 08:52:43.097
Dec 14 08:52:43.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17" satisfied condition "Succeeded or Failed"
Dec 14 08:52:43.108: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:52:43.131
Dec 14 08:52:43.146: INFO: Waiting for pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 to disappear
Dec 14 08:52:43.157: INFO: Pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:52:43.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8890" for this suite. 12/14/22 08:52:43.178
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":41,"skipped":681,"failed":0}
------------------------------
• [4.225 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:38.966
    Dec 14 08:52:38.966: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:52:38.967
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:39.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:39.023
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-e668ea64-13de-42a9-904b-be0d540bd003 12/14/22 08:52:39.043
    STEP: Creating a pod to test consume configMaps 12/14/22 08:52:39.056
    Dec 14 08:52:39.073: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17" in namespace "projected-8890" to be "Succeeded or Failed"
    Dec 14 08:52:39.084: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Pending", Reason="", readiness=false. Elapsed: 10.998398ms
    Dec 14 08:52:41.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023509122s
    Dec 14 08:52:43.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023161693s
    STEP: Saw pod success 12/14/22 08:52:43.097
    Dec 14 08:52:43.097: INFO: Pod "pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17" satisfied condition "Succeeded or Failed"
    Dec 14 08:52:43.108: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:52:43.131
    Dec 14 08:52:43.146: INFO: Waiting for pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 to disappear
    Dec 14 08:52:43.157: INFO: Pod pod-projected-configmaps-fa44ed76-9069-4208-80d1-8224bf475b17 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:52:43.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8890" for this suite. 12/14/22 08:52:43.178
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:43.191
Dec 14 08:52:43.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 08:52:43.192
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:43.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:43.246
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 12/14/22 08:52:43.267
STEP: Counting existing ResourceQuota 12/14/22 08:52:48.279
STEP: Creating a ResourceQuota 12/14/22 08:52:53.291
STEP: Ensuring resource quota status is calculated 12/14/22 08:52:53.303
STEP: Creating a Secret 12/14/22 08:52:55.317
STEP: Ensuring resource quota status captures secret creation 12/14/22 08:52:55.334
STEP: Deleting a secret 12/14/22 08:52:57.346
STEP: Ensuring resource quota status released usage 12/14/22 08:52:57.358
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 08:52:59.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9372" for this suite. 12/14/22 08:52:59.392
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":42,"skipped":681,"failed":0}
------------------------------
• [16.213 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:43.191
    Dec 14 08:52:43.191: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 08:52:43.192
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:43.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:43.246
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 12/14/22 08:52:43.267
    STEP: Counting existing ResourceQuota 12/14/22 08:52:48.279
    STEP: Creating a ResourceQuota 12/14/22 08:52:53.291
    STEP: Ensuring resource quota status is calculated 12/14/22 08:52:53.303
    STEP: Creating a Secret 12/14/22 08:52:55.317
    STEP: Ensuring resource quota status captures secret creation 12/14/22 08:52:55.334
    STEP: Deleting a secret 12/14/22 08:52:57.346
    STEP: Ensuring resource quota status released usage 12/14/22 08:52:57.358
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 08:52:59.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9372" for this suite. 12/14/22 08:52:59.392
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:52:59.406
Dec 14 08:52:59.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:52:59.407
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:59.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:59.471
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-db862e4a-c0ff-4458-ba99-049a75d0fae6 12/14/22 08:52:59.493
STEP: Creating a pod to test consume configMaps 12/14/22 08:52:59.505
Dec 14 08:52:59.523: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b" in namespace "projected-4601" to be "Succeeded or Failed"
Dec 14 08:52:59.535: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.543596ms
Dec 14 08:53:01.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024128296s
Dec 14 08:53:03.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023816903s
STEP: Saw pod success 12/14/22 08:53:03.547
Dec 14 08:53:03.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b" satisfied condition "Succeeded or Failed"
Dec 14 08:53:03.559: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b container agnhost-container: <nil>
STEP: delete the pod 12/14/22 08:53:03.581
Dec 14 08:53:03.596: INFO: Waiting for pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b to disappear
Dec 14 08:53:03.607: INFO: Pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 08:53:03.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4601" for this suite. 12/14/22 08:53:03.628
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":43,"skipped":720,"failed":0}
------------------------------
• [4.234 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:52:59.406
    Dec 14 08:52:59.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:52:59.407
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:52:59.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:52:59.471
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-db862e4a-c0ff-4458-ba99-049a75d0fae6 12/14/22 08:52:59.493
    STEP: Creating a pod to test consume configMaps 12/14/22 08:52:59.505
    Dec 14 08:52:59.523: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b" in namespace "projected-4601" to be "Succeeded or Failed"
    Dec 14 08:52:59.535: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.543596ms
    Dec 14 08:53:01.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024128296s
    Dec 14 08:53:03.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023816903s
    STEP: Saw pod success 12/14/22 08:53:03.547
    Dec 14 08:53:03.547: INFO: Pod "pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b" satisfied condition "Succeeded or Failed"
    Dec 14 08:53:03.559: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 08:53:03.581
    Dec 14 08:53:03.596: INFO: Waiting for pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b to disappear
    Dec 14 08:53:03.607: INFO: Pod pod-projected-configmaps-0d253270-c96c-44cf-b016-0d42cd81a10b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 08:53:03.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4601" for this suite. 12/14/22 08:53:03.628
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:03.642
Dec 14 08:53:03.642: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 08:53:03.643
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:03.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:03.699
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 12/14/22 08:53:03.72
Dec 14 08:53:03.739: INFO: Waiting up to 5m0s for pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0" in namespace "projected-5570" to be "running and ready"
Dec 14 08:53:03.751: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.333801ms
Dec 14 08:53:03.751: INFO: The phase of Pod labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 08:53:05.763: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.023068274s
Dec 14 08:53:05.763: INFO: The phase of Pod labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 is Running (Ready = true)
Dec 14 08:53:05.763: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0" satisfied condition "running and ready"
Dec 14 08:53:06.323: INFO: Successfully updated pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 08:53:10.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5570" for this suite. 12/14/22 08:53:10.57
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":44,"skipped":754,"failed":0}
------------------------------
• [6.941 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:03.642
    Dec 14 08:53:03.642: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 08:53:03.643
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:03.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:03.699
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 12/14/22 08:53:03.72
    Dec 14 08:53:03.739: INFO: Waiting up to 5m0s for pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0" in namespace "projected-5570" to be "running and ready"
    Dec 14 08:53:03.751: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.333801ms
    Dec 14 08:53:03.751: INFO: The phase of Pod labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 08:53:05.763: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.023068274s
    Dec 14 08:53:05.763: INFO: The phase of Pod labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 is Running (Ready = true)
    Dec 14 08:53:05.763: INFO: Pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0" satisfied condition "running and ready"
    Dec 14 08:53:06.323: INFO: Successfully updated pod "labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 08:53:10.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5570" for this suite. 12/14/22 08:53:10.57
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:53:10.584
Dec 14 08:53:10.584: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 08:53:10.585
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:10.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:10.641
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 08:53:10.662: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 08:53:10.687: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 08:53:10.699: INFO: 
Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
Dec 14 08:53:10.716: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.716: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 08:53:10.717: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container proxy ready: true, restart count 0
Dec 14 08:53:10.717: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 08:53:10.717: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 08:53:10.717: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 08:53:10.717: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 08:53:10.717: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 08:53:10.717: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 08:53:10.717: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container coredns ready: true, restart count 0
Dec 14 08:53:10.717: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container coredns ready: true, restart count 0
Dec 14 08:53:10.717: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 08:53:10.717: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 08:53:10.717: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 08:53:10.717: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 08:53:10.717: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 08:53:10.717: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 08:53:10.717: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 08:53:10.717: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 08:53:10.717: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 08:53:10.717: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 08:53:10.717: INFO: node-problem-detector-5vcdz from kube-system started at 2022-12-14 08:30:57 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 08:53:10.717: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 08:53:10.717: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 08:53:10.717: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.717: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 14 08:53:10.717: INFO: 
Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
Dec 14 08:53:10.743: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 08:53:10.743: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container proxy ready: true, restart count 0
Dec 14 08:53:10.743: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 08:53:10.743: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 08:53:10.743: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 08:53:10.743: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 08:53:10.743: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 08:53:10.743: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 08:53:10.743: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 08:53:10.743: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.743: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 08:53:10.744: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 08:53:10.744: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 08:53:10.744: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 08:53:10.744: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 08:53:10.744: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 08:53:10.744: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 08:53:10.744: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 08:53:10.744: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 08:53:10.744: INFO: node-problem-detector-pb2dn from kube-system started at 2022-12-14 08:30:56 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 08:53:10.744: INFO: labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 from projected-5570 started at 2022-12-14 08:53:03 +0000 UTC (1 container statuses recorded)
Dec 14 08:53:10.744: INFO: 	Container client-container ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 08:53:10.744
Dec 14 08:53:10.764: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3637" to be "running"
Dec 14 08:53:10.775: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 11.096997ms
Dec 14 08:53:12.788: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.023903953s
Dec 14 08:53:12.788: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 08:53:12.799
STEP: Trying to apply a random label on the found node. 12/14/22 08:53:12.834
STEP: verifying the node has the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac 95 12/14/22 08:53:12.854
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/14/22 08:53:12.866
Dec 14 08:53:12.883: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3637" to be "not pending"
Dec 14 08:53:12.893: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.813023ms
Dec 14 08:53:14.907: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.02406464s
Dec 14 08:53:14.907: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.18.72 on the node which pod4 resides and expect not scheduled 12/14/22 08:53:14.907
Dec 14 08:53:14.922: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3637" to be "not pending"
Dec 14 08:53:14.933: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.992797ms
Dec 14 08:53:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023393074s
Dec 14 08:53:18.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024011741s
Dec 14 08:53:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023017849s
Dec 14 08:53:22.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024416835s
Dec 14 08:53:24.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022396136s
Dec 14 08:53:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02254992s
Dec 14 08:53:28.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024302911s
Dec 14 08:53:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023791424s
Dec 14 08:53:32.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024635662s
Dec 14 08:53:34.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.026410752s
Dec 14 08:53:36.953: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.030469249s
Dec 14 08:53:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.022762441s
Dec 14 08:53:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023418302s
Dec 14 08:53:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.02468303s
Dec 14 08:53:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.024457381s
Dec 14 08:53:46.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.026448936s
Dec 14 08:53:48.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024078769s
Dec 14 08:53:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023689791s
Dec 14 08:53:52.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.022873225s
Dec 14 08:53:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.023365963s
Dec 14 08:53:56.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.026852252s
Dec 14 08:53:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024029942s
Dec 14 08:54:00.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.026437516s
Dec 14 08:54:02.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023847735s
Dec 14 08:54:04.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.02432741s
Dec 14 08:54:06.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024917408s
Dec 14 08:54:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.023902995s
Dec 14 08:54:10.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.024044048s
Dec 14 08:54:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.024863459s
Dec 14 08:54:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.024672085s
Dec 14 08:54:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.023920674s
Dec 14 08:54:18.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.032990455s
Dec 14 08:54:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.023615084s
Dec 14 08:54:22.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023175061s
Dec 14 08:54:24.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.022645752s
Dec 14 08:54:26.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023678943s
Dec 14 08:54:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.022936245s
Dec 14 08:54:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023593246s
Dec 14 08:54:32.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.022596268s
Dec 14 08:54:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024361216s
Dec 14 08:54:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.023495679s
Dec 14 08:54:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.022878394s
Dec 14 08:54:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023430344s
Dec 14 08:54:42.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023672591s
Dec 14 08:54:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.024358422s
Dec 14 08:54:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.02328873s
Dec 14 08:54:48.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.022833146s
Dec 14 08:54:50.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024591996s
Dec 14 08:54:52.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.032485224s
Dec 14 08:54:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.02396841s
Dec 14 08:54:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.023019387s
Dec 14 08:54:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02425635s
Dec 14 08:55:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02346251s
Dec 14 08:55:02.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024048643s
Dec 14 08:55:04.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.022694189s
Dec 14 08:55:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023467309s
Dec 14 08:55:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.023982509s
Dec 14 08:55:10.948: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.025257137s
Dec 14 08:55:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.024005857s
Dec 14 08:55:14.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023405281s
Dec 14 08:55:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.023344338s
Dec 14 08:55:18.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.023770625s
Dec 14 08:55:20.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.024219843s
Dec 14 08:55:22.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.022909494s
Dec 14 08:55:24.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.024697737s
Dec 14 08:55:26.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.023428871s
Dec 14 08:55:28.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.024184313s
Dec 14 08:55:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.023517594s
Dec 14 08:55:32.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.023784708s
Dec 14 08:55:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.024357782s
Dec 14 08:55:36.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.024345518s
Dec 14 08:55:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.022680357s
Dec 14 08:55:40.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.024080228s
Dec 14 08:55:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.024458233s
Dec 14 08:55:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.024019126s
Dec 14 08:55:46.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.024163367s
Dec 14 08:55:48.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.023156257s
Dec 14 08:55:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.023048755s
Dec 14 08:55:52.971: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.048645821s
Dec 14 08:55:54.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.024167482s
Dec 14 08:55:56.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.022404054s
Dec 14 08:55:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024124164s
Dec 14 08:56:00.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.023998855s
Dec 14 08:56:02.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023331612s
Dec 14 08:56:04.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.024209345s
Dec 14 08:56:06.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.022601622s
Dec 14 08:56:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.023289831s
Dec 14 08:56:10.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.023661519s
Dec 14 08:56:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.024005514s
Dec 14 08:56:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.024345503s
Dec 14 08:56:16.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.022687713s
Dec 14 08:56:18.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.022794304s
Dec 14 08:56:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.023658385s
Dec 14 08:56:22.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024449794s
Dec 14 08:56:24.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.026459334s
Dec 14 08:56:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.022602507s
Dec 14 08:56:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.022854898s
Dec 14 08:56:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.023555581s
Dec 14 08:56:32.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.024887199s
Dec 14 08:56:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.024308925s
Dec 14 08:56:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.023711277s
Dec 14 08:56:38.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.024472633s
Dec 14 08:56:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.023507905s
Dec 14 08:56:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.024521158s
Dec 14 08:56:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.024841191s
Dec 14 08:56:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.023020542s
Dec 14 08:56:48.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.022413778s
Dec 14 08:56:50.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022617801s
Dec 14 08:56:52.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.024145897s
Dec 14 08:56:54.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.024017275s
Dec 14 08:56:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.023387473s
Dec 14 08:56:58.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.022912774s
Dec 14 08:57:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.023820925s
Dec 14 08:57:02.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024156317s
Dec 14 08:57:04.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.023815533s
Dec 14 08:57:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.023659503s
Dec 14 08:57:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.023233587s
Dec 14 08:57:10.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.02280901s
Dec 14 08:57:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.024637473s
Dec 14 08:57:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.024216945s
Dec 14 08:57:16.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.024238307s
Dec 14 08:57:18.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.02418281s
Dec 14 08:57:20.953: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.030511203s
Dec 14 08:57:22.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.022877475s
Dec 14 08:57:24.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.024769785s
Dec 14 08:57:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.022747043s
Dec 14 08:57:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.022867329s
Dec 14 08:57:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.02388084s
Dec 14 08:57:32.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.022867465s
Dec 14 08:57:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.024512918s
Dec 14 08:57:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.023009625s
Dec 14 08:57:38.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023947474s
Dec 14 08:57:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023455754s
Dec 14 08:57:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.024304716s
Dec 14 08:57:44.948: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.025135392s
Dec 14 08:57:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.023218535s
Dec 14 08:57:48.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.026430304s
Dec 14 08:57:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.023756711s
Dec 14 08:57:52.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.024277104s
Dec 14 08:57:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.023035612s
Dec 14 08:57:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.023583631s
Dec 14 08:57:58.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.023493932s
Dec 14 08:58:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.023384214s
Dec 14 08:58:02.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.026454478s
Dec 14 08:58:04.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.032392308s
Dec 14 08:58:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.023903418s
Dec 14 08:58:08.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.024485298s
Dec 14 08:58:10.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.024313863s
Dec 14 08:58:12.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.022724272s
Dec 14 08:58:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.024571701s
Dec 14 08:58:14.958: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.035903051s
STEP: removing the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 08:58:14.959
STEP: verifying the node doesn't have the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac 12/14/22 08:58:14.996
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 08:58:15.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3637" for this suite. 12/14/22 08:58:15.024
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":45,"skipped":787,"failed":0}
------------------------------
• [SLOW TEST] [304.452 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:53:10.584
    Dec 14 08:53:10.584: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 08:53:10.585
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:53:10.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:53:10.641
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 08:53:10.662: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 08:53:10.687: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 08:53:10.699: INFO: 
    Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
    Dec 14 08:53:10.716: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.716: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 08:53:10.717: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: node-problem-detector-5vcdz from kube-system started at 2022-12-14 08:30:57 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.717: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec 14 08:53:10.717: INFO: 
    Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
    Dec 14 08:53:10.743: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 08:53:10.743: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.743: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 08:53:10.744: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 08:53:10.744: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 08:53:10.744: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: node-problem-detector-pb2dn from kube-system started at 2022-12-14 08:30:56 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 08:53:10.744: INFO: labelsupdate367b8b7d-dfb6-44d3-83d0-9d28c529ecd0 from projected-5570 started at 2022-12-14 08:53:03 +0000 UTC (1 container statuses recorded)
    Dec 14 08:53:10.744: INFO: 	Container client-container ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 08:53:10.744
    Dec 14 08:53:10.764: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3637" to be "running"
    Dec 14 08:53:10.775: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 11.096997ms
    Dec 14 08:53:12.788: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.023903953s
    Dec 14 08:53:12.788: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 08:53:12.799
    STEP: Trying to apply a random label on the found node. 12/14/22 08:53:12.834
    STEP: verifying the node has the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac 95 12/14/22 08:53:12.854
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 12/14/22 08:53:12.866
    Dec 14 08:53:12.883: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3637" to be "not pending"
    Dec 14 08:53:12.893: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.813023ms
    Dec 14 08:53:14.907: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.02406464s
    Dec 14 08:53:14.907: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.18.72 on the node which pod4 resides and expect not scheduled 12/14/22 08:53:14.907
    Dec 14 08:53:14.922: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3637" to be "not pending"
    Dec 14 08:53:14.933: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.992797ms
    Dec 14 08:53:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023393074s
    Dec 14 08:53:18.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024011741s
    Dec 14 08:53:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023017849s
    Dec 14 08:53:22.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024416835s
    Dec 14 08:53:24.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022396136s
    Dec 14 08:53:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02254992s
    Dec 14 08:53:28.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024302911s
    Dec 14 08:53:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023791424s
    Dec 14 08:53:32.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.024635662s
    Dec 14 08:53:34.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.026410752s
    Dec 14 08:53:36.953: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.030469249s
    Dec 14 08:53:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.022762441s
    Dec 14 08:53:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023418302s
    Dec 14 08:53:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.02468303s
    Dec 14 08:53:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.024457381s
    Dec 14 08:53:46.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.026448936s
    Dec 14 08:53:48.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.024078769s
    Dec 14 08:53:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023689791s
    Dec 14 08:53:52.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.022873225s
    Dec 14 08:53:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.023365963s
    Dec 14 08:53:56.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.026852252s
    Dec 14 08:53:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024029942s
    Dec 14 08:54:00.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.026437516s
    Dec 14 08:54:02.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023847735s
    Dec 14 08:54:04.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.02432741s
    Dec 14 08:54:06.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024917408s
    Dec 14 08:54:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.023902995s
    Dec 14 08:54:10.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.024044048s
    Dec 14 08:54:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.024863459s
    Dec 14 08:54:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.024672085s
    Dec 14 08:54:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.023920674s
    Dec 14 08:54:18.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.032990455s
    Dec 14 08:54:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.023615084s
    Dec 14 08:54:22.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023175061s
    Dec 14 08:54:24.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.022645752s
    Dec 14 08:54:26.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023678943s
    Dec 14 08:54:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.022936245s
    Dec 14 08:54:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023593246s
    Dec 14 08:54:32.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.022596268s
    Dec 14 08:54:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024361216s
    Dec 14 08:54:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.023495679s
    Dec 14 08:54:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.022878394s
    Dec 14 08:54:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023430344s
    Dec 14 08:54:42.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.023672591s
    Dec 14 08:54:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.024358422s
    Dec 14 08:54:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.02328873s
    Dec 14 08:54:48.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.022833146s
    Dec 14 08:54:50.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024591996s
    Dec 14 08:54:52.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.032485224s
    Dec 14 08:54:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.02396841s
    Dec 14 08:54:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.023019387s
    Dec 14 08:54:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02425635s
    Dec 14 08:55:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.02346251s
    Dec 14 08:55:02.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024048643s
    Dec 14 08:55:04.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.022694189s
    Dec 14 08:55:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023467309s
    Dec 14 08:55:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.023982509s
    Dec 14 08:55:10.948: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.025257137s
    Dec 14 08:55:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.024005857s
    Dec 14 08:55:14.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023405281s
    Dec 14 08:55:16.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.023344338s
    Dec 14 08:55:18.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.023770625s
    Dec 14 08:55:20.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.024219843s
    Dec 14 08:55:22.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.022909494s
    Dec 14 08:55:24.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.024697737s
    Dec 14 08:55:26.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.023428871s
    Dec 14 08:55:28.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.024184313s
    Dec 14 08:55:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.023517594s
    Dec 14 08:55:32.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.023784708s
    Dec 14 08:55:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.024357782s
    Dec 14 08:55:36.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.024345518s
    Dec 14 08:55:38.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.022680357s
    Dec 14 08:55:40.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.024080228s
    Dec 14 08:55:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.024458233s
    Dec 14 08:55:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.024019126s
    Dec 14 08:55:46.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.024163367s
    Dec 14 08:55:48.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.023156257s
    Dec 14 08:55:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.023048755s
    Dec 14 08:55:52.971: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.048645821s
    Dec 14 08:55:54.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.024167482s
    Dec 14 08:55:56.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.022404054s
    Dec 14 08:55:58.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.024124164s
    Dec 14 08:56:00.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.023998855s
    Dec 14 08:56:02.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.023331612s
    Dec 14 08:56:04.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.024209345s
    Dec 14 08:56:06.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.022601622s
    Dec 14 08:56:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.023289831s
    Dec 14 08:56:10.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.023661519s
    Dec 14 08:56:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.024005514s
    Dec 14 08:56:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.024345503s
    Dec 14 08:56:16.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.022687713s
    Dec 14 08:56:18.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.022794304s
    Dec 14 08:56:20.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.023658385s
    Dec 14 08:56:22.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.024449794s
    Dec 14 08:56:24.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.026459334s
    Dec 14 08:56:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.022602507s
    Dec 14 08:56:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.022854898s
    Dec 14 08:56:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.023555581s
    Dec 14 08:56:32.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.024887199s
    Dec 14 08:56:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.024308925s
    Dec 14 08:56:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.023711277s
    Dec 14 08:56:38.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.024472633s
    Dec 14 08:56:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.023507905s
    Dec 14 08:56:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.024521158s
    Dec 14 08:56:44.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.024841191s
    Dec 14 08:56:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.023020542s
    Dec 14 08:56:48.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.022413778s
    Dec 14 08:56:50.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.022617801s
    Dec 14 08:56:52.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.024145897s
    Dec 14 08:56:54.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.024017275s
    Dec 14 08:56:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.023387473s
    Dec 14 08:56:58.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.022912774s
    Dec 14 08:57:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.023820925s
    Dec 14 08:57:02.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.024156317s
    Dec 14 08:57:04.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.023815533s
    Dec 14 08:57:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.023659503s
    Dec 14 08:57:08.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.023233587s
    Dec 14 08:57:10.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.02280901s
    Dec 14 08:57:12.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.024637473s
    Dec 14 08:57:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.024216945s
    Dec 14 08:57:16.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.024238307s
    Dec 14 08:57:18.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.02418281s
    Dec 14 08:57:20.953: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.030511203s
    Dec 14 08:57:22.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.022877475s
    Dec 14 08:57:24.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.024769785s
    Dec 14 08:57:26.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.022747043s
    Dec 14 08:57:28.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.022867329s
    Dec 14 08:57:30.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.02388084s
    Dec 14 08:57:32.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.022867465s
    Dec 14 08:57:34.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.024512918s
    Dec 14 08:57:36.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.023009625s
    Dec 14 08:57:38.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.023947474s
    Dec 14 08:57:40.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.023455754s
    Dec 14 08:57:42.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.024304716s
    Dec 14 08:57:44.948: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.025135392s
    Dec 14 08:57:46.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.023218535s
    Dec 14 08:57:48.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.026430304s
    Dec 14 08:57:50.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.023756711s
    Dec 14 08:57:52.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.024277104s
    Dec 14 08:57:54.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.023035612s
    Dec 14 08:57:56.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.023583631s
    Dec 14 08:57:58.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.023493932s
    Dec 14 08:58:00.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.023384214s
    Dec 14 08:58:02.949: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.026454478s
    Dec 14 08:58:04.955: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.032392308s
    Dec 14 08:58:06.946: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.023903418s
    Dec 14 08:58:08.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.024485298s
    Dec 14 08:58:10.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.024313863s
    Dec 14 08:58:12.945: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.022724272s
    Dec 14 08:58:14.947: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.024571701s
    Dec 14 08:58:14.958: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.035903051s
    STEP: removing the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 08:58:14.959
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-325f6627-aa33-4045-927a-e14cbddd54ac 12/14/22 08:58:14.996
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 08:58:15.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3637" for this suite. 12/14/22 08:58:15.024
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:15.037
Dec 14 08:58:15.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 08:58:15.038
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:15.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:15.101
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 12/14/22 08:58:15.122
STEP: creating 12/14/22 08:58:15.123
STEP: getting 12/14/22 08:58:15.135
STEP: listing 12/14/22 08:58:15.147
STEP: watching 12/14/22 08:58:15.158
Dec 14 08:58:15.159: INFO: starting watch
STEP: cluster-wide listing 12/14/22 08:58:15.169
STEP: cluster-wide watching 12/14/22 08:58:15.18
Dec 14 08:58:15.180: INFO: starting watch
STEP: patching 12/14/22 08:58:15.19
STEP: updating 12/14/22 08:58:15.203
Dec 14 08:58:15.227: INFO: waiting for watch events with expected annotations
Dec 14 08:58:15.227: INFO: saw patched and updated annotations
STEP: patching /status 12/14/22 08:58:15.227
STEP: updating /status 12/14/22 08:58:15.241
STEP: get /status 12/14/22 08:58:15.269
STEP: deleting 12/14/22 08:58:15.281
STEP: deleting a collection 12/14/22 08:58:15.316
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 08:58:15.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2688" for this suite. 12/14/22 08:58:15.353
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":46,"skipped":795,"failed":0}
------------------------------
• [0.328 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:15.037
    Dec 14 08:58:15.037: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 08:58:15.038
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:15.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:15.101
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 12/14/22 08:58:15.122
    STEP: creating 12/14/22 08:58:15.123
    STEP: getting 12/14/22 08:58:15.135
    STEP: listing 12/14/22 08:58:15.147
    STEP: watching 12/14/22 08:58:15.158
    Dec 14 08:58:15.159: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 08:58:15.169
    STEP: cluster-wide watching 12/14/22 08:58:15.18
    Dec 14 08:58:15.180: INFO: starting watch
    STEP: patching 12/14/22 08:58:15.19
    STEP: updating 12/14/22 08:58:15.203
    Dec 14 08:58:15.227: INFO: waiting for watch events with expected annotations
    Dec 14 08:58:15.227: INFO: saw patched and updated annotations
    STEP: patching /status 12/14/22 08:58:15.227
    STEP: updating /status 12/14/22 08:58:15.241
    STEP: get /status 12/14/22 08:58:15.269
    STEP: deleting 12/14/22 08:58:15.281
    STEP: deleting a collection 12/14/22 08:58:15.316
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 08:58:15.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2688" for this suite. 12/14/22 08:58:15.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:15.366
Dec 14 08:58:15.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 08:58:15.368
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:15.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:15.422
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 12/14/22 08:58:15.449
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_tcp@PTR;sleep 1; done
 12/14/22 08:58:15.484
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_tcp@PTR;sleep 1; done
 12/14/22 08:58:15.484
STEP: creating a pod to probe DNS 12/14/22 08:58:15.484
STEP: submitting the pod to kubernetes 12/14/22 08:58:15.484
Dec 14 08:58:15.512: INFO: Waiting up to 15m0s for pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e" in namespace "dns-8533" to be "running"
Dec 14 08:58:15.523: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980646ms
Dec 14 08:58:17.543: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e": Phase="Running", Reason="", readiness=true. Elapsed: 2.031223837s
Dec 14 08:58:17.544: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e" satisfied condition "running"
STEP: retrieving the pod 12/14/22 08:58:17.544
STEP: looking for the results for each expected name from probers 12/14/22 08:58:17.557
Dec 14 08:58:17.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.754: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.772: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.862: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.879: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.897: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.914: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:17.986: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:23.004: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.057: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.099: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.189: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.207: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.224: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.242: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:23.317: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:28.006: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.054: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.072: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.090: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.177: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.195: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.214: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.231: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:28.302: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:33.069: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.118: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.136: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.153: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.242: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.261: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.284: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.304: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:33.374: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:38.004: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.063: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.094: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.111: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.202: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.220: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.237: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.255: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:38.327: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:43.006: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.054: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.071: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.112: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.245: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.262: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.280: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.297: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:43.371: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:48.005: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.059: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.095: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.184: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.201: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.219: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.238: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
Dec 14 08:58:48.308: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

Dec 14 08:58:53.334: INFO: DNS probes using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e succeeded

STEP: deleting the pod 12/14/22 08:58:53.334
STEP: deleting the test service 12/14/22 08:58:53.351
STEP: deleting the test headless service 12/14/22 08:58:53.368
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 08:58:53.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8533" for this suite. 12/14/22 08:58:53.402
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":47,"skipped":819,"failed":0}
------------------------------
• [38.048 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:15.366
    Dec 14 08:58:15.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 08:58:15.368
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:15.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:15.422
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 12/14/22 08:58:15.449
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_tcp@PTR;sleep 1; done
     12/14/22 08:58:15.484
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.23.27.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.27.23.130_tcp@PTR;sleep 1; done
     12/14/22 08:58:15.484
    STEP: creating a pod to probe DNS 12/14/22 08:58:15.484
    STEP: submitting the pod to kubernetes 12/14/22 08:58:15.484
    Dec 14 08:58:15.512: INFO: Waiting up to 15m0s for pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e" in namespace "dns-8533" to be "running"
    Dec 14 08:58:15.523: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980646ms
    Dec 14 08:58:17.543: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e": Phase="Running", Reason="", readiness=true. Elapsed: 2.031223837s
    Dec 14 08:58:17.544: INFO: Pod "dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 08:58:17.544
    STEP: looking for the results for each expected name from probers 12/14/22 08:58:17.557
    Dec 14 08:58:17.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.754: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.772: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.862: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.879: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.897: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.914: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:17.986: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:23.004: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.057: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.099: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.189: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.207: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.224: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.242: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:23.317: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:28.006: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.054: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.072: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.090: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.177: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.195: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.214: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.231: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:28.302: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:33.069: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.118: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.136: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.153: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.242: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.261: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.284: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.304: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:33.374: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:38.004: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.063: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.094: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.111: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.202: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.220: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.237: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.255: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:38.327: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:43.006: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.054: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.071: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.112: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.245: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.262: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.280: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.297: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:43.371: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:48.005: INFO: Unable to read wheezy_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.059: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.077: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.095: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.184: INFO: Unable to read jessie_udp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.201: INFO: Unable to read jessie_tcp@dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.219: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.238: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local from pod dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e: the server could not find the requested resource (get pods dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e)
    Dec 14 08:58:48.308: INFO: Lookups using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e failed for: [wheezy_udp@dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@dns-test-service.dns-8533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_udp@dns-test-service.dns-8533.svc.cluster.local jessie_tcp@dns-test-service.dns-8533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8533.svc.cluster.local]

    Dec 14 08:58:53.334: INFO: DNS probes using dns-8533/dns-test-c9c24528-bd73-4ec6-9f3b-2fff11f9332e succeeded

    STEP: deleting the pod 12/14/22 08:58:53.334
    STEP: deleting the test service 12/14/22 08:58:53.351
    STEP: deleting the test headless service 12/14/22 08:58:53.368
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 08:58:53.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8533" for this suite. 12/14/22 08:58:53.402
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:58:53.415
Dec 14 08:58:53.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 08:58:53.415
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:53.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:53.47
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 08:58:53.496
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-96dk 12/14/22 08:58:53.52
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:58:53.52
Dec 14 08:58:53.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-96dk" in namespace "subpath-4813" to be "Succeeded or Failed"
Dec 14 08:58:53.549: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Pending", Reason="", readiness=false. Elapsed: 11.094515ms
Dec 14 08:58:55.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 2.022929352s
Dec 14 08:58:57.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 4.024518059s
Dec 14 08:58:59.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 6.02320086s
Dec 14 08:59:01.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 8.023885202s
Dec 14 08:59:03.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 10.024450636s
Dec 14 08:59:05.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 12.023513937s
Dec 14 08:59:07.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 14.024394246s
Dec 14 08:59:09.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 16.023484262s
Dec 14 08:59:11.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 18.024085847s
Dec 14 08:59:13.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 20.024476321s
Dec 14 08:59:15.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=false. Elapsed: 22.023313283s
Dec 14 08:59:17.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023485s
STEP: Saw pod success 12/14/22 08:59:17.562
Dec 14 08:59:17.562: INFO: Pod "pod-subpath-test-configmap-96dk" satisfied condition "Succeeded or Failed"
Dec 14 08:59:17.573: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-configmap-96dk container test-container-subpath-configmap-96dk: <nil>
STEP: delete the pod 12/14/22 08:59:17.601
Dec 14 08:59:17.615: INFO: Waiting for pod pod-subpath-test-configmap-96dk to disappear
Dec 14 08:59:17.627: INFO: Pod pod-subpath-test-configmap-96dk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-96dk 12/14/22 08:59:17.627
Dec 14 08:59:17.627: INFO: Deleting pod "pod-subpath-test-configmap-96dk" in namespace "subpath-4813"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 08:59:17.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4813" for this suite. 12/14/22 08:59:17.659
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":48,"skipped":823,"failed":0}
------------------------------
• [24.257 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:58:53.415
    Dec 14 08:58:53.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 08:58:53.415
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:58:53.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:58:53.47
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 08:58:53.496
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-96dk 12/14/22 08:58:53.52
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 08:58:53.52
    Dec 14 08:58:53.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-96dk" in namespace "subpath-4813" to be "Succeeded or Failed"
    Dec 14 08:58:53.549: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Pending", Reason="", readiness=false. Elapsed: 11.094515ms
    Dec 14 08:58:55.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 2.022929352s
    Dec 14 08:58:57.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 4.024518059s
    Dec 14 08:58:59.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 6.02320086s
    Dec 14 08:59:01.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 8.023885202s
    Dec 14 08:59:03.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 10.024450636s
    Dec 14 08:59:05.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 12.023513937s
    Dec 14 08:59:07.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 14.024394246s
    Dec 14 08:59:09.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 16.023484262s
    Dec 14 08:59:11.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 18.024085847s
    Dec 14 08:59:13.562: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=true. Elapsed: 20.024476321s
    Dec 14 08:59:15.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Running", Reason="", readiness=false. Elapsed: 22.023313283s
    Dec 14 08:59:17.561: INFO: Pod "pod-subpath-test-configmap-96dk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023485s
    STEP: Saw pod success 12/14/22 08:59:17.562
    Dec 14 08:59:17.562: INFO: Pod "pod-subpath-test-configmap-96dk" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:17.573: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-configmap-96dk container test-container-subpath-configmap-96dk: <nil>
    STEP: delete the pod 12/14/22 08:59:17.601
    Dec 14 08:59:17.615: INFO: Waiting for pod pod-subpath-test-configmap-96dk to disappear
    Dec 14 08:59:17.627: INFO: Pod pod-subpath-test-configmap-96dk no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-96dk 12/14/22 08:59:17.627
    Dec 14 08:59:17.627: INFO: Deleting pod "pod-subpath-test-configmap-96dk" in namespace "subpath-4813"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 08:59:17.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4813" for this suite. 12/14/22 08:59:17.659
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:17.674
Dec 14 08:59:17.675: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 08:59:17.675
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:17.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:17.73
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Dec 14 08:59:17.768: INFO: Waiting up to 5m0s for pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13" in namespace "containers-2546" to be "running"
Dec 14 08:59:17.779: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13": Phase="Pending", Reason="", readiness=false. Elapsed: 11.024981ms
Dec 14 08:59:19.792: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13": Phase="Running", Reason="", readiness=true. Elapsed: 2.024194172s
Dec 14 08:59:19.793: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 08:59:19.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2546" for this suite. 12/14/22 08:59:19.837
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":49,"skipped":863,"failed":0}
------------------------------
• [2.175 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:17.674
    Dec 14 08:59:17.675: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 08:59:17.675
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:17.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:17.73
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Dec 14 08:59:17.768: INFO: Waiting up to 5m0s for pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13" in namespace "containers-2546" to be "running"
    Dec 14 08:59:17.779: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13": Phase="Pending", Reason="", readiness=false. Elapsed: 11.024981ms
    Dec 14 08:59:19.792: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13": Phase="Running", Reason="", readiness=true. Elapsed: 2.024194172s
    Dec 14 08:59:19.793: INFO: Pod "client-containers-c98ce8c0-521c-4972-a839-a8edff10fe13" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 08:59:19.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2546" for this suite. 12/14/22 08:59:19.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:19.852
Dec 14 08:59:19.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 08:59:19.852
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:19.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:19.908
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 08:59:19.93
Dec 14 08:59:19.949: INFO: Waiting up to 5m0s for pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e" in namespace "emptydir-2080" to be "Succeeded or Failed"
Dec 14 08:59:19.960: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.097185ms
Dec 14 08:59:21.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023796073s
Dec 14 08:59:23.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023164763s
STEP: Saw pod success 12/14/22 08:59:23.972
Dec 14 08:59:23.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e" satisfied condition "Succeeded or Failed"
Dec 14 08:59:23.983: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e container test-container: <nil>
STEP: delete the pod 12/14/22 08:59:24.007
Dec 14 08:59:24.022: INFO: Waiting for pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e to disappear
Dec 14 08:59:24.035: INFO: Pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 08:59:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2080" for this suite. 12/14/22 08:59:24.056
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":50,"skipped":904,"failed":0}
------------------------------
• [4.217 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:19.852
    Dec 14 08:59:19.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 08:59:19.852
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:19.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:19.908
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 08:59:19.93
    Dec 14 08:59:19.949: INFO: Waiting up to 5m0s for pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e" in namespace "emptydir-2080" to be "Succeeded or Failed"
    Dec 14 08:59:19.960: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.097185ms
    Dec 14 08:59:21.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023796073s
    Dec 14 08:59:23.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023164763s
    STEP: Saw pod success 12/14/22 08:59:23.972
    Dec 14 08:59:23.972: INFO: Pod "pod-79ea762a-31f9-4157-9eb8-893c6aafe72e" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:23.983: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e container test-container: <nil>
    STEP: delete the pod 12/14/22 08:59:24.007
    Dec 14 08:59:24.022: INFO: Waiting for pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e to disappear
    Dec 14 08:59:24.035: INFO: Pod pod-79ea762a-31f9-4157-9eb8-893c6aafe72e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 08:59:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2080" for this suite. 12/14/22 08:59:24.056
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:24.069
Dec 14 08:59:24.069: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:24.07
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:24.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:24.126
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:24.146
Dec 14 08:59:24.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f" in namespace "downward-api-795" to be "Succeeded or Failed"
Dec 14 08:59:24.176: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.019672ms
Dec 14 08:59:26.188: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022845121s
Dec 14 08:59:28.189: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023968869s
STEP: Saw pod success 12/14/22 08:59:28.189
Dec 14 08:59:28.189: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f" satisfied condition "Succeeded or Failed"
Dec 14 08:59:28.200: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f container client-container: <nil>
STEP: delete the pod 12/14/22 08:59:28.223
Dec 14 08:59:28.238: INFO: Waiting for pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f to disappear
Dec 14 08:59:28.249: INFO: Pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 08:59:28.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-795" for this suite. 12/14/22 08:59:28.27
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":51,"skipped":916,"failed":0}
------------------------------
• [4.213 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:24.069
    Dec 14 08:59:24.069: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:24.07
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:24.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:24.126
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:24.146
    Dec 14 08:59:24.165: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f" in namespace "downward-api-795" to be "Succeeded or Failed"
    Dec 14 08:59:24.176: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.019672ms
    Dec 14 08:59:26.188: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022845121s
    Dec 14 08:59:28.189: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023968869s
    STEP: Saw pod success 12/14/22 08:59:28.189
    Dec 14 08:59:28.189: INFO: Pod "downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:28.200: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f container client-container: <nil>
    STEP: delete the pod 12/14/22 08:59:28.223
    Dec 14 08:59:28.238: INFO: Waiting for pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f to disappear
    Dec 14 08:59:28.249: INFO: Pod downwardapi-volume-1aa472f4-0693-42ab-bf5d-45afb027a05f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 08:59:28.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-795" for this suite. 12/14/22 08:59:28.27
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:28.283
Dec 14 08:59:28.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename csistoragecapacity 12/14/22 08:59:28.284
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:28.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:28.339
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 12/14/22 08:59:28.36
STEP: getting /apis/storage.k8s.io 12/14/22 08:59:28.38
STEP: getting /apis/storage.k8s.io/v1 12/14/22 08:59:28.39
STEP: creating 12/14/22 08:59:28.4
STEP: watching 12/14/22 08:59:28.436
Dec 14 08:59:28.436: INFO: starting watch
STEP: getting 12/14/22 08:59:28.468
STEP: listing in namespace 12/14/22 08:59:28.479
STEP: listing across namespaces 12/14/22 08:59:28.496
STEP: patching 12/14/22 08:59:28.508
STEP: updating 12/14/22 08:59:28.52
Dec 14 08:59:28.533: INFO: waiting for watch events with expected annotations in namespace
Dec 14 08:59:28.533: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 12/14/22 08:59:28.533
STEP: deleting a collection 12/14/22 08:59:28.568
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Dec 14 08:59:28.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-2964" for this suite. 12/14/22 08:59:28.608
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":52,"skipped":921,"failed":0}
------------------------------
• [0.338 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:28.283
    Dec 14 08:59:28.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename csistoragecapacity 12/14/22 08:59:28.284
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:28.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:28.339
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 12/14/22 08:59:28.36
    STEP: getting /apis/storage.k8s.io 12/14/22 08:59:28.38
    STEP: getting /apis/storage.k8s.io/v1 12/14/22 08:59:28.39
    STEP: creating 12/14/22 08:59:28.4
    STEP: watching 12/14/22 08:59:28.436
    Dec 14 08:59:28.436: INFO: starting watch
    STEP: getting 12/14/22 08:59:28.468
    STEP: listing in namespace 12/14/22 08:59:28.479
    STEP: listing across namespaces 12/14/22 08:59:28.496
    STEP: patching 12/14/22 08:59:28.508
    STEP: updating 12/14/22 08:59:28.52
    Dec 14 08:59:28.533: INFO: waiting for watch events with expected annotations in namespace
    Dec 14 08:59:28.533: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 12/14/22 08:59:28.533
    STEP: deleting a collection 12/14/22 08:59:28.568
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Dec 14 08:59:28.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-2964" for this suite. 12/14/22 08:59:28.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:28.622
Dec 14 08:59:28.622: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 08:59:28.623
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:28.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:28.678
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 12/14/22 08:59:28.699
STEP: Ensuring job reaches completions 12/14/22 08:59:28.712
STEP: Ensuring pods with index for job exist 12/14/22 08:59:36.724
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 08:59:36.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-58" for this suite. 12/14/22 08:59:36.776
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":53,"skipped":927,"failed":0}
------------------------------
• [8.166 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:28.622
    Dec 14 08:59:28.622: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 08:59:28.623
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:28.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:28.678
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 12/14/22 08:59:28.699
    STEP: Ensuring job reaches completions 12/14/22 08:59:28.712
    STEP: Ensuring pods with index for job exist 12/14/22 08:59:36.724
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 08:59:36.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-58" for this suite. 12/14/22 08:59:36.776
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:36.788
Dec 14 08:59:36.789: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:36.789
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:36.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:36.844
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:36.865
Dec 14 08:59:36.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193" in namespace "downward-api-4659" to be "Succeeded or Failed"
Dec 14 08:59:36.898: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Pending", Reason="", readiness=false. Elapsed: 11.456742ms
Dec 14 08:59:38.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023981163s
Dec 14 08:59:40.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023491102s
STEP: Saw pod success 12/14/22 08:59:40.91
Dec 14 08:59:40.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193" satisfied condition "Succeeded or Failed"
Dec 14 08:59:40.921: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 container client-container: <nil>
STEP: delete the pod 12/14/22 08:59:40.944
Dec 14 08:59:40.958: INFO: Waiting for pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 to disappear
Dec 14 08:59:40.969: INFO: Pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 08:59:40.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4659" for this suite. 12/14/22 08:59:40.99
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":54,"skipped":930,"failed":0}
------------------------------
• [4.215 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:36.788
    Dec 14 08:59:36.789: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 08:59:36.789
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:36.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:36.844
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 12/14/22 08:59:36.865
    Dec 14 08:59:36.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193" in namespace "downward-api-4659" to be "Succeeded or Failed"
    Dec 14 08:59:36.898: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Pending", Reason="", readiness=false. Elapsed: 11.456742ms
    Dec 14 08:59:38.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023981163s
    Dec 14 08:59:40.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023491102s
    STEP: Saw pod success 12/14/22 08:59:40.91
    Dec 14 08:59:40.910: INFO: Pod "downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193" satisfied condition "Succeeded or Failed"
    Dec 14 08:59:40.921: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 container client-container: <nil>
    STEP: delete the pod 12/14/22 08:59:40.944
    Dec 14 08:59:40.958: INFO: Waiting for pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 to disappear
    Dec 14 08:59:40.969: INFO: Pod downwardapi-volume-cfade8ca-2363-493b-86cc-0724ca39c193 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 08:59:40.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4659" for this suite. 12/14/22 08:59:40.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:41.004
Dec 14 08:59:41.004: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 08:59:41.004
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:41.039
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:41.06
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 12/14/22 08:59:41.08
Dec 14 08:59:41.081: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 08:59:46.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6110" for this suite. 12/14/22 08:59:46.41
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":55,"skipped":937,"failed":0}
------------------------------
• [5.420 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:41.004
    Dec 14 08:59:41.004: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 08:59:41.004
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:41.039
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:41.06
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 12/14/22 08:59:41.08
    Dec 14 08:59:41.081: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 08:59:46.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6110" for this suite. 12/14/22 08:59:46.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:46.424
Dec 14 08:59:46.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 08:59:46.425
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:46.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:46.48
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Dec 14 08:59:46.527: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 08:59:46.527
Dec 14 08:59:46.527: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-mbjpk" in namespace "deployment-2691" to be "running"
Dec 14 08:59:46.538: INFO: Pod "test-cleanup-controller-mbjpk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.893453ms
Dec 14 08:59:48.551: INFO: Pod "test-cleanup-controller-mbjpk": Phase="Running", Reason="", readiness=true. Elapsed: 2.024073635s
Dec 14 08:59:48.551: INFO: Pod "test-cleanup-controller-mbjpk" satisfied condition "running"
Dec 14 08:59:48.551: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/14/22 08:59:48.587
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 08:59:50.647: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2691  11d74dbd-52ae-46dc-8432-e7a5c41f815f 23096 1 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002f44d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:59:48 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-12-14 08:59:49 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 08:59:50.659: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-2691  57c01135-27f6-4c46-a5d7-b1cd41899923 23089 1 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 11d74dbd-52ae-46dc-8432-e7a5c41f815f 0xc0050e4da7 0xc0050e4da8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"11d74dbd-52ae-46dc-8432-e7a5c41f815f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0050e4e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 08:59:50.671: INFO: Pod "test-cleanup-deployment-69cb9c5497-kh8z6" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-kh8z6 test-cleanup-deployment-69cb9c5497- deployment-2691  d5510ba8-52af-46b7-9dc3-8fcc1db9f36a 23088 0 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:bb84f436d5ab2e2b7d9a80ff956768fbe49a238f919a05c8a88bf0769d646104 cni.projectcalico.org/podIP:172.16.0.69/32 cni.projectcalico.org/podIPs:172.16.0.69/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 57c01135-27f6-4c46-a5d7-b1cd41899923 0xc0050e5217 0xc0050e5218}] [] [{kube-controller-manager Update v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"57c01135-27f6-4c46-a5d7-b1cd41899923\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4756g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4756g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.69,StartTime:2022-12-14 08:59:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:59:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://4e23622862c393181414cb0436b50b9b29232fc88fa4024576ded2751c024db9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 08:59:50.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2691" for this suite. 12/14/22 08:59:50.692
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":56,"skipped":944,"failed":0}
------------------------------
• [4.280 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:46.424
    Dec 14 08:59:46.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 08:59:46.425
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:46.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:46.48
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Dec 14 08:59:46.527: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 08:59:46.527
    Dec 14 08:59:46.527: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-mbjpk" in namespace "deployment-2691" to be "running"
    Dec 14 08:59:46.538: INFO: Pod "test-cleanup-controller-mbjpk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.893453ms
    Dec 14 08:59:48.551: INFO: Pod "test-cleanup-controller-mbjpk": Phase="Running", Reason="", readiness=true. Elapsed: 2.024073635s
    Dec 14 08:59:48.551: INFO: Pod "test-cleanup-controller-mbjpk" satisfied condition "running"
    Dec 14 08:59:48.551: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 12/14/22 08:59:48.587
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 08:59:50.647: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2691  11d74dbd-52ae-46dc-8432-e7a5c41f815f 23096 1 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002f44d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 08:59:48 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-12-14 08:59:49 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 08:59:50.659: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-2691  57c01135-27f6-4c46-a5d7-b1cd41899923 23089 1 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 11d74dbd-52ae-46dc-8432-e7a5c41f815f 0xc0050e4da7 0xc0050e4da8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"11d74dbd-52ae-46dc-8432-e7a5c41f815f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0050e4e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 08:59:50.671: INFO: Pod "test-cleanup-deployment-69cb9c5497-kh8z6" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-kh8z6 test-cleanup-deployment-69cb9c5497- deployment-2691  d5510ba8-52af-46b7-9dc3-8fcc1db9f36a 23088 0 2022-12-14 08:59:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:bb84f436d5ab2e2b7d9a80ff956768fbe49a238f919a05c8a88bf0769d646104 cni.projectcalico.org/podIP:172.16.0.69/32 cni.projectcalico.org/podIPs:172.16.0.69/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 57c01135-27f6-4c46-a5d7-b1cd41899923 0xc0050e5217 0xc0050e5218}] [] [{kube-controller-manager Update v1 2022-12-14 08:59:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"57c01135-27f6-4c46-a5d7-b1cd41899923\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 08:59:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4756g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4756g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 08:59:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.69,StartTime:2022-12-14 08:59:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 08:59:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://4e23622862c393181414cb0436b50b9b29232fc88fa4024576ded2751c024db9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 08:59:50.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2691" for this suite. 12/14/22 08:59:50.692
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 08:59:50.706
Dec 14 08:59:50.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 08:59:50.707
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:50.741
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:50.762
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 12/14/22 08:59:50.782
STEP: creating a new configmap 12/14/22 08:59:50.792
STEP: modifying the configmap once 12/14/22 08:59:50.804
STEP: changing the label value of the configmap 12/14/22 08:59:50.827
STEP: Expecting to observe a delete notification for the watched object 12/14/22 08:59:50.849
Dec 14 08:59:50.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23110 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 08:59:50.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23111 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 08:59:50.850: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23113 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 12/14/22 08:59:50.85
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/14/22 08:59:50.873
STEP: changing the label value of the configmap back 12/14/22 09:00:00.874
STEP: modifying the configmap a third time 12/14/22 09:00:00.897
STEP: deleting the configmap 12/14/22 09:00:00.921
STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/14/22 09:00:00.933
Dec 14 09:00:00.933: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23207 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:00:00.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23208 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:00:00.934: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23209 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:00:00.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-166" for this suite. 12/14/22 09:00:00.955
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":57,"skipped":967,"failed":0}
------------------------------
• [10.261 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 08:59:50.706
    Dec 14 08:59:50.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 08:59:50.707
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 08:59:50.741
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 08:59:50.762
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 12/14/22 08:59:50.782
    STEP: creating a new configmap 12/14/22 08:59:50.792
    STEP: modifying the configmap once 12/14/22 08:59:50.804
    STEP: changing the label value of the configmap 12/14/22 08:59:50.827
    STEP: Expecting to observe a delete notification for the watched object 12/14/22 08:59:50.849
    Dec 14 08:59:50.850: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23110 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 08:59:50.850: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23111 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 08:59:50.850: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23113 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 08:59:50 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 12/14/22 08:59:50.85
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 12/14/22 08:59:50.873
    STEP: changing the label value of the configmap back 12/14/22 09:00:00.874
    STEP: modifying the configmap a third time 12/14/22 09:00:00.897
    STEP: deleting the configmap 12/14/22 09:00:00.921
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 12/14/22 09:00:00.933
    Dec 14 09:00:00.933: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23207 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:00:00.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23208 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:00:00.934: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-166  058831cb-f178-4e86-94b6-d95b12edf077 23209 0 2022-12-14 08:59:50 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-12-14 09:00:00 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:00:00.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-166" for this suite. 12/14/22 09:00:00.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:00.97
Dec 14 09:00:00.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:00:00.97
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:01.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:01.027
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 12/14/22 09:00:01.048
STEP: Waiting for the pdb to be processed 12/14/22 09:00:01.06
STEP: First trying to evict a pod which shouldn't be evictable 12/14/22 09:00:03.096
STEP: Waiting for all pods to be running 12/14/22 09:00:03.096
Dec 14 09:00:03.107: INFO: pods: 1 < 3
STEP: locating a running pod 12/14/22 09:00:05.12
STEP: Updating the pdb to allow a pod to be evicted 12/14/22 09:00:05.145
STEP: Waiting for the pdb to be processed 12/14/22 09:00:05.168
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 09:00:05.179
STEP: Waiting for all pods to be running 12/14/22 09:00:05.179
STEP: Waiting for the pdb to observed all healthy pods 12/14/22 09:00:05.19
STEP: Patching the pdb to disallow a pod to be evicted 12/14/22 09:00:05.219
STEP: Waiting for the pdb to be processed 12/14/22 09:00:05.245
STEP: Waiting for all pods to be running 12/14/22 09:00:05.256
Dec 14 09:00:05.268: INFO: running pods: 2 < 3
STEP: locating a running pod 12/14/22 09:00:07.281
STEP: Deleting the pdb to allow a pod to be evicted 12/14/22 09:00:07.306
STEP: Waiting for the pdb to be deleted 12/14/22 09:00:07.318
STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 09:00:07.329
STEP: Waiting for all pods to be running 12/14/22 09:00:07.329
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:00:07.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-71" for this suite. 12/14/22 09:00:07.369
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":58,"skipped":1028,"failed":0}
------------------------------
• [6.412 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:00.97
    Dec 14 09:00:00.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:00:00.97
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:01.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:01.027
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 12/14/22 09:00:01.048
    STEP: Waiting for the pdb to be processed 12/14/22 09:00:01.06
    STEP: First trying to evict a pod which shouldn't be evictable 12/14/22 09:00:03.096
    STEP: Waiting for all pods to be running 12/14/22 09:00:03.096
    Dec 14 09:00:03.107: INFO: pods: 1 < 3
    STEP: locating a running pod 12/14/22 09:00:05.12
    STEP: Updating the pdb to allow a pod to be evicted 12/14/22 09:00:05.145
    STEP: Waiting for the pdb to be processed 12/14/22 09:00:05.168
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 09:00:05.179
    STEP: Waiting for all pods to be running 12/14/22 09:00:05.179
    STEP: Waiting for the pdb to observed all healthy pods 12/14/22 09:00:05.19
    STEP: Patching the pdb to disallow a pod to be evicted 12/14/22 09:00:05.219
    STEP: Waiting for the pdb to be processed 12/14/22 09:00:05.245
    STEP: Waiting for all pods to be running 12/14/22 09:00:05.256
    Dec 14 09:00:05.268: INFO: running pods: 2 < 3
    STEP: locating a running pod 12/14/22 09:00:07.281
    STEP: Deleting the pdb to allow a pod to be evicted 12/14/22 09:00:07.306
    STEP: Waiting for the pdb to be deleted 12/14/22 09:00:07.318
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 12/14/22 09:00:07.329
    STEP: Waiting for all pods to be running 12/14/22 09:00:07.329
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:00:07.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-71" for this suite. 12/14/22 09:00:07.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:07.388
Dec 14 09:00:07.388: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:00:07.388
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:07.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:07.444
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:00:07.496
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:00:08.006
STEP: Deploying the webhook pod 12/14/22 09:00:08.018
STEP: Wait for the deployment to be ready 12/14/22 09:00:08.044
Dec 14 09:00:08.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:00:10.09
STEP: Verifying the service has paired with the endpoint 12/14/22 09:00:10.106
Dec 14 09:00:11.107: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 12/14/22 09:00:11.119
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.262
STEP: Updating a validating webhook configuration's rules to not include the create operation 12/14/22 09:00:11.392
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.416
STEP: Patching a validating webhook configuration's rules to include the create operation 12/14/22 09:00:11.44
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.454
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:00:11.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1732" for this suite. 12/14/22 09:00:11.555
STEP: Destroying namespace "webhook-1732-markers" for this suite. 12/14/22 09:00:11.568
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":59,"skipped":1166,"failed":0}
------------------------------
• [4.258 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:07.388
    Dec 14 09:00:07.388: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:00:07.388
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:07.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:07.444
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:00:07.496
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:00:08.006
    STEP: Deploying the webhook pod 12/14/22 09:00:08.018
    STEP: Wait for the deployment to be ready 12/14/22 09:00:08.044
    Dec 14 09:00:08.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:00:10.09
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:00:10.106
    Dec 14 09:00:11.107: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 12/14/22 09:00:11.119
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.262
    STEP: Updating a validating webhook configuration's rules to not include the create operation 12/14/22 09:00:11.392
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.416
    STEP: Patching a validating webhook configuration's rules to include the create operation 12/14/22 09:00:11.44
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:00:11.454
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:00:11.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1732" for this suite. 12/14/22 09:00:11.555
    STEP: Destroying namespace "webhook-1732-markers" for this suite. 12/14/22 09:00:11.568
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:11.646
Dec 14 09:00:11.646: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:00:11.647
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:11.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:11.702
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Dec 14 09:00:11.753: INFO: created pod
Dec 14 09:00:11.753: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7019" to be "Succeeded or Failed"
Dec 14 09:00:11.764: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.841336ms
Dec 14 09:00:13.778: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024481246s
Dec 14 09:00:15.777: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023587714s
STEP: Saw pod success 12/14/22 09:00:15.777
Dec 14 09:00:15.777: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Dec 14 09:00:45.778: INFO: polling logs
Dec 14 09:00:45.801: INFO: Pod logs: 
I1214 09:00:12.378279       1 log.go:195] OK: Got token
I1214 09:00:12.378352       1 log.go:195] validating with in-cluster discovery
I1214 09:00:12.378823       1 log.go:195] OK: got issuer https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com
I1214 09:00:12.378872       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-7019:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671009012, NotBefore:1671008412, IssuedAt:1671008412, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7019", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b1aa4a07-f507-43cb-8df0-3186943b3808"}}}
I1214 09:00:12.394887       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com
I1214 09:00:12.399241       1 log.go:195] OK: Validated signature on JWT
I1214 09:00:12.399459       1 log.go:195] OK: Got valid claims from token!
I1214 09:00:12.399480       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-7019:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671009012, NotBefore:1671008412, IssuedAt:1671008412, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7019", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b1aa4a07-f507-43cb-8df0-3186943b3808"}}}

Dec 14 09:00:45.801: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:00:45.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7019" for this suite. 12/14/22 09:00:45.835
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":60,"skipped":1172,"failed":0}
------------------------------
• [34.202 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:11.646
    Dec 14 09:00:11.646: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:00:11.647
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:11.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:11.702
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Dec 14 09:00:11.753: INFO: created pod
    Dec 14 09:00:11.753: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-7019" to be "Succeeded or Failed"
    Dec 14 09:00:11.764: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.841336ms
    Dec 14 09:00:13.778: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024481246s
    Dec 14 09:00:15.777: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023587714s
    STEP: Saw pod success 12/14/22 09:00:15.777
    Dec 14 09:00:15.777: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Dec 14 09:00:45.778: INFO: polling logs
    Dec 14 09:00:45.801: INFO: Pod logs: 
    I1214 09:00:12.378279       1 log.go:195] OK: Got token
    I1214 09:00:12.378352       1 log.go:195] validating with in-cluster discovery
    I1214 09:00:12.378823       1 log.go:195] OK: got issuer https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com
    I1214 09:00:12.378872       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-7019:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671009012, NotBefore:1671008412, IssuedAt:1671008412, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7019", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b1aa4a07-f507-43cb-8df0-3186943b3808"}}}
    I1214 09:00:12.394887       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com
    I1214 09:00:12.399241       1 log.go:195] OK: Validated signature on JWT
    I1214 09:00:12.399459       1 log.go:195] OK: Got valid claims from token!
    I1214 09:00:12.399480       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", Subject:"system:serviceaccount:svcaccounts-7019:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1671009012, NotBefore:1671008412, IssuedAt:1671008412, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7019", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"b1aa4a07-f507-43cb-8df0-3186943b3808"}}}

    Dec 14 09:00:45.801: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:00:45.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7019" for this suite. 12/14/22 09:00:45.835
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:45.848
Dec 14 09:00:45.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:00:45.85
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:45.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:45.904
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 12/14/22 09:00:45.925
STEP: listing secrets in all namespaces to ensure that there are more than zero 12/14/22 09:00:45.937
STEP: patching the secret 12/14/22 09:00:45.95
STEP: deleting the secret using a LabelSelector 12/14/22 09:00:45.975
STEP: listing secrets in all namespaces, searching for label name and value in patch 12/14/22 09:00:45.988
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:00:46.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2999" for this suite. 12/14/22 09:00:46.013
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":61,"skipped":1175,"failed":0}
------------------------------
• [0.176 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:45.848
    Dec 14 09:00:45.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:00:45.85
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:45.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:45.904
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 12/14/22 09:00:45.925
    STEP: listing secrets in all namespaces to ensure that there are more than zero 12/14/22 09:00:45.937
    STEP: patching the secret 12/14/22 09:00:45.95
    STEP: deleting the secret using a LabelSelector 12/14/22 09:00:45.975
    STEP: listing secrets in all namespaces, searching for label name and value in patch 12/14/22 09:00:45.988
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:00:46.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2999" for this suite. 12/14/22 09:00:46.013
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:00:46.025
Dec 14 09:00:46.026: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 09:00:46.026
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:46.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:46.08
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 12/14/22 09:00:46.1
Dec 14 09:00:46.100: INFO: PodSpec: initContainers in spec.initContainers
Dec 14 09:01:33.688: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-24852fc1-993a-4507-842e-e624cd8fbd24", GenerateName:"", Namespace:"init-container-676", SelfLink:"", UID:"b2dc3870-57a4-4546-8d62-a3d8dbabfe1c", ResourceVersion:"23882", Generation:0, CreationTimestamp:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"100891672"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"370fc3bd124ef41785b2e7179f1d2842f995b6000e41a8fe1ad8a843c1b9245b", "cni.projectcalico.org/podIP":"172.16.0.75/32", "cni.projectcalico.org/podIPs":"172.16.0.75/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 1, 33, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba180), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kf27f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002ca9700), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0030aef38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"izgw8jfcr55yi09nr0a5xaz", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000a3db90), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030aefb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030aefd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0030aefd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0030aefdc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000412ed0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.18.72", PodIP:"172.16.0.75", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.0.75"}}, StartTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a3dc70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a3dce0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://24f22622cff38f8de7ebc1b02a15e4e814a56e385da16388e73fe9445553696e", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ca9780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ca9760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0030af06f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:01:33.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-676" for this suite. 12/14/22 09:01:33.711
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":62,"skipped":1210,"failed":0}
------------------------------
• [47.698 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:00:46.025
    Dec 14 09:00:46.026: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 09:00:46.026
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:00:46.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:00:46.08
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 12/14/22 09:00:46.1
    Dec 14 09:00:46.100: INFO: PodSpec: initContainers in spec.initContainers
    Dec 14 09:01:33.688: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-24852fc1-993a-4507-842e-e624cd8fbd24", GenerateName:"", Namespace:"init-container-676", SelfLink:"", UID:"b2dc3870-57a4-4546-8d62-a3d8dbabfe1c", ResourceVersion:"23882", Generation:0, CreationTimestamp:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"100891672"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"370fc3bd124ef41785b2e7179f1d2842f995b6000e41a8fe1ad8a843c1b9245b", "cni.projectcalico.org/podIP":"172.16.0.75/32", "cni.projectcalico.org/podIPs":"172.16.0.75/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"Go-http-client", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba138), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.December, 14, 9, 1, 33, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000fba180), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kf27f", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002ca9700), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf27f", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0030aef38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"izgw8jfcr55yi09nr0a5xaz", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000a3db90), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030aefb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0030aefd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0030aefd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0030aefdc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000412ed0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.18.72", PodIP:"172.16.0.75", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.0.75"}}, StartTime:time.Date(2022, time.December, 14, 9, 0, 46, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a3dc70)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000a3dce0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://24f22622cff38f8de7ebc1b02a15e4e814a56e385da16388e73fe9445553696e", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ca9780), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002ca9760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0030af06f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:01:33.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-676" for this suite. 12/14/22 09:01:33.711
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:33.726
Dec 14 09:01:33.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:01:33.727
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:33.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:33.782
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:01:33.803
Dec 14 09:01:33.822: INFO: Waiting up to 5m0s for pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755" in namespace "downward-api-3004" to be "Succeeded or Failed"
Dec 14 09:01:33.833: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Pending", Reason="", readiness=false. Elapsed: 11.014639ms
Dec 14 09:01:35.845: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023297243s
Dec 14 09:01:37.846: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023804191s
STEP: Saw pod success 12/14/22 09:01:37.846
Dec 14 09:01:37.846: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755" satisfied condition "Succeeded or Failed"
Dec 14 09:01:37.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 container client-container: <nil>
STEP: delete the pod 12/14/22 09:01:37.922
Dec 14 09:01:37.938: INFO: Waiting for pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 to disappear
Dec 14 09:01:37.949: INFO: Pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:01:37.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3004" for this suite. 12/14/22 09:01:37.969
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":63,"skipped":1253,"failed":0}
------------------------------
• [4.259 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:33.726
    Dec 14 09:01:33.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:01:33.727
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:33.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:33.782
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:01:33.803
    Dec 14 09:01:33.822: INFO: Waiting up to 5m0s for pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755" in namespace "downward-api-3004" to be "Succeeded or Failed"
    Dec 14 09:01:33.833: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Pending", Reason="", readiness=false. Elapsed: 11.014639ms
    Dec 14 09:01:35.845: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023297243s
    Dec 14 09:01:37.846: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023804191s
    STEP: Saw pod success 12/14/22 09:01:37.846
    Dec 14 09:01:37.846: INFO: Pod "downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:37.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:01:37.922
    Dec 14 09:01:37.938: INFO: Waiting for pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 to disappear
    Dec 14 09:01:37.949: INFO: Pod downwardapi-volume-339d5f70-e6db-4602-ba94-582518248755 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:01:37.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3004" for this suite. 12/14/22 09:01:37.969
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:37.986
Dec 14 09:01:37.986: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:01:37.987
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:38.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:38.043
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 12/14/22 09:01:38.064
STEP: wait for the container to reach Failed 12/14/22 09:01:38.082
STEP: get the container status 12/14/22 09:01:42.141
STEP: the container should be terminated 12/14/22 09:01:42.152
STEP: the termination message should be set 12/14/22 09:01:42.153
Dec 14 09:01:42.153: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/14/22 09:01:42.153
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:01:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7665" for this suite. 12/14/22 09:01:42.199
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":64,"skipped":1256,"failed":0}
------------------------------
• [4.227 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:37.986
    Dec 14 09:01:37.986: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:01:37.987
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:38.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:38.043
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 12/14/22 09:01:38.064
    STEP: wait for the container to reach Failed 12/14/22 09:01:38.082
    STEP: get the container status 12/14/22 09:01:42.141
    STEP: the container should be terminated 12/14/22 09:01:42.152
    STEP: the termination message should be set 12/14/22 09:01:42.153
    Dec 14 09:01:42.153: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/14/22 09:01:42.153
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:01:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7665" for this suite. 12/14/22 09:01:42.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:42.213
Dec 14 09:01:42.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:01:42.214
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:42.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:42.269
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-78fde0cc-e033-425b-81bb-6317e4d34a00 12/14/22 09:01:42.289
STEP: Creating a pod to test consume secrets 12/14/22 09:01:42.301
Dec 14 09:01:42.320: INFO: Waiting up to 5m0s for pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8" in namespace "secrets-3281" to be "Succeeded or Failed"
Dec 14 09:01:42.331: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.407288ms
Dec 14 09:01:44.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024207191s
Dec 14 09:01:46.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024219158s
STEP: Saw pod success 12/14/22 09:01:46.344
Dec 14 09:01:46.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8" satisfied condition "Succeeded or Failed"
Dec 14 09:01:46.356: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:01:46.378
Dec 14 09:01:46.393: INFO: Waiting for pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 to disappear
Dec 14 09:01:46.404: INFO: Pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:01:46.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3281" for this suite. 12/14/22 09:01:46.425
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":65,"skipped":1268,"failed":0}
------------------------------
• [4.223 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:42.213
    Dec 14 09:01:42.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:01:42.214
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:42.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:42.269
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-78fde0cc-e033-425b-81bb-6317e4d34a00 12/14/22 09:01:42.289
    STEP: Creating a pod to test consume secrets 12/14/22 09:01:42.301
    Dec 14 09:01:42.320: INFO: Waiting up to 5m0s for pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8" in namespace "secrets-3281" to be "Succeeded or Failed"
    Dec 14 09:01:42.331: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.407288ms
    Dec 14 09:01:44.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024207191s
    Dec 14 09:01:46.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024219158s
    STEP: Saw pod success 12/14/22 09:01:46.344
    Dec 14 09:01:46.344: INFO: Pod "pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:46.356: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:01:46.378
    Dec 14 09:01:46.393: INFO: Waiting for pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 to disappear
    Dec 14 09:01:46.404: INFO: Pod pod-secrets-c7c61ba3-8ed6-4298-a3ef-4193ee5a24b8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:01:46.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3281" for this suite. 12/14/22 09:01:46.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:46.438
Dec 14 09:01:46.438: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:01:46.438
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:46.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:46.498
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 12/14/22 09:01:46.519
Dec 14 09:01:46.538: INFO: Waiting up to 5m0s for pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a" in namespace "downward-api-4820" to be "running and ready"
Dec 14 09:01:46.550: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.860143ms
Dec 14 09:01:46.550: INFO: The phase of Pod labelsupdate050199ce-84eb-483c-9aca-3b93d008230a is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:01:48.563: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a": Phase="Running", Reason="", readiness=true. Elapsed: 2.024883748s
Dec 14 09:01:48.563: INFO: The phase of Pod labelsupdate050199ce-84eb-483c-9aca-3b93d008230a is Running (Ready = true)
Dec 14 09:01:48.563: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a" satisfied condition "running and ready"
Dec 14 09:01:49.125: INFO: Successfully updated pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:01:51.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4820" for this suite. 12/14/22 09:01:51.193
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":66,"skipped":1295,"failed":0}
------------------------------
• [4.768 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:46.438
    Dec 14 09:01:46.438: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:01:46.438
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:46.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:46.498
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 12/14/22 09:01:46.519
    Dec 14 09:01:46.538: INFO: Waiting up to 5m0s for pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a" in namespace "downward-api-4820" to be "running and ready"
    Dec 14 09:01:46.550: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.860143ms
    Dec 14 09:01:46.550: INFO: The phase of Pod labelsupdate050199ce-84eb-483c-9aca-3b93d008230a is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:01:48.563: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a": Phase="Running", Reason="", readiness=true. Elapsed: 2.024883748s
    Dec 14 09:01:48.563: INFO: The phase of Pod labelsupdate050199ce-84eb-483c-9aca-3b93d008230a is Running (Ready = true)
    Dec 14 09:01:48.563: INFO: Pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a" satisfied condition "running and ready"
    Dec 14 09:01:49.125: INFO: Successfully updated pod "labelsupdate050199ce-84eb-483c-9aca-3b93d008230a"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:01:51.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4820" for this suite. 12/14/22 09:01:51.193
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:51.206
Dec 14 09:01:51.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:01:51.207
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:51.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:51.262
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 12/14/22 09:01:51.283
STEP: fetching the ConfigMap 12/14/22 09:01:51.295
STEP: patching the ConfigMap 12/14/22 09:01:51.306
STEP: listing all ConfigMaps in all namespaces with a label selector 12/14/22 09:01:51.319
STEP: deleting the ConfigMap by collection with a label selector 12/14/22 09:01:51.331
STEP: listing all ConfigMaps in test namespace 12/14/22 09:01:51.346
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:01:51.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7020" for this suite. 12/14/22 09:01:51.369
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":67,"skipped":1299,"failed":0}
------------------------------
• [0.176 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:51.206
    Dec 14 09:01:51.206: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:01:51.207
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:51.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:51.262
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 12/14/22 09:01:51.283
    STEP: fetching the ConfigMap 12/14/22 09:01:51.295
    STEP: patching the ConfigMap 12/14/22 09:01:51.306
    STEP: listing all ConfigMaps in all namespaces with a label selector 12/14/22 09:01:51.319
    STEP: deleting the ConfigMap by collection with a label selector 12/14/22 09:01:51.331
    STEP: listing all ConfigMaps in test namespace 12/14/22 09:01:51.346
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:01:51.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7020" for this suite. 12/14/22 09:01:51.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:51.382
Dec 14 09:01:51.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:01:51.383
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:51.418
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:51.438
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:01:51.513
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:01:51.525
Dec 14 09:01:51.548: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:01:51.548: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:01:52.580: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:01:52.580: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 09:01:53.580: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:01:53.580: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets 12/14/22 09:01:53.592
STEP: DeleteCollection of the DaemonSets 12/14/22 09:01:53.605
STEP: Verify that ReplicaSets have been deleted 12/14/22 09:01:53.619
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Dec 14 09:01:53.655: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24083"},"items":null}

Dec 14 09:01:53.667: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24083"},"items":[{"metadata":{"name":"daemon-set-jbcwd","generateName":"daemon-set-","namespace":"daemonsets-2757","uid":"22f16b56-5279-4c1a-97b8-1a5ca747c777","resourceVersion":"24083","creationTimestamp":"2022-12-14T09:01:51Z","deletionTimestamp":"2022-12-14T09:02:23Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"465c562331641c99bd1887e54b016443485ba97ee5e76028e53e177248f00e9c","cni.projectcalico.org/podIP":"172.16.1.38/32","cni.projectcalico.org/podIPs":"172.16.1.38/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"90399af0-0b6f-476a-be7f-7498ff7a3e1c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90399af0-0b6f-476a-be7f-7498ff7a3e1c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6mstw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6mstw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"izgw86e9lj0cm6u1hvldynz","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["izgw86e9lj0cm6u1hvldynz"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"}],"hostIP":"10.250.18.71","podIP":"172.16.1.38","podIPs":[{"ip":"172.16.1.38"}],"startTime":"2022-12-14T09:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T09:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://5890206aa221e8eca31ae6ce69e539456aac58761b5f991017e278c1427a6d3a","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wbws9","generateName":"daemon-set-","namespace":"daemonsets-2757","uid":"664849be-c6b3-4f10-81b2-ccbca28516a4","resourceVersion":"24082","creationTimestamp":"2022-12-14T09:01:51Z","deletionTimestamp":"2022-12-14T09:02:23Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"4bdb769ff43fcc53633d780ea7e2769cb59d26b7123fc9cef2a49cd801990594","cni.projectcalico.org/podIP":"172.16.0.80/32","cni.projectcalico.org/podIPs":"172.16.0.80/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"90399af0-0b6f-476a-be7f-7498ff7a3e1c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90399af0-0b6f-476a-be7f-7498ff7a3e1c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gptm6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gptm6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"izgw8jfcr55yi09nr0a5xaz","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["izgw8jfcr55yi09nr0a5xaz"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"}],"hostIP":"10.250.18.72","podIP":"172.16.0.80","podIPs":[{"ip":"172.16.0.80"}],"startTime":"2022-12-14T09:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T09:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://3c0979ee98cacc177c6ea9c93b6320241b04424b08b3e53be86d2342ed2e16ce","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:01:53.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2757" for this suite. 12/14/22 09:01:53.715
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":68,"skipped":1307,"failed":0}
------------------------------
• [2.345 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:51.382
    Dec 14 09:01:51.382: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:01:51.383
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:51.418
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:51.438
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:01:51.513
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:01:51.525
    Dec 14 09:01:51.548: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:01:51.548: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:01:52.580: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:01:52.580: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 09:01:53.580: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:01:53.580: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: listing all DeamonSets 12/14/22 09:01:53.592
    STEP: DeleteCollection of the DaemonSets 12/14/22 09:01:53.605
    STEP: Verify that ReplicaSets have been deleted 12/14/22 09:01:53.619
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Dec 14 09:01:53.655: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24083"},"items":null}

    Dec 14 09:01:53.667: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24083"},"items":[{"metadata":{"name":"daemon-set-jbcwd","generateName":"daemon-set-","namespace":"daemonsets-2757","uid":"22f16b56-5279-4c1a-97b8-1a5ca747c777","resourceVersion":"24083","creationTimestamp":"2022-12-14T09:01:51Z","deletionTimestamp":"2022-12-14T09:02:23Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"465c562331641c99bd1887e54b016443485ba97ee5e76028e53e177248f00e9c","cni.projectcalico.org/podIP":"172.16.1.38/32","cni.projectcalico.org/podIPs":"172.16.1.38/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"90399af0-0b6f-476a-be7f-7498ff7a3e1c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90399af0-0b6f-476a-be7f-7498ff7a3e1c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.38\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6mstw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6mstw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"izgw86e9lj0cm6u1hvldynz","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["izgw86e9lj0cm6u1hvldynz"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"}],"hostIP":"10.250.18.71","podIP":"172.16.1.38","podIPs":[{"ip":"172.16.1.38"}],"startTime":"2022-12-14T09:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T09:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://5890206aa221e8eca31ae6ce69e539456aac58761b5f991017e278c1427a6d3a","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-wbws9","generateName":"daemon-set-","namespace":"daemonsets-2757","uid":"664849be-c6b3-4f10-81b2-ccbca28516a4","resourceVersion":"24082","creationTimestamp":"2022-12-14T09:01:51Z","deletionTimestamp":"2022-12-14T09:02:23Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"4bdb769ff43fcc53633d780ea7e2769cb59d26b7123fc9cef2a49cd801990594","cni.projectcalico.org/podIP":"172.16.0.80/32","cni.projectcalico.org/podIPs":"172.16.0.80/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"90399af0-0b6f-476a-be7f-7498ff7a3e1c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"Go-http-client","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"90399af0-0b6f-476a-be7f-7498ff7a3e1c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-12-14T09:01:52Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gptm6","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gptm6","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"izgw8jfcr55yi09nr0a5xaz","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["izgw8jfcr55yi09nr0a5xaz"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:52Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-12-14T09:01:51Z"}],"hostIP":"10.250.18.72","podIP":"172.16.0.80","podIPs":[{"ip":"172.16.0.80"}],"startTime":"2022-12-14T09:01:51Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-12-14T09:01:52Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://3c0979ee98cacc177c6ea9c93b6320241b04424b08b3e53be86d2342ed2e16ce","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:01:53.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2757" for this suite. 12/14/22 09:01:53.715
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:53.729
Dec 14 09:01:53.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables 12/14/22 09:01:53.729
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:53.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:53.785
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Dec 14 09:01:53.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4806" for this suite. 12/14/22 09:01:53.839
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":69,"skipped":1344,"failed":0}
------------------------------
• [0.123 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:53.729
    Dec 14 09:01:53.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename tables 12/14/22 09:01:53.729
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:53.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:53.785
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Dec 14 09:01:53.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-4806" for this suite. 12/14/22 09:01:53.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:53.852
Dec 14 09:01:53.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:01:53.853
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:53.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:53.908
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:01:53.928
Dec 14 09:01:53.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16" in namespace "projected-9867" to be "Succeeded or Failed"
Dec 14 09:01:53.958: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Pending", Reason="", readiness=false. Elapsed: 10.814864ms
Dec 14 09:01:55.970: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022920689s
Dec 14 09:01:57.972: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025075973s
STEP: Saw pod success 12/14/22 09:01:57.972
Dec 14 09:01:57.973: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16" satisfied condition "Succeeded or Failed"
Dec 14 09:01:57.984: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 container client-container: <nil>
STEP: delete the pod 12/14/22 09:01:58.008
Dec 14 09:01:58.023: INFO: Waiting for pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 to disappear
Dec 14 09:01:58.034: INFO: Pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:01:58.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9867" for this suite. 12/14/22 09:01:58.054
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":70,"skipped":1365,"failed":0}
------------------------------
• [4.214 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:53.852
    Dec 14 09:01:53.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:01:53.853
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:53.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:53.908
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:01:53.928
    Dec 14 09:01:53.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16" in namespace "projected-9867" to be "Succeeded or Failed"
    Dec 14 09:01:53.958: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Pending", Reason="", readiness=false. Elapsed: 10.814864ms
    Dec 14 09:01:55.970: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022920689s
    Dec 14 09:01:57.972: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025075973s
    STEP: Saw pod success 12/14/22 09:01:57.972
    Dec 14 09:01:57.973: INFO: Pod "downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16" satisfied condition "Succeeded or Failed"
    Dec 14 09:01:57.984: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:01:58.008
    Dec 14 09:01:58.023: INFO: Waiting for pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 to disappear
    Dec 14 09:01:58.034: INFO: Pod downwardapi-volume-dfa5ec64-5b52-494a-93e0-48f5d9cf8f16 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:01:58.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9867" for this suite. 12/14/22 09:01:58.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:01:58.067
Dec 14 09:01:58.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:01:58.068
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:58.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:58.123
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-6e335c65-e6b9-4ca4-a5b4-8a170096835a 12/14/22 09:01:58.155
STEP: Creating secret with name s-test-opt-upd-e8ca57ca-4353-4591-8e53-52fee392569f 12/14/22 09:01:58.167
STEP: Creating the pod 12/14/22 09:01:58.179
Dec 14 09:01:58.198: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d" in namespace "projected-3006" to be "running and ready"
Dec 14 09:01:58.209: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.92143ms
Dec 14 09:01:58.209: INFO: The phase of Pod pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:02:00.222: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d": Phase="Running", Reason="", readiness=true. Elapsed: 2.023429611s
Dec 14 09:02:00.222: INFO: The phase of Pod pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d is Running (Ready = true)
Dec 14 09:02:00.222: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-6e335c65-e6b9-4ca4-a5b4-8a170096835a 12/14/22 09:02:00.41
STEP: Updating secret s-test-opt-upd-e8ca57ca-4353-4591-8e53-52fee392569f 12/14/22 09:02:00.423
STEP: Creating secret with name s-test-opt-create-553053f6-9bbf-41ca-a0c9-1b8298dfd787 12/14/22 09:02:00.435
STEP: waiting to observe update in volume 12/14/22 09:02:00.447
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:02:04.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3006" for this suite. 12/14/22 09:02:04.727
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":71,"skipped":1378,"failed":0}
------------------------------
• [6.673 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:01:58.067
    Dec 14 09:01:58.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:01:58.068
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:01:58.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:01:58.123
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-6e335c65-e6b9-4ca4-a5b4-8a170096835a 12/14/22 09:01:58.155
    STEP: Creating secret with name s-test-opt-upd-e8ca57ca-4353-4591-8e53-52fee392569f 12/14/22 09:01:58.167
    STEP: Creating the pod 12/14/22 09:01:58.179
    Dec 14 09:01:58.198: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d" in namespace "projected-3006" to be "running and ready"
    Dec 14 09:01:58.209: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.92143ms
    Dec 14 09:01:58.209: INFO: The phase of Pod pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:02:00.222: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d": Phase="Running", Reason="", readiness=true. Elapsed: 2.023429611s
    Dec 14 09:02:00.222: INFO: The phase of Pod pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d is Running (Ready = true)
    Dec 14 09:02:00.222: INFO: Pod "pod-projected-secrets-f5104beb-3530-4ade-8ec7-cfacb6ba642d" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-6e335c65-e6b9-4ca4-a5b4-8a170096835a 12/14/22 09:02:00.41
    STEP: Updating secret s-test-opt-upd-e8ca57ca-4353-4591-8e53-52fee392569f 12/14/22 09:02:00.423
    STEP: Creating secret with name s-test-opt-create-553053f6-9bbf-41ca-a0c9-1b8298dfd787 12/14/22 09:02:00.435
    STEP: waiting to observe update in volume 12/14/22 09:02:00.447
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:02:04.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3006" for this suite. 12/14/22 09:02:04.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:02:04.741
Dec 14 09:02:04.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:02:04.742
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:02:04.777
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:02:04.797
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 12/14/22 09:02:04.817
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local;sleep 1; done
 12/14/22 09:02:04.83
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local;sleep 1; done
 12/14/22 09:02:04.83
STEP: creating a pod to probe DNS 12/14/22 09:02:04.83
STEP: submitting the pod to kubernetes 12/14/22 09:02:04.83
Dec 14 09:02:04.854: INFO: Waiting up to 15m0s for pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a" in namespace "dns-9245" to be "running"
Dec 14 09:02:04.871: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.490497ms
Dec 14 09:02:06.884: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a": Phase="Running", Reason="", readiness=true. Elapsed: 2.030193291s
Dec 14 09:02:06.884: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:02:06.884
STEP: looking for the results for each expected name from probers 12/14/22 09:02:06.896
Dec 14 09:02:07.019: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.073: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.090: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.108: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.127: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.164: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.182: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:07.182: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:12.200: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.226: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.276: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.293: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.312: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.329: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.347: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.364: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:12.364: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:17.209: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.267: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.320: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.342: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.360: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.378: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.395: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.412: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:17.412: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:22.201: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.248: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.265: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.283: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.300: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.318: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.335: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.353: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:22.353: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:27.201: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.248: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.266: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.287: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.309: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.330: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.351: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.368: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:27.368: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:32.202: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.232: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.280: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.297: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.315: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.334: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.351: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.368: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
Dec 14 09:02:32.368: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

Dec 14 09:02:37.353: INFO: DNS probes using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a succeeded

STEP: deleting the pod 12/14/22 09:02:37.353
STEP: deleting the test headless service 12/14/22 09:02:37.37
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:02:37.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9245" for this suite. 12/14/22 09:02:37.405
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":72,"skipped":1412,"failed":0}
------------------------------
• [32.676 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:02:04.741
    Dec 14 09:02:04.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:02:04.742
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:02:04.777
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:02:04.797
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 12/14/22 09:02:04.817
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local;sleep 1; done
     12/14/22 09:02:04.83
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9245.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local;sleep 1; done
     12/14/22 09:02:04.83
    STEP: creating a pod to probe DNS 12/14/22 09:02:04.83
    STEP: submitting the pod to kubernetes 12/14/22 09:02:04.83
    Dec 14 09:02:04.854: INFO: Waiting up to 15m0s for pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a" in namespace "dns-9245" to be "running"
    Dec 14 09:02:04.871: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.490497ms
    Dec 14 09:02:06.884: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a": Phase="Running", Reason="", readiness=true. Elapsed: 2.030193291s
    Dec 14 09:02:06.884: INFO: Pod "dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:02:06.884
    STEP: looking for the results for each expected name from probers 12/14/22 09:02:06.896
    Dec 14 09:02:07.019: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.073: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.090: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.108: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.127: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.147: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.164: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.182: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:07.182: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:12.200: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.226: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.276: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.293: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.312: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.329: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.347: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.364: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:12.364: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:17.209: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.267: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.320: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.342: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.360: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.378: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.395: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.412: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:17.412: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:22.201: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.248: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.265: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.283: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.300: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.318: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.335: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.353: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:22.353: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:27.201: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.248: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.266: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.287: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.309: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.330: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.351: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.368: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:27.368: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:32.202: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.232: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.280: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.297: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.315: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.334: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.351: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.368: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local from pod dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a: the server could not find the requested resource (get pods dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a)
    Dec 14 09:02:32.368: INFO: Lookups using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9245.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9245.svc.cluster.local jessie_udp@dns-test-service-2.dns-9245.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9245.svc.cluster.local]

    Dec 14 09:02:37.353: INFO: DNS probes using dns-9245/dns-test-82652c27-a4b5-4bc9-a982-4c881995c16a succeeded

    STEP: deleting the pod 12/14/22 09:02:37.353
    STEP: deleting the test headless service 12/14/22 09:02:37.37
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:02:37.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9245" for this suite. 12/14/22 09:02:37.405
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:02:37.419
Dec 14 09:02:37.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:02:37.42
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:02:37.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:02:37.474
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f in namespace container-probe-7027 12/14/22 09:02:37.505
Dec 14 09:02:37.525: INFO: Waiting up to 5m0s for pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f" in namespace "container-probe-7027" to be "not pending"
Dec 14 09:02:37.536: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.314242ms
Dec 14 09:02:39.548: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f": Phase="Running", Reason="", readiness=true. Elapsed: 2.023515701s
Dec 14 09:02:39.548: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f" satisfied condition "not pending"
Dec 14 09:02:39.548: INFO: Started pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f in namespace container-probe-7027
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:02:39.548
Dec 14 09:02:39.560: INFO: Initial restart count of pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f is 0
STEP: deleting the pod 12/14/22 09:06:41.16
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:06:41.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7027" for this suite. 12/14/22 09:06:41.196
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":73,"skipped":1455,"failed":0}
------------------------------
• [243.789 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:02:37.419
    Dec 14 09:02:37.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:02:37.42
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:02:37.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:02:37.474
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f in namespace container-probe-7027 12/14/22 09:02:37.505
    Dec 14 09:02:37.525: INFO: Waiting up to 5m0s for pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f" in namespace "container-probe-7027" to be "not pending"
    Dec 14 09:02:37.536: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.314242ms
    Dec 14 09:02:39.548: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f": Phase="Running", Reason="", readiness=true. Elapsed: 2.023515701s
    Dec 14 09:02:39.548: INFO: Pod "liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f" satisfied condition "not pending"
    Dec 14 09:02:39.548: INFO: Started pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f in namespace container-probe-7027
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:02:39.548
    Dec 14 09:02:39.560: INFO: Initial restart count of pod liveness-b9dd5e66-5c06-4a0d-bfd8-c53438a9680f is 0
    STEP: deleting the pod 12/14/22 09:06:41.16
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:06:41.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7027" for this suite. 12/14/22 09:06:41.196
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:41.209
Dec 14 09:06:41.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:06:41.21
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:41.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:41.264
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:06:41.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4505" for this suite. 12/14/22 09:06:41.407
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":74,"skipped":1461,"failed":0}
------------------------------
• [0.210 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:41.209
    Dec 14 09:06:41.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:06:41.21
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:41.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:41.264
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:06:41.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4505" for this suite. 12/14/22 09:06:41.407
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:41.419
Dec 14 09:06:41.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:06:41.42
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:41.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:41.475
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/14/22 09:06:41.496
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:06:41.88
STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:06:41.894
STEP: Wait for the deployment to be ready 12/14/22 09:06:41.919
Dec 14 09:06:41.952: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-crd-conversion-webhook-deployment-59dfc5db8d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:06:43.965
STEP: Verifying the service has paired with the endpoint 12/14/22 09:06:43.981
Dec 14 09:06:44.982: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Dec 14 09:06:44.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource 12/14/22 09:06:47.229
STEP: v2 custom resource should be converted 12/14/22 09:06:47.241
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:06:47.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4480" for this suite. 12/14/22 09:06:47.868
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":75,"skipped":1462,"failed":0}
------------------------------
• [6.516 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:41.419
    Dec 14 09:06:41.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:06:41.42
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:41.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:41.475
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/14/22 09:06:41.496
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:06:41.88
    STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:06:41.894
    STEP: Wait for the deployment to be ready 12/14/22 09:06:41.919
    Dec 14 09:06:41.952: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-crd-conversion-webhook-deployment-59dfc5db8d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 6, 41, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:06:43.965
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:06:43.981
    Dec 14 09:06:44.982: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Dec 14 09:06:44.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating a v1 custom resource 12/14/22 09:06:47.229
    STEP: v2 custom resource should be converted 12/14/22 09:06:47.241
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:06:47.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-4480" for this suite. 12/14/22 09:06:47.868
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:47.936
Dec 14 09:06:47.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 09:06:47.937
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:47.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:48.009
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 09:06:48.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1411" for this suite. 12/14/22 09:06:48.128
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":76,"skipped":1462,"failed":0}
------------------------------
• [0.205 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:47.936
    Dec 14 09:06:47.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 09:06:47.937
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:47.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:48.009
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 09:06:48.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-1411" for this suite. 12/14/22 09:06:48.128
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:48.141
Dec 14 09:06:48.141: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:06:48.142
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:48.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:48.197
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:06:48.218
Dec 14 09:06:48.247: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46" in namespace "projected-8572" to be "Succeeded or Failed"
Dec 14 09:06:48.259: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Pending", Reason="", readiness=false. Elapsed: 11.532112ms
Dec 14 09:06:50.272: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024495577s
Dec 14 09:06:52.273: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025275299s
STEP: Saw pod success 12/14/22 09:06:52.273
Dec 14 09:06:52.273: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46" satisfied condition "Succeeded or Failed"
Dec 14 09:06:52.284: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 container client-container: <nil>
STEP: delete the pod 12/14/22 09:06:52.434
Dec 14 09:06:52.448: INFO: Waiting for pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 to disappear
Dec 14 09:06:52.460: INFO: Pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:06:52.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8572" for this suite. 12/14/22 09:06:52.48
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":77,"skipped":1464,"failed":0}
------------------------------
• [4.351 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:48.141
    Dec 14 09:06:48.141: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:06:48.142
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:48.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:48.197
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:06:48.218
    Dec 14 09:06:48.247: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46" in namespace "projected-8572" to be "Succeeded or Failed"
    Dec 14 09:06:48.259: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Pending", Reason="", readiness=false. Elapsed: 11.532112ms
    Dec 14 09:06:50.272: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024495577s
    Dec 14 09:06:52.273: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025275299s
    STEP: Saw pod success 12/14/22 09:06:52.273
    Dec 14 09:06:52.273: INFO: Pod "downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46" satisfied condition "Succeeded or Failed"
    Dec 14 09:06:52.284: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:06:52.434
    Dec 14 09:06:52.448: INFO: Waiting for pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 to disappear
    Dec 14 09:06:52.460: INFO: Pod downwardapi-volume-eb6cc6a4-2198-427c-a209-2b9017ae0f46 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:06:52.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8572" for this suite. 12/14/22 09:06:52.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:52.493
Dec 14 09:06:52.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 09:06:52.494
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:52.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:52.556
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 12/14/22 09:06:52.577
STEP: getting /apis/discovery.k8s.io 12/14/22 09:06:52.597
STEP: getting /apis/discovery.k8s.iov1 12/14/22 09:06:52.607
STEP: creating 12/14/22 09:06:52.617
STEP: getting 12/14/22 09:06:52.653
STEP: listing 12/14/22 09:06:52.664
STEP: watching 12/14/22 09:06:52.675
Dec 14 09:06:52.675: INFO: starting watch
STEP: cluster-wide listing 12/14/22 09:06:52.686
STEP: cluster-wide watching 12/14/22 09:06:52.698
Dec 14 09:06:52.698: INFO: starting watch
STEP: patching 12/14/22 09:06:52.708
STEP: updating 12/14/22 09:06:52.721
Dec 14 09:06:52.744: INFO: waiting for watch events with expected annotations
Dec 14 09:06:52.744: INFO: saw patched and updated annotations
STEP: deleting 12/14/22 09:06:52.744
STEP: deleting a collection 12/14/22 09:06:52.779
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 09:06:52.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9322" for this suite. 12/14/22 09:06:52.817
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":78,"skipped":1476,"failed":0}
------------------------------
• [0.337 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:52.493
    Dec 14 09:06:52.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 09:06:52.494
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:52.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:52.556
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 12/14/22 09:06:52.577
    STEP: getting /apis/discovery.k8s.io 12/14/22 09:06:52.597
    STEP: getting /apis/discovery.k8s.iov1 12/14/22 09:06:52.607
    STEP: creating 12/14/22 09:06:52.617
    STEP: getting 12/14/22 09:06:52.653
    STEP: listing 12/14/22 09:06:52.664
    STEP: watching 12/14/22 09:06:52.675
    Dec 14 09:06:52.675: INFO: starting watch
    STEP: cluster-wide listing 12/14/22 09:06:52.686
    STEP: cluster-wide watching 12/14/22 09:06:52.698
    Dec 14 09:06:52.698: INFO: starting watch
    STEP: patching 12/14/22 09:06:52.708
    STEP: updating 12/14/22 09:06:52.721
    Dec 14 09:06:52.744: INFO: waiting for watch events with expected annotations
    Dec 14 09:06:52.744: INFO: saw patched and updated annotations
    STEP: deleting 12/14/22 09:06:52.744
    STEP: deleting a collection 12/14/22 09:06:52.779
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 09:06:52.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9322" for this suite. 12/14/22 09:06:52.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:06:52.831
Dec 14 09:06:52.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:06:52.832
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:52.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:52.887
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 12/14/22 09:06:52.919
STEP: Patching the Job 12/14/22 09:06:52.932
STEP: Watching for Job to be patched 12/14/22 09:06:52.948
Dec 14 09:06:52.959: INFO: Event ADDED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec 14 09:06:52.959: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j] and annotations: map[batch.kubernetes.io/job-tracking:]
Dec 14 09:06:52.959: INFO: Event MODIFIED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 12/14/22 09:06:52.959
STEP: Watching for Job to be updated 12/14/22 09:06:52.983
Dec 14 09:06:52.994: INFO: Event MODIFIED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:06:52.994: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 12/14/22 09:06:52.994
Dec 14 09:06:53.005: INFO: Job: e2e-kgp9j as labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched]
STEP: Waiting for job to complete 12/14/22 09:06:53.005
STEP: Delete a job collection with a labelselector 12/14/22 09:07:01.017
STEP: Watching for Job to be deleted 12/14/22 09:07:01.032
Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Dec 14 09:07:01.043: INFO: Event DELETED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 12/14/22 09:07:01.043
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:07:01.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6661" for this suite. 12/14/22 09:07:01.066
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":79,"skipped":1486,"failed":0}
------------------------------
• [8.248 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:06:52.831
    Dec 14 09:06:52.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:06:52.832
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:06:52.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:06:52.887
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 12/14/22 09:06:52.919
    STEP: Patching the Job 12/14/22 09:06:52.932
    STEP: Watching for Job to be patched 12/14/22 09:06:52.948
    Dec 14 09:06:52.959: INFO: Event ADDED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec 14 09:06:52.959: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j] and annotations: map[batch.kubernetes.io/job-tracking:]
    Dec 14 09:06:52.959: INFO: Event MODIFIED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 12/14/22 09:06:52.959
    STEP: Watching for Job to be updated 12/14/22 09:06:52.983
    Dec 14 09:06:52.994: INFO: Event MODIFIED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:06:52.994: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 12/14/22 09:06:52.994
    Dec 14 09:06:53.005: INFO: Job: e2e-kgp9j as labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched]
    STEP: Waiting for job to complete 12/14/22 09:06:53.005
    STEP: Delete a job collection with a labelselector 12/14/22 09:07:01.017
    STEP: Watching for Job to be deleted 12/14/22 09:07:01.032
    Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:07:01.043: INFO: Event MODIFIED observed for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Dec 14 09:07:01.043: INFO: Event DELETED found for Job e2e-kgp9j in namespace job-6661 with labels: map[e2e-job-label:e2e-kgp9j e2e-kgp9j:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 12/14/22 09:07:01.043
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:07:01.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6661" for this suite. 12/14/22 09:07:01.066
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:01.079
Dec 14 09:07:01.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:07:01.08
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:01.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:01.136
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-8341 12/14/22 09:07:01.157
STEP: creating a selector 12/14/22 09:07:01.158
STEP: Creating the service pods in kubernetes 12/14/22 09:07:01.158
Dec 14 09:07:01.158: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:07:01.217: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8341" to be "running and ready"
Dec 14 09:07:01.235: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.074796ms
Dec 14 09:07:01.235: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:07:03.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.031251317s
Dec 14 09:07:03.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:05.247: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.029777909s
Dec 14 09:07:05.247: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:07.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.031321947s
Dec 14 09:07:07.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:09.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.031018504s
Dec 14 09:07:09.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:11.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.031309478s
Dec 14 09:07:11.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:13.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.030917872s
Dec 14 09:07:13.248: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:07:13.248: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:07:13.279: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8341" to be "running and ready"
Dec 14 09:07:13.291: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.653619ms
Dec 14 09:07:13.291: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:07:13.291: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:07:13.302
Dec 14 09:07:13.318: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8341" to be "running"
Dec 14 09:07:13.329: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.820076ms
Dec 14 09:07:15.341: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022559523s
Dec 14 09:07:15.341: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:07:15.355: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:07:15.355: INFO: Breadth first check of 172.16.1.39 on host 10.250.18.71...
Dec 14 09:07:15.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.92:9080/dial?request=hostname&protocol=http&host=172.16.1.39&port=8083&tries=1'] Namespace:pod-network-test-8341 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:07:15.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:07:15.368: INFO: ExecWithOptions: Clientset creation
Dec 14 09:07:15.368: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-8341/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.92%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.1.39%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:07:15.914: INFO: Waiting for responses: map[]
Dec 14 09:07:15.914: INFO: reached 172.16.1.39 after 0/1 tries
Dec 14 09:07:15.914: INFO: Breadth first check of 172.16.0.91 on host 10.250.18.72...
Dec 14 09:07:15.925: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.92:9080/dial?request=hostname&protocol=http&host=172.16.0.91&port=8083&tries=1'] Namespace:pod-network-test-8341 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:07:15.925: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:07:15.926: INFO: ExecWithOptions: Clientset creation
Dec 14 09:07:15.926: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-8341/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.92%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.91%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:07:16.246: INFO: Waiting for responses: map[]
Dec 14 09:07:16.246: INFO: reached 172.16.0.91 after 0/1 tries
Dec 14 09:07:16.246: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:07:16.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8341" for this suite. 12/14/22 09:07:16.268
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":80,"skipped":1487,"failed":0}
------------------------------
• [15.201 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:01.079
    Dec 14 09:07:01.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:07:01.08
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:01.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:01.136
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-8341 12/14/22 09:07:01.157
    STEP: creating a selector 12/14/22 09:07:01.158
    STEP: Creating the service pods in kubernetes 12/14/22 09:07:01.158
    Dec 14 09:07:01.158: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:07:01.217: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8341" to be "running and ready"
    Dec 14 09:07:01.235: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.074796ms
    Dec 14 09:07:01.235: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:07:03.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.031251317s
    Dec 14 09:07:03.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:05.247: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.029777909s
    Dec 14 09:07:05.247: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:07.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.031321947s
    Dec 14 09:07:07.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:09.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.031018504s
    Dec 14 09:07:09.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:11.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.031309478s
    Dec 14 09:07:11.248: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:13.248: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.030917872s
    Dec 14 09:07:13.248: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:07:13.248: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:07:13.279: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8341" to be "running and ready"
    Dec 14 09:07:13.291: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.653619ms
    Dec 14 09:07:13.291: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:07:13.291: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:07:13.302
    Dec 14 09:07:13.318: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8341" to be "running"
    Dec 14 09:07:13.329: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.820076ms
    Dec 14 09:07:15.341: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.022559523s
    Dec 14 09:07:15.341: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:07:15.355: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:07:15.355: INFO: Breadth first check of 172.16.1.39 on host 10.250.18.71...
    Dec 14 09:07:15.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.92:9080/dial?request=hostname&protocol=http&host=172.16.1.39&port=8083&tries=1'] Namespace:pod-network-test-8341 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:07:15.367: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:07:15.368: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:07:15.368: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-8341/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.92%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.1.39%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:07:15.914: INFO: Waiting for responses: map[]
    Dec 14 09:07:15.914: INFO: reached 172.16.1.39 after 0/1 tries
    Dec 14 09:07:15.914: INFO: Breadth first check of 172.16.0.91 on host 10.250.18.72...
    Dec 14 09:07:15.925: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.92:9080/dial?request=hostname&protocol=http&host=172.16.0.91&port=8083&tries=1'] Namespace:pod-network-test-8341 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:07:15.925: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:07:15.926: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:07:15.926: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-8341/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.92%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.0.91%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:07:16.246: INFO: Waiting for responses: map[]
    Dec 14 09:07:16.246: INFO: reached 172.16.0.91 after 0/1 tries
    Dec 14 09:07:16.246: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:07:16.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8341" for this suite. 12/14/22 09:07:16.268
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:16.283
Dec 14 09:07:16.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:07:16.284
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:16.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:16.346
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 12/14/22 09:07:16.367
Dec 14 09:07:16.367: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1416 cluster-info'
Dec 14 09:07:16.450: INFO: stderr: ""
Dec 14 09:07:16.450: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:07:16.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1416" for this suite. 12/14/22 09:07:16.463
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":81,"skipped":1547,"failed":0}
------------------------------
• [0.194 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:16.283
    Dec 14 09:07:16.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:07:16.284
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:16.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:16.346
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 12/14/22 09:07:16.367
    Dec 14 09:07:16.367: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1416 cluster-info'
    Dec 14 09:07:16.450: INFO: stderr: ""
    Dec 14 09:07:16.450: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:07:16.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1416" for this suite. 12/14/22 09:07:16.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:16.478
Dec 14 09:07:16.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:07:16.479
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:16.524
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:16.545
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-616 12/14/22 09:07:16.565
STEP: creating a selector 12/14/22 09:07:16.566
STEP: Creating the service pods in kubernetes 12/14/22 09:07:16.566
Dec 14 09:07:16.566: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:07:16.623: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-616" to be "running and ready"
Dec 14 09:07:16.634: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.117672ms
Dec 14 09:07:16.634: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:07:18.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.024227664s
Dec 14 09:07:18.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:20.651: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028151954s
Dec 14 09:07:20.651: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:22.648: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.024860224s
Dec 14 09:07:22.648: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:24.661: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.038730049s
Dec 14 09:07:24.661: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:26.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.023301259s
Dec 14 09:07:26.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:28.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.024675808s
Dec 14 09:07:28.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:30.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.023632257s
Dec 14 09:07:30.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:32.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.024340072s
Dec 14 09:07:32.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:34.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.023490486s
Dec 14 09:07:34.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:36.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.023648594s
Dec 14 09:07:36.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:07:38.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.024312886s
Dec 14 09:07:38.647: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:07:38.647: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:07:38.659: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-616" to be "running and ready"
Dec 14 09:07:38.670: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.49922ms
Dec 14 09:07:38.670: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:07:38.670: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:07:38.682
Dec 14 09:07:38.714: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-616" to be "running"
Dec 14 09:07:38.726: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.472398ms
Dec 14 09:07:40.739: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024476548s
Dec 14 09:07:40.739: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:07:40.750: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-616" to be "running"
Dec 14 09:07:40.762: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.550355ms
Dec 14 09:07:40.762: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec 14 09:07:40.774: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:07:40.774: INFO: Going to poll 172.16.1.40 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:07:40.785: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.1.40 8081 | grep -v '^\s*$'] Namespace:pod-network-test-616 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:07:40.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:07:40.786: INFO: ExecWithOptions: Clientset creation
Dec 14 09:07:40.786: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-616/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.1.40+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:07:42.124: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 14 09:07:42.124: INFO: Going to poll 172.16.0.93 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Dec 14 09:07:42.136: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.93 8081 | grep -v '^\s*$'] Namespace:pod-network-test-616 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:07:42.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:07:42.136: INFO: ExecWithOptions: Clientset creation
Dec 14 09:07:42.136: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-616/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.93+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:07:43.557: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:07:43.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-616" for this suite. 12/14/22 09:07:43.578
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":82,"skipped":1559,"failed":0}
------------------------------
• [27.113 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:16.478
    Dec 14 09:07:16.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:07:16.479
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:16.524
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:16.545
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-616 12/14/22 09:07:16.565
    STEP: creating a selector 12/14/22 09:07:16.566
    STEP: Creating the service pods in kubernetes 12/14/22 09:07:16.566
    Dec 14 09:07:16.566: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:07:16.623: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-616" to be "running and ready"
    Dec 14 09:07:16.634: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.117672ms
    Dec 14 09:07:16.634: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:07:18.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.024227664s
    Dec 14 09:07:18.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:20.651: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.028151954s
    Dec 14 09:07:20.651: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:22.648: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.024860224s
    Dec 14 09:07:22.648: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:24.661: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.038730049s
    Dec 14 09:07:24.661: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:26.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.023301259s
    Dec 14 09:07:26.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:28.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.024675808s
    Dec 14 09:07:28.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:30.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.023632257s
    Dec 14 09:07:30.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:32.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.024340072s
    Dec 14 09:07:32.647: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:34.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.023490486s
    Dec 14 09:07:34.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:36.646: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.023648594s
    Dec 14 09:07:36.646: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:07:38.647: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.024312886s
    Dec 14 09:07:38.647: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:07:38.647: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:07:38.659: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-616" to be "running and ready"
    Dec 14 09:07:38.670: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.49922ms
    Dec 14 09:07:38.670: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:07:38.670: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:07:38.682
    Dec 14 09:07:38.714: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-616" to be "running"
    Dec 14 09:07:38.726: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.472398ms
    Dec 14 09:07:40.739: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.024476548s
    Dec 14 09:07:40.739: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:07:40.750: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-616" to be "running"
    Dec 14 09:07:40.762: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.550355ms
    Dec 14 09:07:40.762: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec 14 09:07:40.774: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:07:40.774: INFO: Going to poll 172.16.1.40 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:07:40.785: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.1.40 8081 | grep -v '^\s*$'] Namespace:pod-network-test-616 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:07:40.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:07:40.786: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:07:40.786: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-616/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.1.40+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:07:42.124: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec 14 09:07:42.124: INFO: Going to poll 172.16.0.93 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 09:07:42.136: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.0.93 8081 | grep -v '^\s*$'] Namespace:pod-network-test-616 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:07:42.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:07:42.136: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:07:42.136: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-616/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.0.93+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:07:43.557: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:07:43.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-616" for this suite. 12/14/22 09:07:43.578
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:43.591
Dec 14 09:07:43.591: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:07:43.592
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:43.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:43.647
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 12/14/22 09:07:43.668
Dec 14 09:07:43.686: INFO: Waiting up to 5m0s for pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb" in namespace "downward-api-7534" to be "Succeeded or Failed"
Dec 14 09:07:43.697: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.106698ms
Dec 14 09:07:45.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023209471s
Dec 14 09:07:47.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023418945s
STEP: Saw pod success 12/14/22 09:07:47.709
Dec 14 09:07:47.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb" satisfied condition "Succeeded or Failed"
Dec 14 09:07:47.721: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:07:47.745
Dec 14 09:07:47.760: INFO: Waiting for pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb to disappear
Dec 14 09:07:47.771: INFO: Pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 09:07:47.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7534" for this suite. 12/14/22 09:07:47.792
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":83,"skipped":1576,"failed":0}
------------------------------
• [4.213 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:43.591
    Dec 14 09:07:43.591: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:07:43.592
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:43.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:43.647
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 12/14/22 09:07:43.668
    Dec 14 09:07:43.686: INFO: Waiting up to 5m0s for pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb" in namespace "downward-api-7534" to be "Succeeded or Failed"
    Dec 14 09:07:43.697: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.106698ms
    Dec 14 09:07:45.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023209471s
    Dec 14 09:07:47.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023418945s
    STEP: Saw pod success 12/14/22 09:07:47.709
    Dec 14 09:07:47.709: INFO: Pod "downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb" satisfied condition "Succeeded or Failed"
    Dec 14 09:07:47.721: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:07:47.745
    Dec 14 09:07:47.760: INFO: Waiting for pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb to disappear
    Dec 14 09:07:47.771: INFO: Pod downward-api-1f340ca7-eac0-4864-9069-99c44fe8f1bb no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 09:07:47.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7534" for this suite. 12/14/22 09:07:47.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:47.808
Dec 14 09:07:47.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:07:47.809
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:47.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:47.864
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Dec 14 09:07:47.885: INFO: Creating simple deployment test-new-deployment
Dec 14 09:07:47.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 12/14/22 09:07:49.955
STEP: updating a scale subresource 12/14/22 09:07:49.967
STEP: verifying the deployment Spec.Replicas was modified 12/14/22 09:07:49.991
STEP: Patch a scale subresource 12/14/22 09:07:50.003
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:07:50.039: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8559  31fc1e1b-dd6b-465b-bd19-eba84d9039a2 26447 3 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-14 09:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003766d68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:2,UpdatedReplicas:2,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-14 09:07:49 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:07:49 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 09:07:50.051: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8559  135f8172-22ea-4245-ad0f-30371f250516 26451 3 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 31fc1e1b-dd6b-465b-bd19-eba84d9039a2 0xc0028e6167 0xc0028e6168}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"31fc1e1b-dd6b-465b-bd19-eba84d9039a2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0028e61f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:07:50.063: INFO: Pod "test-new-deployment-845c8977d9-5bjhm" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-5bjhm test-new-deployment-845c8977d9- deployment-8559  5cdcb9ea-e94d-4e2f-8463-4240f377e0c7 26442 0 2022-12-14 09:07:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e65f7 0xc0028e65f8}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pwgzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pwgzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:07:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:07:50.063: INFO: Pod "test-new-deployment-845c8977d9-ctnjl" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-ctnjl test-new-deployment-845c8977d9- deployment-8559  46d10cc4-f250-486d-b837-4ab8e6bb930b 26454 0 2022-12-14 09:07:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e67b7 0xc0028e67b8}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cjsgp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cjsgp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:07:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:07:50.064: INFO: Pod "test-new-deployment-845c8977d9-nc4zc" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-nc4zc test-new-deployment-845c8977d9- deployment-8559  b0fdd9b2-da0f-454b-9788-6caf17b3920e 26452 0 2022-12-14 09:07:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e6977 0xc0028e6978}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wtmkx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wtmkx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:07:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:07:50.064: INFO: Pod "test-new-deployment-845c8977d9-ssv8f" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-ssv8f test-new-deployment-845c8977d9- deployment-8559  437f90d8-6751-49f0-8107-b40a45546cd5 26425 0 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b32b1fba7c7c7e1bfb5110f21640b4a972830dd852c7712bb138b62e8bc9c509 cni.projectcalico.org/podIP:172.16.0.96/32 cni.projectcalico.org/podIPs:172.16.0.96/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e6b57 0xc0028e6b58}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:07:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:07:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6pbtt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6pbtt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.96,StartTime:2022-12-14 09:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:07:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75be0b604276c0f9717f50d2eda92334a7c3ea526440f11ef71c9065338bf5e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:07:50.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8559" for this suite. 12/14/22 09:07:50.084
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":84,"skipped":1658,"failed":0}
------------------------------
• [2.289 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:47.808
    Dec 14 09:07:47.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:07:47.809
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:47.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:47.864
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Dec 14 09:07:47.885: INFO: Creating simple deployment test-new-deployment
    Dec 14 09:07:47.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 7, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 12/14/22 09:07:49.955
    STEP: updating a scale subresource 12/14/22 09:07:49.967
    STEP: verifying the deployment Spec.Replicas was modified 12/14/22 09:07:49.991
    STEP: Patch a scale subresource 12/14/22 09:07:50.003
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:07:50.039: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-8559  31fc1e1b-dd6b-465b-bd19-eba84d9039a2 26447 3 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-12-14 09:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003766d68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:2,UpdatedReplicas:2,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-12-14 09:07:49 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:07:49 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 09:07:50.051: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8559  135f8172-22ea-4245-ad0f-30371f250516 26451 3 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 31fc1e1b-dd6b-465b-bd19-eba84d9039a2 0xc0028e6167 0xc0028e6168}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"31fc1e1b-dd6b-465b-bd19-eba84d9039a2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0028e61f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:4,FullyLabeledReplicas:4,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:07:50.063: INFO: Pod "test-new-deployment-845c8977d9-5bjhm" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-5bjhm test-new-deployment-845c8977d9- deployment-8559  5cdcb9ea-e94d-4e2f-8463-4240f377e0c7 26442 0 2022-12-14 09:07:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e65f7 0xc0028e65f8}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pwgzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pwgzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:07:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:07:50.063: INFO: Pod "test-new-deployment-845c8977d9-ctnjl" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-ctnjl test-new-deployment-845c8977d9- deployment-8559  46d10cc4-f250-486d-b837-4ab8e6bb930b 26454 0 2022-12-14 09:07:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e67b7 0xc0028e67b8}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cjsgp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cjsgp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:07:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:07:50.064: INFO: Pod "test-new-deployment-845c8977d9-nc4zc" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-nc4zc test-new-deployment-845c8977d9- deployment-8559  b0fdd9b2-da0f-454b-9788-6caf17b3920e 26452 0 2022-12-14 09:07:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e6977 0xc0028e6978}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:07:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wtmkx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wtmkx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:07:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:07:50.064: INFO: Pod "test-new-deployment-845c8977d9-ssv8f" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-ssv8f test-new-deployment-845c8977d9- deployment-8559  437f90d8-6751-49f0-8107-b40a45546cd5 26425 0 2022-12-14 09:07:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b32b1fba7c7c7e1bfb5110f21640b4a972830dd852c7712bb138b62e8bc9c509 cni.projectcalico.org/podIP:172.16.0.96/32 cni.projectcalico.org/podIPs:172.16.0.96/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 135f8172-22ea-4245-ad0f-30371f250516 0xc0028e6b57 0xc0028e6b58}] [] [{kube-controller-manager Update v1 2022-12-14 09:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"135f8172-22ea-4245-ad0f-30371f250516\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:07:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:07:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.96\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6pbtt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6pbtt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.96,StartTime:2022-12-14 09:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:07:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75be0b604276c0f9717f50d2eda92334a7c3ea526440f11ef71c9065338bf5e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.96,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:07:50.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8559" for this suite. 12/14/22 09:07:50.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:07:50.099
Dec 14 09:07:50.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 09:07:50.099
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:50.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:50.155
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 09:07:50.177
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-hxxl 12/14/22 09:07:50.201
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 09:07:50.201
Dec 14 09:07:50.221: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hxxl" in namespace "subpath-7627" to be "Succeeded or Failed"
Dec 14 09:07:50.232: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.078547ms
Dec 14 09:07:52.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023401455s
Dec 14 09:07:54.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 4.023082438s
Dec 14 09:07:56.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 6.023120605s
Dec 14 09:07:58.246: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 8.025105408s
Dec 14 09:08:00.276: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 10.055605191s
Dec 14 09:08:02.245: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 12.024292905s
Dec 14 09:08:04.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 14.023746375s
Dec 14 09:08:06.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 16.022968363s
Dec 14 09:08:08.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 18.02355438s
Dec 14 09:08:10.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 20.023463772s
Dec 14 09:08:12.245: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=false. Elapsed: 22.023757871s
Dec 14 09:08:14.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023416171s
STEP: Saw pod success 12/14/22 09:08:14.244
Dec 14 09:08:14.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl" satisfied condition "Succeeded or Failed"
Dec 14 09:08:14.256: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-downwardapi-hxxl container test-container-subpath-downwardapi-hxxl: <nil>
STEP: delete the pod 12/14/22 09:08:14.279
Dec 14 09:08:14.295: INFO: Waiting for pod pod-subpath-test-downwardapi-hxxl to disappear
Dec 14 09:08:14.307: INFO: Pod pod-subpath-test-downwardapi-hxxl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hxxl 12/14/22 09:08:14.307
Dec 14 09:08:14.307: INFO: Deleting pod "pod-subpath-test-downwardapi-hxxl" in namespace "subpath-7627"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 09:08:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7627" for this suite. 12/14/22 09:08:14.34
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":85,"skipped":1679,"failed":0}
------------------------------
• [24.254 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:07:50.099
    Dec 14 09:07:50.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 09:07:50.099
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:07:50.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:07:50.155
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 09:07:50.177
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-hxxl 12/14/22 09:07:50.201
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 09:07:50.201
    Dec 14 09:07:50.221: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hxxl" in namespace "subpath-7627" to be "Succeeded or Failed"
    Dec 14 09:07:50.232: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.078547ms
    Dec 14 09:07:52.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 2.023401455s
    Dec 14 09:07:54.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 4.023082438s
    Dec 14 09:07:56.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 6.023120605s
    Dec 14 09:07:58.246: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 8.025105408s
    Dec 14 09:08:00.276: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 10.055605191s
    Dec 14 09:08:02.245: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 12.024292905s
    Dec 14 09:08:04.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 14.023746375s
    Dec 14 09:08:06.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 16.022968363s
    Dec 14 09:08:08.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 18.02355438s
    Dec 14 09:08:10.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=true. Elapsed: 20.023463772s
    Dec 14 09:08:12.245: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Running", Reason="", readiness=false. Elapsed: 22.023757871s
    Dec 14 09:08:14.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023416171s
    STEP: Saw pod success 12/14/22 09:08:14.244
    Dec 14 09:08:14.244: INFO: Pod "pod-subpath-test-downwardapi-hxxl" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:14.256: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-downwardapi-hxxl container test-container-subpath-downwardapi-hxxl: <nil>
    STEP: delete the pod 12/14/22 09:08:14.279
    Dec 14 09:08:14.295: INFO: Waiting for pod pod-subpath-test-downwardapi-hxxl to disappear
    Dec 14 09:08:14.307: INFO: Pod pod-subpath-test-downwardapi-hxxl no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-hxxl 12/14/22 09:08:14.307
    Dec 14 09:08:14.307: INFO: Deleting pod "pod-subpath-test-downwardapi-hxxl" in namespace "subpath-7627"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 09:08:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7627" for this suite. 12/14/22 09:08:14.34
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:14.353
Dec 14 09:08:14.353: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:08:14.354
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:14.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:14.409
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:08:14.43
Dec 14 09:08:14.430: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1852 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Dec 14 09:08:14.524: INFO: stderr: ""
Dec 14 09:08:14.524: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:08:14.524
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Dec 14 09:08:14.536: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1852 delete pods e2e-test-httpd-pod'
Dec 14 09:08:16.760: INFO: stderr: ""
Dec 14 09:08:16.760: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:08:16.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1852" for this suite. 12/14/22 09:08:16.781
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":86,"skipped":1679,"failed":0}
------------------------------
• [2.442 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:14.353
    Dec 14 09:08:14.353: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:08:14.354
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:14.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:14.409
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:08:14.43
    Dec 14 09:08:14.430: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1852 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Dec 14 09:08:14.524: INFO: stderr: ""
    Dec 14 09:08:14.524: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:08:14.524
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Dec 14 09:08:14.536: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1852 delete pods e2e-test-httpd-pod'
    Dec 14 09:08:16.760: INFO: stderr: ""
    Dec 14 09:08:16.760: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:08:16.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1852" for this suite. 12/14/22 09:08:16.781
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:16.796
Dec 14 09:08:16.796: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:08:16.796
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:16.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:16.852
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:08:16.873
Dec 14 09:08:16.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071" in namespace "projected-4097" to be "Succeeded or Failed"
Dec 14 09:08:16.903: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Pending", Reason="", readiness=false. Elapsed: 11.299526ms
Dec 14 09:08:18.916: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024255197s
Dec 14 09:08:20.915: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023433099s
STEP: Saw pod success 12/14/22 09:08:20.915
Dec 14 09:08:20.915: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071" satisfied condition "Succeeded or Failed"
Dec 14 09:08:20.927: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 container client-container: <nil>
STEP: delete the pod 12/14/22 09:08:20.956
Dec 14 09:08:20.972: INFO: Waiting for pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 to disappear
Dec 14 09:08:20.983: INFO: Pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:08:20.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4097" for this suite. 12/14/22 09:08:21.004
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":87,"skipped":1707,"failed":0}
------------------------------
• [4.221 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:16.796
    Dec 14 09:08:16.796: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:08:16.796
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:16.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:16.852
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:08:16.873
    Dec 14 09:08:16.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071" in namespace "projected-4097" to be "Succeeded or Failed"
    Dec 14 09:08:16.903: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Pending", Reason="", readiness=false. Elapsed: 11.299526ms
    Dec 14 09:08:18.916: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024255197s
    Dec 14 09:08:20.915: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023433099s
    STEP: Saw pod success 12/14/22 09:08:20.915
    Dec 14 09:08:20.915: INFO: Pod "downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:20.927: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:08:20.956
    Dec 14 09:08:20.972: INFO: Waiting for pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 to disappear
    Dec 14 09:08:20.983: INFO: Pod downwardapi-volume-884fea5d-02bc-49d4-89a7-f310f3555071 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:08:20.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4097" for this suite. 12/14/22 09:08:21.004
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:21.018
Dec 14 09:08:21.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:08:21.019
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:21.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:21.075
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 12/14/22 09:08:21.096
STEP: Ensure pods equal to paralellism count is attached to the job 12/14/22 09:08:21.109
STEP: patching /status 12/14/22 09:08:23.122
STEP: updating /status 12/14/22 09:08:23.136
STEP: get /status 12/14/22 09:08:23.161
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:08:23.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9123" for this suite. 12/14/22 09:08:23.194
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":88,"skipped":1740,"failed":0}
------------------------------
• [2.188 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:21.018
    Dec 14 09:08:21.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:08:21.019
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:21.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:21.075
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 12/14/22 09:08:21.096
    STEP: Ensure pods equal to paralellism count is attached to the job 12/14/22 09:08:21.109
    STEP: patching /status 12/14/22 09:08:23.122
    STEP: updating /status 12/14/22 09:08:23.136
    STEP: get /status 12/14/22 09:08:23.161
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:08:23.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9123" for this suite. 12/14/22 09:08:23.194
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:23.207
Dec 14 09:08:23.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 09:08:23.208
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:23.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:23.264
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Dec 14 09:08:23.303: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b" in namespace "security-context-test-6256" to be "Succeeded or Failed"
Dec 14 09:08:23.315: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.466175ms
Dec 14 09:08:25.327: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023695853s
Dec 14 09:08:27.328: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024941714s
Dec 14 09:08:27.329: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b" satisfied condition "Succeeded or Failed"
Dec 14 09:08:27.365: INFO: Got logs for pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 09:08:27.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6256" for this suite. 12/14/22 09:08:27.386
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":89,"skipped":1744,"failed":0}
------------------------------
• [4.192 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:23.207
    Dec 14 09:08:23.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 09:08:23.208
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:23.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:23.264
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Dec 14 09:08:23.303: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b" in namespace "security-context-test-6256" to be "Succeeded or Failed"
    Dec 14 09:08:23.315: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.466175ms
    Dec 14 09:08:25.327: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023695853s
    Dec 14 09:08:27.328: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024941714s
    Dec 14 09:08:27.329: INFO: Pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:27.365: INFO: Got logs for pod "busybox-privileged-false-2d4d27e5-694a-4965-b058-14e9f9d3355b": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 09:08:27.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6256" for this suite. 12/14/22 09:08:27.386
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:27.4
Dec 14 09:08:27.400: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:08:27.401
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:27.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:27.457
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 12/14/22 09:08:27.479
STEP: getting /apis/node.k8s.io 12/14/22 09:08:27.499
STEP: getting /apis/node.k8s.io/v1 12/14/22 09:08:27.512
STEP: creating 12/14/22 09:08:27.523
STEP: watching 12/14/22 09:08:27.56
Dec 14 09:08:27.560: INFO: starting watch
STEP: getting 12/14/22 09:08:27.582
STEP: listing 12/14/22 09:08:27.594
STEP: patching 12/14/22 09:08:27.606
STEP: updating 12/14/22 09:08:27.618
Dec 14 09:08:27.630: INFO: waiting for watch events with expected annotations
STEP: deleting 12/14/22 09:08:27.63
STEP: deleting a collection 12/14/22 09:08:27.666
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 09:08:27.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1688" for this suite. 12/14/22 09:08:27.705
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":90,"skipped":1745,"failed":0}
------------------------------
• [0.317 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:27.4
    Dec 14 09:08:27.400: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:08:27.401
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:27.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:27.457
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 12/14/22 09:08:27.479
    STEP: getting /apis/node.k8s.io 12/14/22 09:08:27.499
    STEP: getting /apis/node.k8s.io/v1 12/14/22 09:08:27.512
    STEP: creating 12/14/22 09:08:27.523
    STEP: watching 12/14/22 09:08:27.56
    Dec 14 09:08:27.560: INFO: starting watch
    STEP: getting 12/14/22 09:08:27.582
    STEP: listing 12/14/22 09:08:27.594
    STEP: patching 12/14/22 09:08:27.606
    STEP: updating 12/14/22 09:08:27.618
    Dec 14 09:08:27.630: INFO: waiting for watch events with expected annotations
    STEP: deleting 12/14/22 09:08:27.63
    STEP: deleting a collection 12/14/22 09:08:27.666
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 09:08:27.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1688" for this suite. 12/14/22 09:08:27.705
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:27.717
Dec 14 09:08:27.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:08:27.718
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:27.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:27.774
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-4cf235e9-09b0-451e-b122-1097b1cf5eb3 12/14/22 09:08:27.807
STEP: Creating the pod 12/14/22 09:08:27.819
Dec 14 09:08:27.838: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810" in namespace "configmap-4621" to be "running"
Dec 14 09:08:27.849: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810": Phase="Pending", Reason="", readiness=false. Elapsed: 11.116693ms
Dec 14 09:08:29.862: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810": Phase="Running", Reason="", readiness=false. Elapsed: 2.023894087s
Dec 14 09:08:29.862: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810" satisfied condition "running"
STEP: Waiting for pod with text data 12/14/22 09:08:29.862
STEP: Waiting for pod with binary data 12/14/22 09:08:29.885
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:08:30.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4621" for this suite. 12/14/22 09:08:30.097
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":91,"skipped":1745,"failed":0}
------------------------------
• [2.399 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:27.717
    Dec 14 09:08:27.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:08:27.718
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:27.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:27.774
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-4cf235e9-09b0-451e-b122-1097b1cf5eb3 12/14/22 09:08:27.807
    STEP: Creating the pod 12/14/22 09:08:27.819
    Dec 14 09:08:27.838: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810" in namespace "configmap-4621" to be "running"
    Dec 14 09:08:27.849: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810": Phase="Pending", Reason="", readiness=false. Elapsed: 11.116693ms
    Dec 14 09:08:29.862: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810": Phase="Running", Reason="", readiness=false. Elapsed: 2.023894087s
    Dec 14 09:08:29.862: INFO: Pod "pod-configmaps-cf241395-3b7f-45ff-a485-685ea4c57810" satisfied condition "running"
    STEP: Waiting for pod with text data 12/14/22 09:08:29.862
    STEP: Waiting for pod with binary data 12/14/22 09:08:29.885
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:08:30.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4621" for this suite. 12/14/22 09:08:30.097
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:30.116
Dec 14 09:08:30.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:08:30.117
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:30.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:30.172
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:08:30.253
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:08:30.265
Dec 14 09:08:30.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:08:30.289: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:08:31.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:08:31.323: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:08:32.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:08:32.323: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status 12/14/22 09:08:32.334
Dec 14 09:08:32.346: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 12/14/22 09:08:32.346
Dec 14 09:08:32.371: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 12/14/22 09:08:32.371
Dec 14 09:08:32.383: INFO: Observed &DaemonSet event: ADDED
Dec 14 09:08:32.383: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.384: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.384: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.384: INFO: Found daemon set daemon-set in namespace daemonsets-3188 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 09:08:32.384: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 12/14/22 09:08:32.384
STEP: watching for the daemon set status to be patched 12/14/22 09:08:32.398
Dec 14 09:08:32.408: INFO: Observed &DaemonSet event: ADDED
Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.409: INFO: Observed daemon set daemon-set in namespace daemonsets-3188 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
Dec 14 09:08:32.409: INFO: Found daemon set daemon-set in namespace daemonsets-3188 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Dec 14 09:08:32.409: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:08:32.42
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3188, will wait for the garbage collector to delete the pods 12/14/22 09:08:32.421
Dec 14 09:08:32.496: INFO: Deleting DaemonSet.extensions daemon-set took: 12.704767ms
Dec 14 09:08:32.596: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.162918ms
Dec 14 09:08:34.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:08:34.908: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:08:34.920: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26885"},"items":null}

Dec 14 09:08:34.931: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26885"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:08:34.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3188" for this suite. 12/14/22 09:08:34.988
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":92,"skipped":1745,"failed":0}
------------------------------
• [4.884 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:30.116
    Dec 14 09:08:30.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:08:30.117
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:30.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:30.172
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:08:30.253
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:08:30.265
    Dec 14 09:08:30.289: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:08:30.289: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:08:31.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:08:31.323: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:08:32.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:08:32.323: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Getting /status 12/14/22 09:08:32.334
    Dec 14 09:08:32.346: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 12/14/22 09:08:32.346
    Dec 14 09:08:32.371: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 12/14/22 09:08:32.371
    Dec 14 09:08:32.383: INFO: Observed &DaemonSet event: ADDED
    Dec 14 09:08:32.383: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.384: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.384: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.384: INFO: Found daemon set daemon-set in namespace daemonsets-3188 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 09:08:32.384: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 12/14/22 09:08:32.384
    STEP: watching for the daemon set status to be patched 12/14/22 09:08:32.398
    Dec 14 09:08:32.408: INFO: Observed &DaemonSet event: ADDED
    Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.409: INFO: Observed daemon set daemon-set in namespace daemonsets-3188 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 09:08:32.409: INFO: Observed &DaemonSet event: MODIFIED
    Dec 14 09:08:32.409: INFO: Found daemon set daemon-set in namespace daemonsets-3188 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Dec 14 09:08:32.409: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:08:32.42
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3188, will wait for the garbage collector to delete the pods 12/14/22 09:08:32.421
    Dec 14 09:08:32.496: INFO: Deleting DaemonSet.extensions daemon-set took: 12.704767ms
    Dec 14 09:08:32.596: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.162918ms
    Dec 14 09:08:34.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:08:34.908: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:08:34.920: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26885"},"items":null}

    Dec 14 09:08:34.931: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26885"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:08:34.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3188" for this suite. 12/14/22 09:08:34.988
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:35.001
Dec 14 09:08:35.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:08:35.002
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:35.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:35.058
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-4ccf941a-1d24-441c-8f0f-a9f808351539 12/14/22 09:08:35.079
STEP: Creating a pod to test consume secrets 12/14/22 09:08:35.091
Dec 14 09:08:35.111: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af" in namespace "projected-8686" to be "Succeeded or Failed"
Dec 14 09:08:35.122: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Pending", Reason="", readiness=false. Elapsed: 11.32183ms
Dec 14 09:08:37.136: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Running", Reason="", readiness=false. Elapsed: 2.024760125s
Dec 14 09:08:39.135: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023882296s
STEP: Saw pod success 12/14/22 09:08:39.135
Dec 14 09:08:39.135: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af" satisfied condition "Succeeded or Failed"
Dec 14 09:08:39.147: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:08:39.17
Dec 14 09:08:39.187: INFO: Waiting for pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af to disappear
Dec 14 09:08:39.198: INFO: Pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:08:39.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8686" for this suite. 12/14/22 09:08:39.22
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":93,"skipped":1749,"failed":0}
------------------------------
• [4.232 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:35.001
    Dec 14 09:08:35.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:08:35.002
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:35.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:35.058
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-4ccf941a-1d24-441c-8f0f-a9f808351539 12/14/22 09:08:35.079
    STEP: Creating a pod to test consume secrets 12/14/22 09:08:35.091
    Dec 14 09:08:35.111: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af" in namespace "projected-8686" to be "Succeeded or Failed"
    Dec 14 09:08:35.122: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Pending", Reason="", readiness=false. Elapsed: 11.32183ms
    Dec 14 09:08:37.136: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Running", Reason="", readiness=false. Elapsed: 2.024760125s
    Dec 14 09:08:39.135: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023882296s
    STEP: Saw pod success 12/14/22 09:08:39.135
    Dec 14 09:08:39.135: INFO: Pod "pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af" satisfied condition "Succeeded or Failed"
    Dec 14 09:08:39.147: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:08:39.17
    Dec 14 09:08:39.187: INFO: Waiting for pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af to disappear
    Dec 14 09:08:39.198: INFO: Pod pod-projected-secrets-36c360db-e7de-463d-b759-0b698599f5af no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:08:39.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8686" for this suite. 12/14/22 09:08:39.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:39.234
Dec 14 09:08:39.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:08:39.234
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:39.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:39.292
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 12/14/22 09:08:39.313
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:08:39.325
STEP: Creating a ResourceQuota with not best effort scope 12/14/22 09:08:41.338
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:08:41.35
STEP: Creating a best-effort pod 12/14/22 09:08:43.362
STEP: Ensuring resource quota with best effort scope captures the pod usage 12/14/22 09:08:43.384
STEP: Ensuring resource quota with not best effort ignored the pod usage 12/14/22 09:08:45.395
STEP: Deleting the pod 12/14/22 09:08:47.407
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:08:47.421
STEP: Creating a not best-effort pod 12/14/22 09:08:49.481
STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/14/22 09:08:49.526
STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/14/22 09:08:51.54
STEP: Deleting the pod 12/14/22 09:08:53.556
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:08:53.571
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:08:55.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4056" for this suite. 12/14/22 09:08:55.613
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":94,"skipped":1762,"failed":0}
------------------------------
• [16.392 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:39.234
    Dec 14 09:08:39.234: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:08:39.234
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:39.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:39.292
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 12/14/22 09:08:39.313
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:08:39.325
    STEP: Creating a ResourceQuota with not best effort scope 12/14/22 09:08:41.338
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:08:41.35
    STEP: Creating a best-effort pod 12/14/22 09:08:43.362
    STEP: Ensuring resource quota with best effort scope captures the pod usage 12/14/22 09:08:43.384
    STEP: Ensuring resource quota with not best effort ignored the pod usage 12/14/22 09:08:45.395
    STEP: Deleting the pod 12/14/22 09:08:47.407
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:08:47.421
    STEP: Creating a not best-effort pod 12/14/22 09:08:49.481
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 12/14/22 09:08:49.526
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 12/14/22 09:08:51.54
    STEP: Deleting the pod 12/14/22 09:08:53.556
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:08:53.571
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:08:55.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4056" for this suite. 12/14/22 09:08:55.613
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:55.626
Dec 14 09:08:55.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:08:55.627
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:55.662
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:55.684
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 12/14/22 09:08:55.706
Dec 14 09:08:55.706: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7690 proxy --unix-socket=/tmp/kubectl-proxy-unix2118785320/test'
STEP: retrieving proxy /api/ output 12/14/22 09:08:55.76
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:08:55.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7690" for this suite. 12/14/22 09:08:55.775
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":95,"skipped":1771,"failed":0}
------------------------------
• [0.163 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:55.626
    Dec 14 09:08:55.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:08:55.627
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:55.662
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:55.684
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 12/14/22 09:08:55.706
    Dec 14 09:08:55.706: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7690 proxy --unix-socket=/tmp/kubectl-proxy-unix2118785320/test'
    STEP: retrieving proxy /api/ output 12/14/22 09:08:55.76
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:08:55.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7690" for this suite. 12/14/22 09:08:55.775
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:55.791
Dec 14 09:08:55.791: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:08:55.791
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:55.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:55.849
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 12/14/22 09:08:55.872
Dec 14 09:08:55.872: INFO: Creating e2e-svc-a-2hxj9
Dec 14 09:08:55.888: INFO: Creating e2e-svc-b-xqf2l
Dec 14 09:08:55.905: INFO: Creating e2e-svc-c-296fr
STEP: deleting service collection 12/14/22 09:08:55.94
Dec 14 09:08:55.979: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:08:55.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-739" for this suite. 12/14/22 09:08:55.993
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":96,"skipped":1799,"failed":0}
------------------------------
• [0.217 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:55.791
    Dec 14 09:08:55.791: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:08:55.791
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:55.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:55.849
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 12/14/22 09:08:55.872
    Dec 14 09:08:55.872: INFO: Creating e2e-svc-a-2hxj9
    Dec 14 09:08:55.888: INFO: Creating e2e-svc-b-xqf2l
    Dec 14 09:08:55.905: INFO: Creating e2e-svc-c-296fr
    STEP: deleting service collection 12/14/22 09:08:55.94
    Dec 14 09:08:55.979: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:08:55.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-739" for this suite. 12/14/22 09:08:55.993
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:08:56.009
Dec 14 09:08:56.009: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:08:56.01
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:56.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:56.07
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-2889 12/14/22 09:08:56.099
STEP: creating service affinity-clusterip-transition in namespace services-2889 12/14/22 09:08:56.099
STEP: creating replication controller affinity-clusterip-transition in namespace services-2889 12/14/22 09:08:56.115
I1214 09:08:56.128851    6248 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2889, replica count: 3
I1214 09:08:59.180927    6248 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:08:59.207: INFO: Creating new exec pod
Dec 14 09:08:59.226: INFO: Waiting up to 5m0s for pod "execpod-affinityblbfd" in namespace "services-2889" to be "running"
Dec 14 09:08:59.239: INFO: Pod "execpod-affinityblbfd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385114ms
Dec 14 09:09:01.254: INFO: Pod "execpod-affinityblbfd": Phase="Running", Reason="", readiness=true. Elapsed: 2.0274292s
Dec 14 09:09:01.254: INFO: Pod "execpod-affinityblbfd" satisfied condition "running"
Dec 14 09:09:02.254: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Dec 14 09:09:02.829: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Dec 14 09:09:02.829: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:09:02.829: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.128.200 80'
Dec 14 09:09:03.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.128.200 80\nConnection to 172.31.128.200 80 port [tcp/http] succeeded!\n"
Dec 14 09:09:03.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:09:03.307: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.128.200:80/ ; done'
Dec 14 09:09:03.886: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n"
Dec 14 09:09:03.886: INFO: stdout: "\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-68l99"
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
Dec 14 09:09:03.915: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.128.200:80/ ; done'
Dec 14 09:09:04.458: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n"
Dec 14 09:09:04.458: INFO: stdout: "\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb"
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
Dec 14 09:09:04.458: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2889, will wait for the garbage collector to delete the pods 12/14/22 09:09:04.474
Dec 14 09:09:04.554: INFO: Deleting ReplicationController affinity-clusterip-transition took: 15.35241ms
Dec 14 09:09:04.655: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.122846ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:09:07.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2889" for this suite. 12/14/22 09:09:07.099
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":97,"skipped":1823,"failed":0}
------------------------------
• [11.105 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:08:56.009
    Dec 14 09:08:56.009: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:08:56.01
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:08:56.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:08:56.07
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-2889 12/14/22 09:08:56.099
    STEP: creating service affinity-clusterip-transition in namespace services-2889 12/14/22 09:08:56.099
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2889 12/14/22 09:08:56.115
    I1214 09:08:56.128851    6248 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2889, replica count: 3
    I1214 09:08:59.180927    6248 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:08:59.207: INFO: Creating new exec pod
    Dec 14 09:08:59.226: INFO: Waiting up to 5m0s for pod "execpod-affinityblbfd" in namespace "services-2889" to be "running"
    Dec 14 09:08:59.239: INFO: Pod "execpod-affinityblbfd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385114ms
    Dec 14 09:09:01.254: INFO: Pod "execpod-affinityblbfd": Phase="Running", Reason="", readiness=true. Elapsed: 2.0274292s
    Dec 14 09:09:01.254: INFO: Pod "execpod-affinityblbfd" satisfied condition "running"
    Dec 14 09:09:02.254: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Dec 14 09:09:02.829: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Dec 14 09:09:02.829: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:09:02.829: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.128.200 80'
    Dec 14 09:09:03.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.128.200 80\nConnection to 172.31.128.200 80 port [tcp/http] succeeded!\n"
    Dec 14 09:09:03.280: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:09:03.307: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.128.200:80/ ; done'
    Dec 14 09:09:03.886: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n"
    Dec 14 09:09:03.886: INFO: stdout: "\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-blbwv\naffinity-clusterip-transition-68l99\naffinity-clusterip-transition-68l99"
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-blbwv
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.886: INFO: Received response from host: affinity-clusterip-transition-68l99
    Dec 14 09:09:03.915: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2889 exec execpod-affinityblbfd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.128.200:80/ ; done'
    Dec 14 09:09:04.458: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.128.200:80/\n"
    Dec 14 09:09:04.458: INFO: stdout: "\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb\naffinity-clusterip-transition-6ztnb"
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Received response from host: affinity-clusterip-transition-6ztnb
    Dec 14 09:09:04.458: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2889, will wait for the garbage collector to delete the pods 12/14/22 09:09:04.474
    Dec 14 09:09:04.554: INFO: Deleting ReplicationController affinity-clusterip-transition took: 15.35241ms
    Dec 14 09:09:04.655: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.122846ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:09:07.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2889" for this suite. 12/14/22 09:09:07.099
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:09:07.114
Dec 14 09:09:07.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:09:07.115
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:07.156
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:07.18
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-318 12/14/22 09:09:07.203
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 12/14/22 09:09:07.218
STEP: Creating stateful set ss in namespace statefulset-318 12/14/22 09:09:07.231
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-318 12/14/22 09:09:07.245
Dec 14 09:09:07.259: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:09:17.272: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/14/22 09:09:17.272
Dec 14 09:09:17.284: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:09:17.797: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:09:17.797: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:09:17.797: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:09:17.809: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 14 09:09:27.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:09:27.823: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:09:27.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999485s
Dec 14 09:09:28.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987527012s
Dec 14 09:09:29.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975605046s
Dec 14 09:09:30.928: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9621995s
Dec 14 09:09:31.940: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.93204462s
Dec 14 09:09:32.953: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.918844706s
Dec 14 09:09:33.966: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.90628274s
Dec 14 09:09:34.977: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.893993656s
Dec 14 09:09:35.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.882350273s
Dec 14 09:09:37.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 870.19516ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-318 12/14/22 09:09:38.002
Dec 14 09:09:38.013: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:09:38.634: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:09:38.634: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:09:38.634: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:09:38.646: INFO: Found 1 stateful pods, waiting for 3
Dec 14 09:09:48.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:09:48.661: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:09:48.661: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 12/14/22 09:09:48.661
STEP: Scale down will halt with unhealthy stateful pod 12/14/22 09:09:48.662
Dec 14 09:09:48.685: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:09:49.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:09:49.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:09:49.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:09:49.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:09:49.669: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:09:49.669: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:09:49.669: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:09:49.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:09:50.218: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:09:50.218: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:09:50.218: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:09:50.218: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:09:50.230: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 14 09:10:00.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:10:00.258: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:10:00.258: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:10:00.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999578s
Dec 14 09:10:01.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987883467s
Dec 14 09:10:02.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974232918s
Dec 14 09:10:03.335: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.961652624s
Dec 14 09:10:04.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.949259487s
Dec 14 09:10:05.360: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.936408831s
Dec 14 09:10:06.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.924018274s
Dec 14 09:10:07.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.91155941s
Dec 14 09:10:08.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898203817s
Dec 14 09:10:09.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 885.792213ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-318 12/14/22 09:10:10.411
Dec 14 09:10:10.426: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:10:10.888: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:10:10.888: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:10:10.888: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:10:10.894: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:10:11.433: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:10:11.433: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:10:11.433: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:10:11.433: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:10:12.013: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:10:12.013: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:10:12.013: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:10:12.013: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 12/14/22 09:10:22.061
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:10:22.062: INFO: Deleting all statefulset in ns statefulset-318
Dec 14 09:10:22.073: INFO: Scaling statefulset ss to 0
Dec 14 09:10:22.109: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:10:22.121: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:10:22.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-318" for this suite. 12/14/22 09:10:22.177
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":98,"skipped":1823,"failed":0}
------------------------------
• [75.075 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:09:07.114
    Dec 14 09:09:07.114: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:09:07.115
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:09:07.156
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:09:07.18
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-318 12/14/22 09:09:07.203
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 12/14/22 09:09:07.218
    STEP: Creating stateful set ss in namespace statefulset-318 12/14/22 09:09:07.231
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-318 12/14/22 09:09:07.245
    Dec 14 09:09:07.259: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:09:17.272: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 12/14/22 09:09:17.272
    Dec 14 09:09:17.284: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:09:17.797: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:09:17.797: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:09:17.797: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:09:17.809: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec 14 09:09:27.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:09:27.823: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:09:27.872: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999485s
    Dec 14 09:09:28.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987527012s
    Dec 14 09:09:29.897: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975605046s
    Dec 14 09:09:30.928: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.9621995s
    Dec 14 09:09:31.940: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.93204462s
    Dec 14 09:09:32.953: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.918844706s
    Dec 14 09:09:33.966: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.90628274s
    Dec 14 09:09:34.977: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.893993656s
    Dec 14 09:09:35.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.882350273s
    Dec 14 09:09:37.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 870.19516ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-318 12/14/22 09:09:38.002
    Dec 14 09:09:38.013: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:09:38.634: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:09:38.634: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:09:38.634: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:09:38.646: INFO: Found 1 stateful pods, waiting for 3
    Dec 14 09:09:48.661: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:09:48.661: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:09:48.661: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 12/14/22 09:09:48.661
    STEP: Scale down will halt with unhealthy stateful pod 12/14/22 09:09:48.662
    Dec 14 09:09:48.685: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:09:49.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:09:49.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:09:49.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:09:49.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:09:49.669: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:09:49.669: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:09:49.669: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:09:49.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:09:50.218: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:09:50.218: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:09:50.218: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:09:50.218: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:09:50.230: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Dec 14 09:10:00.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:10:00.258: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:10:00.258: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:10:00.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999578s
    Dec 14 09:10:01.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987883467s
    Dec 14 09:10:02.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974232918s
    Dec 14 09:10:03.335: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.961652624s
    Dec 14 09:10:04.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.949259487s
    Dec 14 09:10:05.360: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.936408831s
    Dec 14 09:10:06.372: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.924018274s
    Dec 14 09:10:07.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.91155941s
    Dec 14 09:10:08.398: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898203817s
    Dec 14 09:10:09.410: INFO: Verifying statefulset ss doesn't scale past 3 for another 885.792213ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-318 12/14/22 09:10:10.411
    Dec 14 09:10:10.426: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:10:10.888: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:10:10.888: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:10:10.888: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:10:10.894: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:10:11.433: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:10:11.433: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:10:11.433: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:10:11.433: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-318 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:10:12.013: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:10:12.013: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:10:12.013: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:10:12.013: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 12/14/22 09:10:22.061
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:10:22.062: INFO: Deleting all statefulset in ns statefulset-318
    Dec 14 09:10:22.073: INFO: Scaling statefulset ss to 0
    Dec 14 09:10:22.109: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:10:22.121: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:10:22.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-318" for this suite. 12/14/22 09:10:22.177
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:22.19
Dec 14 09:10:22.190: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:10:22.191
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:22.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:22.246
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Dec 14 09:10:22.267: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/14/22 09:10:22.296
STEP: Checking rc "condition-test" has the desired failure condition set 12/14/22 09:10:22.31
STEP: Scaling down rc "condition-test" to satisfy pod quota 12/14/22 09:10:23.335
Dec 14 09:10:23.360: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 12/14/22 09:10:23.36
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:10:23.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2261" for this suite. 12/14/22 09:10:23.393
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":99,"skipped":1827,"failed":0}
------------------------------
• [1.216 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:22.19
    Dec 14 09:10:22.190: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:10:22.191
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:22.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:22.246
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Dec 14 09:10:22.267: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 12/14/22 09:10:22.296
    STEP: Checking rc "condition-test" has the desired failure condition set 12/14/22 09:10:22.31
    STEP: Scaling down rc "condition-test" to satisfy pod quota 12/14/22 09:10:23.335
    Dec 14 09:10:23.360: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 12/14/22 09:10:23.36
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:10:23.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2261" for this suite. 12/14/22 09:10:23.393
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:23.406
Dec 14 09:10:23.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:10:23.407
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:23.442
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:23.463
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5000 12/14/22 09:10:23.484
STEP: changing the ExternalName service to type=ClusterIP 12/14/22 09:10:23.495
STEP: creating replication controller externalname-service in namespace services-5000 12/14/22 09:10:23.524
I1214 09:10:23.536731    6248 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5000, replica count: 2
I1214 09:10:26.587836    6248 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:10:26.587: INFO: Creating new exec pod
Dec 14 09:10:26.605: INFO: Waiting up to 5m0s for pod "execpodmdrdv" in namespace "services-5000" to be "running"
Dec 14 09:10:26.616: INFO: Pod "execpodmdrdv": Phase="Pending", Reason="", readiness=false. Elapsed: 11.074606ms
Dec 14 09:10:28.628: INFO: Pod "execpodmdrdv": Phase="Running", Reason="", readiness=true. Elapsed: 2.02298832s
Dec 14 09:10:28.628: INFO: Pod "execpodmdrdv" satisfied condition "running"
Dec 14 09:10:29.629: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:10:30.208: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:10:30.208: INFO: stdout: ""
Dec 14 09:10:31.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:10:31.731: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:10:31.731: INFO: stdout: ""
Dec 14 09:10:32.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:10:32.819: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:10:32.819: INFO: stdout: "externalname-service-gscfl"
Dec 14 09:10:32.819: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.50.131 80'
Dec 14 09:10:33.414: INFO: stderr: "+ nc -v -t -w 2 172.24.50.131 80\nConnection to 172.24.50.131 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 14 09:10:33.415: INFO: stdout: "externalname-service-2xhtr"
Dec 14 09:10:33.415: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:10:33.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5000" for this suite. 12/14/22 09:10:33.452
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":100,"skipped":1827,"failed":0}
------------------------------
• [10.059 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:23.406
    Dec 14 09:10:23.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:10:23.407
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:23.442
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:23.463
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5000 12/14/22 09:10:23.484
    STEP: changing the ExternalName service to type=ClusterIP 12/14/22 09:10:23.495
    STEP: creating replication controller externalname-service in namespace services-5000 12/14/22 09:10:23.524
    I1214 09:10:23.536731    6248 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5000, replica count: 2
    I1214 09:10:26.587836    6248 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:10:26.587: INFO: Creating new exec pod
    Dec 14 09:10:26.605: INFO: Waiting up to 5m0s for pod "execpodmdrdv" in namespace "services-5000" to be "running"
    Dec 14 09:10:26.616: INFO: Pod "execpodmdrdv": Phase="Pending", Reason="", readiness=false. Elapsed: 11.074606ms
    Dec 14 09:10:28.628: INFO: Pod "execpodmdrdv": Phase="Running", Reason="", readiness=true. Elapsed: 2.02298832s
    Dec 14 09:10:28.628: INFO: Pod "execpodmdrdv" satisfied condition "running"
    Dec 14 09:10:29.629: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:10:30.208: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:10:30.208: INFO: stdout: ""
    Dec 14 09:10:31.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:10:31.731: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:10:31.731: INFO: stdout: ""
    Dec 14 09:10:32.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:10:32.819: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:10:32.819: INFO: stdout: "externalname-service-gscfl"
    Dec 14 09:10:32.819: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-5000 exec execpodmdrdv -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.50.131 80'
    Dec 14 09:10:33.414: INFO: stderr: "+ nc -v -t -w 2 172.24.50.131 80\nConnection to 172.24.50.131 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Dec 14 09:10:33.415: INFO: stdout: "externalname-service-2xhtr"
    Dec 14 09:10:33.415: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:10:33.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5000" for this suite. 12/14/22 09:10:33.452
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:33.466
Dec 14 09:10:33.466: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:10:33.467
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:33.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:33.529
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Dec 14 09:10:33.569: INFO: Waiting up to 5m0s for pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4" in namespace "container-probe-6345" to be "running and ready"
Dec 14 09:10:33.580: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.252479ms
Dec 14 09:10:33.580: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:10:35.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 2.023462286s
Dec 14 09:10:35.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:37.594: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 4.024858515s
Dec 14 09:10:37.594: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:39.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 6.023811628s
Dec 14 09:10:39.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:41.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 8.023698736s
Dec 14 09:10:41.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:43.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 10.02422871s
Dec 14 09:10:43.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:45.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 12.023331803s
Dec 14 09:10:45.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:47.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 14.023525987s
Dec 14 09:10:47.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:49.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 16.023679358s
Dec 14 09:10:49.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:51.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 18.023731903s
Dec 14 09:10:51.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:53.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 20.023871464s
Dec 14 09:10:53.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
Dec 14 09:10:55.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=true. Elapsed: 22.023763475s
Dec 14 09:10:55.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = true)
Dec 14 09:10:55.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4" satisfied condition "running and ready"
Dec 14 09:10:55.604: INFO: Container started at 2022-12-14 09:10:34 +0000 UTC, pod became ready at 2022-12-14 09:10:53 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:10:55.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6345" for this suite. 12/14/22 09:10:55.625
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":101,"skipped":1829,"failed":0}
------------------------------
• [22.172 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:33.466
    Dec 14 09:10:33.466: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:10:33.467
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:33.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:33.529
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Dec 14 09:10:33.569: INFO: Waiting up to 5m0s for pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4" in namespace "container-probe-6345" to be "running and ready"
    Dec 14 09:10:33.580: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.252479ms
    Dec 14 09:10:33.580: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:10:35.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 2.023462286s
    Dec 14 09:10:35.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:37.594: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 4.024858515s
    Dec 14 09:10:37.594: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:39.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 6.023811628s
    Dec 14 09:10:39.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:41.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 8.023698736s
    Dec 14 09:10:41.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:43.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 10.02422871s
    Dec 14 09:10:43.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:45.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 12.023331803s
    Dec 14 09:10:45.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:47.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 14.023525987s
    Dec 14 09:10:47.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:49.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 16.023679358s
    Dec 14 09:10:49.592: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:51.592: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 18.023731903s
    Dec 14 09:10:51.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:53.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=false. Elapsed: 20.023871464s
    Dec 14 09:10:53.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = false)
    Dec 14 09:10:55.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4": Phase="Running", Reason="", readiness=true. Elapsed: 22.023763475s
    Dec 14 09:10:55.593: INFO: The phase of Pod test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4 is Running (Ready = true)
    Dec 14 09:10:55.593: INFO: Pod "test-webserver-ebdb0869-045b-43ce-9579-a215ef60d9a4" satisfied condition "running and ready"
    Dec 14 09:10:55.604: INFO: Container started at 2022-12-14 09:10:34 +0000 UTC, pod became ready at 2022-12-14 09:10:53 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:10:55.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6345" for this suite. 12/14/22 09:10:55.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:10:55.639
Dec 14 09:10:55.640: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:10:55.641
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:55.677
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:55.698
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 12/14/22 09:10:55.719
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9256;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9256;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +notcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_tcp@PTR;sleep 1; done
 12/14/22 09:10:55.747
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9256;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9256;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +notcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_tcp@PTR;sleep 1; done
 12/14/22 09:10:55.747
STEP: creating a pod to probe DNS 12/14/22 09:10:55.747
STEP: submitting the pod to kubernetes 12/14/22 09:10:55.747
Dec 14 09:10:55.767: INFO: Waiting up to 15m0s for pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3" in namespace "dns-9256" to be "running"
Dec 14 09:10:55.778: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.367111ms
Dec 14 09:10:57.797: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3": Phase="Running", Reason="", readiness=true. Elapsed: 2.029861555s
Dec 14 09:10:57.797: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:10:57.797
STEP: looking for the results for each expected name from probers 12/14/22 09:10:57.808
Dec 14 09:10:57.952: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.001: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.018: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.035: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.052: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.090: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.113: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.202: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.219: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.237: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.254: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.271: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.289: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.306: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.323: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:10:58.394: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:03.415: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.461: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.486: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.503: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.528: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.546: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.563: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.581: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.676: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.693: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.711: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.753: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.771: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.800: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.820: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:03.905: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:08.415: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.464: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.482: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.499: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.522: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.539: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.561: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.578: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.667: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.684: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.702: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.739: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.758: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.776: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.793: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.811: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:08.919: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:13.416: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.468: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.486: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.504: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.527: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.545: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.563: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.580: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.669: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.688: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.706: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.742: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.760: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.778: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:13.866: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:18.500: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:18.612: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:18.703: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:18.802: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:18.907: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.020: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.139: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.228: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.245: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.263: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.280: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.298: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.315: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.333: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.355: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:19.427: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:23.419: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.473: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.494: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.525: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.547: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.567: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.587: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.610: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.716: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.738: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.759: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.781: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.802: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.823: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.843: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.863: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
Dec 14 09:11:23.959: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

Dec 14 09:11:28.871: INFO: DNS probes using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 succeeded

STEP: deleting the pod 12/14/22 09:11:28.871
STEP: deleting the test service 12/14/22 09:11:28.887
STEP: deleting the test headless service 12/14/22 09:11:28.906
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:11:28.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9256" for this suite. 12/14/22 09:11:28.933
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":102,"skipped":1893,"failed":0}
------------------------------
• [33.306 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:10:55.639
    Dec 14 09:10:55.640: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:10:55.641
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:10:55.677
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:10:55.698
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 12/14/22 09:10:55.719
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9256;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9256;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +notcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_tcp@PTR;sleep 1; done
     12/14/22 09:10:55.747
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9256;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9256;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9256.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9256.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9256.svc;check="$$(dig +notcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_udp@PTR;check="$$(dig +tcp +noall +answer +search 44.188.25.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.25.188.44_tcp@PTR;sleep 1; done
     12/14/22 09:10:55.747
    STEP: creating a pod to probe DNS 12/14/22 09:10:55.747
    STEP: submitting the pod to kubernetes 12/14/22 09:10:55.747
    Dec 14 09:10:55.767: INFO: Waiting up to 15m0s for pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3" in namespace "dns-9256" to be "running"
    Dec 14 09:10:55.778: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3": Phase="Pending", Reason="", readiness=false. Elapsed: 11.367111ms
    Dec 14 09:10:57.797: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3": Phase="Running", Reason="", readiness=true. Elapsed: 2.029861555s
    Dec 14 09:10:57.797: INFO: Pod "dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:10:57.797
    STEP: looking for the results for each expected name from probers 12/14/22 09:10:57.808
    Dec 14 09:10:57.952: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.001: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.018: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.035: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.052: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.072: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.090: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.113: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.202: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.219: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.237: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.254: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.271: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.289: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.306: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.323: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:10:58.394: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:03.415: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.461: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.486: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.503: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.528: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.546: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.563: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.581: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.676: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.693: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.711: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.753: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.771: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.800: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.820: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:03.905: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:08.415: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.464: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.482: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.499: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.522: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.539: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.561: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.578: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.667: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.684: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.702: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.739: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.758: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.776: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.793: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.811: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:08.919: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:13.416: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.468: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.486: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.504: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.527: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.545: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.563: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.580: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.669: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.688: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.706: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.742: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.760: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.778: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:13.866: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:18.500: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:18.612: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:18.703: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:18.802: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:18.907: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.020: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.139: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.228: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.245: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.263: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.280: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.298: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.315: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.333: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.355: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:19.427: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:23.419: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.473: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.494: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.525: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.547: INFO: Unable to read wheezy_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.567: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.587: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.610: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.716: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.738: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.759: INFO: Unable to read jessie_udp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.781: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256 from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.802: INFO: Unable to read jessie_udp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.823: INFO: Unable to read jessie_tcp@dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.843: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.863: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc from pod dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3: the server could not find the requested resource (get pods dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3)
    Dec 14 09:11:23.959: INFO: Lookups using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9256 wheezy_tcp@dns-test-service.dns-9256 wheezy_udp@dns-test-service.dns-9256.svc wheezy_tcp@dns-test-service.dns-9256.svc wheezy_udp@_http._tcp.dns-test-service.dns-9256.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9256.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9256 jessie_tcp@dns-test-service.dns-9256 jessie_udp@dns-test-service.dns-9256.svc jessie_tcp@dns-test-service.dns-9256.svc jessie_udp@_http._tcp.dns-test-service.dns-9256.svc jessie_tcp@_http._tcp.dns-test-service.dns-9256.svc]

    Dec 14 09:11:28.871: INFO: DNS probes using dns-9256/dns-test-e7c9ade1-3c93-40c4-8503-395e00eb72a3 succeeded

    STEP: deleting the pod 12/14/22 09:11:28.871
    STEP: deleting the test service 12/14/22 09:11:28.887
    STEP: deleting the test headless service 12/14/22 09:11:28.906
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:11:28.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9256" for this suite. 12/14/22 09:11:28.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:28.947
Dec 14 09:11:28.947: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:11:28.948
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:28.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:29.004
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-e67f1fb7-2174-4f70-933c-a598b00c6fcf 12/14/22 09:11:29.025
STEP: Creating a pod to test consume secrets 12/14/22 09:11:29.037
Dec 14 09:11:29.054: INFO: Waiting up to 5m0s for pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95" in namespace "secrets-791" to be "Succeeded or Failed"
Dec 14 09:11:29.066: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Pending", Reason="", readiness=false. Elapsed: 11.295393ms
Dec 14 09:11:31.078: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023259291s
Dec 14 09:11:33.079: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024911269s
STEP: Saw pod success 12/14/22 09:11:33.079
Dec 14 09:11:33.080: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95" satisfied condition "Succeeded or Failed"
Dec 14 09:11:33.091: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 container secret-env-test: <nil>
STEP: delete the pod 12/14/22 09:11:33.114
Dec 14 09:11:33.131: INFO: Waiting for pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 to disappear
Dec 14 09:11:33.142: INFO: Pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:11:33.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-791" for this suite. 12/14/22 09:11:33.165
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":103,"skipped":1909,"failed":0}
------------------------------
• [4.230 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:28.947
    Dec 14 09:11:28.947: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:11:28.948
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:28.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:29.004
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-e67f1fb7-2174-4f70-933c-a598b00c6fcf 12/14/22 09:11:29.025
    STEP: Creating a pod to test consume secrets 12/14/22 09:11:29.037
    Dec 14 09:11:29.054: INFO: Waiting up to 5m0s for pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95" in namespace "secrets-791" to be "Succeeded or Failed"
    Dec 14 09:11:29.066: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Pending", Reason="", readiness=false. Elapsed: 11.295393ms
    Dec 14 09:11:31.078: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023259291s
    Dec 14 09:11:33.079: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024911269s
    STEP: Saw pod success 12/14/22 09:11:33.079
    Dec 14 09:11:33.080: INFO: Pod "pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95" satisfied condition "Succeeded or Failed"
    Dec 14 09:11:33.091: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 container secret-env-test: <nil>
    STEP: delete the pod 12/14/22 09:11:33.114
    Dec 14 09:11:33.131: INFO: Waiting for pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 to disappear
    Dec 14 09:11:33.142: INFO: Pod pod-secrets-6c1d0cea-8020-445e-84cf-669a6df54b95 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:11:33.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-791" for this suite. 12/14/22 09:11:33.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:33.178
Dec 14 09:11:33.178: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:11:33.179
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:33.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:33.235
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-c751ff9f-2c2f-49c9-8d2c-cb37f4b7a3a3 12/14/22 09:11:33.256
STEP: Creating a pod to test consume secrets 12/14/22 09:11:33.268
Dec 14 09:11:33.287: INFO: Waiting up to 5m0s for pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd" in namespace "secrets-892" to be "Succeeded or Failed"
Dec 14 09:11:33.299: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.580251ms
Dec 14 09:11:35.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0242737s
Dec 14 09:11:37.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024537573s
STEP: Saw pod success 12/14/22 09:11:37.312
Dec 14 09:11:37.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd" satisfied condition "Succeeded or Failed"
Dec 14 09:11:37.324: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:11:37.347
Dec 14 09:11:37.363: INFO: Waiting for pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd to disappear
Dec 14 09:11:37.374: INFO: Pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:11:37.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-892" for this suite. 12/14/22 09:11:37.396
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":104,"skipped":1923,"failed":0}
------------------------------
• [4.231 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:33.178
    Dec 14 09:11:33.178: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:11:33.179
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:33.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:33.235
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-c751ff9f-2c2f-49c9-8d2c-cb37f4b7a3a3 12/14/22 09:11:33.256
    STEP: Creating a pod to test consume secrets 12/14/22 09:11:33.268
    Dec 14 09:11:33.287: INFO: Waiting up to 5m0s for pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd" in namespace "secrets-892" to be "Succeeded or Failed"
    Dec 14 09:11:33.299: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.580251ms
    Dec 14 09:11:35.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0242737s
    Dec 14 09:11:37.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024537573s
    STEP: Saw pod success 12/14/22 09:11:37.312
    Dec 14 09:11:37.312: INFO: Pod "pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd" satisfied condition "Succeeded or Failed"
    Dec 14 09:11:37.324: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:11:37.347
    Dec 14 09:11:37.363: INFO: Waiting for pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd to disappear
    Dec 14 09:11:37.374: INFO: Pod pod-secrets-483183ad-7acb-4014-b21e-74c81926cefd no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:11:37.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-892" for this suite. 12/14/22 09:11:37.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:37.409
Dec 14 09:11:37.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:11:37.41
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:37.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:37.466
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:11:37.514
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:38.089
STEP: Deploying the webhook pod 12/14/22 09:11:38.103
STEP: Wait for the deployment to be ready 12/14/22 09:11:38.129
Dec 14 09:11:38.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:11:40.177
STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:40.197
Dec 14 09:11:41.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Dec 14 09:11:41.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/14/22 09:11:41.233
STEP: Creating a custom resource that should be denied by the webhook 12/14/22 09:11:41.376
STEP: Creating a custom resource whose deletion would be denied by the webhook 12/14/22 09:11:43.532
STEP: Updating the custom resource with disallowed data should be denied 12/14/22 09:11:43.639
STEP: Deleting the custom resource should be denied 12/14/22 09:11:43.758
STEP: Remove the offending key and value from the custom resource data 12/14/22 09:11:43.866
STEP: Deleting the updated custom resource should be successful 12/14/22 09:11:43.986
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:11:44.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7121" for this suite. 12/14/22 09:11:44.666
STEP: Destroying namespace "webhook-7121-markers" for this suite. 12/14/22 09:11:44.679
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":105,"skipped":1931,"failed":0}
------------------------------
• [7.336 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:37.409
    Dec 14 09:11:37.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:11:37.41
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:37.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:37.466
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:11:37.514
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:11:38.089
    STEP: Deploying the webhook pod 12/14/22 09:11:38.103
    STEP: Wait for the deployment to be ready 12/14/22 09:11:38.129
    Dec 14 09:11:38.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 11, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:11:40.177
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:11:40.197
    Dec 14 09:11:41.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Dec 14 09:11:41.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 12/14/22 09:11:41.233
    STEP: Creating a custom resource that should be denied by the webhook 12/14/22 09:11:41.376
    STEP: Creating a custom resource whose deletion would be denied by the webhook 12/14/22 09:11:43.532
    STEP: Updating the custom resource with disallowed data should be denied 12/14/22 09:11:43.639
    STEP: Deleting the custom resource should be denied 12/14/22 09:11:43.758
    STEP: Remove the offending key and value from the custom resource data 12/14/22 09:11:43.866
    STEP: Deleting the updated custom resource should be successful 12/14/22 09:11:43.986
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:11:44.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7121" for this suite. 12/14/22 09:11:44.666
    STEP: Destroying namespace "webhook-7121-markers" for this suite. 12/14/22 09:11:44.679
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:44.746
Dec 14 09:11:44.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 09:11:44.748
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:44.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:44.803
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 12/14/22 09:11:44.824
Dec 14 09:11:44.824: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:11:48.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8523" for this suite. 12/14/22 09:11:48.726
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":106,"skipped":1932,"failed":0}
------------------------------
• [3.992 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:44.746
    Dec 14 09:11:44.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 09:11:44.748
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:44.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:44.803
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 12/14/22 09:11:44.824
    Dec 14 09:11:44.824: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:11:48.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8523" for this suite. 12/14/22 09:11:48.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:11:48.739
Dec 14 09:11:48.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:11:48.74
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:48.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:48.797
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/14/22 09:11:48.818
Dec 14 09:11:48.819: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/14/22 09:12:05.158
Dec 14 09:12:05.159: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:12:09.468: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:12:22.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4042" for this suite. 12/14/22 09:12:22.735
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":107,"skipped":1963,"failed":0}
------------------------------
• [34.009 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:11:48.739
    Dec 14 09:11:48.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:11:48.74
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:11:48.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:11:48.797
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 12/14/22 09:11:48.818
    Dec 14 09:11:48.819: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 12/14/22 09:12:05.158
    Dec 14 09:12:05.159: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:12:09.468: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:12:22.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4042" for this suite. 12/14/22 09:12:22.735
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:22.751
Dec 14 09:12:22.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:12:22.752
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:22.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:22.807
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-0b7af131-f616-4cb1-bc20-0a04dafcdcd1 12/14/22 09:12:22.84
STEP: Creating configMap with name cm-test-opt-upd-f013064d-af98-4fc5-8293-af8fe1a450b1 12/14/22 09:12:22.852
STEP: Creating the pod 12/14/22 09:12:22.864
Dec 14 09:12:22.883: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860" in namespace "projected-991" to be "running and ready"
Dec 14 09:12:22.893: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860": Phase="Pending", Reason="", readiness=false. Elapsed: 10.637984ms
Dec 14 09:12:22.894: INFO: The phase of Pod pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:12:24.906: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860": Phase="Running", Reason="", readiness=true. Elapsed: 2.023644923s
Dec 14 09:12:24.907: INFO: The phase of Pod pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860 is Running (Ready = true)
Dec 14 09:12:24.907: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-0b7af131-f616-4cb1-bc20-0a04dafcdcd1 12/14/22 09:12:25.172
STEP: Updating configmap cm-test-opt-upd-f013064d-af98-4fc5-8293-af8fe1a450b1 12/14/22 09:12:25.184
STEP: Creating configMap with name cm-test-opt-create-e6b0cd54-2fc2-44eb-b33c-9f529d0a3c98 12/14/22 09:12:25.197
STEP: waiting to observe update in volume 12/14/22 09:12:25.209
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:12:29.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-991" for this suite. 12/14/22 09:12:29.492
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":108,"skipped":2026,"failed":0}
------------------------------
• [6.754 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:22.751
    Dec 14 09:12:22.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:12:22.752
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:22.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:22.807
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-0b7af131-f616-4cb1-bc20-0a04dafcdcd1 12/14/22 09:12:22.84
    STEP: Creating configMap with name cm-test-opt-upd-f013064d-af98-4fc5-8293-af8fe1a450b1 12/14/22 09:12:22.852
    STEP: Creating the pod 12/14/22 09:12:22.864
    Dec 14 09:12:22.883: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860" in namespace "projected-991" to be "running and ready"
    Dec 14 09:12:22.893: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860": Phase="Pending", Reason="", readiness=false. Elapsed: 10.637984ms
    Dec 14 09:12:22.894: INFO: The phase of Pod pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:12:24.906: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860": Phase="Running", Reason="", readiness=true. Elapsed: 2.023644923s
    Dec 14 09:12:24.907: INFO: The phase of Pod pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860 is Running (Ready = true)
    Dec 14 09:12:24.907: INFO: Pod "pod-projected-configmaps-50e25edf-b952-4bbe-be67-3b31fefb7860" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-0b7af131-f616-4cb1-bc20-0a04dafcdcd1 12/14/22 09:12:25.172
    STEP: Updating configmap cm-test-opt-upd-f013064d-af98-4fc5-8293-af8fe1a450b1 12/14/22 09:12:25.184
    STEP: Creating configMap with name cm-test-opt-create-e6b0cd54-2fc2-44eb-b33c-9f529d0a3c98 12/14/22 09:12:25.197
    STEP: waiting to observe update in volume 12/14/22 09:12:25.209
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:12:29.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-991" for this suite. 12/14/22 09:12:29.492
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:29.506
Dec 14 09:12:29.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:12:29.507
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:29.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:29.563
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:12:29.591
Dec 14 09:12:29.610: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32" in namespace "projected-7040" to be "Succeeded or Failed"
Dec 14 09:12:29.621: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Pending", Reason="", readiness=false. Elapsed: 11.031392ms
Dec 14 09:12:31.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02435726s
Dec 14 09:12:33.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024459612s
STEP: Saw pod success 12/14/22 09:12:33.635
Dec 14 09:12:33.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32" satisfied condition "Succeeded or Failed"
Dec 14 09:12:33.647: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 container client-container: <nil>
STEP: delete the pod 12/14/22 09:12:33.674
Dec 14 09:12:33.689: INFO: Waiting for pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 to disappear
Dec 14 09:12:33.700: INFO: Pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:12:33.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7040" for this suite. 12/14/22 09:12:33.721
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":109,"skipped":2052,"failed":0}
------------------------------
• [4.228 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:29.506
    Dec 14 09:12:29.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:12:29.507
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:29.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:29.563
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:12:29.591
    Dec 14 09:12:29.610: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32" in namespace "projected-7040" to be "Succeeded or Failed"
    Dec 14 09:12:29.621: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Pending", Reason="", readiness=false. Elapsed: 11.031392ms
    Dec 14 09:12:31.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02435726s
    Dec 14 09:12:33.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024459612s
    STEP: Saw pod success 12/14/22 09:12:33.635
    Dec 14 09:12:33.635: INFO: Pod "downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32" satisfied condition "Succeeded or Failed"
    Dec 14 09:12:33.647: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:12:33.674
    Dec 14 09:12:33.689: INFO: Waiting for pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 to disappear
    Dec 14 09:12:33.700: INFO: Pod downwardapi-volume-73b7e918-163e-483e-88b2-039fcb2f5c32 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:12:33.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7040" for this suite. 12/14/22 09:12:33.721
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:33.735
Dec 14 09:12:33.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:12:33.736
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:33.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:33.792
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9028 12/14/22 09:12:33.813
STEP: changing the ExternalName service to type=NodePort 12/14/22 09:12:33.825
STEP: creating replication controller externalname-service in namespace services-9028 12/14/22 09:12:33.853
I1214 09:12:33.866842    6248 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9028, replica count: 2
I1214 09:12:36.919482    6248 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:12:36.919: INFO: Creating new exec pod
Dec 14 09:12:36.938: INFO: Waiting up to 5m0s for pod "execpodpc7zs" in namespace "services-9028" to be "running"
Dec 14 09:12:36.949: INFO: Pod "execpodpc7zs": Phase="Pending", Reason="", readiness=false. Elapsed: 11.392879ms
Dec 14 09:12:38.962: INFO: Pod "execpodpc7zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.023997735s
Dec 14 09:12:38.962: INFO: Pod "execpodpc7zs" satisfied condition "running"
Dec 14 09:12:39.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Dec 14 09:12:40.447: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 14 09:12:40.447: INFO: stdout: "externalname-service-g7pkk"
Dec 14 09:12:40.447: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.27.81.224 80'
Dec 14 09:12:40.934: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.27.81.224 80\nConnection to 172.27.81.224 80 port [tcp/http] succeeded!\n"
Dec 14 09:12:40.934: INFO: stdout: "externalname-service-dvxpn"
Dec 14 09:12:40.934: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30283'
Dec 14 09:12:41.410: INFO: stderr: "+ nc -v -t -w 2 10.250.18.71 30283\n+ echo hostName\nConnection to 10.250.18.71 30283 port [tcp/*] succeeded!\n"
Dec 14 09:12:41.410: INFO: stdout: ""
Dec 14 09:12:42.410: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30283'
Dec 14 09:12:42.980: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 30283\nConnection to 10.250.18.71 30283 port [tcp/*] succeeded!\n"
Dec 14 09:12:42.980: INFO: stdout: "externalname-service-g7pkk"
Dec 14 09:12:42.980: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30283'
Dec 14 09:12:43.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30283\nConnection to 10.250.18.72 30283 port [tcp/*] succeeded!\n"
Dec 14 09:12:43.513: INFO: stdout: "externalname-service-g7pkk"
Dec 14 09:12:43.513: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:12:43.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9028" for this suite. 12/14/22 09:12:43.554
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":110,"skipped":2077,"failed":0}
------------------------------
• [9.833 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:33.735
    Dec 14 09:12:33.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:12:33.736
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:33.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:33.792
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-9028 12/14/22 09:12:33.813
    STEP: changing the ExternalName service to type=NodePort 12/14/22 09:12:33.825
    STEP: creating replication controller externalname-service in namespace services-9028 12/14/22 09:12:33.853
    I1214 09:12:33.866842    6248 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9028, replica count: 2
    I1214 09:12:36.919482    6248 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:12:36.919: INFO: Creating new exec pod
    Dec 14 09:12:36.938: INFO: Waiting up to 5m0s for pod "execpodpc7zs" in namespace "services-9028" to be "running"
    Dec 14 09:12:36.949: INFO: Pod "execpodpc7zs": Phase="Pending", Reason="", readiness=false. Elapsed: 11.392879ms
    Dec 14 09:12:38.962: INFO: Pod "execpodpc7zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.023997735s
    Dec 14 09:12:38.962: INFO: Pod "execpodpc7zs" satisfied condition "running"
    Dec 14 09:12:39.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Dec 14 09:12:40.447: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Dec 14 09:12:40.447: INFO: stdout: "externalname-service-g7pkk"
    Dec 14 09:12:40.447: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.27.81.224 80'
    Dec 14 09:12:40.934: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.27.81.224 80\nConnection to 172.27.81.224 80 port [tcp/http] succeeded!\n"
    Dec 14 09:12:40.934: INFO: stdout: "externalname-service-dvxpn"
    Dec 14 09:12:40.934: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30283'
    Dec 14 09:12:41.410: INFO: stderr: "+ nc -v -t -w 2 10.250.18.71 30283\n+ echo hostName\nConnection to 10.250.18.71 30283 port [tcp/*] succeeded!\n"
    Dec 14 09:12:41.410: INFO: stdout: ""
    Dec 14 09:12:42.410: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30283'
    Dec 14 09:12:42.980: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 30283\nConnection to 10.250.18.71 30283 port [tcp/*] succeeded!\n"
    Dec 14 09:12:42.980: INFO: stdout: "externalname-service-g7pkk"
    Dec 14 09:12:42.980: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-9028 exec execpodpc7zs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30283'
    Dec 14 09:12:43.513: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30283\nConnection to 10.250.18.72 30283 port [tcp/*] succeeded!\n"
    Dec 14 09:12:43.513: INFO: stdout: "externalname-service-g7pkk"
    Dec 14 09:12:43.513: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:12:43.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9028" for this suite. 12/14/22 09:12:43.554
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:43.568
Dec 14 09:12:43.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:12:43.569
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:43.613
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:43.633
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 12/14/22 09:12:43.654
STEP: listing all events in all namespaces 12/14/22 09:12:43.667
STEP: patching the test event 12/14/22 09:12:43.681
STEP: fetching the test event 12/14/22 09:12:43.696
STEP: updating the test event 12/14/22 09:12:43.708
STEP: getting the test event 12/14/22 09:12:43.742
STEP: deleting the test event 12/14/22 09:12:43.755
STEP: listing all events in all namespaces 12/14/22 09:12:43.769
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec 14 09:12:43.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1839" for this suite. 12/14/22 09:12:43.797
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":111,"skipped":2081,"failed":0}
------------------------------
• [0.242 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:43.568
    Dec 14 09:12:43.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:12:43.569
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:43.613
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:43.633
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 12/14/22 09:12:43.654
    STEP: listing all events in all namespaces 12/14/22 09:12:43.667
    STEP: patching the test event 12/14/22 09:12:43.681
    STEP: fetching the test event 12/14/22 09:12:43.696
    STEP: updating the test event 12/14/22 09:12:43.708
    STEP: getting the test event 12/14/22 09:12:43.742
    STEP: deleting the test event 12/14/22 09:12:43.755
    STEP: listing all events in all namespaces 12/14/22 09:12:43.769
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec 14 09:12:43.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1839" for this suite. 12/14/22 09:12:43.797
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:43.81
Dec 14 09:12:43.810: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:12:43.811
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:43.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:43.868
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/14/22 09:12:43.889
Dec 14 09:12:43.908: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5156  df44cff2-61a8-4f8b-a5c2-4437792ddf73 28921 0 2022-12-14 09:12:43 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-14 09:12:43 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-69znh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-69znh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:12:43.908: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5156" to be "running and ready"
Dec 14 09:12:43.919: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 11.16482ms
Dec 14 09:12:43.919: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:12:45.932: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.024079164s
Dec 14 09:12:45.932: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Dec 14 09:12:45.932: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 12/14/22 09:12:45.932
Dec 14 09:12:45.933: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5156 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:12:45.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:12:45.933: INFO: ExecWithOptions: Clientset creation
Dec 14 09:12:45.933: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-5156/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 12/14/22 09:12:46.426
Dec 14 09:12:46.426: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5156 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:12:46.426: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:12:46.427: INFO: ExecWithOptions: Clientset creation
Dec 14 09:12:46.427: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-5156/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 09:12:46.844: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:12:46.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5156" for this suite. 12/14/22 09:12:46.88
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":112,"skipped":2084,"failed":0}
------------------------------
• [3.083 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:43.81
    Dec 14 09:12:43.810: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:12:43.811
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:43.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:43.868
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 12/14/22 09:12:43.889
    Dec 14 09:12:43.908: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5156  df44cff2-61a8-4f8b-a5c2-4437792ddf73 28921 0 2022-12-14 09:12:43 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-12-14 09:12:43 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-69znh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-69znh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:12:43.908: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5156" to be "running and ready"
    Dec 14 09:12:43.919: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 11.16482ms
    Dec 14 09:12:43.919: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:12:45.932: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.024079164s
    Dec 14 09:12:45.932: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Dec 14 09:12:45.932: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 12/14/22 09:12:45.932
    Dec 14 09:12:45.933: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5156 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:12:45.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:12:45.933: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:12:45.933: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-5156/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 12/14/22 09:12:46.426
    Dec 14 09:12:46.426: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5156 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:12:46.426: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:12:46.427: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:12:46.427: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/dns-5156/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 09:12:46.844: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:12:46.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5156" for this suite. 12/14/22 09:12:46.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:46.894
Dec 14 09:12:46.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:12:46.895
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:46.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:46.954
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 12/14/22 09:12:46.975
Dec 14 09:12:46.975: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1972 api-versions'
Dec 14 09:12:47.098: INFO: stderr: ""
Dec 14 09:12:47.098: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling.k8s.io/v1\nautoscaling.k8s.io/v1beta2\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:12:47.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1972" for this suite. 12/14/22 09:12:47.111
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":113,"skipped":2098,"failed":0}
------------------------------
• [0.229 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:46.894
    Dec 14 09:12:46.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:12:46.895
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:46.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:46.954
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 12/14/22 09:12:46.975
    Dec 14 09:12:46.975: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1972 api-versions'
    Dec 14 09:12:47.098: INFO: stderr: ""
    Dec 14 09:12:47.098: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling.k8s.io/v1\nautoscaling.k8s.io/v1beta2\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\ndns.gardener.cloud/v1alpha1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nsnapshot.storage.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:12:47.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1972" for this suite. 12/14/22 09:12:47.111
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:12:47.124
Dec 14 09:12:47.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:12:47.125
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:47.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:47.182
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 in namespace container-probe-6005 12/14/22 09:12:47.203
Dec 14 09:12:47.220: INFO: Waiting up to 5m0s for pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08" in namespace "container-probe-6005" to be "not pending"
Dec 14 09:12:47.231: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08": Phase="Pending", Reason="", readiness=false. Elapsed: 10.821106ms
Dec 14 09:12:49.243: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08": Phase="Running", Reason="", readiness=true. Elapsed: 2.022513617s
Dec 14 09:12:49.243: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08" satisfied condition "not pending"
Dec 14 09:12:49.243: INFO: Started pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 in namespace container-probe-6005
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:12:49.243
Dec 14 09:12:49.254: INFO: Initial restart count of pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 is 0
STEP: deleting the pod 12/14/22 09:16:50.9
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:16:50.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6005" for this suite. 12/14/22 09:16:50.936
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":114,"skipped":2100,"failed":0}
------------------------------
• [243.824 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:12:47.124
    Dec 14 09:12:47.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:12:47.125
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:12:47.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:12:47.182
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 in namespace container-probe-6005 12/14/22 09:12:47.203
    Dec 14 09:12:47.220: INFO: Waiting up to 5m0s for pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08" in namespace "container-probe-6005" to be "not pending"
    Dec 14 09:12:47.231: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08": Phase="Pending", Reason="", readiness=false. Elapsed: 10.821106ms
    Dec 14 09:12:49.243: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08": Phase="Running", Reason="", readiness=true. Elapsed: 2.022513617s
    Dec 14 09:12:49.243: INFO: Pod "test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08" satisfied condition "not pending"
    Dec 14 09:12:49.243: INFO: Started pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 in namespace container-probe-6005
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:12:49.243
    Dec 14 09:12:49.254: INFO: Initial restart count of pod test-webserver-c85c9693-3021-4c79-86ac-2c101b756e08 is 0
    STEP: deleting the pod 12/14/22 09:16:50.9
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:16:50.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6005" for this suite. 12/14/22 09:16:50.936
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:16:50.953
Dec 14 09:16:50.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:16:50.954
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:16:50.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:16:51.071
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-23066094-4cef-4a91-a117-fe13a2e1f074 12/14/22 09:16:51.091
STEP: Creating a pod to test consume configMaps 12/14/22 09:16:51.103
Dec 14 09:16:51.129: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad" in namespace "projected-9299" to be "Succeeded or Failed"
Dec 14 09:16:51.144: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Pending", Reason="", readiness=false. Elapsed: 14.766208ms
Dec 14 09:16:53.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026791379s
Dec 14 09:16:55.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026569016s
STEP: Saw pod success 12/14/22 09:16:55.156
Dec 14 09:16:55.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad" satisfied condition "Succeeded or Failed"
Dec 14 09:16:55.168: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:16:55.231
Dec 14 09:16:55.245: INFO: Waiting for pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad to disappear
Dec 14 09:16:55.256: INFO: Pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:16:55.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9299" for this suite. 12/14/22 09:16:55.278
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":115,"skipped":2174,"failed":0}
------------------------------
• [4.338 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:16:50.953
    Dec 14 09:16:50.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:16:50.954
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:16:50.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:16:51.071
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-23066094-4cef-4a91-a117-fe13a2e1f074 12/14/22 09:16:51.091
    STEP: Creating a pod to test consume configMaps 12/14/22 09:16:51.103
    Dec 14 09:16:51.129: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad" in namespace "projected-9299" to be "Succeeded or Failed"
    Dec 14 09:16:51.144: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Pending", Reason="", readiness=false. Elapsed: 14.766208ms
    Dec 14 09:16:53.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026791379s
    Dec 14 09:16:55.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026569016s
    STEP: Saw pod success 12/14/22 09:16:55.156
    Dec 14 09:16:55.156: INFO: Pod "pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad" satisfied condition "Succeeded or Failed"
    Dec 14 09:16:55.168: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:16:55.231
    Dec 14 09:16:55.245: INFO: Waiting for pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad to disappear
    Dec 14 09:16:55.256: INFO: Pod pod-projected-configmaps-8211f61e-e6b9-47e9-b705-0fe6c58109ad no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:16:55.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9299" for this suite. 12/14/22 09:16:55.278
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:16:55.291
Dec 14 09:16:55.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:16:55.293
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:16:55.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:16:55.348
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 12/14/22 09:16:55.369
STEP: Creating a ResourceQuota 12/14/22 09:17:00.381
STEP: Ensuring resource quota status is calculated 12/14/22 09:17:00.393
STEP: Creating a ReplicationController 12/14/22 09:17:02.406
STEP: Ensuring resource quota status captures replication controller creation 12/14/22 09:17:02.423
STEP: Deleting a ReplicationController 12/14/22 09:17:04.437
STEP: Ensuring resource quota status released usage 12/14/22 09:17:04.45
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:17:06.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7518" for this suite. 12/14/22 09:17:06.484
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":116,"skipped":2176,"failed":0}
------------------------------
• [11.205 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:16:55.291
    Dec 14 09:16:55.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:16:55.293
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:16:55.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:16:55.348
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 12/14/22 09:16:55.369
    STEP: Creating a ResourceQuota 12/14/22 09:17:00.381
    STEP: Ensuring resource quota status is calculated 12/14/22 09:17:00.393
    STEP: Creating a ReplicationController 12/14/22 09:17:02.406
    STEP: Ensuring resource quota status captures replication controller creation 12/14/22 09:17:02.423
    STEP: Deleting a ReplicationController 12/14/22 09:17:04.437
    STEP: Ensuring resource quota status released usage 12/14/22 09:17:04.45
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:17:06.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7518" for this suite. 12/14/22 09:17:06.484
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:06.498
Dec 14 09:17:06.498: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 09:17:06.498
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.554
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 12/14/22 09:17:06.575
Dec 14 09:17:06.587: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 12/14/22 09:17:06.587
Dec 14 09:17:06.602: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 12/14/22 09:17:06.602
Dec 14 09:17:06.627: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:17:06.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3290" for this suite. 12/14/22 09:17:06.639
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":117,"skipped":2195,"failed":0}
------------------------------
• [0.155 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:06.498
    Dec 14 09:17:06.498: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 09:17:06.498
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.554
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 12/14/22 09:17:06.575
    Dec 14 09:17:06.587: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 12/14/22 09:17:06.587
    Dec 14 09:17:06.602: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 12/14/22 09:17:06.602
    Dec 14 09:17:06.627: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:17:06.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3290" for this suite. 12/14/22 09:17:06.639
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:06.654
Dec 14 09:17:06.654: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:17:06.655
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.71
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-3235 12/14/22 09:17:06.731
Dec 14 09:17:06.749: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3235" to be "running and ready"
Dec 14 09:17:06.760: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.867774ms
Dec 14 09:17:06.760: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:17:08.772: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.023095377s
Dec 14 09:17:08.773: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 14 09:17:08.773: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec 14 09:17:08.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 14 09:17:09.299: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 14 09:17:09.300: INFO: stdout: "iptables"
Dec 14 09:17:09.300: INFO: proxyMode: iptables
Dec 14 09:17:09.315: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 14 09:17:09.331: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-3235 12/14/22 09:17:09.331
STEP: creating replication controller affinity-clusterip-timeout in namespace services-3235 12/14/22 09:17:09.357
I1214 09:17:09.371208    6248 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3235, replica count: 3
I1214 09:17:12.423722    6248 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:17:12.446: INFO: Creating new exec pod
Dec 14 09:17:12.462: INFO: Waiting up to 5m0s for pod "execpod-affinitydv7dl" in namespace "services-3235" to be "running"
Dec 14 09:17:12.473: INFO: Pod "execpod-affinitydv7dl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104097ms
Dec 14 09:17:14.486: INFO: Pod "execpod-affinitydv7dl": Phase="Running", Reason="", readiness=true. Elapsed: 2.024405667s
Dec 14 09:17:14.486: INFO: Pod "execpod-affinitydv7dl" satisfied condition "running"
Dec 14 09:17:15.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Dec 14 09:17:16.114: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Dec 14 09:17:16.115: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:17:16.115: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.33.128 80'
Dec 14 09:17:16.772: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.24.33.128 80\nConnection to 172.24.33.128 80 port [tcp/http] succeeded!\n"
Dec 14 09:17:16.772: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:17:16.772: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.24.33.128:80/ ; done'
Dec 14 09:17:17.381: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
Dec 14 09:17:17.381: INFO: stdout: "\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf"
Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
Dec 14 09:17:17.382: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.24.33.128:80/'
Dec 14 09:17:17.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
Dec 14 09:17:17.886: INFO: stdout: "affinity-clusterip-timeout-hw9bf"
Dec 14 09:17:37.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.24.33.128:80/'
Dec 14 09:17:38.390: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
Dec 14 09:17:38.390: INFO: stdout: "affinity-clusterip-timeout-5zg7d"
Dec 14 09:17:38.390: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3235, will wait for the garbage collector to delete the pods 12/14/22 09:17:38.406
Dec 14 09:17:38.480: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 12.25245ms
Dec 14 09:17:38.581: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.686363ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:17:40.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3235" for this suite. 12/14/22 09:17:40.72
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":118,"skipped":2214,"failed":0}
------------------------------
• [34.080 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:06.654
    Dec 14 09:17:06.654: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:17:06.655
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:06.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:06.71
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-3235 12/14/22 09:17:06.731
    Dec 14 09:17:06.749: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3235" to be "running and ready"
    Dec 14 09:17:06.760: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.867774ms
    Dec 14 09:17:06.760: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:17:08.772: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.023095377s
    Dec 14 09:17:08.773: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec 14 09:17:08.773: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec 14 09:17:08.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec 14 09:17:09.299: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec 14 09:17:09.300: INFO: stdout: "iptables"
    Dec 14 09:17:09.300: INFO: proxyMode: iptables
    Dec 14 09:17:09.315: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec 14 09:17:09.331: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-3235 12/14/22 09:17:09.331
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-3235 12/14/22 09:17:09.357
    I1214 09:17:09.371208    6248 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-3235, replica count: 3
    I1214 09:17:12.423722    6248 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:17:12.446: INFO: Creating new exec pod
    Dec 14 09:17:12.462: INFO: Waiting up to 5m0s for pod "execpod-affinitydv7dl" in namespace "services-3235" to be "running"
    Dec 14 09:17:12.473: INFO: Pod "execpod-affinitydv7dl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.104097ms
    Dec 14 09:17:14.486: INFO: Pod "execpod-affinitydv7dl": Phase="Running", Reason="", readiness=true. Elapsed: 2.024405667s
    Dec 14 09:17:14.486: INFO: Pod "execpod-affinitydv7dl" satisfied condition "running"
    Dec 14 09:17:15.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Dec 14 09:17:16.114: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-timeout 80\n+ echo hostName\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Dec 14 09:17:16.115: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:17:16.115: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.33.128 80'
    Dec 14 09:17:16.772: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.24.33.128 80\nConnection to 172.24.33.128 80 port [tcp/http] succeeded!\n"
    Dec 14 09:17:16.772: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:17:16.772: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.24.33.128:80/ ; done'
    Dec 14 09:17:17.381: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
    Dec 14 09:17:17.381: INFO: stdout: "\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf\naffinity-clusterip-timeout-hw9bf"
    Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.381: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Received response from host: affinity-clusterip-timeout-hw9bf
    Dec 14 09:17:17.382: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.24.33.128:80/'
    Dec 14 09:17:17.886: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
    Dec 14 09:17:17.886: INFO: stdout: "affinity-clusterip-timeout-hw9bf"
    Dec 14 09:17:37.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-3235 exec execpod-affinitydv7dl -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.24.33.128:80/'
    Dec 14 09:17:38.390: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.24.33.128:80/\n"
    Dec 14 09:17:38.390: INFO: stdout: "affinity-clusterip-timeout-5zg7d"
    Dec 14 09:17:38.390: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-3235, will wait for the garbage collector to delete the pods 12/14/22 09:17:38.406
    Dec 14 09:17:38.480: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 12.25245ms
    Dec 14 09:17:38.581: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.686363ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:17:40.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3235" for this suite. 12/14/22 09:17:40.72
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:40.735
Dec 14 09:17:40.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:17:40.736
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:40.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:40.791
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 12/14/22 09:17:40.812
Dec 14 09:17:40.829: INFO: Waiting up to 5m0s for pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29" in namespace "pods-7769" to be "running and ready"
Dec 14 09:17:40.840: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29": Phase="Pending", Reason="", readiness=false. Elapsed: 11.057253ms
Dec 14 09:17:40.840: INFO: The phase of Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:17:42.852: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29": Phase="Running", Reason="", readiness=true. Elapsed: 2.023874558s
Dec 14 09:17:42.852: INFO: The phase of Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 is Running (Ready = true)
Dec 14 09:17:42.853: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29" satisfied condition "running and ready"
Dec 14 09:17:42.876: INFO: Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 has hostIP: 10.250.18.72
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:17:42.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7769" for this suite. 12/14/22 09:17:42.897
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":119,"skipped":2234,"failed":0}
------------------------------
• [2.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:40.735
    Dec 14 09:17:40.735: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:17:40.736
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:40.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:40.791
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 12/14/22 09:17:40.812
    Dec 14 09:17:40.829: INFO: Waiting up to 5m0s for pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29" in namespace "pods-7769" to be "running and ready"
    Dec 14 09:17:40.840: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29": Phase="Pending", Reason="", readiness=false. Elapsed: 11.057253ms
    Dec 14 09:17:40.840: INFO: The phase of Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:17:42.852: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29": Phase="Running", Reason="", readiness=true. Elapsed: 2.023874558s
    Dec 14 09:17:42.852: INFO: The phase of Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 is Running (Ready = true)
    Dec 14 09:17:42.853: INFO: Pod "pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29" satisfied condition "running and ready"
    Dec 14 09:17:42.876: INFO: Pod pod-hostip-3e3fb649-ca34-4948-84e1-d09b14fedf29 has hostIP: 10.250.18.72
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:17:42.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7769" for this suite. 12/14/22 09:17:42.897
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:42.91
Dec 14 09:17:42.910: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:17:42.91
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:42.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:42.966
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Dec 14 09:17:42.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:17:45.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8198" for this suite. 12/14/22 09:17:45.711
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":120,"skipped":2237,"failed":0}
------------------------------
• [2.813 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:42.91
    Dec 14 09:17:42.910: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:17:42.91
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:42.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:42.966
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Dec 14 09:17:42.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:17:45.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8198" for this suite. 12/14/22 09:17:45.711
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:17:45.724
Dec 14 09:17:45.724: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:17:45.725
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:45.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:45.778
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 12/14/22 09:17:45.798
STEP: waiting for pod running 12/14/22 09:17:45.816
Dec 14 09:17:45.816: INFO: Waiting up to 2m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326" to be "running"
Dec 14 09:17:45.827: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.717183ms
Dec 14 09:17:47.840: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Running", Reason="", readiness=true. Elapsed: 2.023356186s
Dec 14 09:17:47.840: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" satisfied condition "running"
STEP: creating a file in subpath 12/14/22 09:17:47.84
Dec 14 09:17:47.851: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9326 PodName:var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:17:47.851: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:17:47.852: INFO: ExecWithOptions: Clientset creation
Dec 14 09:17:47.852: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-9326/pods/var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 12/14/22 09:17:48.024
Dec 14 09:17:48.035: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9326 PodName:var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:17:48.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:17:48.036: INFO: ExecWithOptions: Clientset creation
Dec 14 09:17:48.036: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-9326/pods/var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 12/14/22 09:17:48.489
Dec 14 09:17:49.016: INFO: Successfully updated pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7"
STEP: waiting for annotated pod running 12/14/22 09:17:49.016
Dec 14 09:17:49.016: INFO: Waiting up to 2m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326" to be "running"
Dec 14 09:17:49.028: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Running", Reason="", readiness=true. Elapsed: 11.370862ms
Dec 14 09:17:49.028: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 09:17:49.028
Dec 14 09:17:49.028: INFO: Deleting pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326"
Dec 14 09:17:49.042: INFO: Wait up to 5m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:18:23.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9326" for this suite. 12/14/22 09:18:23.087
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":121,"skipped":2270,"failed":0}
------------------------------
• [37.376 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:17:45.724
    Dec 14 09:17:45.724: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:17:45.725
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:17:45.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:17:45.778
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 12/14/22 09:17:45.798
    STEP: waiting for pod running 12/14/22 09:17:45.816
    Dec 14 09:17:45.816: INFO: Waiting up to 2m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326" to be "running"
    Dec 14 09:17:45.827: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.717183ms
    Dec 14 09:17:47.840: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Running", Reason="", readiness=true. Elapsed: 2.023356186s
    Dec 14 09:17:47.840: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" satisfied condition "running"
    STEP: creating a file in subpath 12/14/22 09:17:47.84
    Dec 14 09:17:47.851: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-9326 PodName:var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:17:47.851: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:17:47.852: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:17:47.852: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-9326/pods/var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 12/14/22 09:17:48.024
    Dec 14 09:17:48.035: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-9326 PodName:var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:17:48.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:17:48.036: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:17:48.036: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/var-expansion-9326/pods/var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 12/14/22 09:17:48.489
    Dec 14 09:17:49.016: INFO: Successfully updated pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7"
    STEP: waiting for annotated pod running 12/14/22 09:17:49.016
    Dec 14 09:17:49.016: INFO: Waiting up to 2m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326" to be "running"
    Dec 14 09:17:49.028: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7": Phase="Running", Reason="", readiness=true. Elapsed: 11.370862ms
    Dec 14 09:17:49.028: INFO: Pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 09:17:49.028
    Dec 14 09:17:49.028: INFO: Deleting pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" in namespace "var-expansion-9326"
    Dec 14 09:17:49.042: INFO: Wait up to 5m0s for pod "var-expansion-73e5bcbe-4578-42ce-b2a0-a6a85ff1dfc7" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:18:23.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9326" for this suite. 12/14/22 09:18:23.087
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:23.1
Dec 14 09:18:23.100: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:18:23.101
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:23.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:23.157
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-aca30f60-05df-4c34-9969-5d5980cd2113 12/14/22 09:18:23.178
STEP: Creating a pod to test consume configMaps 12/14/22 09:18:23.19
Dec 14 09:18:23.208: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114" in namespace "projected-9027" to be "Succeeded or Failed"
Dec 14 09:18:23.219: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Pending", Reason="", readiness=false. Elapsed: 11.053638ms
Dec 14 09:18:25.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023424564s
Dec 14 09:18:27.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023152309s
STEP: Saw pod success 12/14/22 09:18:27.231
Dec 14 09:18:27.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114" satisfied condition "Succeeded or Failed"
Dec 14 09:18:27.243: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:18:27.331
Dec 14 09:18:27.347: INFO: Waiting for pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 to disappear
Dec 14 09:18:27.358: INFO: Pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:18:27.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9027" for this suite. 12/14/22 09:18:27.379
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":122,"skipped":2270,"failed":0}
------------------------------
• [4.292 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:23.1
    Dec 14 09:18:23.100: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:18:23.101
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:23.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:23.157
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-aca30f60-05df-4c34-9969-5d5980cd2113 12/14/22 09:18:23.178
    STEP: Creating a pod to test consume configMaps 12/14/22 09:18:23.19
    Dec 14 09:18:23.208: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114" in namespace "projected-9027" to be "Succeeded or Failed"
    Dec 14 09:18:23.219: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Pending", Reason="", readiness=false. Elapsed: 11.053638ms
    Dec 14 09:18:25.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023424564s
    Dec 14 09:18:27.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023152309s
    STEP: Saw pod success 12/14/22 09:18:27.231
    Dec 14 09:18:27.231: INFO: Pod "pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114" satisfied condition "Succeeded or Failed"
    Dec 14 09:18:27.243: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:18:27.331
    Dec 14 09:18:27.347: INFO: Waiting for pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 to disappear
    Dec 14 09:18:27.358: INFO: Pod pod-projected-configmaps-73e5e926-2c97-4dff-aa1c-186d77277114 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:18:27.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9027" for this suite. 12/14/22 09:18:27.379
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:27.392
Dec 14 09:18:27.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:18:27.393
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.449
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:27.486
Dec 14 09:18:27.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption-2 12/14/22 09:18:27.488
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.542
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.575
STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.608
STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.632
STEP: listing a collection of PDBs across all namespaces 12/14/22 09:18:27.643
STEP: listing a collection of PDBs in namespace disruption-3731 12/14/22 09:18:27.655
STEP: deleting a collection of PDBs 12/14/22 09:18:27.667
STEP: Waiting for the PDB collection to be deleted 12/14/22 09:18:27.683
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Dec 14 09:18:27.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-9618" for this suite. 12/14/22 09:18:27.706
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:18:27.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3731" for this suite. 12/14/22 09:18:27.731
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":123,"skipped":2276,"failed":0}
------------------------------
• [0.351 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:27.392
    Dec 14 09:18:27.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:18:27.393
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.449
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:27.486
    Dec 14 09:18:27.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption-2 12/14/22 09:18:27.488
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.542
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.575
    STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.608
    STEP: Waiting for the pdb to be processed 12/14/22 09:18:27.632
    STEP: listing a collection of PDBs across all namespaces 12/14/22 09:18:27.643
    STEP: listing a collection of PDBs in namespace disruption-3731 12/14/22 09:18:27.655
    STEP: deleting a collection of PDBs 12/14/22 09:18:27.667
    STEP: Waiting for the PDB collection to be deleted 12/14/22 09:18:27.683
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Dec 14 09:18:27.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-9618" for this suite. 12/14/22 09:18:27.706
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:18:27.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3731" for this suite. 12/14/22 09:18:27.731
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:27.744
Dec 14 09:18:27.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename limitrange 12/14/22 09:18:27.745
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.801
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 12/14/22 09:18:27.822
STEP: Setting up watch 12/14/22 09:18:27.822
STEP: Submitting a LimitRange 12/14/22 09:18:27.935
STEP: Verifying LimitRange creation was observed 12/14/22 09:18:27.948
STEP: Fetching the LimitRange to ensure it has proper values 12/14/22 09:18:27.948
Dec 14 09:18:27.962: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 14 09:18:27.962: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 12/14/22 09:18:27.962
STEP: Ensuring Pod has resource requirements applied from LimitRange 12/14/22 09:18:27.977
Dec 14 09:18:27.989: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Dec 14 09:18:27.989: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 12/14/22 09:18:27.989
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/14/22 09:18:28.005
Dec 14 09:18:28.016: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Dec 14 09:18:28.017: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 12/14/22 09:18:28.017
STEP: Failing to create a Pod with more than max resources 12/14/22 09:18:28.031
STEP: Updating a LimitRange 12/14/22 09:18:28.045
STEP: Verifying LimitRange updating is effective 12/14/22 09:18:28.058
STEP: Creating a Pod with less than former min resources 12/14/22 09:18:30.07
STEP: Failing to create a Pod with more than max resources 12/14/22 09:18:30.086
STEP: Deleting a LimitRange 12/14/22 09:18:30.101
STEP: Verifying the LimitRange was deleted 12/14/22 09:18:30.114
Dec 14 09:18:35.129: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 12/14/22 09:18:35.129
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Dec 14 09:18:35.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6208" for this suite. 12/14/22 09:18:35.168
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":124,"skipped":2276,"failed":0}
------------------------------
• [7.437 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:27.744
    Dec 14 09:18:27.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename limitrange 12/14/22 09:18:27.745
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:27.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:27.801
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 12/14/22 09:18:27.822
    STEP: Setting up watch 12/14/22 09:18:27.822
    STEP: Submitting a LimitRange 12/14/22 09:18:27.935
    STEP: Verifying LimitRange creation was observed 12/14/22 09:18:27.948
    STEP: Fetching the LimitRange to ensure it has proper values 12/14/22 09:18:27.948
    Dec 14 09:18:27.962: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec 14 09:18:27.962: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 12/14/22 09:18:27.962
    STEP: Ensuring Pod has resource requirements applied from LimitRange 12/14/22 09:18:27.977
    Dec 14 09:18:27.989: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Dec 14 09:18:27.989: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 12/14/22 09:18:27.989
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 12/14/22 09:18:28.005
    Dec 14 09:18:28.016: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Dec 14 09:18:28.017: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 12/14/22 09:18:28.017
    STEP: Failing to create a Pod with more than max resources 12/14/22 09:18:28.031
    STEP: Updating a LimitRange 12/14/22 09:18:28.045
    STEP: Verifying LimitRange updating is effective 12/14/22 09:18:28.058
    STEP: Creating a Pod with less than former min resources 12/14/22 09:18:30.07
    STEP: Failing to create a Pod with more than max resources 12/14/22 09:18:30.086
    STEP: Deleting a LimitRange 12/14/22 09:18:30.101
    STEP: Verifying the LimitRange was deleted 12/14/22 09:18:30.114
    Dec 14 09:18:35.129: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 12/14/22 09:18:35.129
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Dec 14 09:18:35.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-6208" for this suite. 12/14/22 09:18:35.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:35.182
Dec 14 09:18:35.182: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:18:35.183
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:35.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:35.237
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:18:35.257
Dec 14 09:18:35.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295" in namespace "downward-api-46" to be "Succeeded or Failed"
Dec 14 09:18:35.286: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667378ms
Dec 14 09:18:37.303: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027592001s
Dec 14 09:18:39.298: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022686546s
STEP: Saw pod success 12/14/22 09:18:39.298
Dec 14 09:18:39.298: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295" satisfied condition "Succeeded or Failed"
Dec 14 09:18:39.310: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 container client-container: <nil>
STEP: delete the pod 12/14/22 09:18:39.333
Dec 14 09:18:39.349: INFO: Waiting for pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 to disappear
Dec 14 09:18:39.361: INFO: Pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:18:39.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-46" for this suite. 12/14/22 09:18:39.382
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":125,"skipped":2288,"failed":0}
------------------------------
• [4.212 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:35.182
    Dec 14 09:18:35.182: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:18:35.183
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:35.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:35.237
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:18:35.257
    Dec 14 09:18:35.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295" in namespace "downward-api-46" to be "Succeeded or Failed"
    Dec 14 09:18:35.286: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667378ms
    Dec 14 09:18:37.303: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027592001s
    Dec 14 09:18:39.298: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022686546s
    STEP: Saw pod success 12/14/22 09:18:39.298
    Dec 14 09:18:39.298: INFO: Pod "downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295" satisfied condition "Succeeded or Failed"
    Dec 14 09:18:39.310: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:18:39.333
    Dec 14 09:18:39.349: INFO: Waiting for pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 to disappear
    Dec 14 09:18:39.361: INFO: Pod downwardapi-volume-6e576459-47b4-4eb1-9c34-763a3bb23295 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:18:39.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-46" for this suite. 12/14/22 09:18:39.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:18:39.395
Dec 14 09:18:39.395: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch 12/14/22 09:18:39.396
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:39.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:39.451
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Dec 14 09:18:39.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR  12/14/22 09:18:41.579
Dec 14 09:18:41.591: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:18:41Z]] name:name1 resourceVersion:31198 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 12/14/22 09:18:51.592
Dec 14 09:18:51.610: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:18:51Z]] name:name2 resourceVersion:31253 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 12/14/22 09:19:01.611
Dec 14 09:19:01.625: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:01Z]] name:name1 resourceVersion:31332 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 12/14/22 09:19:11.626
Dec 14 09:19:11.640: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:11Z]] name:name2 resourceVersion:31384 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 12/14/22 09:19:21.641
Dec 14 09:19:21.654: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:01Z]] name:name1 resourceVersion:31435 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 12/14/22 09:19:31.655
Dec 14 09:19:31.670: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:11Z]] name:name2 resourceVersion:31486 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:19:42.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9625" for this suite. 12/14/22 09:19:42.226
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":126,"skipped":2313,"failed":0}
------------------------------
• [62.843 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:18:39.395
    Dec 14 09:18:39.395: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-watch 12/14/22 09:18:39.396
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:18:39.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:18:39.451
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Dec 14 09:18:39.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating first CR  12/14/22 09:18:41.579
    Dec 14 09:18:41.591: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:18:41Z]] name:name1 resourceVersion:31198 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 12/14/22 09:18:51.592
    Dec 14 09:18:51.610: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:18:51Z]] name:name2 resourceVersion:31253 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 12/14/22 09:19:01.611
    Dec 14 09:19:01.625: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:01Z]] name:name1 resourceVersion:31332 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 12/14/22 09:19:11.626
    Dec 14 09:19:11.640: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:11Z]] name:name2 resourceVersion:31384 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 12/14/22 09:19:21.641
    Dec 14 09:19:21.654: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:01Z]] name:name1 resourceVersion:31435 uid:cb15eaf9-ab9b-4e72-b939-72b8fcc64923] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 12/14/22 09:19:31.655
    Dec 14 09:19:31.670: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-12-14T09:18:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-12-14T09:19:11Z]] name:name2 resourceVersion:31486 uid:854936a8-2b52-4040-860d-204c024b49ab] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:19:42.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-9625" for this suite. 12/14/22 09:19:42.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:19:42.243
Dec 14 09:19:42.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:19:42.245
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:42.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:42.299
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5073 12/14/22 09:19:42.319
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-5073 12/14/22 09:19:42.331
Dec 14 09:19:42.355: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:19:52.367: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 12/14/22 09:19:52.397
STEP: updating a scale subresource 12/14/22 09:19:52.408
STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 09:19:52.422
STEP: Patch a scale subresource 12/14/22 09:19:52.433
STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 09:19:52.447
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:19:52.458: INFO: Deleting all statefulset in ns statefulset-5073
Dec 14 09:19:52.469: INFO: Scaling statefulset ss to 0
Dec 14 09:20:02.528: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:20:02.540: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:20:02.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5073" for this suite. 12/14/22 09:20:02.605
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":127,"skipped":2387,"failed":0}
------------------------------
• [20.374 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:19:42.243
    Dec 14 09:19:42.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:19:42.245
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:19:42.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:19:42.299
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5073 12/14/22 09:19:42.319
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-5073 12/14/22 09:19:42.331
    Dec 14 09:19:42.355: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:19:52.367: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 12/14/22 09:19:52.397
    STEP: updating a scale subresource 12/14/22 09:19:52.408
    STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 09:19:52.422
    STEP: Patch a scale subresource 12/14/22 09:19:52.433
    STEP: verifying the statefulset Spec.Replicas was modified 12/14/22 09:19:52.447
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:19:52.458: INFO: Deleting all statefulset in ns statefulset-5073
    Dec 14 09:19:52.469: INFO: Scaling statefulset ss to 0
    Dec 14 09:20:02.528: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:20:02.540: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:20:02.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5073" for this suite. 12/14/22 09:20:02.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:02.618
Dec 14 09:20:02.618: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:20:02.619
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:02.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:02.675
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-4d45da42-0018-49bf-b8e2-2abd291cc14b 12/14/22 09:20:02.696
STEP: Creating a pod to test consume secrets 12/14/22 09:20:02.708
Dec 14 09:20:02.726: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c" in namespace "projected-7243" to be "Succeeded or Failed"
Dec 14 09:20:02.737: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.757365ms
Dec 14 09:20:04.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023851499s
Dec 14 09:20:06.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023932593s
STEP: Saw pod success 12/14/22 09:20:06.75
Dec 14 09:20:06.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c" satisfied condition "Succeeded or Failed"
Dec 14 09:20:06.762: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:20:06.785
Dec 14 09:20:06.799: INFO: Waiting for pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c to disappear
Dec 14 09:20:06.811: INFO: Pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:20:06.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7243" for this suite. 12/14/22 09:20:06.832
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":128,"skipped":2400,"failed":0}
------------------------------
• [4.226 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:02.618
    Dec 14 09:20:02.618: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:20:02.619
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:02.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:02.675
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-4d45da42-0018-49bf-b8e2-2abd291cc14b 12/14/22 09:20:02.696
    STEP: Creating a pod to test consume secrets 12/14/22 09:20:02.708
    Dec 14 09:20:02.726: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c" in namespace "projected-7243" to be "Succeeded or Failed"
    Dec 14 09:20:02.737: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.757365ms
    Dec 14 09:20:04.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023851499s
    Dec 14 09:20:06.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023932593s
    STEP: Saw pod success 12/14/22 09:20:06.75
    Dec 14 09:20:06.750: INFO: Pod "pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c" satisfied condition "Succeeded or Failed"
    Dec 14 09:20:06.762: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:20:06.785
    Dec 14 09:20:06.799: INFO: Waiting for pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c to disappear
    Dec 14 09:20:06.811: INFO: Pod pod-projected-secrets-7fae6718-9ec2-402d-9098-d1f98295256c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:20:06.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7243" for this suite. 12/14/22 09:20:06.832
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:06.844
Dec 14 09:20:06.845: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:20:06.846
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.903
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 12/14/22 09:20:06.923
STEP: wait for the container to reach Succeeded 12/14/22 09:20:06.942
STEP: get the container status 12/14/22 09:20:09.99
STEP: the container should be terminated 12/14/22 09:20:10.002
STEP: the termination message should be set 12/14/22 09:20:10.002
Dec 14 09:20:10.002: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 12/14/22 09:20:10.002
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:20:10.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5041" for this suite. 12/14/22 09:20:10.054
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":129,"skipped":2404,"failed":0}
------------------------------
• [3.222 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:06.844
    Dec 14 09:20:06.845: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:20:06.846
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:06.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:06.903
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 12/14/22 09:20:06.923
    STEP: wait for the container to reach Succeeded 12/14/22 09:20:06.942
    STEP: get the container status 12/14/22 09:20:09.99
    STEP: the container should be terminated 12/14/22 09:20:10.002
    STEP: the termination message should be set 12/14/22 09:20:10.002
    Dec 14 09:20:10.002: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 12/14/22 09:20:10.002
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:20:10.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5041" for this suite. 12/14/22 09:20:10.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:20:10.068
Dec 14 09:20:10.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:20:10.069
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:10.104
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:10.124
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 12/14/22 09:20:10.145
Dec 14 09:20:10.164: INFO: Waiting up to 2m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706" to be "running"
Dec 14 09:20:10.175: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.999429ms
Dec 14 09:20:12.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023730888s
Dec 14 09:20:14.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024224993s
Dec 14 09:20:16.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023019212s
Dec 14 09:20:18.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024803201s
Dec 14 09:20:20.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023480643s
Dec 14 09:20:22.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023731492s
Dec 14 09:20:24.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024357665s
Dec 14 09:20:26.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023269863s
Dec 14 09:20:28.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023681858s
Dec 14 09:20:30.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.025427961s
Dec 14 09:20:32.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.024282351s
Dec 14 09:20:34.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023678118s
Dec 14 09:20:36.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023876943s
Dec 14 09:20:38.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.024772023s
Dec 14 09:20:40.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.023434239s
Dec 14 09:20:42.186: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 32.022343755s
Dec 14 09:20:44.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.023812274s
Dec 14 09:20:46.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023020309s
Dec 14 09:20:48.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.024711174s
Dec 14 09:20:50.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 40.024105929s
Dec 14 09:20:52.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.02349103s
Dec 14 09:20:54.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024278139s
Dec 14 09:20:56.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 46.023397842s
Dec 14 09:20:58.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023822696s
Dec 14 09:21:00.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 50.024261012s
Dec 14 09:21:02.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024096005s
Dec 14 09:21:04.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 54.024211723s
Dec 14 09:21:06.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023713925s
Dec 14 09:21:08.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.024793499s
Dec 14 09:21:10.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.02473126s
Dec 14 09:21:12.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.024318015s
Dec 14 09:21:14.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.023657708s
Dec 14 09:21:16.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.023482833s
Dec 14 09:21:18.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.02487896s
Dec 14 09:21:20.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.023131464s
Dec 14 09:21:22.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023564373s
Dec 14 09:21:24.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.023235665s
Dec 14 09:21:26.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023276311s
Dec 14 09:21:28.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.023983995s
Dec 14 09:21:30.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024757102s
Dec 14 09:21:32.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.023602047s
Dec 14 09:21:34.192: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.028224722s
Dec 14 09:21:36.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023578309s
Dec 14 09:21:38.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024037245s
Dec 14 09:21:40.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.024576475s
Dec 14 09:21:42.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.02471112s
Dec 14 09:21:44.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.023894792s
Dec 14 09:21:46.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.02426215s
Dec 14 09:21:48.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.023533806s
Dec 14 09:21:50.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.023031227s
Dec 14 09:21:52.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.02329252s
Dec 14 09:21:54.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02286245s
Dec 14 09:21:56.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.022783883s
Dec 14 09:21:58.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024316797s
Dec 14 09:22:00.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.023057537s
Dec 14 09:22:02.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023992666s
Dec 14 09:22:04.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02449477s
Dec 14 09:22:06.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023172105s
Dec 14 09:22:08.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.024924895s
Dec 14 09:22:10.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023449579s
Dec 14 09:22:10.199: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.034921732s
STEP: updating the pod 12/14/22 09:22:10.199
Dec 14 09:22:10.724: INFO: Successfully updated pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9"
STEP: waiting for pod running 12/14/22 09:22:10.724
Dec 14 09:22:10.725: INFO: Waiting up to 2m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706" to be "running"
Dec 14 09:22:10.736: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.231745ms
Dec 14 09:22:12.748: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.023747672s
Dec 14 09:22:12.748: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 09:22:12.748
Dec 14 09:22:12.748: INFO: Deleting pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706"
Dec 14 09:22:12.761: INFO: Wait up to 5m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:22:44.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8706" for this suite. 12/14/22 09:22:44.806
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":130,"skipped":2429,"failed":0}
------------------------------
• [154.751 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:20:10.068
    Dec 14 09:20:10.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:20:10.069
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:20:10.104
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:20:10.124
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 12/14/22 09:20:10.145
    Dec 14 09:20:10.164: INFO: Waiting up to 2m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706" to be "running"
    Dec 14 09:20:10.175: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.999429ms
    Dec 14 09:20:12.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023730888s
    Dec 14 09:20:14.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024224993s
    Dec 14 09:20:16.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023019212s
    Dec 14 09:20:18.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024803201s
    Dec 14 09:20:20.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.023480643s
    Dec 14 09:20:22.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.023731492s
    Dec 14 09:20:24.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024357665s
    Dec 14 09:20:26.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023269863s
    Dec 14 09:20:28.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023681858s
    Dec 14 09:20:30.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.025427961s
    Dec 14 09:20:32.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.024282351s
    Dec 14 09:20:34.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023678118s
    Dec 14 09:20:36.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.023876943s
    Dec 14 09:20:38.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.024772023s
    Dec 14 09:20:40.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.023434239s
    Dec 14 09:20:42.186: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 32.022343755s
    Dec 14 09:20:44.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.023812274s
    Dec 14 09:20:46.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023020309s
    Dec 14 09:20:48.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.024711174s
    Dec 14 09:20:50.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 40.024105929s
    Dec 14 09:20:52.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.02349103s
    Dec 14 09:20:54.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.024278139s
    Dec 14 09:20:56.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 46.023397842s
    Dec 14 09:20:58.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 48.023822696s
    Dec 14 09:21:00.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 50.024261012s
    Dec 14 09:21:02.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 52.024096005s
    Dec 14 09:21:04.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 54.024211723s
    Dec 14 09:21:06.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 56.023713925s
    Dec 14 09:21:08.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.024793499s
    Dec 14 09:21:10.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.02473126s
    Dec 14 09:21:12.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.024318015s
    Dec 14 09:21:14.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.023657708s
    Dec 14 09:21:16.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.023482833s
    Dec 14 09:21:18.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.02487896s
    Dec 14 09:21:20.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.023131464s
    Dec 14 09:21:22.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.023564373s
    Dec 14 09:21:24.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.023235665s
    Dec 14 09:21:26.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.023276311s
    Dec 14 09:21:28.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.023983995s
    Dec 14 09:21:30.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.024757102s
    Dec 14 09:21:32.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.023602047s
    Dec 14 09:21:34.192: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.028224722s
    Dec 14 09:21:36.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.023578309s
    Dec 14 09:21:38.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.024037245s
    Dec 14 09:21:40.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.024576475s
    Dec 14 09:21:42.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.02471112s
    Dec 14 09:21:44.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.023894792s
    Dec 14 09:21:46.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.02426215s
    Dec 14 09:21:48.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.023533806s
    Dec 14 09:21:50.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.023031227s
    Dec 14 09:21:52.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.02329252s
    Dec 14 09:21:54.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.02286245s
    Dec 14 09:21:56.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.022783883s
    Dec 14 09:21:58.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.024316797s
    Dec 14 09:22:00.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.023057537s
    Dec 14 09:22:02.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023992666s
    Dec 14 09:22:04.188: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.02449477s
    Dec 14 09:22:06.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.023172105s
    Dec 14 09:22:08.189: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.024924895s
    Dec 14 09:22:10.187: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023449579s
    Dec 14 09:22:10.199: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.034921732s
    STEP: updating the pod 12/14/22 09:22:10.199
    Dec 14 09:22:10.724: INFO: Successfully updated pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9"
    STEP: waiting for pod running 12/14/22 09:22:10.724
    Dec 14 09:22:10.725: INFO: Waiting up to 2m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706" to be "running"
    Dec 14 09:22:10.736: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.231745ms
    Dec 14 09:22:12.748: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9": Phase="Running", Reason="", readiness=true. Elapsed: 2.023747672s
    Dec 14 09:22:12.748: INFO: Pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 09:22:12.748
    Dec 14 09:22:12.748: INFO: Deleting pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" in namespace "var-expansion-8706"
    Dec 14 09:22:12.761: INFO: Wait up to 5m0s for pod "var-expansion-239624ba-8900-4eb1-8135-ccaba3cdf7c9" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:22:44.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8706" for this suite. 12/14/22 09:22:44.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:44.821
Dec 14 09:22:44.821: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:22:44.822
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:44.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:44.876
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:22:44.909
Dec 14 09:22:44.936: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-200" to be "running and ready"
Dec 14 09:22:44.948: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.250216ms
Dec 14 09:22:44.948: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:22:46.961: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.024425252s
Dec 14 09:22:46.961: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:22:46.961: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 12/14/22 09:22:46.973
Dec 14 09:22:46.989: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-200" to be "running and ready"
Dec 14 09:22:47.000: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.055364ms
Dec 14 09:22:47.000: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:22:49.013: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.023325383s
Dec 14 09:22:49.013: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Dec 14 09:22:49.013: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/14/22 09:22:49.024
STEP: delete the pod with lifecycle hook 12/14/22 09:22:49.046
Dec 14 09:22:49.059: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 14 09:22:49.071: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 14 09:22:51.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 14 09:22:51.083: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:22:51.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-200" for this suite. 12/14/22 09:22:51.103
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":131,"skipped":2450,"failed":0}
------------------------------
• [6.295 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:44.821
    Dec 14 09:22:44.821: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:22:44.822
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:44.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:44.876
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:22:44.909
    Dec 14 09:22:44.936: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-200" to be "running and ready"
    Dec 14 09:22:44.948: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.250216ms
    Dec 14 09:22:44.948: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:22:46.961: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.024425252s
    Dec 14 09:22:46.961: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:22:46.961: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 12/14/22 09:22:46.973
    Dec 14 09:22:46.989: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-200" to be "running and ready"
    Dec 14 09:22:47.000: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 11.055364ms
    Dec 14 09:22:47.000: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:22:49.013: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.023325383s
    Dec 14 09:22:49.013: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Dec 14 09:22:49.013: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/14/22 09:22:49.024
    STEP: delete the pod with lifecycle hook 12/14/22 09:22:49.046
    Dec 14 09:22:49.059: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec 14 09:22:49.071: INFO: Pod pod-with-poststart-exec-hook still exists
    Dec 14 09:22:51.071: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Dec 14 09:22:51.083: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:22:51.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-200" for this suite. 12/14/22 09:22:51.103
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:51.116
Dec 14 09:22:51.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:22:51.117
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:51.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:51.171
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 12/14/22 09:22:51.192
Dec 14 09:22:51.209: INFO: Waiting up to 5m0s for pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4" in namespace "var-expansion-1957" to be "Succeeded or Failed"
Dec 14 09:22:51.220: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.783367ms
Dec 14 09:22:53.232: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022576796s
Dec 14 09:22:55.233: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023466192s
STEP: Saw pod success 12/14/22 09:22:55.233
Dec 14 09:22:55.399: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4" satisfied condition "Succeeded or Failed"
Dec 14 09:22:55.411: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:22:55.433
Dec 14 09:22:55.455: INFO: Waiting for pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 to disappear
Dec 14 09:22:55.466: INFO: Pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:22:55.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1957" for this suite. 12/14/22 09:22:55.487
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":132,"skipped":2455,"failed":0}
------------------------------
• [4.383 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:51.116
    Dec 14 09:22:51.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:22:51.117
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:51.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:51.171
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 12/14/22 09:22:51.192
    Dec 14 09:22:51.209: INFO: Waiting up to 5m0s for pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4" in namespace "var-expansion-1957" to be "Succeeded or Failed"
    Dec 14 09:22:51.220: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.783367ms
    Dec 14 09:22:53.232: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022576796s
    Dec 14 09:22:55.233: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023466192s
    STEP: Saw pod success 12/14/22 09:22:55.233
    Dec 14 09:22:55.399: INFO: Pod "var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4" satisfied condition "Succeeded or Failed"
    Dec 14 09:22:55.411: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:22:55.433
    Dec 14 09:22:55.455: INFO: Waiting for pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 to disappear
    Dec 14 09:22:55.466: INFO: Pod var-expansion-0f9bc230-8cfb-43bb-95d5-def0d456d8d4 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:22:55.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1957" for this suite. 12/14/22 09:22:55.487
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:55.499
Dec 14 09:22:55.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:22:55.501
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:55.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:55.557
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Dec 14 09:22:55.628: INFO: created pod pod-service-account-defaultsa
Dec 14 09:22:55.628: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 14 09:22:55.644: INFO: created pod pod-service-account-mountsa
Dec 14 09:22:55.644: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 14 09:22:55.659: INFO: created pod pod-service-account-nomountsa
Dec 14 09:22:55.659: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 14 09:22:55.675: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 14 09:22:55.675: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 14 09:22:55.690: INFO: created pod pod-service-account-mountsa-mountspec
Dec 14 09:22:55.690: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 14 09:22:55.705: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 14 09:22:55.705: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 14 09:22:55.720: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 14 09:22:55.720: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 14 09:22:55.735: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 14 09:22:55.735: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 14 09:22:55.750: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 14 09:22:55.750: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:22:55.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4671" for this suite. 12/14/22 09:22:55.761
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":133,"skipped":2456,"failed":0}
------------------------------
• [0.274 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:55.499
    Dec 14 09:22:55.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:22:55.501
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:55.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:55.557
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Dec 14 09:22:55.628: INFO: created pod pod-service-account-defaultsa
    Dec 14 09:22:55.628: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Dec 14 09:22:55.644: INFO: created pod pod-service-account-mountsa
    Dec 14 09:22:55.644: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Dec 14 09:22:55.659: INFO: created pod pod-service-account-nomountsa
    Dec 14 09:22:55.659: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Dec 14 09:22:55.675: INFO: created pod pod-service-account-defaultsa-mountspec
    Dec 14 09:22:55.675: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Dec 14 09:22:55.690: INFO: created pod pod-service-account-mountsa-mountspec
    Dec 14 09:22:55.690: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Dec 14 09:22:55.705: INFO: created pod pod-service-account-nomountsa-mountspec
    Dec 14 09:22:55.705: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Dec 14 09:22:55.720: INFO: created pod pod-service-account-defaultsa-nomountspec
    Dec 14 09:22:55.720: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Dec 14 09:22:55.735: INFO: created pod pod-service-account-mountsa-nomountspec
    Dec 14 09:22:55.735: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Dec 14 09:22:55.750: INFO: created pod pod-service-account-nomountsa-nomountspec
    Dec 14 09:22:55.750: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:22:55.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4671" for this suite. 12/14/22 09:22:55.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:55.774
Dec 14 09:22:55.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:22:55.775
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:55.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:55.829
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:22:55.875
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:22:56.135
STEP: Deploying the webhook pod 12/14/22 09:22:56.148
STEP: Wait for the deployment to be ready 12/14/22 09:22:56.172
Dec 14 09:22:56.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:22:58.219
STEP: Verifying the service has paired with the endpoint 12/14/22 09:22:58.252
Dec 14 09:22:59.252: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/14/22 09:22:59.264
STEP: create a namespace for the webhook 12/14/22 09:22:59.384
STEP: create a configmap should be unconditionally rejected by the webhook 12/14/22 09:22:59.398
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:22:59.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6536" for this suite. 12/14/22 09:22:59.489
STEP: Destroying namespace "webhook-6536-markers" for this suite. 12/14/22 09:22:59.503
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":134,"skipped":2480,"failed":0}
------------------------------
• [3.795 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:55.774
    Dec 14 09:22:55.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:22:55.775
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:55.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:55.829
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:22:55.875
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:22:56.135
    STEP: Deploying the webhook pod 12/14/22 09:22:56.148
    STEP: Wait for the deployment to be ready 12/14/22 09:22:56.172
    Dec 14 09:22:56.206: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 22, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:22:58.219
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:22:58.252
    Dec 14 09:22:59.252: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 12/14/22 09:22:59.264
    STEP: create a namespace for the webhook 12/14/22 09:22:59.384
    STEP: create a configmap should be unconditionally rejected by the webhook 12/14/22 09:22:59.398
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:22:59.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6536" for this suite. 12/14/22 09:22:59.489
    STEP: Destroying namespace "webhook-6536-markers" for this suite. 12/14/22 09:22:59.503
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:22:59.57
Dec 14 09:22:59.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:22:59.571
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:59.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:59.635
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Dec 14 09:22:59.656: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:23:01.954
Dec 14 09:23:01.955: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 create -f -'
Dec 14 09:23:02.643: INFO: stderr: ""
Dec 14 09:23:02.643: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 14 09:23:02.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 delete e2e-test-crd-publish-openapi-5641-crds test-cr'
Dec 14 09:23:02.759: INFO: stderr: ""
Dec 14 09:23:02.759: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 14 09:23:02.759: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 apply -f -'
Dec 14 09:23:02.999: INFO: stderr: ""
Dec 14 09:23:02.999: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 14 09:23:02.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 delete e2e-test-crd-publish-openapi-5641-crds test-cr'
Dec 14 09:23:03.119: INFO: stderr: ""
Dec 14 09:23:03.119: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 12/14/22 09:23:03.119
Dec 14 09:23:03.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 explain e2e-test-crd-publish-openapi-5641-crds'
Dec 14 09:23:03.365: INFO: stderr: ""
Dec 14 09:23:03.365: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5641-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:23:07.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5142" for this suite. 12/14/22 09:23:07.73
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":135,"skipped":2494,"failed":0}
------------------------------
• [8.167 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:22:59.57
    Dec 14 09:22:59.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:22:59.571
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:22:59.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:22:59.635
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Dec 14 09:22:59.656: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:23:01.954
    Dec 14 09:23:01.955: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 create -f -'
    Dec 14 09:23:02.643: INFO: stderr: ""
    Dec 14 09:23:02.643: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec 14 09:23:02.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 delete e2e-test-crd-publish-openapi-5641-crds test-cr'
    Dec 14 09:23:02.759: INFO: stderr: ""
    Dec 14 09:23:02.759: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Dec 14 09:23:02.759: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 apply -f -'
    Dec 14 09:23:02.999: INFO: stderr: ""
    Dec 14 09:23:02.999: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Dec 14 09:23:02.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 --namespace=crd-publish-openapi-5142 delete e2e-test-crd-publish-openapi-5641-crds test-cr'
    Dec 14 09:23:03.119: INFO: stderr: ""
    Dec 14 09:23:03.119: INFO: stdout: "e2e-test-crd-publish-openapi-5641-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 12/14/22 09:23:03.119
    Dec 14 09:23:03.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-5142 explain e2e-test-crd-publish-openapi-5641-crds'
    Dec 14 09:23:03.365: INFO: stderr: ""
    Dec 14 09:23:03.365: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5641-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:23:07.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5142" for this suite. 12/14/22 09:23:07.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:23:07.738
Dec 14 09:23:07.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:23:07.739
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:07.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:07.766
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 12/14/22 09:23:07.776
STEP: Ensuring a job is scheduled 12/14/22 09:23:07.783
STEP: Ensuring exactly one is scheduled 12/14/22 09:24:01.79
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:24:01.796
STEP: Ensuring no more jobs are scheduled 12/14/22 09:24:01.802
STEP: Removing cronjob 12/14/22 09:29:01.815
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:29:01.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2804" for this suite. 12/14/22 09:29:01.833
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":136,"skipped":2520,"failed":0}
------------------------------
• [SLOW TEST] [354.102 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:23:07.738
    Dec 14 09:23:07.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:23:07.739
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:23:07.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:23:07.766
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 12/14/22 09:23:07.776
    STEP: Ensuring a job is scheduled 12/14/22 09:23:07.783
    STEP: Ensuring exactly one is scheduled 12/14/22 09:24:01.79
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:24:01.796
    STEP: Ensuring no more jobs are scheduled 12/14/22 09:24:01.802
    STEP: Removing cronjob 12/14/22 09:29:01.815
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:29:01.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2804" for this suite. 12/14/22 09:29:01.833
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:01.84
Dec 14 09:29:01.841: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename ingressclass 12/14/22 09:29:01.841
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:01.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:01.868
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 12/14/22 09:29:01.877
STEP: getting /apis/networking.k8s.io 12/14/22 09:29:01.886
STEP: getting /apis/networking.k8s.iov1 12/14/22 09:29:01.89
STEP: creating 12/14/22 09:29:01.895
STEP: getting 12/14/22 09:29:01.914
STEP: listing 12/14/22 09:29:01.919
STEP: watching 12/14/22 09:29:01.926
Dec 14 09:29:01.926: INFO: starting watch
STEP: patching 12/14/22 09:29:01.931
STEP: updating 12/14/22 09:29:01.938
Dec 14 09:29:01.944: INFO: waiting for watch events with expected annotations
Dec 14 09:29:01.944: INFO: saw patched and updated annotations
STEP: deleting 12/14/22 09:29:01.944
STEP: deleting a collection 12/14/22 09:29:01.963
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Dec 14 09:29:01.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-666" for this suite. 12/14/22 09:29:01.983
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":137,"skipped":2525,"failed":0}
------------------------------
• [0.149 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:01.84
    Dec 14 09:29:01.841: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename ingressclass 12/14/22 09:29:01.841
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:01.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:01.868
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 12/14/22 09:29:01.877
    STEP: getting /apis/networking.k8s.io 12/14/22 09:29:01.886
    STEP: getting /apis/networking.k8s.iov1 12/14/22 09:29:01.89
    STEP: creating 12/14/22 09:29:01.895
    STEP: getting 12/14/22 09:29:01.914
    STEP: listing 12/14/22 09:29:01.919
    STEP: watching 12/14/22 09:29:01.926
    Dec 14 09:29:01.926: INFO: starting watch
    STEP: patching 12/14/22 09:29:01.931
    STEP: updating 12/14/22 09:29:01.938
    Dec 14 09:29:01.944: INFO: waiting for watch events with expected annotations
    Dec 14 09:29:01.944: INFO: saw patched and updated annotations
    STEP: deleting 12/14/22 09:29:01.944
    STEP: deleting a collection 12/14/22 09:29:01.963
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Dec 14 09:29:01.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-666" for this suite. 12/14/22 09:29:01.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:01.99
Dec 14 09:29:01.990: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:29:01.991
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:02.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:02.017
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 12/14/22 09:29:02.026
Dec 14 09:29:02.047: INFO: Waiting up to 5m0s for pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328" in namespace "downward-api-8054" to be "Succeeded or Failed"
Dec 14 09:29:02.053: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Pending", Reason="", readiness=false. Elapsed: 5.521274ms
Dec 14 09:29:04.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012903952s
Dec 14 09:29:06.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012415354s
STEP: Saw pod success 12/14/22 09:29:06.06
Dec 14 09:29:06.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328" satisfied condition "Succeeded or Failed"
Dec 14 09:29:06.066: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:29:06.131
Dec 14 09:29:06.140: INFO: Waiting for pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 to disappear
Dec 14 09:29:06.146: INFO: Pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 09:29:06.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8054" for this suite. 12/14/22 09:29:06.155
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":138,"skipped":2534,"failed":0}
------------------------------
• [4.171 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:01.99
    Dec 14 09:29:01.990: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:29:01.991
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:02.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:02.017
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 12/14/22 09:29:02.026
    Dec 14 09:29:02.047: INFO: Waiting up to 5m0s for pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328" in namespace "downward-api-8054" to be "Succeeded or Failed"
    Dec 14 09:29:02.053: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Pending", Reason="", readiness=false. Elapsed: 5.521274ms
    Dec 14 09:29:04.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012903952s
    Dec 14 09:29:06.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012415354s
    STEP: Saw pod success 12/14/22 09:29:06.06
    Dec 14 09:29:06.060: INFO: Pod "downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328" satisfied condition "Succeeded or Failed"
    Dec 14 09:29:06.066: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:29:06.131
    Dec 14 09:29:06.140: INFO: Waiting for pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 to disappear
    Dec 14 09:29:06.146: INFO: Pod downward-api-794d8b4d-a475-4117-9031-3e6cdeb58328 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 09:29:06.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8054" for this suite. 12/14/22 09:29:06.155
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:06.161
Dec 14 09:29:06.162: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:29:06.162
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:06.179
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:06.188
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 12/14/22 09:29:06.197
STEP: starting a background goroutine to produce watch events 12/14/22 09:29:06.202
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/14/22 09:29:06.202
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:29:08.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6232" for this suite. 12/14/22 09:29:09.02
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":139,"skipped":2542,"failed":0}
------------------------------
• [2.909 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:06.161
    Dec 14 09:29:06.162: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:29:06.162
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:06.179
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:06.188
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 12/14/22 09:29:06.197
    STEP: starting a background goroutine to produce watch events 12/14/22 09:29:06.202
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 12/14/22 09:29:06.202
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:29:08.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6232" for this suite. 12/14/22 09:29:09.02
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:09.071
Dec 14 09:29:09.071: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:29:09.072
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:09.09
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:09.099
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:29:09.123
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:09.484
STEP: Deploying the webhook pod 12/14/22 09:29:09.49
STEP: Wait for the deployment to be ready 12/14/22 09:29:09.502
Dec 14 09:29:09.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:29:11.533
STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:11.542
Dec 14 09:29:12.542: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Dec 14 09:29:12.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7680-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:29:13.07
STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:29:13.202
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:29:15.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4484" for this suite. 12/14/22 09:29:15.998
STEP: Destroying namespace "webhook-4484-markers" for this suite. 12/14/22 09:29:16.005
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":140,"skipped":2557,"failed":0}
------------------------------
• [6.972 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:09.071
    Dec 14 09:29:09.071: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:29:09.072
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:09.09
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:09.099
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:29:09.123
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:09.484
    STEP: Deploying the webhook pod 12/14/22 09:29:09.49
    STEP: Wait for the deployment to be ready 12/14/22 09:29:09.502
    Dec 14 09:29:09.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:29:11.533
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:11.542
    Dec 14 09:29:12.542: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Dec 14 09:29:12.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7680-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:29:13.07
    STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:29:13.202
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:29:15.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4484" for this suite. 12/14/22 09:29:15.998
    STEP: Destroying namespace "webhook-4484-markers" for this suite. 12/14/22 09:29:16.005
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:16.047
Dec 14 09:29:16.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:29:16.048
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:16.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:16.079
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 12/14/22 09:29:16.094
STEP: waiting for available Endpoint 12/14/22 09:29:16.1
STEP: listing all Endpoints 12/14/22 09:29:16.105
STEP: updating the Endpoint 12/14/22 09:29:16.111
STEP: fetching the Endpoint 12/14/22 09:29:16.122
STEP: patching the Endpoint 12/14/22 09:29:16.128
STEP: fetching the Endpoint 12/14/22 09:29:16.141
STEP: deleting the Endpoint by Collection 12/14/22 09:29:16.147
STEP: waiting for Endpoint deletion 12/14/22 09:29:16.156
STEP: fetching the Endpoint 12/14/22 09:29:16.16
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:29:16.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-745" for this suite. 12/14/22 09:29:16.172
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":141,"skipped":2630,"failed":0}
------------------------------
• [0.132 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:16.047
    Dec 14 09:29:16.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:29:16.048
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:16.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:16.079
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 12/14/22 09:29:16.094
    STEP: waiting for available Endpoint 12/14/22 09:29:16.1
    STEP: listing all Endpoints 12/14/22 09:29:16.105
    STEP: updating the Endpoint 12/14/22 09:29:16.111
    STEP: fetching the Endpoint 12/14/22 09:29:16.122
    STEP: patching the Endpoint 12/14/22 09:29:16.128
    STEP: fetching the Endpoint 12/14/22 09:29:16.141
    STEP: deleting the Endpoint by Collection 12/14/22 09:29:16.147
    STEP: waiting for Endpoint deletion 12/14/22 09:29:16.156
    STEP: fetching the Endpoint 12/14/22 09:29:16.16
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:29:16.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-745" for this suite. 12/14/22 09:29:16.172
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:16.179
Dec 14 09:29:16.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:29:16.18
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:16.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:16.205
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:29:16.228
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:16.953
STEP: Deploying the webhook pod 12/14/22 09:29:16.959
STEP: Wait for the deployment to be ready 12/14/22 09:29:16.972
Dec 14 09:29:16.984: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:29:19.002
STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:19.012
Dec 14 09:29:20.012: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 12/14/22 09:29:20.018
STEP: Creating a custom resource definition that should be denied by the webhook 12/14/22 09:29:20.152
Dec 14 09:29:20.152: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:29:20.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5383" for this suite. 12/14/22 09:29:20.291
STEP: Destroying namespace "webhook-5383-markers" for this suite. 12/14/22 09:29:20.298
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":142,"skipped":2643,"failed":0}
------------------------------
• [4.159 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:16.179
    Dec 14 09:29:16.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:29:16.18
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:16.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:16.205
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:29:16.228
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:16.953
    STEP: Deploying the webhook pod 12/14/22 09:29:16.959
    STEP: Wait for the deployment to be ready 12/14/22 09:29:16.972
    Dec 14 09:29:16.984: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:29:19.002
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:19.012
    Dec 14 09:29:20.012: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 12/14/22 09:29:20.018
    STEP: Creating a custom resource definition that should be denied by the webhook 12/14/22 09:29:20.152
    Dec 14 09:29:20.152: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:29:20.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5383" for this suite. 12/14/22 09:29:20.291
    STEP: Destroying namespace "webhook-5383-markers" for this suite. 12/14/22 09:29:20.298
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:20.339
Dec 14 09:29:20.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:29:20.34
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:20.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:20.366
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 12/14/22 09:29:20.375
STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:29:20.382
STEP: delete the deployment 12/14/22 09:29:20.388
STEP: wait for all rs to be garbage collected 12/14/22 09:29:20.395
STEP: expected 0 rs, got 1 rs 12/14/22 09:29:20.401
STEP: expected 0 pods, got 2 pods 12/14/22 09:29:20.407
STEP: Gathering metrics 12/14/22 09:29:20.931
W1214 09:29:20.949744    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:29:20.949: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:29:20.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5898" for this suite. 12/14/22 09:29:20.956
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":143,"skipped":2652,"failed":0}
------------------------------
• [0.624 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:20.339
    Dec 14 09:29:20.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:29:20.34
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:20.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:20.366
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 12/14/22 09:29:20.375
    STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:29:20.382
    STEP: delete the deployment 12/14/22 09:29:20.388
    STEP: wait for all rs to be garbage collected 12/14/22 09:29:20.395
    STEP: expected 0 rs, got 1 rs 12/14/22 09:29:20.401
    STEP: expected 0 pods, got 2 pods 12/14/22 09:29:20.407
    STEP: Gathering metrics 12/14/22 09:29:20.931
    W1214 09:29:20.949744    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:29:20.949: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:29:20.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5898" for this suite. 12/14/22 09:29:20.956
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:20.963
Dec 14 09:29:20.964: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container 12/14/22 09:29:20.964
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:20.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:20.99
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 12/14/22 09:29:21
Dec 14 09:29:21.000: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:29:23.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9713" for this suite. 12/14/22 09:29:23.978
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":144,"skipped":2653,"failed":0}
------------------------------
• [3.022 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:20.963
    Dec 14 09:29:20.964: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename init-container 12/14/22 09:29:20.964
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:20.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:20.99
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 12/14/22 09:29:21
    Dec 14 09:29:21.000: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:29:23.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9713" for this suite. 12/14/22 09:29:23.978
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:23.987
Dec 14 09:29:23.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:29:23.988
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:24.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:24.014
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 12/14/22 09:29:24.023
STEP: wait for the container to reach Succeeded 12/14/22 09:29:24.035
STEP: get the container status 12/14/22 09:29:27.082
STEP: the container should be terminated 12/14/22 09:29:27.088
STEP: the termination message should be set 12/14/22 09:29:27.088
Dec 14 09:29:27.088: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 12/14/22 09:29:27.088
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:29:27.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4092" for this suite. 12/14/22 09:29:27.113
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":145,"skipped":2693,"failed":0}
------------------------------
• [3.132 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:23.987
    Dec 14 09:29:23.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:29:23.988
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:24.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:24.014
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 12/14/22 09:29:24.023
    STEP: wait for the container to reach Succeeded 12/14/22 09:29:24.035
    STEP: get the container status 12/14/22 09:29:27.082
    STEP: the container should be terminated 12/14/22 09:29:27.088
    STEP: the termination message should be set 12/14/22 09:29:27.088
    Dec 14 09:29:27.088: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 12/14/22 09:29:27.088
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:29:27.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4092" for this suite. 12/14/22 09:29:27.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:27.12
Dec 14 09:29:27.120: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:29:27.121
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:27.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:27.148
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:29:27.172
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:27.394
STEP: Deploying the webhook pod 12/14/22 09:29:27.401
STEP: Wait for the deployment to be ready 12/14/22 09:29:27.415
Dec 14 09:29:27.427: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:29:29.447
STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:29.456
Dec 14 09:29:30.458: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 12/14/22 09:29:30.464
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/14/22 09:29:30.469
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 09:29:30.469
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:29:30.469
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:29:30.473
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:29:30.473
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:29:30.478
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:29:30.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2642" for this suite. 12/14/22 09:29:30.487
STEP: Destroying namespace "webhook-2642-markers" for this suite. 12/14/22 09:29:30.494
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":146,"skipped":2711,"failed":0}
------------------------------
• [3.415 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:27.12
    Dec 14 09:29:27.120: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:29:27.121
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:27.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:27.148
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:29:27.172
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:29:27.394
    STEP: Deploying the webhook pod 12/14/22 09:29:27.401
    STEP: Wait for the deployment to be ready 12/14/22 09:29:27.415
    Dec 14 09:29:27.427: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:29:29.447
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:29:29.456
    Dec 14 09:29:30.458: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 12/14/22 09:29:30.464
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 12/14/22 09:29:30.469
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 12/14/22 09:29:30.469
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:29:30.469
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 12/14/22 09:29:30.473
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:29:30.473
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 12/14/22 09:29:30.478
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:29:30.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2642" for this suite. 12/14/22 09:29:30.487
    STEP: Destroying namespace "webhook-2642-markers" for this suite. 12/14/22 09:29:30.494
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:30.536
Dec 14 09:29:30.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:29:30.536
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:30.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:30.564
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:29:30.573
Dec 14 09:29:30.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9" in namespace "downward-api-4938" to be "Succeeded or Failed"
Dec 14 09:29:30.591: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.877297ms
Dec 14 09:29:32.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013194481s
Dec 14 09:29:34.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013190263s
STEP: Saw pod success 12/14/22 09:29:34.599
Dec 14 09:29:34.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9" satisfied condition "Succeeded or Failed"
Dec 14 09:29:34.605: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 container client-container: <nil>
STEP: delete the pod 12/14/22 09:29:34.629
Dec 14 09:29:34.640: INFO: Waiting for pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 to disappear
Dec 14 09:29:34.645: INFO: Pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:29:34.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4938" for this suite. 12/14/22 09:29:34.655
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":147,"skipped":2723,"failed":0}
------------------------------
• [4.126 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:30.536
    Dec 14 09:29:30.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:29:30.536
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:30.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:30.564
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:29:30.573
    Dec 14 09:29:30.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9" in namespace "downward-api-4938" to be "Succeeded or Failed"
    Dec 14 09:29:30.591: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.877297ms
    Dec 14 09:29:32.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013194481s
    Dec 14 09:29:34.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013190263s
    STEP: Saw pod success 12/14/22 09:29:34.599
    Dec 14 09:29:34.599: INFO: Pod "downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9" satisfied condition "Succeeded or Failed"
    Dec 14 09:29:34.605: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:29:34.629
    Dec 14 09:29:34.640: INFO: Waiting for pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 to disappear
    Dec 14 09:29:34.645: INFO: Pod downwardapi-volume-6241e906-a74d-4aa9-ad05-c3dab69487f9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:29:34.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4938" for this suite. 12/14/22 09:29:34.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:34.663
Dec 14 09:29:34.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:29:34.664
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:34.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:34.692
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 12/14/22 09:29:34.7
STEP: Creating a ResourceQuota 12/14/22 09:29:39.706
STEP: Ensuring resource quota status is calculated 12/14/22 09:29:39.712
STEP: Creating a ReplicaSet 12/14/22 09:29:41.72
STEP: Ensuring resource quota status captures replicaset creation 12/14/22 09:29:41.73
STEP: Deleting a ReplicaSet 12/14/22 09:29:43.737
STEP: Ensuring resource quota status released usage 12/14/22 09:29:43.744
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:29:45.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3750" for this suite. 12/14/22 09:29:45.762
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":148,"skipped":2753,"failed":0}
------------------------------
• [11.106 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:34.663
    Dec 14 09:29:34.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:29:34.664
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:34.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:34.692
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 12/14/22 09:29:34.7
    STEP: Creating a ResourceQuota 12/14/22 09:29:39.706
    STEP: Ensuring resource quota status is calculated 12/14/22 09:29:39.712
    STEP: Creating a ReplicaSet 12/14/22 09:29:41.72
    STEP: Ensuring resource quota status captures replicaset creation 12/14/22 09:29:41.73
    STEP: Deleting a ReplicaSet 12/14/22 09:29:43.737
    STEP: Ensuring resource quota status released usage 12/14/22 09:29:43.744
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:29:45.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3750" for this suite. 12/14/22 09:29:45.762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:45.77
Dec 14 09:29:45.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:29:45.771
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:45.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:45.798
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 09:29:45.808
Dec 14 09:29:45.821: INFO: Waiting up to 5m0s for pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f" in namespace "emptydir-8065" to be "Succeeded or Failed"
Dec 14 09:29:45.827: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019981ms
Dec 14 09:29:47.834: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013016795s
Dec 14 09:29:49.835: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014203394s
STEP: Saw pod success 12/14/22 09:29:49.835
Dec 14 09:29:49.835: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f" satisfied condition "Succeeded or Failed"
Dec 14 09:29:49.841: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f container test-container: <nil>
STEP: delete the pod 12/14/22 09:29:49.858
Dec 14 09:29:49.868: INFO: Waiting for pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f to disappear
Dec 14 09:29:49.874: INFO: Pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:29:49.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8065" for this suite. 12/14/22 09:29:49.884
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":149,"skipped":2758,"failed":0}
------------------------------
• [4.121 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:45.77
    Dec 14 09:29:45.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:29:45.771
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:45.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:45.798
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 09:29:45.808
    Dec 14 09:29:45.821: INFO: Waiting up to 5m0s for pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f" in namespace "emptydir-8065" to be "Succeeded or Failed"
    Dec 14 09:29:45.827: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019981ms
    Dec 14 09:29:47.834: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013016795s
    Dec 14 09:29:49.835: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014203394s
    STEP: Saw pod success 12/14/22 09:29:49.835
    Dec 14 09:29:49.835: INFO: Pod "pod-39e0c122-010f-40eb-ae91-6364b2e7b30f" satisfied condition "Succeeded or Failed"
    Dec 14 09:29:49.841: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f container test-container: <nil>
    STEP: delete the pod 12/14/22 09:29:49.858
    Dec 14 09:29:49.868: INFO: Waiting for pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f to disappear
    Dec 14 09:29:49.874: INFO: Pod pod-39e0c122-010f-40eb-ae91-6364b2e7b30f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:29:49.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8065" for this suite. 12/14/22 09:29:49.884
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:49.892
Dec 14 09:29:49.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:29:49.892
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:49.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:49.919
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 12/14/22 09:29:49.929
STEP: submitting the pod to kubernetes 12/14/22 09:29:49.929
Dec 14 09:29:49.941: INFO: Waiting up to 5m0s for pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" in namespace "pods-7922" to be "running and ready"
Dec 14 09:29:49.947: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.782517ms
Dec 14 09:29:49.947: INFO: The phase of Pod pod-update-c16578eb-5c01-4c67-99b1-9fade047886b is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:29:51.953: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012300039s
Dec 14 09:29:51.953: INFO: The phase of Pod pod-update-c16578eb-5c01-4c67-99b1-9fade047886b is Running (Ready = true)
Dec 14 09:29:51.953: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/14/22 09:29:51.959
STEP: updating the pod 12/14/22 09:29:51.965
Dec 14 09:29:52.482: INFO: Successfully updated pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b"
Dec 14 09:29:52.482: INFO: Waiting up to 5m0s for pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" in namespace "pods-7922" to be "running"
Dec 14 09:29:52.487: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Running", Reason="", readiness=true. Elapsed: 5.790931ms
Dec 14 09:29:52.487: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 12/14/22 09:29:52.487
Dec 14 09:29:52.493: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:29:52.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7922" for this suite. 12/14/22 09:29:52.503
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":150,"skipped":2763,"failed":0}
------------------------------
• [2.619 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:49.892
    Dec 14 09:29:49.892: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:29:49.892
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:49.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:49.919
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 12/14/22 09:29:49.929
    STEP: submitting the pod to kubernetes 12/14/22 09:29:49.929
    Dec 14 09:29:49.941: INFO: Waiting up to 5m0s for pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" in namespace "pods-7922" to be "running and ready"
    Dec 14 09:29:49.947: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.782517ms
    Dec 14 09:29:49.947: INFO: The phase of Pod pod-update-c16578eb-5c01-4c67-99b1-9fade047886b is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:29:51.953: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Running", Reason="", readiness=true. Elapsed: 2.012300039s
    Dec 14 09:29:51.953: INFO: The phase of Pod pod-update-c16578eb-5c01-4c67-99b1-9fade047886b is Running (Ready = true)
    Dec 14 09:29:51.953: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/14/22 09:29:51.959
    STEP: updating the pod 12/14/22 09:29:51.965
    Dec 14 09:29:52.482: INFO: Successfully updated pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b"
    Dec 14 09:29:52.482: INFO: Waiting up to 5m0s for pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" in namespace "pods-7922" to be "running"
    Dec 14 09:29:52.487: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b": Phase="Running", Reason="", readiness=true. Elapsed: 5.790931ms
    Dec 14 09:29:52.487: INFO: Pod "pod-update-c16578eb-5c01-4c67-99b1-9fade047886b" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 12/14/22 09:29:52.487
    Dec 14 09:29:52.493: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:29:52.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7922" for this suite. 12/14/22 09:29:52.503
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:52.511
Dec 14 09:29:52.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:29:52.512
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:52.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:52.542
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-5b3f3221-3deb-4bc4-bdb0-9ba0851cba6c 12/14/22 09:29:52.551
STEP: Creating secret with name secret-projected-all-test-volume-0682fb6d-fed2-42ec-8f17-4bb1d93b2b2e 12/14/22 09:29:52.558
STEP: Creating a pod to test Check all projections for projected volume plugin 12/14/22 09:29:52.564
Dec 14 09:29:52.578: INFO: Waiting up to 5m0s for pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543" in namespace "projected-8221" to be "Succeeded or Failed"
Dec 14 09:29:52.583: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Pending", Reason="", readiness=false. Elapsed: 5.454349ms
Dec 14 09:29:54.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012641187s
Dec 14 09:29:56.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012319283s
STEP: Saw pod success 12/14/22 09:29:56.59
Dec 14 09:29:56.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543" satisfied condition "Succeeded or Failed"
Dec 14 09:29:56.596: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 container projected-all-volume-test: <nil>
STEP: delete the pod 12/14/22 09:29:56.614
Dec 14 09:29:56.634: INFO: Waiting for pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 to disappear
Dec 14 09:29:56.641: INFO: Pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Dec 14 09:29:56.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8221" for this suite. 12/14/22 09:29:56.651
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":151,"skipped":2770,"failed":0}
------------------------------
• [4.147 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:52.511
    Dec 14 09:29:52.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:29:52.512
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:52.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:52.542
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-5b3f3221-3deb-4bc4-bdb0-9ba0851cba6c 12/14/22 09:29:52.551
    STEP: Creating secret with name secret-projected-all-test-volume-0682fb6d-fed2-42ec-8f17-4bb1d93b2b2e 12/14/22 09:29:52.558
    STEP: Creating a pod to test Check all projections for projected volume plugin 12/14/22 09:29:52.564
    Dec 14 09:29:52.578: INFO: Waiting up to 5m0s for pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543" in namespace "projected-8221" to be "Succeeded or Failed"
    Dec 14 09:29:52.583: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Pending", Reason="", readiness=false. Elapsed: 5.454349ms
    Dec 14 09:29:54.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012641187s
    Dec 14 09:29:56.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012319283s
    STEP: Saw pod success 12/14/22 09:29:56.59
    Dec 14 09:29:56.590: INFO: Pod "projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543" satisfied condition "Succeeded or Failed"
    Dec 14 09:29:56.596: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 container projected-all-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:29:56.614
    Dec 14 09:29:56.634: INFO: Waiting for pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 to disappear
    Dec 14 09:29:56.641: INFO: Pod projected-volume-fb6a21cf-9335-4582-9daa-8ec7bf4a1543 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Dec 14 09:29:56.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8221" for this suite. 12/14/22 09:29:56.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:29:56.662
Dec 14 09:29:56.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:29:56.663
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:56.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:56.692
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 09:29:56.702
Dec 14 09:29:56.714: INFO: Waiting up to 5m0s for pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3" in namespace "emptydir-6287" to be "Succeeded or Failed"
Dec 14 09:29:56.720: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.949022ms
Dec 14 09:29:58.726: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01267945s
Dec 14 09:30:00.727: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013000139s
STEP: Saw pod success 12/14/22 09:30:00.727
Dec 14 09:30:00.727: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3" satisfied condition "Succeeded or Failed"
Dec 14 09:30:00.733: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 container test-container: <nil>
STEP: delete the pod 12/14/22 09:30:00.751
Dec 14 09:30:00.761: INFO: Waiting for pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 to disappear
Dec 14 09:30:00.768: INFO: Pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:30:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6287" for this suite. 12/14/22 09:30:00.778
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":152,"skipped":2828,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:29:56.662
    Dec 14 09:29:56.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:29:56.663
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:29:56.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:29:56.692
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 09:29:56.702
    Dec 14 09:29:56.714: INFO: Waiting up to 5m0s for pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3" in namespace "emptydir-6287" to be "Succeeded or Failed"
    Dec 14 09:29:56.720: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.949022ms
    Dec 14 09:29:58.726: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01267945s
    Dec 14 09:30:00.727: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013000139s
    STEP: Saw pod success 12/14/22 09:30:00.727
    Dec 14 09:30:00.727: INFO: Pod "pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3" satisfied condition "Succeeded or Failed"
    Dec 14 09:30:00.733: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:30:00.751
    Dec 14 09:30:00.761: INFO: Waiting for pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 to disappear
    Dec 14 09:30:00.768: INFO: Pod pod-7d9110e6-3c4a-4d09-8350-96ff427d01e3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:30:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6287" for this suite. 12/14/22 09:30:00.778
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:00.787
Dec 14 09:30:00.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:30:00.788
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:00.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:00.816
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 12/14/22 09:30:00.825
Dec 14 09:30:00.838: INFO: Waiting up to 5m0s for pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457" in namespace "downward-api-6048" to be "Succeeded or Failed"
Dec 14 09:30:00.843: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Pending", Reason="", readiness=false. Elapsed: 5.418339ms
Dec 14 09:30:02.850: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012345617s
Dec 14 09:30:04.852: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01394154s
STEP: Saw pod success 12/14/22 09:30:04.852
Dec 14 09:30:04.852: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457" satisfied condition "Succeeded or Failed"
Dec 14 09:30:04.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:30:04.876
Dec 14 09:30:04.886: INFO: Waiting for pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 to disappear
Dec 14 09:30:04.891: INFO: Pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 09:30:04.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6048" for this suite. 12/14/22 09:30:04.901
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":153,"skipped":2845,"failed":0}
------------------------------
• [4.121 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:00.787
    Dec 14 09:30:00.787: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:30:00.788
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:00.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:00.816
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 12/14/22 09:30:00.825
    Dec 14 09:30:00.838: INFO: Waiting up to 5m0s for pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457" in namespace "downward-api-6048" to be "Succeeded or Failed"
    Dec 14 09:30:00.843: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Pending", Reason="", readiness=false. Elapsed: 5.418339ms
    Dec 14 09:30:02.850: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012345617s
    Dec 14 09:30:04.852: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01394154s
    STEP: Saw pod success 12/14/22 09:30:04.852
    Dec 14 09:30:04.852: INFO: Pod "downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457" satisfied condition "Succeeded or Failed"
    Dec 14 09:30:04.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:30:04.876
    Dec 14 09:30:04.886: INFO: Waiting for pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 to disappear
    Dec 14 09:30:04.891: INFO: Pod downward-api-63b05405-1ba1-40a6-b3c8-39ab13bf6457 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 09:30:04.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6048" for this suite. 12/14/22 09:30:04.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:04.91
Dec 14 09:30:04.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:30:04.912
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:04.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:04.939
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-99061486-d1ca-48aa-8cd3-cd4709ed85eb 12/14/22 09:30:04.948
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:30:04.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2305" for this suite. 12/14/22 09:30:04.96
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":154,"skipped":2866,"failed":0}
------------------------------
• [0.057 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:04.91
    Dec 14 09:30:04.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:30:04.912
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:04.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:04.939
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-99061486-d1ca-48aa-8cd3-cd4709ed85eb 12/14/22 09:30:04.948
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:30:04.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2305" for this suite. 12/14/22 09:30:04.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:04.969
Dec 14 09:30:04.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:04.97
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:04.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:04.998
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Dec 14 09:30:05.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:30:07.918
Dec 14 09:30:07.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 create -f -'
Dec 14 09:30:08.757: INFO: stderr: ""
Dec 14 09:30:08.757: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 14 09:30:08.757: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 delete e2e-test-crd-publish-openapi-8892-crds test-cr'
Dec 14 09:30:08.842: INFO: stderr: ""
Dec 14 09:30:08.842: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 14 09:30:08.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 apply -f -'
Dec 14 09:30:09.095: INFO: stderr: ""
Dec 14 09:30:09.095: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 14 09:30:09.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 delete e2e-test-crd-publish-openapi-8892-crds test-cr'
Dec 14 09:30:09.209: INFO: stderr: ""
Dec 14 09:30:09.209: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 12/14/22 09:30:09.209
Dec 14 09:30:09.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 explain e2e-test-crd-publish-openapi-8892-crds'
Dec 14 09:30:09.425: INFO: stderr: ""
Dec 14 09:30:09.425: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8892-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:30:12.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-160" for this suite. 12/14/22 09:30:12.293
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":155,"skipped":2883,"failed":0}
------------------------------
• [7.336 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:04.969
    Dec 14 09:30:04.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:04.97
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:04.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:04.998
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Dec 14 09:30:05.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 12/14/22 09:30:07.918
    Dec 14 09:30:07.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 create -f -'
    Dec 14 09:30:08.757: INFO: stderr: ""
    Dec 14 09:30:08.757: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec 14 09:30:08.757: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 delete e2e-test-crd-publish-openapi-8892-crds test-cr'
    Dec 14 09:30:08.842: INFO: stderr: ""
    Dec 14 09:30:08.842: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Dec 14 09:30:08.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 apply -f -'
    Dec 14 09:30:09.095: INFO: stderr: ""
    Dec 14 09:30:09.095: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Dec 14 09:30:09.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 --namespace=crd-publish-openapi-160 delete e2e-test-crd-publish-openapi-8892-crds test-cr'
    Dec 14 09:30:09.209: INFO: stderr: ""
    Dec 14 09:30:09.209: INFO: stdout: "e2e-test-crd-publish-openapi-8892-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 12/14/22 09:30:09.209
    Dec 14 09:30:09.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-160 explain e2e-test-crd-publish-openapi-8892-crds'
    Dec 14 09:30:09.425: INFO: stderr: ""
    Dec 14 09:30:09.425: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8892-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:30:12.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-160" for this suite. 12/14/22 09:30:12.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:12.305
Dec 14 09:30:12.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:30:12.306
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:12.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:12.36
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:30:12.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4676" for this suite. 12/14/22 09:30:12.403
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":156,"skipped":2891,"failed":0}
------------------------------
• [0.110 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:12.305
    Dec 14 09:30:12.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:30:12.306
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:12.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:12.36
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:30:12.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4676" for this suite. 12/14/22 09:30:12.403
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:12.416
Dec 14 09:30:12.416: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:12.417
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:12.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:12.471
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 12/14/22 09:30:12.491
Dec 14 09:30:12.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd 12/14/22 09:30:21.272
STEP: check the unserved version gets removed 12/14/22 09:30:21.304
STEP: check the other version is not changed 12/14/22 09:30:24.588
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:30:30.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4590" for this suite. 12/14/22 09:30:31.015
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":157,"skipped":2918,"failed":0}
------------------------------
• [18.607 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:12.416
    Dec 14 09:30:12.416: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:30:12.417
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:12.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:12.471
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 12/14/22 09:30:12.491
    Dec 14 09:30:12.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: mark a version not serverd 12/14/22 09:30:21.272
    STEP: check the unserved version gets removed 12/14/22 09:30:21.304
    STEP: check the other version is not changed 12/14/22 09:30:24.588
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:30:30.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4590" for this suite. 12/14/22 09:30:31.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:31.024
Dec 14 09:30:31.024: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:30:31.025
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:31.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:31.052
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:30:31.078
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:30:31.46
STEP: Deploying the webhook pod 12/14/22 09:30:31.469
STEP: Wait for the deployment to be ready 12/14/22 09:30:31.482
Dec 14 09:30:31.493: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:30:33.512
STEP: Verifying the service has paired with the endpoint 12/14/22 09:30:33.522
Dec 14 09:30:34.523: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 12/14/22 09:30:34.594
STEP: Creating a configMap that should be mutated 12/14/22 09:30:34.728
STEP: Deleting the collection of validation webhooks 12/14/22 09:30:35.508
STEP: Creating a configMap that should not be mutated 12/14/22 09:30:35.537
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:30:35.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6351" for this suite. 12/14/22 09:30:35.558
STEP: Destroying namespace "webhook-6351-markers" for this suite. 12/14/22 09:30:35.564
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":158,"skipped":2925,"failed":0}
------------------------------
• [4.578 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:31.024
    Dec 14 09:30:31.024: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:30:31.025
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:31.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:31.052
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:30:31.078
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:30:31.46
    STEP: Deploying the webhook pod 12/14/22 09:30:31.469
    STEP: Wait for the deployment to be ready 12/14/22 09:30:31.482
    Dec 14 09:30:31.493: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:30:33.512
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:30:33.522
    Dec 14 09:30:34.523: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 12/14/22 09:30:34.594
    STEP: Creating a configMap that should be mutated 12/14/22 09:30:34.728
    STEP: Deleting the collection of validation webhooks 12/14/22 09:30:35.508
    STEP: Creating a configMap that should not be mutated 12/14/22 09:30:35.537
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:30:35.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6351" for this suite. 12/14/22 09:30:35.558
    STEP: Destroying namespace "webhook-6351-markers" for this suite. 12/14/22 09:30:35.564
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:35.603
Dec 14 09:30:35.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 09:30:35.604
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.641
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 12/14/22 09:30:35.65
Dec 14 09:30:35.656: INFO: created test-podtemplate-1
Dec 14 09:30:35.663: INFO: created test-podtemplate-2
Dec 14 09:30:35.669: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 12/14/22 09:30:35.669
STEP: delete collection of pod templates 12/14/22 09:30:35.676
Dec 14 09:30:35.676: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 12/14/22 09:30:35.687
Dec 14 09:30:35.687: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 09:30:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7005" for this suite. 12/14/22 09:30:35.699
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":159,"skipped":2936,"failed":0}
------------------------------
• [0.103 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:35.603
    Dec 14 09:30:35.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 09:30:35.604
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.641
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 12/14/22 09:30:35.65
    Dec 14 09:30:35.656: INFO: created test-podtemplate-1
    Dec 14 09:30:35.663: INFO: created test-podtemplate-2
    Dec 14 09:30:35.669: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 12/14/22 09:30:35.669
    STEP: delete collection of pod templates 12/14/22 09:30:35.676
    Dec 14 09:30:35.676: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 12/14/22 09:30:35.687
    Dec 14 09:30:35.687: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 09:30:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7005" for this suite. 12/14/22 09:30:35.699
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:35.706
Dec 14 09:30:35.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sysctl 12/14/22 09:30:35.707
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.724
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.734
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 12/14/22 09:30:35.743
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Dec 14 09:30:35.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1016" for this suite. 12/14/22 09:30:35.761
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":160,"skipped":2937,"failed":0}
------------------------------
• [0.061 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:35.706
    Dec 14 09:30:35.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sysctl 12/14/22 09:30:35.707
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.724
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.734
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 12/14/22 09:30:35.743
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Dec 14 09:30:35.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1016" for this suite. 12/14/22 09:30:35.761
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:35.768
Dec 14 09:30:35.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:30:35.769
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.797
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Dec 14 09:30:35.819: INFO: Waiting up to 2m0s for pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" in namespace "var-expansion-6962" to be "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:30:35.824: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.192341ms
Dec 14 09:30:37.832: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013177539s
Dec 14 09:30:37.832: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:30:37.832: INFO: Deleting pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" in namespace "var-expansion-6962"
Dec 14 09:30:37.839: INFO: Wait up to 5m0s for pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:30:41.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6962" for this suite. 12/14/22 09:30:41.863
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":161,"skipped":2940,"failed":0}
------------------------------
• [6.103 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:35.768
    Dec 14 09:30:35.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:30:35.769
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:35.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:35.797
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Dec 14 09:30:35.819: INFO: Waiting up to 2m0s for pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" in namespace "var-expansion-6962" to be "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:30:35.824: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.192341ms
    Dec 14 09:30:37.832: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013177539s
    Dec 14 09:30:37.832: INFO: Pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:30:37.832: INFO: Deleting pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" in namespace "var-expansion-6962"
    Dec 14 09:30:37.839: INFO: Wait up to 5m0s for pod "var-expansion-386c68db-46d2-4512-8390-1784a1981ef6" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:30:41.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6962" for this suite. 12/14/22 09:30:41.863
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:41.871
Dec 14 09:30:41.871: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:30:41.872
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:41.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:41.9
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 12/14/22 09:30:41.909
Dec 14 09:30:41.922: INFO: Waiting up to 5m0s for pod "pod-j6hjf" in namespace "pods-1282" to be "running"
Dec 14 09:30:41.929: INFO: Pod "pod-j6hjf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.93907ms
Dec 14 09:30:43.936: INFO: Pod "pod-j6hjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01424468s
Dec 14 09:30:43.936: INFO: Pod "pod-j6hjf" satisfied condition "running"
STEP: patching /status 12/14/22 09:30:43.937
Dec 14 09:30:43.946: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:30:43.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1282" for this suite. 12/14/22 09:30:43.956
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":162,"skipped":2942,"failed":0}
------------------------------
• [2.092 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:41.871
    Dec 14 09:30:41.871: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:30:41.872
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:41.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:41.9
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 12/14/22 09:30:41.909
    Dec 14 09:30:41.922: INFO: Waiting up to 5m0s for pod "pod-j6hjf" in namespace "pods-1282" to be "running"
    Dec 14 09:30:41.929: INFO: Pod "pod-j6hjf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.93907ms
    Dec 14 09:30:43.936: INFO: Pod "pod-j6hjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01424468s
    Dec 14 09:30:43.936: INFO: Pod "pod-j6hjf" satisfied condition "running"
    STEP: patching /status 12/14/22 09:30:43.937
    Dec 14 09:30:43.946: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:30:43.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1282" for this suite. 12/14/22 09:30:43.956
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:43.963
Dec 14 09:30:43.963: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:30:43.964
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:43.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:43.994
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 12/14/22 09:30:44.013
STEP: watching for Pod to be ready 12/14/22 09:30:44.025
Dec 14 09:30:44.041: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions []
Dec 14 09:30:44.041: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
Dec 14 09:30:44.042: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
Dec 14 09:30:44.468: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
Dec 14 09:30:45.195: INFO: Found Pod pod-test in namespace pods-6718 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 12/14/22 09:30:45.201
STEP: getting the Pod and ensuring that it's patched 12/14/22 09:30:45.216
STEP: replacing the Pod's status Ready condition to False 12/14/22 09:30:45.222
STEP: check the Pod again to ensure its Ready conditions are False 12/14/22 09:30:45.237
STEP: deleting the Pod via a Collection with a LabelSelector 12/14/22 09:30:45.237
STEP: watching for the Pod to be deleted 12/14/22 09:30:45.245
Dec 14 09:30:45.251: INFO: observed event type MODIFIED
Dec 14 09:30:47.192: INFO: observed event type MODIFIED
Dec 14 09:30:47.362: INFO: observed event type MODIFIED
Dec 14 09:30:48.199: INFO: observed event type MODIFIED
Dec 14 09:30:48.205: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:30:48.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6718" for this suite. 12/14/22 09:30:48.223
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":163,"skipped":2943,"failed":0}
------------------------------
• [4.288 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:43.963
    Dec 14 09:30:43.963: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:30:43.964
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:43.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:43.994
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 12/14/22 09:30:44.013
    STEP: watching for Pod to be ready 12/14/22 09:30:44.025
    Dec 14 09:30:44.041: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Dec 14 09:30:44.041: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
    Dec 14 09:30:44.042: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
    Dec 14 09:30:44.468: INFO: observed Pod pod-test in namespace pods-6718 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
    Dec 14 09:30:45.195: INFO: Found Pod pod-test in namespace pods-6718 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:30:44 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 12/14/22 09:30:45.201
    STEP: getting the Pod and ensuring that it's patched 12/14/22 09:30:45.216
    STEP: replacing the Pod's status Ready condition to False 12/14/22 09:30:45.222
    STEP: check the Pod again to ensure its Ready conditions are False 12/14/22 09:30:45.237
    STEP: deleting the Pod via a Collection with a LabelSelector 12/14/22 09:30:45.237
    STEP: watching for the Pod to be deleted 12/14/22 09:30:45.245
    Dec 14 09:30:45.251: INFO: observed event type MODIFIED
    Dec 14 09:30:47.192: INFO: observed event type MODIFIED
    Dec 14 09:30:47.362: INFO: observed event type MODIFIED
    Dec 14 09:30:48.199: INFO: observed event type MODIFIED
    Dec 14 09:30:48.205: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:30:48.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6718" for this suite. 12/14/22 09:30:48.223
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:48.251
Dec 14 09:30:48.252: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:30:48.252
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:48.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:48.281
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Dec 14 09:30:48.309: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4810 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 09:30:48.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4810" for this suite. 12/14/22 09:30:48.328
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":164,"skipped":2952,"failed":0}
------------------------------
• [0.083 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:48.251
    Dec 14 09:30:48.252: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:30:48.252
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:48.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:48.281
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Dec 14 09:30:48.309: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4810 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 09:30:48.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4810" for this suite. 12/14/22 09:30:48.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:30:48.335
Dec 14 09:30:48.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:30:48.336
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:48.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:48.363
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2530 12/14/22 09:30:48.373
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 12/14/22 09:30:48.38
STEP: Creating pod with conflicting port in namespace statefulset-2530 12/14/22 09:30:48.386
STEP: Waiting until pod test-pod will start running in namespace statefulset-2530 12/14/22 09:30:48.4
Dec 14 09:30:48.400: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2530" to be "running"
Dec 14 09:30:48.406: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.683193ms
Dec 14 09:30:50.413: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012390767s
Dec 14 09:30:50.413: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-2530 12/14/22 09:30:50.413
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2530 12/14/22 09:30:50.419
Dec 14 09:30:50.431: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Pending. Waiting for statefulset controller to delete.
Dec 14 09:30:50.444: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Failed. Waiting for statefulset controller to delete.
Dec 14 09:30:50.449: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Failed. Waiting for statefulset controller to delete.
Dec 14 09:30:50.450: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2530
STEP: Removing pod with conflicting port in namespace statefulset-2530 12/14/22 09:30:50.45
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2530 and will be in running state 12/14/22 09:30:50.46
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:30:52.472: INFO: Deleting all statefulset in ns statefulset-2530
Dec 14 09:30:52.478: INFO: Scaling statefulset ss to 0
Dec 14 09:31:02.506: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:31:02.512: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:31:02.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2530" for this suite. 12/14/22 09:31:02.54
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":165,"skipped":2958,"failed":0}
------------------------------
• [14.212 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:30:48.335
    Dec 14 09:30:48.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:30:48.336
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:30:48.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:30:48.363
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2530 12/14/22 09:30:48.373
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 12/14/22 09:30:48.38
    STEP: Creating pod with conflicting port in namespace statefulset-2530 12/14/22 09:30:48.386
    STEP: Waiting until pod test-pod will start running in namespace statefulset-2530 12/14/22 09:30:48.4
    Dec 14 09:30:48.400: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2530" to be "running"
    Dec 14 09:30:48.406: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.683193ms
    Dec 14 09:30:50.413: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012390767s
    Dec 14 09:30:50.413: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-2530 12/14/22 09:30:50.413
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2530 12/14/22 09:30:50.419
    Dec 14 09:30:50.431: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Pending. Waiting for statefulset controller to delete.
    Dec 14 09:30:50.444: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Failed. Waiting for statefulset controller to delete.
    Dec 14 09:30:50.449: INFO: Observed stateful pod in namespace: statefulset-2530, name: ss-0, uid: 4b79f516-109e-41fb-bff1-ef103965cd30, status phase: Failed. Waiting for statefulset controller to delete.
    Dec 14 09:30:50.450: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2530
    STEP: Removing pod with conflicting port in namespace statefulset-2530 12/14/22 09:30:50.45
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2530 and will be in running state 12/14/22 09:30:50.46
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:30:52.472: INFO: Deleting all statefulset in ns statefulset-2530
    Dec 14 09:30:52.478: INFO: Scaling statefulset ss to 0
    Dec 14 09:31:02.506: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:31:02.512: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:31:02.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2530" for this suite. 12/14/22 09:31:02.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:02.548
Dec 14 09:31:02.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:31:02.549
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:02.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:02.575
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 09:31:02.584
Dec 14 09:31:02.597: INFO: Waiting up to 5m0s for pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a" in namespace "emptydir-7910" to be "Succeeded or Failed"
Dec 14 09:31:02.602: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.656195ms
Dec 14 09:31:04.609: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012055799s
Dec 14 09:31:06.610: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012891712s
STEP: Saw pod success 12/14/22 09:31:06.61
Dec 14 09:31:06.610: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a" satisfied condition "Succeeded or Failed"
Dec 14 09:31:06.616: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a container test-container: <nil>
STEP: delete the pod 12/14/22 09:31:06.644
Dec 14 09:31:06.669: INFO: Waiting for pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a to disappear
Dec 14 09:31:06.675: INFO: Pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:31:06.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7910" for this suite. 12/14/22 09:31:06.685
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":166,"skipped":2970,"failed":0}
------------------------------
• [4.145 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:02.548
    Dec 14 09:31:02.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:31:02.549
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:02.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:02.575
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 12/14/22 09:31:02.584
    Dec 14 09:31:02.597: INFO: Waiting up to 5m0s for pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a" in namespace "emptydir-7910" to be "Succeeded or Failed"
    Dec 14 09:31:02.602: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.656195ms
    Dec 14 09:31:04.609: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012055799s
    Dec 14 09:31:06.610: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012891712s
    STEP: Saw pod success 12/14/22 09:31:06.61
    Dec 14 09:31:06.610: INFO: Pod "pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a" satisfied condition "Succeeded or Failed"
    Dec 14 09:31:06.616: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a container test-container: <nil>
    STEP: delete the pod 12/14/22 09:31:06.644
    Dec 14 09:31:06.669: INFO: Waiting for pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a to disappear
    Dec 14 09:31:06.675: INFO: Pod pod-770cb5f2-0af2-4bc4-9736-60ad9df31b6a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:31:06.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7910" for this suite. 12/14/22 09:31:06.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:06.694
Dec 14 09:31:06.694: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events 12/14/22 09:31:06.695
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.722
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 12/14/22 09:31:06.732
Dec 14 09:31:06.739: INFO: created test-event-1
Dec 14 09:31:06.746: INFO: created test-event-2
Dec 14 09:31:06.753: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 12/14/22 09:31:06.753
STEP: delete collection of events 12/14/22 09:31:06.759
Dec 14 09:31:06.760: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 12/14/22 09:31:06.777
Dec 14 09:31:06.777: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Dec 14 09:31:06.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2036" for this suite. 12/14/22 09:31:06.791
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":167,"skipped":2996,"failed":0}
------------------------------
• [0.104 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:06.694
    Dec 14 09:31:06.694: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename events 12/14/22 09:31:06.695
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.722
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 12/14/22 09:31:06.732
    Dec 14 09:31:06.739: INFO: created test-event-1
    Dec 14 09:31:06.746: INFO: created test-event-2
    Dec 14 09:31:06.753: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 12/14/22 09:31:06.753
    STEP: delete collection of events 12/14/22 09:31:06.759
    Dec 14 09:31:06.760: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 12/14/22 09:31:06.777
    Dec 14 09:31:06.777: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Dec 14 09:31:06.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-2036" for this suite. 12/14/22 09:31:06.791
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:06.799
Dec 14 09:31:06.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:31:06.8
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.828
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 12/14/22 09:31:06.839
Dec 14 09:31:06.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 create -f -'
Dec 14 09:31:07.499: INFO: stderr: ""
Dec 14 09:31:07.499: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:07.499
Dec 14 09:31:07.499: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:07.612: INFO: stderr: ""
Dec 14 09:31:07.612: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
Dec 14 09:31:07.612: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:07.697: INFO: stderr: ""
Dec 14 09:31:07.697: INFO: stdout: ""
Dec 14 09:31:07.697: INFO: update-demo-nautilus-ln7l4 is created but not running
Dec 14 09:31:12.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:12.811: INFO: stderr: ""
Dec 14 09:31:12.811: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
Dec 14 09:31:12.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:12.909: INFO: stderr: ""
Dec 14 09:31:12.909: INFO: stdout: "true"
Dec 14 09:31:12.909: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:31:13.010: INFO: stderr: ""
Dec 14 09:31:13.010: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:31:13.010: INFO: validating pod update-demo-nautilus-ln7l4
Dec 14 09:31:13.056: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:31:13.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:31:13.056: INFO: update-demo-nautilus-ln7l4 is verified up and running
Dec 14 09:31:13.056: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:13.142: INFO: stderr: ""
Dec 14 09:31:13.142: INFO: stdout: "true"
Dec 14 09:31:13.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:31:13.255: INFO: stderr: ""
Dec 14 09:31:13.255: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:31:13.255: INFO: validating pod update-demo-nautilus-vp9pg
Dec 14 09:31:13.371: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:31:13.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:31:13.372: INFO: update-demo-nautilus-vp9pg is verified up and running
STEP: scaling down the replication controller 12/14/22 09:31:13.372
Dec 14 09:31:13.374: INFO: scanned /root for discovery docs: <nil>
Dec 14 09:31:13.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Dec 14 09:31:14.474: INFO: stderr: ""
Dec 14 09:31:14.474: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:14.474
Dec 14 09:31:14.474: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:14.588: INFO: stderr: ""
Dec 14 09:31:14.588: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
STEP: Replicas for name=update-demo: expected=1 actual=2 12/14/22 09:31:14.588
Dec 14 09:31:19.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:19.692: INFO: stderr: ""
Dec 14 09:31:19.692: INFO: stdout: "update-demo-nautilus-vp9pg "
Dec 14 09:31:19.692: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:19.793: INFO: stderr: ""
Dec 14 09:31:19.793: INFO: stdout: "true"
Dec 14 09:31:19.793: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:31:19.874: INFO: stderr: ""
Dec 14 09:31:19.874: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:31:19.874: INFO: validating pod update-demo-nautilus-vp9pg
Dec 14 09:31:19.886: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:31:19.886: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:31:19.886: INFO: update-demo-nautilus-vp9pg is verified up and running
STEP: scaling up the replication controller 12/14/22 09:31:19.886
Dec 14 09:31:19.887: INFO: scanned /root for discovery docs: <nil>
Dec 14 09:31:19.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Dec 14 09:31:21.031: INFO: stderr: ""
Dec 14 09:31:21.031: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:21.031
Dec 14 09:31:21.031: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:21.147: INFO: stderr: ""
Dec 14 09:31:21.147: INFO: stdout: "update-demo-nautilus-flvkt update-demo-nautilus-vp9pg "
Dec 14 09:31:21.147: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:21.246: INFO: stderr: ""
Dec 14 09:31:21.246: INFO: stdout: ""
Dec 14 09:31:21.246: INFO: update-demo-nautilus-flvkt is created but not running
Dec 14 09:31:26.246: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 09:31:26.332: INFO: stderr: ""
Dec 14 09:31:26.332: INFO: stdout: "update-demo-nautilus-flvkt update-demo-nautilus-vp9pg "
Dec 14 09:31:26.332: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:26.446: INFO: stderr: ""
Dec 14 09:31:26.446: INFO: stdout: "true"
Dec 14 09:31:26.446: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:31:26.553: INFO: stderr: ""
Dec 14 09:31:26.553: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:31:26.553: INFO: validating pod update-demo-nautilus-flvkt
Dec 14 09:31:26.584: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:31:26.584: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:31:26.584: INFO: update-demo-nautilus-flvkt is verified up and running
Dec 14 09:31:26.584: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 09:31:26.670: INFO: stderr: ""
Dec 14 09:31:26.670: INFO: stdout: "true"
Dec 14 09:31:26.670: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 09:31:26.776: INFO: stderr: ""
Dec 14 09:31:26.776: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 09:31:26.776: INFO: validating pod update-demo-nautilus-vp9pg
Dec 14 09:31:26.789: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 09:31:26.789: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 09:31:26.789: INFO: update-demo-nautilus-vp9pg is verified up and running
STEP: using delete to clean up resources 12/14/22 09:31:26.789
Dec 14 09:31:26.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 delete --grace-period=0 --force -f -'
Dec 14 09:31:26.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:31:26.871: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 14 09:31:26.871: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get rc,svc -l name=update-demo --no-headers'
Dec 14 09:31:26.996: INFO: stderr: "No resources found in kubectl-7293 namespace.\n"
Dec 14 09:31:26.996: INFO: stdout: ""
Dec 14 09:31:26.996: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 09:31:27.090: INFO: stderr: ""
Dec 14 09:31:27.090: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:31:27.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7293" for this suite. 12/14/22 09:31:27.099
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":168,"skipped":2999,"failed":0}
------------------------------
• [20.308 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:06.799
    Dec 14 09:31:06.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:31:06.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:06.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:06.828
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 12/14/22 09:31:06.839
    Dec 14 09:31:06.839: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 create -f -'
    Dec 14 09:31:07.499: INFO: stderr: ""
    Dec 14 09:31:07.499: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:07.499
    Dec 14 09:31:07.499: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:07.612: INFO: stderr: ""
    Dec 14 09:31:07.612: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
    Dec 14 09:31:07.612: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:07.697: INFO: stderr: ""
    Dec 14 09:31:07.697: INFO: stdout: ""
    Dec 14 09:31:07.697: INFO: update-demo-nautilus-ln7l4 is created but not running
    Dec 14 09:31:12.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:12.811: INFO: stderr: ""
    Dec 14 09:31:12.811: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
    Dec 14 09:31:12.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:12.909: INFO: stderr: ""
    Dec 14 09:31:12.909: INFO: stdout: "true"
    Dec 14 09:31:12.909: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-ln7l4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:31:13.010: INFO: stderr: ""
    Dec 14 09:31:13.010: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:31:13.010: INFO: validating pod update-demo-nautilus-ln7l4
    Dec 14 09:31:13.056: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:31:13.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:31:13.056: INFO: update-demo-nautilus-ln7l4 is verified up and running
    Dec 14 09:31:13.056: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:13.142: INFO: stderr: ""
    Dec 14 09:31:13.142: INFO: stdout: "true"
    Dec 14 09:31:13.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:31:13.255: INFO: stderr: ""
    Dec 14 09:31:13.255: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:31:13.255: INFO: validating pod update-demo-nautilus-vp9pg
    Dec 14 09:31:13.371: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:31:13.372: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:31:13.372: INFO: update-demo-nautilus-vp9pg is verified up and running
    STEP: scaling down the replication controller 12/14/22 09:31:13.372
    Dec 14 09:31:13.374: INFO: scanned /root for discovery docs: <nil>
    Dec 14 09:31:13.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Dec 14 09:31:14.474: INFO: stderr: ""
    Dec 14 09:31:14.474: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:14.474
    Dec 14 09:31:14.474: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:14.588: INFO: stderr: ""
    Dec 14 09:31:14.588: INFO: stdout: "update-demo-nautilus-ln7l4 update-demo-nautilus-vp9pg "
    STEP: Replicas for name=update-demo: expected=1 actual=2 12/14/22 09:31:14.588
    Dec 14 09:31:19.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:19.692: INFO: stderr: ""
    Dec 14 09:31:19.692: INFO: stdout: "update-demo-nautilus-vp9pg "
    Dec 14 09:31:19.692: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:19.793: INFO: stderr: ""
    Dec 14 09:31:19.793: INFO: stdout: "true"
    Dec 14 09:31:19.793: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:31:19.874: INFO: stderr: ""
    Dec 14 09:31:19.874: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:31:19.874: INFO: validating pod update-demo-nautilus-vp9pg
    Dec 14 09:31:19.886: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:31:19.886: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:31:19.886: INFO: update-demo-nautilus-vp9pg is verified up and running
    STEP: scaling up the replication controller 12/14/22 09:31:19.886
    Dec 14 09:31:19.887: INFO: scanned /root for discovery docs: <nil>
    Dec 14 09:31:19.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Dec 14 09:31:21.031: INFO: stderr: ""
    Dec 14 09:31:21.031: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 09:31:21.031
    Dec 14 09:31:21.031: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:21.147: INFO: stderr: ""
    Dec 14 09:31:21.147: INFO: stdout: "update-demo-nautilus-flvkt update-demo-nautilus-vp9pg "
    Dec 14 09:31:21.147: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:21.246: INFO: stderr: ""
    Dec 14 09:31:21.246: INFO: stdout: ""
    Dec 14 09:31:21.246: INFO: update-demo-nautilus-flvkt is created but not running
    Dec 14 09:31:26.246: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 09:31:26.332: INFO: stderr: ""
    Dec 14 09:31:26.332: INFO: stdout: "update-demo-nautilus-flvkt update-demo-nautilus-vp9pg "
    Dec 14 09:31:26.332: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:26.446: INFO: stderr: ""
    Dec 14 09:31:26.446: INFO: stdout: "true"
    Dec 14 09:31:26.446: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-flvkt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:31:26.553: INFO: stderr: ""
    Dec 14 09:31:26.553: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:31:26.553: INFO: validating pod update-demo-nautilus-flvkt
    Dec 14 09:31:26.584: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:31:26.584: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:31:26.584: INFO: update-demo-nautilus-flvkt is verified up and running
    Dec 14 09:31:26.584: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 09:31:26.670: INFO: stderr: ""
    Dec 14 09:31:26.670: INFO: stdout: "true"
    Dec 14 09:31:26.670: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods update-demo-nautilus-vp9pg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 09:31:26.776: INFO: stderr: ""
    Dec 14 09:31:26.776: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 09:31:26.776: INFO: validating pod update-demo-nautilus-vp9pg
    Dec 14 09:31:26.789: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 09:31:26.789: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 09:31:26.789: INFO: update-demo-nautilus-vp9pg is verified up and running
    STEP: using delete to clean up resources 12/14/22 09:31:26.789
    Dec 14 09:31:26.789: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 delete --grace-period=0 --force -f -'
    Dec 14 09:31:26.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:31:26.871: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec 14 09:31:26.871: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get rc,svc -l name=update-demo --no-headers'
    Dec 14 09:31:26.996: INFO: stderr: "No resources found in kubectl-7293 namespace.\n"
    Dec 14 09:31:26.996: INFO: stdout: ""
    Dec 14 09:31:26.996: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7293 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 09:31:27.090: INFO: stderr: ""
    Dec 14 09:31:27.090: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:31:27.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7293" for this suite. 12/14/22 09:31:27.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:27.108
Dec 14 09:31:27.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:31:27.109
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:27.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:27.136
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:31:27.162
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:31:27.411
STEP: Deploying the webhook pod 12/14/22 09:31:27.418
STEP: Wait for the deployment to be ready 12/14/22 09:31:27.432
Dec 14 09:31:27.444: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:31:29.465
STEP: Verifying the service has paired with the endpoint 12/14/22 09:31:29.475
Dec 14 09:31:30.476: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 12/14/22 09:31:30.483
STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/14/22 09:31:30.633
STEP: Creating a configMap that should not be mutated 12/14/22 09:31:30.641
STEP: Patching a mutating webhook configuration's rules to include the create operation 12/14/22 09:31:30.659
STEP: Creating a configMap that should be mutated 12/14/22 09:31:30.666
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:31:30.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9999" for this suite. 12/14/22 09:31:30.846
STEP: Destroying namespace "webhook-9999-markers" for this suite. 12/14/22 09:31:30.853
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":169,"skipped":3005,"failed":0}
------------------------------
• [3.786 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:27.108
    Dec 14 09:31:27.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:31:27.109
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:27.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:27.136
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:31:27.162
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:31:27.411
    STEP: Deploying the webhook pod 12/14/22 09:31:27.418
    STEP: Wait for the deployment to be ready 12/14/22 09:31:27.432
    Dec 14 09:31:27.444: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:31:29.465
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:31:29.475
    Dec 14 09:31:30.476: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 12/14/22 09:31:30.483
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 12/14/22 09:31:30.633
    STEP: Creating a configMap that should not be mutated 12/14/22 09:31:30.641
    STEP: Patching a mutating webhook configuration's rules to include the create operation 12/14/22 09:31:30.659
    STEP: Creating a configMap that should be mutated 12/14/22 09:31:30.666
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:31:30.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9999" for this suite. 12/14/22 09:31:30.846
    STEP: Destroying namespace "webhook-9999-markers" for this suite. 12/14/22 09:31:30.853
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:30.895
Dec 14 09:31:30.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:31:30.896
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:30.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:30.923
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-58 12/14/22 09:31:30.933
STEP: creating service affinity-nodeport-transition in namespace services-58 12/14/22 09:31:30.933
STEP: creating replication controller affinity-nodeport-transition in namespace services-58 12/14/22 09:31:30.945
I1214 09:31:30.952317    6248 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-58, replica count: 3
I1214 09:31:34.003307    6248 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:31:34.024: INFO: Creating new exec pod
Dec 14 09:31:34.036: INFO: Waiting up to 5m0s for pod "execpod-affinityhvvvs" in namespace "services-58" to be "running"
Dec 14 09:31:34.042: INFO: Pod "execpod-affinityhvvvs": Phase="Pending", Reason="", readiness=false. Elapsed: 5.686211ms
Dec 14 09:31:36.048: INFO: Pod "execpod-affinityhvvvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.011461775s
Dec 14 09:31:36.048: INFO: Pod "execpod-affinityhvvvs" satisfied condition "running"
Dec 14 09:31:37.057: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Dec 14 09:31:37.545: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:37.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:31:37.546: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.103.70 80'
Dec 14 09:31:38.003: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.103.70 80\nConnection to 172.31.103.70 80 port [tcp/http] succeeded!\n"
Dec 14 09:31:38.003: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:31:38.003: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 31748'
Dec 14 09:31:38.545: INFO: stderr: "+ + nc -v -t -w 2 10.250.18.71 31748\necho hostName\nConnection to 10.250.18.71 31748 port [tcp/*] succeeded!\n"
Dec 14 09:31:38.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:31:38.545: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31748'
Dec 14 09:31:39.126: INFO: stderr: "+ nc -v -t -w 2 10.250.18.72 31748\nConnection to 10.250.18.72 31748 port [tcp/*] succeeded!\n+ echo hostName\n"
Dec 14 09:31:39.126: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:31:39.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:31748/ ; done'
Dec 14 09:31:39.804: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n"
Dec 14 09:31:39.804: INFO: stdout: "\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx"
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:39.817: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:31748/ ; done'
Dec 14 09:31:40.439: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n"
Dec 14 09:31:40.439: INFO: stdout: "\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx"
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
Dec 14 09:31:40.439: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-58, will wait for the garbage collector to delete the pods 12/14/22 09:31:40.449
Dec 14 09:31:40.512: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.807499ms
Dec 14 09:31:40.613: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.889851ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:31:42.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-58" for this suite. 12/14/22 09:31:42.539
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":170,"skipped":3024,"failed":0}
------------------------------
• [11.651 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:30.895
    Dec 14 09:31:30.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:31:30.896
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:30.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:30.923
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-58 12/14/22 09:31:30.933
    STEP: creating service affinity-nodeport-transition in namespace services-58 12/14/22 09:31:30.933
    STEP: creating replication controller affinity-nodeport-transition in namespace services-58 12/14/22 09:31:30.945
    I1214 09:31:30.952317    6248 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-58, replica count: 3
    I1214 09:31:34.003307    6248 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:31:34.024: INFO: Creating new exec pod
    Dec 14 09:31:34.036: INFO: Waiting up to 5m0s for pod "execpod-affinityhvvvs" in namespace "services-58" to be "running"
    Dec 14 09:31:34.042: INFO: Pod "execpod-affinityhvvvs": Phase="Pending", Reason="", readiness=false. Elapsed: 5.686211ms
    Dec 14 09:31:36.048: INFO: Pod "execpod-affinityhvvvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.011461775s
    Dec 14 09:31:36.048: INFO: Pod "execpod-affinityhvvvs" satisfied condition "running"
    Dec 14 09:31:37.057: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Dec 14 09:31:37.545: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:37.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:31:37.546: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.103.70 80'
    Dec 14 09:31:38.003: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.103.70 80\nConnection to 172.31.103.70 80 port [tcp/http] succeeded!\n"
    Dec 14 09:31:38.003: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:31:38.003: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 31748'
    Dec 14 09:31:38.545: INFO: stderr: "+ + nc -v -t -w 2 10.250.18.71 31748\necho hostName\nConnection to 10.250.18.71 31748 port [tcp/*] succeeded!\n"
    Dec 14 09:31:38.545: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:31:38.545: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 31748'
    Dec 14 09:31:39.126: INFO: stderr: "+ nc -v -t -w 2 10.250.18.72 31748\nConnection to 10.250.18.72 31748 port [tcp/*] succeeded!\n+ echo hostName\n"
    Dec 14 09:31:39.126: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:31:39.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:31748/ ; done'
    Dec 14 09:31:39.804: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n"
    Dec 14 09:31:39.804: INFO: stdout: "\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-zrbmq\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-hfrbh\naffinity-nodeport-transition-778hx"
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-zrbmq
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-hfrbh
    Dec 14 09:31:39.804: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:39.817: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-58 exec execpod-affinityhvvvs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:31748/ ; done'
    Dec 14 09:31:40.439: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:31748/\n"
    Dec 14 09:31:40.439: INFO: stdout: "\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx\naffinity-nodeport-transition-778hx"
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Received response from host: affinity-nodeport-transition-778hx
    Dec 14 09:31:40.439: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-58, will wait for the garbage collector to delete the pods 12/14/22 09:31:40.449
    Dec 14 09:31:40.512: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.807499ms
    Dec 14 09:31:40.613: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.889851ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:31:42.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-58" for this suite. 12/14/22 09:31:42.539
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:42.547
Dec 14 09:31:42.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:31:42.548
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:42.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:42.575
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-069b3067-28f2-40eb-84e1-8b4005ae368e 12/14/22 09:31:42.584
STEP: Creating a pod to test consume configMaps 12/14/22 09:31:42.59
Dec 14 09:31:42.606: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b" in namespace "configmap-9881" to be "Succeeded or Failed"
Dec 14 09:31:42.611: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.40797ms
Dec 14 09:31:44.618: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012587538s
Dec 14 09:31:46.619: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013361381s
STEP: Saw pod success 12/14/22 09:31:46.619
Dec 14 09:31:46.619: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b" satisfied condition "Succeeded or Failed"
Dec 14 09:31:46.636: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:31:46.653
Dec 14 09:31:46.662: INFO: Waiting for pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b to disappear
Dec 14 09:31:46.667: INFO: Pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:31:46.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9881" for this suite. 12/14/22 09:31:46.677
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":171,"skipped":3053,"failed":0}
------------------------------
• [4.138 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:42.547
    Dec 14 09:31:42.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:31:42.548
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:42.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:42.575
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-069b3067-28f2-40eb-84e1-8b4005ae368e 12/14/22 09:31:42.584
    STEP: Creating a pod to test consume configMaps 12/14/22 09:31:42.59
    Dec 14 09:31:42.606: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b" in namespace "configmap-9881" to be "Succeeded or Failed"
    Dec 14 09:31:42.611: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.40797ms
    Dec 14 09:31:44.618: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012587538s
    Dec 14 09:31:46.619: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013361381s
    STEP: Saw pod success 12/14/22 09:31:46.619
    Dec 14 09:31:46.619: INFO: Pod "pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b" satisfied condition "Succeeded or Failed"
    Dec 14 09:31:46.636: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:31:46.653
    Dec 14 09:31:46.662: INFO: Waiting for pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b to disappear
    Dec 14 09:31:46.667: INFO: Pod pod-configmaps-8e44dba6-088c-41cf-b22a-1e7c26ec7c5b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:31:46.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9881" for this suite. 12/14/22 09:31:46.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:46.686
Dec 14 09:31:46.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:31:46.687
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:46.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:46.715
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8157 12/14/22 09:31:46.724
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 09:31:46.734
STEP: creating service externalsvc in namespace services-8157 12/14/22 09:31:46.734
STEP: creating replication controller externalsvc in namespace services-8157 12/14/22 09:31:46.744
I1214 09:31:46.750992    6248 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8157, replica count: 2
I1214 09:31:49.802632    6248 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 12/14/22 09:31:49.809
Dec 14 09:31:49.827: INFO: Creating new exec pod
Dec 14 09:31:49.840: INFO: Waiting up to 5m0s for pod "execpodn2th7" in namespace "services-8157" to be "running"
Dec 14 09:31:49.846: INFO: Pod "execpodn2th7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.483801ms
Dec 14 09:31:51.852: INFO: Pod "execpodn2th7": Phase="Running", Reason="", readiness=true. Elapsed: 2.012149199s
Dec 14 09:31:51.852: INFO: Pod "execpodn2th7" satisfied condition "running"
Dec 14 09:31:51.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-8157 exec execpodn2th7 -- /bin/sh -x -c nslookup clusterip-service.services-8157.svc.cluster.local'
Dec 14 09:31:52.410: INFO: stderr: "+ nslookup clusterip-service.services-8157.svc.cluster.local\n"
Dec 14 09:31:52.410: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nclusterip-service.services-8157.svc.cluster.local\tcanonical name = externalsvc.services-8157.svc.cluster.local.\nName:\texternalsvc.services-8157.svc.cluster.local\nAddress: 172.26.78.123\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8157, will wait for the garbage collector to delete the pods 12/14/22 09:31:52.41
Dec 14 09:31:52.475: INFO: Deleting ReplicationController externalsvc took: 7.361666ms
Dec 14 09:31:52.576: INFO: Terminating ReplicationController externalsvc pods took: 100.806305ms
Dec 14 09:31:54.512: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:31:54.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8157" for this suite. 12/14/22 09:31:54.559
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":172,"skipped":3098,"failed":0}
------------------------------
• [7.880 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:46.686
    Dec 14 09:31:46.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:31:46.687
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:46.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:46.715
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8157 12/14/22 09:31:46.724
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 09:31:46.734
    STEP: creating service externalsvc in namespace services-8157 12/14/22 09:31:46.734
    STEP: creating replication controller externalsvc in namespace services-8157 12/14/22 09:31:46.744
    I1214 09:31:46.750992    6248 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8157, replica count: 2
    I1214 09:31:49.802632    6248 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 12/14/22 09:31:49.809
    Dec 14 09:31:49.827: INFO: Creating new exec pod
    Dec 14 09:31:49.840: INFO: Waiting up to 5m0s for pod "execpodn2th7" in namespace "services-8157" to be "running"
    Dec 14 09:31:49.846: INFO: Pod "execpodn2th7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.483801ms
    Dec 14 09:31:51.852: INFO: Pod "execpodn2th7": Phase="Running", Reason="", readiness=true. Elapsed: 2.012149199s
    Dec 14 09:31:51.852: INFO: Pod "execpodn2th7" satisfied condition "running"
    Dec 14 09:31:51.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-8157 exec execpodn2th7 -- /bin/sh -x -c nslookup clusterip-service.services-8157.svc.cluster.local'
    Dec 14 09:31:52.410: INFO: stderr: "+ nslookup clusterip-service.services-8157.svc.cluster.local\n"
    Dec 14 09:31:52.410: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nclusterip-service.services-8157.svc.cluster.local\tcanonical name = externalsvc.services-8157.svc.cluster.local.\nName:\texternalsvc.services-8157.svc.cluster.local\nAddress: 172.26.78.123\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-8157, will wait for the garbage collector to delete the pods 12/14/22 09:31:52.41
    Dec 14 09:31:52.475: INFO: Deleting ReplicationController externalsvc took: 7.361666ms
    Dec 14 09:31:52.576: INFO: Terminating ReplicationController externalsvc pods took: 100.806305ms
    Dec 14 09:31:54.512: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:31:54.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8157" for this suite. 12/14/22 09:31:54.559
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:31:54.567
Dec 14 09:31:54.567: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:31:54.567
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:54.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:54.595
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 12/14/22 09:31:54.604
Dec 14 09:31:54.605: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Dec 14 09:31:54.605: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:54.868: INFO: stderr: ""
Dec 14 09:31:54.868: INFO: stdout: "service/agnhost-replica created\n"
Dec 14 09:31:54.868: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Dec 14 09:31:54.868: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:55.450: INFO: stderr: ""
Dec 14 09:31:55.450: INFO: stdout: "service/agnhost-primary created\n"
Dec 14 09:31:55.450: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 14 09:31:55.450: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:55.696: INFO: stderr: ""
Dec 14 09:31:55.696: INFO: stdout: "service/frontend created\n"
Dec 14 09:31:55.696: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Dec 14 09:31:55.696: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:55.939: INFO: stderr: ""
Dec 14 09:31:55.939: INFO: stdout: "deployment.apps/frontend created\n"
Dec 14 09:31:55.939: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 14 09:31:55.939: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:56.176: INFO: stderr: ""
Dec 14 09:31:56.176: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Dec 14 09:31:56.176: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 14 09:31:56.176: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
Dec 14 09:31:56.436: INFO: stderr: ""
Dec 14 09:31:56.436: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 12/14/22 09:31:56.436
Dec 14 09:31:56.436: INFO: Waiting for all frontend pods to be Running.
Dec 14 09:32:01.487: INFO: Waiting for frontend to serve content.
Dec 14 09:32:01.604: INFO: Trying to add a new entry to the guestbook.
Dec 14 09:32:01.748: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 12/14/22 09:32:01.798
Dec 14 09:32:01.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:01.915: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:01.915: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 09:32:01.915
Dec 14 09:32:01.915: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:02.031: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:02.031: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 09:32:02.031
Dec 14 09:32:02.031: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:02.147: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:02.147: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 09:32:02.147
Dec 14 09:32:02.147: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:02.232: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:02.232: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 09:32:02.232
Dec 14 09:32:02.232: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:02.321: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:02.321: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 12/14/22 09:32:02.321
Dec 14 09:32:02.321: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
Dec 14 09:32:02.411: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:32:02.411: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:32:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8236" for this suite. 12/14/22 09:32:02.423
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":173,"skipped":3109,"failed":0}
------------------------------
• [7.863 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:31:54.567
    Dec 14 09:31:54.567: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:31:54.567
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:31:54.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:31:54.595
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 12/14/22 09:31:54.604
    Dec 14 09:31:54.605: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Dec 14 09:31:54.605: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:54.868: INFO: stderr: ""
    Dec 14 09:31:54.868: INFO: stdout: "service/agnhost-replica created\n"
    Dec 14 09:31:54.868: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Dec 14 09:31:54.868: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:55.450: INFO: stderr: ""
    Dec 14 09:31:55.450: INFO: stdout: "service/agnhost-primary created\n"
    Dec 14 09:31:55.450: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Dec 14 09:31:55.450: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:55.696: INFO: stderr: ""
    Dec 14 09:31:55.696: INFO: stdout: "service/frontend created\n"
    Dec 14 09:31:55.696: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Dec 14 09:31:55.696: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:55.939: INFO: stderr: ""
    Dec 14 09:31:55.939: INFO: stdout: "deployment.apps/frontend created\n"
    Dec 14 09:31:55.939: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec 14 09:31:55.939: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:56.176: INFO: stderr: ""
    Dec 14 09:31:56.176: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Dec 14 09:31:56.176: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Dec 14 09:31:56.176: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 create -f -'
    Dec 14 09:31:56.436: INFO: stderr: ""
    Dec 14 09:31:56.436: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 12/14/22 09:31:56.436
    Dec 14 09:31:56.436: INFO: Waiting for all frontend pods to be Running.
    Dec 14 09:32:01.487: INFO: Waiting for frontend to serve content.
    Dec 14 09:32:01.604: INFO: Trying to add a new entry to the guestbook.
    Dec 14 09:32:01.748: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 12/14/22 09:32:01.798
    Dec 14 09:32:01.798: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:01.915: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:01.915: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 09:32:01.915
    Dec 14 09:32:01.915: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:02.031: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:02.031: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 09:32:02.031
    Dec 14 09:32:02.031: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:02.147: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:02.147: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 09:32:02.147
    Dec 14 09:32:02.147: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:02.232: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:02.232: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 09:32:02.232
    Dec 14 09:32:02.232: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:02.321: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:02.321: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 12/14/22 09:32:02.321
    Dec 14 09:32:02.321: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8236 delete --grace-period=0 --force -f -'
    Dec 14 09:32:02.411: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:32:02.411: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:32:02.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8236" for this suite. 12/14/22 09:32:02.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:32:02.433
Dec 14 09:32:02.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:32:02.433
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:02.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:02.46
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:33:02.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2241" for this suite. 12/14/22 09:33:02.501
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":174,"skipped":3123,"failed":0}
------------------------------
• [60.075 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:32:02.433
    Dec 14 09:32:02.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:32:02.433
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:32:02.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:32:02.46
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:33:02.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2241" for this suite. 12/14/22 09:33:02.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:02.509
Dec 14 09:33:02.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:33:02.51
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:02.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:02.539
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2322/configmap-test-86a33088-c96b-4d42-b83f-a24307d99da5 12/14/22 09:33:02.548
STEP: Creating a pod to test consume configMaps 12/14/22 09:33:02.555
Dec 14 09:33:02.568: INFO: Waiting up to 5m0s for pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9" in namespace "configmap-2322" to be "Succeeded or Failed"
Dec 14 09:33:02.574: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.84186ms
Dec 14 09:33:04.581: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013171867s
Dec 14 09:33:06.580: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01247056s
STEP: Saw pod success 12/14/22 09:33:06.58
Dec 14 09:33:06.580: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9" satisfied condition "Succeeded or Failed"
Dec 14 09:33:06.586: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 container env-test: <nil>
STEP: delete the pod 12/14/22 09:33:06.603
Dec 14 09:33:06.613: INFO: Waiting for pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 to disappear
Dec 14 09:33:06.619: INFO: Pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:33:06.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2322" for this suite. 12/14/22 09:33:06.637
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":175,"skipped":3143,"failed":0}
------------------------------
• [4.135 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:02.509
    Dec 14 09:33:02.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:33:02.51
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:02.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:02.539
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2322/configmap-test-86a33088-c96b-4d42-b83f-a24307d99da5 12/14/22 09:33:02.548
    STEP: Creating a pod to test consume configMaps 12/14/22 09:33:02.555
    Dec 14 09:33:02.568: INFO: Waiting up to 5m0s for pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9" in namespace "configmap-2322" to be "Succeeded or Failed"
    Dec 14 09:33:02.574: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.84186ms
    Dec 14 09:33:04.581: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013171867s
    Dec 14 09:33:06.580: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01247056s
    STEP: Saw pod success 12/14/22 09:33:06.58
    Dec 14 09:33:06.580: INFO: Pod "pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9" satisfied condition "Succeeded or Failed"
    Dec 14 09:33:06.586: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 container env-test: <nil>
    STEP: delete the pod 12/14/22 09:33:06.603
    Dec 14 09:33:06.613: INFO: Waiting for pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 to disappear
    Dec 14 09:33:06.619: INFO: Pod pod-configmaps-5855add9-ec46-440a-abe0-84025b3ca3b9 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:33:06.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2322" for this suite. 12/14/22 09:33:06.637
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:06.645
Dec 14 09:33:06.645: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:33:06.645
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:06.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:06.672
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 12/14/22 09:33:06.681
Dec 14 09:33:06.693: INFO: Waiting up to 5m0s for pod "pod-886518be-b5df-4619-bf22-68d56fffebfc" in namespace "emptydir-2194" to be "Succeeded or Failed"
Dec 14 09:33:06.698: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.385767ms
Dec 14 09:33:08.705: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01232103s
Dec 14 09:33:10.706: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012515397s
STEP: Saw pod success 12/14/22 09:33:10.706
Dec 14 09:33:10.706: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc" satisfied condition "Succeeded or Failed"
Dec 14 09:33:10.712: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-886518be-b5df-4619-bf22-68d56fffebfc container test-container: <nil>
STEP: delete the pod 12/14/22 09:33:10.728
Dec 14 09:33:10.739: INFO: Waiting for pod pod-886518be-b5df-4619-bf22-68d56fffebfc to disappear
Dec 14 09:33:10.745: INFO: Pod pod-886518be-b5df-4619-bf22-68d56fffebfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:33:10.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2194" for this suite. 12/14/22 09:33:10.755
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":176,"skipped":3145,"failed":0}
------------------------------
• [4.118 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:06.645
    Dec 14 09:33:06.645: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:33:06.645
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:06.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:06.672
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 12/14/22 09:33:06.681
    Dec 14 09:33:06.693: INFO: Waiting up to 5m0s for pod "pod-886518be-b5df-4619-bf22-68d56fffebfc" in namespace "emptydir-2194" to be "Succeeded or Failed"
    Dec 14 09:33:06.698: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.385767ms
    Dec 14 09:33:08.705: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01232103s
    Dec 14 09:33:10.706: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012515397s
    STEP: Saw pod success 12/14/22 09:33:10.706
    Dec 14 09:33:10.706: INFO: Pod "pod-886518be-b5df-4619-bf22-68d56fffebfc" satisfied condition "Succeeded or Failed"
    Dec 14 09:33:10.712: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-886518be-b5df-4619-bf22-68d56fffebfc container test-container: <nil>
    STEP: delete the pod 12/14/22 09:33:10.728
    Dec 14 09:33:10.739: INFO: Waiting for pod pod-886518be-b5df-4619-bf22-68d56fffebfc to disappear
    Dec 14 09:33:10.745: INFO: Pod pod-886518be-b5df-4619-bf22-68d56fffebfc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:33:10.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2194" for this suite. 12/14/22 09:33:10.755
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:10.763
Dec 14 09:33:10.763: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:33:10.764
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:10.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:10.792
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 12/14/22 09:33:10.809
STEP: create the rc2 12/14/22 09:33:10.816
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/14/22 09:33:15.829
STEP: delete the rc simpletest-rc-to-be-deleted 12/14/22 09:33:16.277
STEP: wait for the rc to be deleted 12/14/22 09:33:16.284
Dec 14 09:33:21.309: INFO: 66 pods remaining
Dec 14 09:33:21.309: INFO: 66 pods has nil DeletionTimestamp
Dec 14 09:33:21.309: INFO: 
STEP: Gathering metrics 12/14/22 09:33:26.304
W1214 09:33:26.319083    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:33:26.319: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 14 09:33:26.319: INFO: Deleting pod "simpletest-rc-to-be-deleted-29qrw" in namespace "gc-5213"
Dec 14 09:33:26.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tfvv" in namespace "gc-5213"
Dec 14 09:33:26.337: INFO: Deleting pod "simpletest-rc-to-be-deleted-2w8r5" in namespace "gc-5213"
Dec 14 09:33:26.345: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s6ms" in namespace "gc-5213"
Dec 14 09:33:26.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-4thcg" in namespace "gc-5213"
Dec 14 09:33:26.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-57dgz" in namespace "gc-5213"
Dec 14 09:33:26.372: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cr22" in namespace "gc-5213"
Dec 14 09:33:26.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-5gmsp" in namespace "gc-5213"
Dec 14 09:33:26.389: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ljcf" in namespace "gc-5213"
Dec 14 09:33:26.397: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v6hh" in namespace "gc-5213"
Dec 14 09:33:26.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vxg9" in namespace "gc-5213"
Dec 14 09:33:26.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wfl2" in namespace "gc-5213"
Dec 14 09:33:26.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lzn8" in namespace "gc-5213"
Dec 14 09:33:26.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-6p8gb" in namespace "gc-5213"
Dec 14 09:33:26.448: INFO: Deleting pod "simpletest-rc-to-be-deleted-7m4xn" in namespace "gc-5213"
Dec 14 09:33:26.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-7vl72" in namespace "gc-5213"
Dec 14 09:33:26.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z5g7" in namespace "gc-5213"
Dec 14 09:33:26.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zs9b" in namespace "gc-5213"
Dec 14 09:33:26.488: INFO: Deleting pod "simpletest-rc-to-be-deleted-82vdk" in namespace "gc-5213"
Dec 14 09:33:26.495: INFO: Deleting pod "simpletest-rc-to-be-deleted-84xv4" in namespace "gc-5213"
Dec 14 09:33:26.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-8c2mc" in namespace "gc-5213"
Dec 14 09:33:26.513: INFO: Deleting pod "simpletest-rc-to-be-deleted-8drpq" in namespace "gc-5213"
Dec 14 09:33:26.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-8llhg" in namespace "gc-5213"
Dec 14 09:33:26.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rq92" in namespace "gc-5213"
Dec 14 09:33:26.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-986b6" in namespace "gc-5213"
Dec 14 09:33:26.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jxtv" in namespace "gc-5213"
Dec 14 09:33:26.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n8tp" in namespace "gc-5213"
Dec 14 09:33:26.567: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s2fj" in namespace "gc-5213"
Dec 14 09:33:26.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-bf8f7" in namespace "gc-5213"
Dec 14 09:33:26.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-bhchb" in namespace "gc-5213"
Dec 14 09:33:26.596: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqrq8" in namespace "gc-5213"
Dec 14 09:33:26.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8p8q" in namespace "gc-5213"
Dec 14 09:33:26.613: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgvcq" in namespace "gc-5213"
Dec 14 09:33:26.622: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjh2p" in namespace "gc-5213"
Dec 14 09:33:26.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjqhx" in namespace "gc-5213"
Dec 14 09:33:26.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddm64" in namespace "gc-5213"
Dec 14 09:33:26.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhgz9" in namespace "gc-5213"
Dec 14 09:33:26.664: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqrp6" in namespace "gc-5213"
Dec 14 09:33:26.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-dw95q" in namespace "gc-5213"
Dec 14 09:33:26.682: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzp46" in namespace "gc-5213"
Dec 14 09:33:26.691: INFO: Deleting pod "simpletest-rc-to-be-deleted-fcxx4" in namespace "gc-5213"
Dec 14 09:33:26.699: INFO: Deleting pod "simpletest-rc-to-be-deleted-fr4r7" in namespace "gc-5213"
Dec 14 09:33:26.707: INFO: Deleting pod "simpletest-rc-to-be-deleted-frjgt" in namespace "gc-5213"
Dec 14 09:33:26.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2zcw" in namespace "gc-5213"
Dec 14 09:33:26.726: INFO: Deleting pod "simpletest-rc-to-be-deleted-gds8c" in namespace "gc-5213"
Dec 14 09:33:26.733: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfz9h" in namespace "gc-5213"
Dec 14 09:33:26.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-gk7ng" in namespace "gc-5213"
Dec 14 09:33:26.751: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtnb9" in namespace "gc-5213"
Dec 14 09:33:26.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwrnm" in namespace "gc-5213"
Dec 14 09:33:26.769: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjxgl" in namespace "gc-5213"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:33:26.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5213" for this suite. 12/14/22 09:33:26.784
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":177,"skipped":3159,"failed":0}
------------------------------
• [16.028 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:10.763
    Dec 14 09:33:10.763: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:33:10.764
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:10.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:10.792
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 12/14/22 09:33:10.809
    STEP: create the rc2 12/14/22 09:33:10.816
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 12/14/22 09:33:15.829
    STEP: delete the rc simpletest-rc-to-be-deleted 12/14/22 09:33:16.277
    STEP: wait for the rc to be deleted 12/14/22 09:33:16.284
    Dec 14 09:33:21.309: INFO: 66 pods remaining
    Dec 14 09:33:21.309: INFO: 66 pods has nil DeletionTimestamp
    Dec 14 09:33:21.309: INFO: 
    STEP: Gathering metrics 12/14/22 09:33:26.304
    W1214 09:33:26.319083    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:33:26.319: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec 14 09:33:26.319: INFO: Deleting pod "simpletest-rc-to-be-deleted-29qrw" in namespace "gc-5213"
    Dec 14 09:33:26.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tfvv" in namespace "gc-5213"
    Dec 14 09:33:26.337: INFO: Deleting pod "simpletest-rc-to-be-deleted-2w8r5" in namespace "gc-5213"
    Dec 14 09:33:26.345: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s6ms" in namespace "gc-5213"
    Dec 14 09:33:26.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-4thcg" in namespace "gc-5213"
    Dec 14 09:33:26.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-57dgz" in namespace "gc-5213"
    Dec 14 09:33:26.372: INFO: Deleting pod "simpletest-rc-to-be-deleted-5cr22" in namespace "gc-5213"
    Dec 14 09:33:26.381: INFO: Deleting pod "simpletest-rc-to-be-deleted-5gmsp" in namespace "gc-5213"
    Dec 14 09:33:26.389: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ljcf" in namespace "gc-5213"
    Dec 14 09:33:26.397: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v6hh" in namespace "gc-5213"
    Dec 14 09:33:26.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-5vxg9" in namespace "gc-5213"
    Dec 14 09:33:26.422: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wfl2" in namespace "gc-5213"
    Dec 14 09:33:26.431: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lzn8" in namespace "gc-5213"
    Dec 14 09:33:26.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-6p8gb" in namespace "gc-5213"
    Dec 14 09:33:26.448: INFO: Deleting pod "simpletest-rc-to-be-deleted-7m4xn" in namespace "gc-5213"
    Dec 14 09:33:26.458: INFO: Deleting pod "simpletest-rc-to-be-deleted-7vl72" in namespace "gc-5213"
    Dec 14 09:33:26.468: INFO: Deleting pod "simpletest-rc-to-be-deleted-7z5g7" in namespace "gc-5213"
    Dec 14 09:33:26.477: INFO: Deleting pod "simpletest-rc-to-be-deleted-7zs9b" in namespace "gc-5213"
    Dec 14 09:33:26.488: INFO: Deleting pod "simpletest-rc-to-be-deleted-82vdk" in namespace "gc-5213"
    Dec 14 09:33:26.495: INFO: Deleting pod "simpletest-rc-to-be-deleted-84xv4" in namespace "gc-5213"
    Dec 14 09:33:26.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-8c2mc" in namespace "gc-5213"
    Dec 14 09:33:26.513: INFO: Deleting pod "simpletest-rc-to-be-deleted-8drpq" in namespace "gc-5213"
    Dec 14 09:33:26.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-8llhg" in namespace "gc-5213"
    Dec 14 09:33:26.531: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rq92" in namespace "gc-5213"
    Dec 14 09:33:26.541: INFO: Deleting pod "simpletest-rc-to-be-deleted-986b6" in namespace "gc-5213"
    Dec 14 09:33:26.550: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jxtv" in namespace "gc-5213"
    Dec 14 09:33:26.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-9n8tp" in namespace "gc-5213"
    Dec 14 09:33:26.567: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s2fj" in namespace "gc-5213"
    Dec 14 09:33:26.577: INFO: Deleting pod "simpletest-rc-to-be-deleted-bf8f7" in namespace "gc-5213"
    Dec 14 09:33:26.586: INFO: Deleting pod "simpletest-rc-to-be-deleted-bhchb" in namespace "gc-5213"
    Dec 14 09:33:26.596: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqrq8" in namespace "gc-5213"
    Dec 14 09:33:26.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8p8q" in namespace "gc-5213"
    Dec 14 09:33:26.613: INFO: Deleting pod "simpletest-rc-to-be-deleted-cgvcq" in namespace "gc-5213"
    Dec 14 09:33:26.622: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjh2p" in namespace "gc-5213"
    Dec 14 09:33:26.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjqhx" in namespace "gc-5213"
    Dec 14 09:33:26.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddm64" in namespace "gc-5213"
    Dec 14 09:33:26.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-dhgz9" in namespace "gc-5213"
    Dec 14 09:33:26.664: INFO: Deleting pod "simpletest-rc-to-be-deleted-dqrp6" in namespace "gc-5213"
    Dec 14 09:33:26.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-dw95q" in namespace "gc-5213"
    Dec 14 09:33:26.682: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzp46" in namespace "gc-5213"
    Dec 14 09:33:26.691: INFO: Deleting pod "simpletest-rc-to-be-deleted-fcxx4" in namespace "gc-5213"
    Dec 14 09:33:26.699: INFO: Deleting pod "simpletest-rc-to-be-deleted-fr4r7" in namespace "gc-5213"
    Dec 14 09:33:26.707: INFO: Deleting pod "simpletest-rc-to-be-deleted-frjgt" in namespace "gc-5213"
    Dec 14 09:33:26.717: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2zcw" in namespace "gc-5213"
    Dec 14 09:33:26.726: INFO: Deleting pod "simpletest-rc-to-be-deleted-gds8c" in namespace "gc-5213"
    Dec 14 09:33:26.733: INFO: Deleting pod "simpletest-rc-to-be-deleted-gfz9h" in namespace "gc-5213"
    Dec 14 09:33:26.742: INFO: Deleting pod "simpletest-rc-to-be-deleted-gk7ng" in namespace "gc-5213"
    Dec 14 09:33:26.751: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtnb9" in namespace "gc-5213"
    Dec 14 09:33:26.760: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwrnm" in namespace "gc-5213"
    Dec 14 09:33:26.769: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjxgl" in namespace "gc-5213"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:33:26.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5213" for this suite. 12/14/22 09:33:26.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:26.793
Dec 14 09:33:26.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:33:26.794
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:26.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:26.819
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 09:33:26.829
Dec 14 09:33:26.840: INFO: Waiting up to 5m0s for pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c" in namespace "emptydir-598" to be "Succeeded or Failed"
Dec 14 09:33:26.845: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.291859ms
Dec 14 09:33:28.852: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012128661s
Dec 14 09:33:30.852: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011787085s
Dec 14 09:33:32.853: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012765647s
STEP: Saw pod success 12/14/22 09:33:32.853
Dec 14 09:33:32.853: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c" satisfied condition "Succeeded or Failed"
Dec 14 09:33:32.859: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c container test-container: <nil>
STEP: delete the pod 12/14/22 09:33:32.876
Dec 14 09:33:32.886: INFO: Waiting for pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c to disappear
Dec 14 09:33:32.896: INFO: Pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:33:32.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-598" for this suite. 12/14/22 09:33:32.906
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":178,"skipped":3209,"failed":0}
------------------------------
• [6.120 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:26.793
    Dec 14 09:33:26.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:33:26.794
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:26.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:26.819
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 09:33:26.829
    Dec 14 09:33:26.840: INFO: Waiting up to 5m0s for pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c" in namespace "emptydir-598" to be "Succeeded or Failed"
    Dec 14 09:33:26.845: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.291859ms
    Dec 14 09:33:28.852: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012128661s
    Dec 14 09:33:30.852: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011787085s
    Dec 14 09:33:32.853: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012765647s
    STEP: Saw pod success 12/14/22 09:33:32.853
    Dec 14 09:33:32.853: INFO: Pod "pod-c55656a8-6d30-498b-9c84-0c434ff9332c" satisfied condition "Succeeded or Failed"
    Dec 14 09:33:32.859: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c container test-container: <nil>
    STEP: delete the pod 12/14/22 09:33:32.876
    Dec 14 09:33:32.886: INFO: Waiting for pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c to disappear
    Dec 14 09:33:32.896: INFO: Pod pod-c55656a8-6d30-498b-9c84-0c434ff9332c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:33:32.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-598" for this suite. 12/14/22 09:33:32.906
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:32.914
Dec 14 09:33:32.914: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:33:32.915
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:32.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:32.947
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:33:32.964
Dec 14 09:33:32.975: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5727" to be "running and ready"
Dec 14 09:33:32.981: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.420971ms
Dec 14 09:33:32.981: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:33:34.987: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.011817846s
Dec 14 09:33:34.987: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:33:34.987: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 12/14/22 09:33:34.993
Dec 14 09:33:35.003: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5727" to be "running and ready"
Dec 14 09:33:35.009: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537624ms
Dec 14 09:33:35.009: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:33:37.017: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013691499s
Dec 14 09:33:37.017: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Dec 14 09:33:37.017: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/14/22 09:33:37.023
Dec 14 09:33:37.030: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:33:37.036: INFO: Pod pod-with-prestop-http-hook still exists
Dec 14 09:33:39.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:33:39.043: INFO: Pod pod-with-prestop-http-hook still exists
Dec 14 09:33:41.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 14 09:33:41.042: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 12/14/22 09:33:41.042
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:33:41.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5727" for this suite. 12/14/22 09:33:41.11
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":179,"skipped":3236,"failed":0}
------------------------------
• [8.203 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:32.914
    Dec 14 09:33:32.914: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:33:32.915
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:32.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:32.947
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:33:32.964
    Dec 14 09:33:32.975: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5727" to be "running and ready"
    Dec 14 09:33:32.981: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.420971ms
    Dec 14 09:33:32.981: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:33:34.987: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.011817846s
    Dec 14 09:33:34.987: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:33:34.987: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 12/14/22 09:33:34.993
    Dec 14 09:33:35.003: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5727" to be "running and ready"
    Dec 14 09:33:35.009: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537624ms
    Dec 14 09:33:35.009: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:33:37.017: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013691499s
    Dec 14 09:33:37.017: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Dec 14 09:33:37.017: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/14/22 09:33:37.023
    Dec 14 09:33:37.030: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:33:37.036: INFO: Pod pod-with-prestop-http-hook still exists
    Dec 14 09:33:39.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:33:39.043: INFO: Pod pod-with-prestop-http-hook still exists
    Dec 14 09:33:41.037: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Dec 14 09:33:41.042: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 12/14/22 09:33:41.042
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:33:41.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5727" for this suite. 12/14/22 09:33:41.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:41.118
Dec 14 09:33:41.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context 12/14/22 09:33:41.119
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:41.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:41.151
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 09:33:41.16
Dec 14 09:33:41.172: INFO: Waiting up to 5m0s for pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836" in namespace "security-context-1825" to be "Succeeded or Failed"
Dec 14 09:33:41.177: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Pending", Reason="", readiness=false. Elapsed: 5.359405ms
Dec 14 09:33:43.187: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015254274s
Dec 14 09:33:45.184: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012367104s
STEP: Saw pod success 12/14/22 09:33:45.184
Dec 14 09:33:45.185: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836" satisfied condition "Succeeded or Failed"
Dec 14 09:33:45.191: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 container test-container: <nil>
STEP: delete the pod 12/14/22 09:33:45.208
Dec 14 09:33:45.218: INFO: Waiting for pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 to disappear
Dec 14 09:33:45.224: INFO: Pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 09:33:45.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-1825" for this suite. 12/14/22 09:33:45.233
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":180,"skipped":3272,"failed":0}
------------------------------
• [4.122 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:41.118
    Dec 14 09:33:41.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context 12/14/22 09:33:41.119
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:41.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:41.151
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 09:33:41.16
    Dec 14 09:33:41.172: INFO: Waiting up to 5m0s for pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836" in namespace "security-context-1825" to be "Succeeded or Failed"
    Dec 14 09:33:41.177: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Pending", Reason="", readiness=false. Elapsed: 5.359405ms
    Dec 14 09:33:43.187: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015254274s
    Dec 14 09:33:45.184: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012367104s
    STEP: Saw pod success 12/14/22 09:33:45.184
    Dec 14 09:33:45.185: INFO: Pod "security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836" satisfied condition "Succeeded or Failed"
    Dec 14 09:33:45.191: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:33:45.208
    Dec 14 09:33:45.218: INFO: Waiting for pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 to disappear
    Dec 14 09:33:45.224: INFO: Pod security-context-5166ecd8-9715-4f50-8f6b-ab6cfb1b1836 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 09:33:45.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-1825" for this suite. 12/14/22 09:33:45.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:45.241
Dec 14 09:33:45.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:33:45.242
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:45.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:45.268
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Dec 14 09:33:45.291: INFO: Waiting up to 2m0s for pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" in namespace "var-expansion-5058" to be "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:33:45.296: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.511158ms
Dec 14 09:33:47.303: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011772227s
Dec 14 09:33:47.303: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Dec 14 09:33:47.303: INFO: Deleting pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" in namespace "var-expansion-5058"
Dec 14 09:33:47.309: INFO: Wait up to 5m0s for pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:33:49.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5058" for this suite. 12/14/22 09:33:49.331
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":181,"skipped":3297,"failed":0}
------------------------------
• [4.097 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:45.241
    Dec 14 09:33:45.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:33:45.242
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:45.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:45.268
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Dec 14 09:33:45.291: INFO: Waiting up to 2m0s for pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" in namespace "var-expansion-5058" to be "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:33:45.296: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.511158ms
    Dec 14 09:33:47.303: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011772227s
    Dec 14 09:33:47.303: INFO: Pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Dec 14 09:33:47.303: INFO: Deleting pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" in namespace "var-expansion-5058"
    Dec 14 09:33:47.309: INFO: Wait up to 5m0s for pod "var-expansion-dc484225-974c-4cf0-ac38-3e594b8c51cd" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:33:49.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5058" for this suite. 12/14/22 09:33:49.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:33:49.339
Dec 14 09:33:49.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:33:49.34
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:49.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:49.367
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a in namespace container-probe-7888 12/14/22 09:33:49.376
Dec 14 09:33:49.389: INFO: Waiting up to 5m0s for pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a" in namespace "container-probe-7888" to be "not pending"
Dec 14 09:33:49.394: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.374621ms
Dec 14 09:33:51.401: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a": Phase="Running", Reason="", readiness=true. Elapsed: 2.011683648s
Dec 14 09:33:51.401: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a" satisfied condition "not pending"
Dec 14 09:33:51.401: INFO: Started pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a in namespace container-probe-7888
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:33:51.401
Dec 14 09:33:51.407: INFO: Initial restart count of pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a is 0
Dec 14 09:34:11.490: INFO: Restart count of pod container-probe-7888/liveness-0ee68255-1423-4ca6-8036-2abe1311686a is now 1 (20.083270398s elapsed)
STEP: deleting the pod 12/14/22 09:34:11.49
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:34:11.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7888" for this suite. 12/14/22 09:34:11.509
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":182,"skipped":3306,"failed":0}
------------------------------
• [22.177 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:33:49.339
    Dec 14 09:33:49.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:33:49.34
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:33:49.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:33:49.367
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a in namespace container-probe-7888 12/14/22 09:33:49.376
    Dec 14 09:33:49.389: INFO: Waiting up to 5m0s for pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a" in namespace "container-probe-7888" to be "not pending"
    Dec 14 09:33:49.394: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.374621ms
    Dec 14 09:33:51.401: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a": Phase="Running", Reason="", readiness=true. Elapsed: 2.011683648s
    Dec 14 09:33:51.401: INFO: Pod "liveness-0ee68255-1423-4ca6-8036-2abe1311686a" satisfied condition "not pending"
    Dec 14 09:33:51.401: INFO: Started pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a in namespace container-probe-7888
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:33:51.401
    Dec 14 09:33:51.407: INFO: Initial restart count of pod liveness-0ee68255-1423-4ca6-8036-2abe1311686a is 0
    Dec 14 09:34:11.490: INFO: Restart count of pod container-probe-7888/liveness-0ee68255-1423-4ca6-8036-2abe1311686a is now 1 (20.083270398s elapsed)
    STEP: deleting the pod 12/14/22 09:34:11.49
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:34:11.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7888" for this suite. 12/14/22 09:34:11.509
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:11.517
Dec 14 09:34:11.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:34:11.518
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:11.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:11.544
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 12/14/22 09:34:11.578
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:34:11.585
Dec 14 09:34:11.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:34:11.596: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:34:12.624: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:34:12.624: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:34:13.612: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:34:13.612: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/14/22 09:34:13.618
Dec 14 09:34:13.652: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:34:13.652: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:34:14.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:34:14.668: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:34:15.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:34:15.668: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 12/14/22 09:34:15.668
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:34:15.678
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6777, will wait for the garbage collector to delete the pods 12/14/22 09:34:15.679
Dec 14 09:34:15.743: INFO: Deleting DaemonSet.extensions daemon-set took: 8.249496ms
Dec 14 09:34:15.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.533836ms
Dec 14 09:34:18.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:34:18.051: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:34:18.056: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38984"},"items":null}

Dec 14 09:34:18.062: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38984"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:34:18.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6777" for this suite. 12/14/22 09:34:18.089
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":183,"skipped":3307,"failed":0}
------------------------------
• [6.579 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:11.517
    Dec 14 09:34:11.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:34:11.518
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:11.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:11.544
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 12/14/22 09:34:11.578
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:34:11.585
    Dec 14 09:34:11.596: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:34:11.596: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:34:12.624: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:34:12.624: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:34:13.612: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:34:13.612: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 12/14/22 09:34:13.618
    Dec 14 09:34:13.652: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:34:13.652: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:34:14.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:34:14.668: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:34:15.667: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:34:15.668: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 12/14/22 09:34:15.668
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:34:15.678
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6777, will wait for the garbage collector to delete the pods 12/14/22 09:34:15.679
    Dec 14 09:34:15.743: INFO: Deleting DaemonSet.extensions daemon-set took: 8.249496ms
    Dec 14 09:34:15.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.533836ms
    Dec 14 09:34:18.051: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:34:18.051: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:34:18.056: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38984"},"items":null}

    Dec 14 09:34:18.062: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38984"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:34:18.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6777" for this suite. 12/14/22 09:34:18.089
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:18.096
Dec 14 09:34:18.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:34:18.097
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:18.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:18.124
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:34:18.147
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:34:18.481
STEP: Deploying the webhook pod 12/14/22 09:34:18.49
STEP: Wait for the deployment to be ready 12/14/22 09:34:18.504
Dec 14 09:34:18.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:34:20.534
STEP: Verifying the service has paired with the endpoint 12/14/22 09:34:20.544
Dec 14 09:34:21.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 12/14/22 09:34:21.616
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:34:21.714
STEP: Deleting the collection of validation webhooks 12/14/22 09:34:21.839
STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:34:21.865
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:34:21.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4165" for this suite. 12/14/22 09:34:21.884
STEP: Destroying namespace "webhook-4165-markers" for this suite. 12/14/22 09:34:21.891
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":184,"skipped":3309,"failed":0}
------------------------------
• [3.834 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:18.096
    Dec 14 09:34:18.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:34:18.097
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:18.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:18.124
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:34:18.147
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:34:18.481
    STEP: Deploying the webhook pod 12/14/22 09:34:18.49
    STEP: Wait for the deployment to be ready 12/14/22 09:34:18.504
    Dec 14 09:34:18.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:34:20.534
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:34:20.544
    Dec 14 09:34:21.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 12/14/22 09:34:21.616
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:34:21.714
    STEP: Deleting the collection of validation webhooks 12/14/22 09:34:21.839
    STEP: Creating a configMap that does not comply to the validation webhook rules 12/14/22 09:34:21.865
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:34:21.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4165" for this suite. 12/14/22 09:34:21.884
    STEP: Destroying namespace "webhook-4165-markers" for this suite. 12/14/22 09:34:21.891
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:21.933
Dec 14 09:34:21.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:34:21.934
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:21.951
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:21.96
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 12/14/22 09:34:21.969
STEP: Ensuring active pods == parallelism 12/14/22 09:34:21.976
STEP: delete a job 12/14/22 09:34:23.983
STEP: deleting Job.batch foo in namespace job-6336, will wait for the garbage collector to delete the pods 12/14/22 09:34:23.983
Dec 14 09:34:24.047: INFO: Deleting Job.batch foo took: 7.165124ms
Dec 14 09:34:24.148: INFO: Terminating Job.batch foo pods took: 101.027054ms
STEP: Ensuring job was deleted 12/14/22 09:34:56.548
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:34:56.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6336" for this suite. 12/14/22 09:34:56.564
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":185,"skipped":3398,"failed":0}
------------------------------
• [34.638 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:21.933
    Dec 14 09:34:21.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:34:21.934
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:21.951
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:21.96
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 12/14/22 09:34:21.969
    STEP: Ensuring active pods == parallelism 12/14/22 09:34:21.976
    STEP: delete a job 12/14/22 09:34:23.983
    STEP: deleting Job.batch foo in namespace job-6336, will wait for the garbage collector to delete the pods 12/14/22 09:34:23.983
    Dec 14 09:34:24.047: INFO: Deleting Job.batch foo took: 7.165124ms
    Dec 14 09:34:24.148: INFO: Terminating Job.batch foo pods took: 101.027054ms
    STEP: Ensuring job was deleted 12/14/22 09:34:56.548
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:34:56.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6336" for this suite. 12/14/22 09:34:56.564
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:56.571
Dec 14 09:34:56.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslicemirroring 12/14/22 09:34:56.572
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:56.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:56.605
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 12/14/22 09:34:56.625
Dec 14 09:34:56.648: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 12/14/22 09:34:58.655
STEP: mirroring deletion of a custom Endpoint 12/14/22 09:34:58.669
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Dec 14 09:34:58.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-3685" for this suite. 12/14/22 09:34:58.691
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":186,"skipped":3401,"failed":0}
------------------------------
• [2.127 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:56.571
    Dec 14 09:34:56.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslicemirroring 12/14/22 09:34:56.572
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:56.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:56.605
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 12/14/22 09:34:56.625
    Dec 14 09:34:56.648: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 12/14/22 09:34:58.655
    STEP: mirroring deletion of a custom Endpoint 12/14/22 09:34:58.669
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Dec 14 09:34:58.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-3685" for this suite. 12/14/22 09:34:58.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:58.699
Dec 14 09:34:58.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename conformance-tests 12/14/22 09:34:58.7
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:58.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:58.726
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 12/14/22 09:34:58.736
Dec 14 09:34:58.737: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Dec 14 09:34:58.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-2172" for this suite. 12/14/22 09:34:58.753
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":187,"skipped":3406,"failed":0}
------------------------------
• [0.061 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:58.699
    Dec 14 09:34:58.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename conformance-tests 12/14/22 09:34:58.7
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:58.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:58.726
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 12/14/22 09:34:58.736
    Dec 14 09:34:58.737: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Dec 14 09:34:58.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-2172" for this suite. 12/14/22 09:34:58.753
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:34:58.76
Dec 14 09:34:58.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 09:34:58.761
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:58.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:58.788
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 12/14/22 09:34:58.798
STEP: Ensuring a job is scheduled 12/14/22 09:34:58.805
STEP: Ensuring exactly one is scheduled 12/14/22 09:35:00.812
STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:35:00.818
STEP: Ensuring the job is replaced with a new one 12/14/22 09:35:00.824
STEP: Removing cronjob 12/14/22 09:36:00.832
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 09:36:00.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1694" for this suite. 12/14/22 09:36:00.852
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":188,"skipped":3422,"failed":0}
------------------------------
• [62.098 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:34:58.76
    Dec 14 09:34:58.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 09:34:58.761
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:34:58.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:34:58.788
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 12/14/22 09:34:58.798
    STEP: Ensuring a job is scheduled 12/14/22 09:34:58.805
    STEP: Ensuring exactly one is scheduled 12/14/22 09:35:00.812
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 12/14/22 09:35:00.818
    STEP: Ensuring the job is replaced with a new one 12/14/22 09:35:00.824
    STEP: Removing cronjob 12/14/22 09:36:00.832
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 09:36:00.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1694" for this suite. 12/14/22 09:36:00.852
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:36:00.861
Dec 14 09:36:00.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:36:00.862
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:00.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:00.89
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-6e95e364-ce89-4fcf-844d-77b6538e0078 12/14/22 09:36:00.9
STEP: Creating a pod to test consume configMaps 12/14/22 09:36:00.908
Dec 14 09:36:00.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292" in namespace "configmap-4761" to be "Succeeded or Failed"
Dec 14 09:36:00.935: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Pending", Reason="", readiness=false. Elapsed: 5.77648ms
Dec 14 09:36:02.943: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013593141s
Dec 14 09:36:04.943: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013825413s
STEP: Saw pod success 12/14/22 09:36:04.943
Dec 14 09:36:04.944: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292" satisfied condition "Succeeded or Failed"
Dec 14 09:36:04.950: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:36:04.972
Dec 14 09:36:04.982: INFO: Waiting for pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 to disappear
Dec 14 09:36:04.988: INFO: Pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:36:04.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4761" for this suite. 12/14/22 09:36:04.998
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":189,"skipped":3458,"failed":0}
------------------------------
• [4.145 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:36:00.861
    Dec 14 09:36:00.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:36:00.862
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:00.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:00.89
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-6e95e364-ce89-4fcf-844d-77b6538e0078 12/14/22 09:36:00.9
    STEP: Creating a pod to test consume configMaps 12/14/22 09:36:00.908
    Dec 14 09:36:00.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292" in namespace "configmap-4761" to be "Succeeded or Failed"
    Dec 14 09:36:00.935: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Pending", Reason="", readiness=false. Elapsed: 5.77648ms
    Dec 14 09:36:02.943: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013593141s
    Dec 14 09:36:04.943: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013825413s
    STEP: Saw pod success 12/14/22 09:36:04.943
    Dec 14 09:36:04.944: INFO: Pod "pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292" satisfied condition "Succeeded or Failed"
    Dec 14 09:36:04.950: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:36:04.972
    Dec 14 09:36:04.982: INFO: Waiting for pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 to disappear
    Dec 14 09:36:04.988: INFO: Pod pod-configmaps-4eacee4a-5b85-4b6b-b6c3-9161f4b6d292 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:36:04.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4761" for this suite. 12/14/22 09:36:04.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:36:05.008
Dec 14 09:36:05.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:36:05.008
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:05.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:05.046
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 12/14/22 09:36:05.056
STEP: When the matched label of one of its pods change 12/14/22 09:36:05.063
Dec 14 09:36:05.069: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 14 09:36:10.079: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 12/14/22 09:36:10.094
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:36:10.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5642" for this suite. 12/14/22 09:36:10.113
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":190,"skipped":3488,"failed":0}
------------------------------
• [5.117 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:36:05.008
    Dec 14 09:36:05.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:36:05.008
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:05.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:05.046
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 12/14/22 09:36:05.056
    STEP: When the matched label of one of its pods change 12/14/22 09:36:05.063
    Dec 14 09:36:05.069: INFO: Pod name pod-release: Found 0 pods out of 1
    Dec 14 09:36:10.079: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/14/22 09:36:10.094
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:36:10.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5642" for this suite. 12/14/22 09:36:10.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:36:10.126
Dec 14 09:36:10.126: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:36:10.127
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:10.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:10.158
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 12/14/22 09:36:10.168
Dec 14 09:36:10.180: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-8496" to be "running and ready"
Dec 14 09:36:10.186: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335205ms
Dec 14 09:36:10.186: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:36:12.193: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.013639725s
Dec 14 09:36:12.193: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Dec 14 09:36:12.193: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 12/14/22 09:36:12.199
STEP: Then the orphan pod is adopted 12/14/22 09:36:12.206
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:36:13.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8496" for this suite. 12/14/22 09:36:13.23
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":191,"skipped":3509,"failed":0}
------------------------------
• [3.111 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:36:10.126
    Dec 14 09:36:10.126: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:36:10.127
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:10.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:10.158
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 12/14/22 09:36:10.168
    Dec 14 09:36:10.180: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-8496" to be "running and ready"
    Dec 14 09:36:10.186: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335205ms
    Dec 14 09:36:10.186: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:36:12.193: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.013639725s
    Dec 14 09:36:12.193: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Dec 14 09:36:12.193: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 12/14/22 09:36:12.199
    STEP: Then the orphan pod is adopted 12/14/22 09:36:12.206
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:36:13.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8496" for this suite. 12/14/22 09:36:13.23
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:36:13.239
Dec 14 09:36:13.239: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe 12/14/22 09:36:13.239
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:13.258
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:13.268
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a in namespace container-probe-4363 12/14/22 09:36:13.278
Dec 14 09:36:13.291: INFO: Waiting up to 5m0s for pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a" in namespace "container-probe-4363" to be "not pending"
Dec 14 09:36:13.304: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.406428ms
Dec 14 09:36:15.310: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012808673s
Dec 14 09:36:15.310: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a" satisfied condition "not pending"
Dec 14 09:36:15.310: INFO: Started pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a in namespace container-probe-4363
STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:36:15.31
Dec 14 09:36:15.317: INFO: Initial restart count of pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a is 0
STEP: deleting the pod 12/14/22 09:40:16.238
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Dec 14 09:40:16.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4363" for this suite. 12/14/22 09:40:16.262
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":192,"skipped":3540,"failed":0}
------------------------------
• [243.031 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:36:13.239
    Dec 14 09:36:13.239: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-probe 12/14/22 09:36:13.239
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:36:13.258
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:36:13.268
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a in namespace container-probe-4363 12/14/22 09:36:13.278
    Dec 14 09:36:13.291: INFO: Waiting up to 5m0s for pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a" in namespace "container-probe-4363" to be "not pending"
    Dec 14 09:36:13.304: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.406428ms
    Dec 14 09:36:15.310: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012808673s
    Dec 14 09:36:15.310: INFO: Pod "busybox-36a8f3a9-050b-4091-928f-d64c6b63377a" satisfied condition "not pending"
    Dec 14 09:36:15.310: INFO: Started pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a in namespace container-probe-4363
    STEP: checking the pod's current state and verifying that restartCount is present 12/14/22 09:36:15.31
    Dec 14 09:36:15.317: INFO: Initial restart count of pod busybox-36a8f3a9-050b-4091-928f-d64c6b63377a is 0
    STEP: deleting the pod 12/14/22 09:40:16.238
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Dec 14 09:40:16.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4363" for this suite. 12/14/22 09:40:16.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:40:16.27
Dec 14 09:40:16.270: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:40:16.272
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:16.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:16.314
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Dec 14 09:40:16.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:40:16.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4656" for this suite. 12/14/22 09:40:16.901
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":193,"skipped":3549,"failed":0}
------------------------------
• [0.638 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:40:16.27
    Dec 14 09:40:16.270: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:40:16.272
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:16.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:16.314
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Dec 14 09:40:16.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:40:16.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4656" for this suite. 12/14/22 09:40:16.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:40:16.909
Dec 14 09:40:16.909: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:40:16.91
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:16.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:16.942
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 12/14/22 09:40:16.952
STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:40:16.96
STEP: delete the deployment 12/14/22 09:40:17.478
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/14/22 09:40:17.485
STEP: Gathering metrics 12/14/22 09:40:47.522
W1214 09:40:47.541082    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:40:47.541: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:40:47.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7535" for this suite. 12/14/22 09:40:47.55
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":194,"skipped":3555,"failed":0}
------------------------------
• [30.649 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:40:16.909
    Dec 14 09:40:16.909: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:40:16.91
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:16.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:16.942
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 12/14/22 09:40:16.952
    STEP: Wait for the Deployment to create new ReplicaSet 12/14/22 09:40:16.96
    STEP: delete the deployment 12/14/22 09:40:17.478
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 12/14/22 09:40:17.485
    STEP: Gathering metrics 12/14/22 09:40:47.522
    W1214 09:40:47.541082    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:40:47.541: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:40:47.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7535" for this suite. 12/14/22 09:40:47.55
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:40:47.558
Dec 14 09:40:47.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:40:47.559
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:47.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:47.589
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:40:47.614
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:40:48.369
STEP: Deploying the webhook pod 12/14/22 09:40:48.378
STEP: Wait for the deployment to be ready 12/14/22 09:40:48.393
Dec 14 09:40:48.406: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:40:50.425
STEP: Verifying the service has paired with the endpoint 12/14/22 09:40:50.466
Dec 14 09:40:51.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/14/22 09:40:51.473
STEP: create a configmap that should be updated by the webhook 12/14/22 09:40:51.606
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:40:51.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5213" for this suite. 12/14/22 09:40:51.718
STEP: Destroying namespace "webhook-5213-markers" for this suite. 12/14/22 09:40:51.726
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":195,"skipped":3562,"failed":0}
------------------------------
• [4.209 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:40:47.558
    Dec 14 09:40:47.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:40:47.559
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:47.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:47.589
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:40:47.614
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:40:48.369
    STEP: Deploying the webhook pod 12/14/22 09:40:48.378
    STEP: Wait for the deployment to be ready 12/14/22 09:40:48.393
    Dec 14 09:40:48.406: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:40:50.425
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:40:50.466
    Dec 14 09:40:51.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 12/14/22 09:40:51.473
    STEP: create a configmap that should be updated by the webhook 12/14/22 09:40:51.606
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:40:51.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5213" for this suite. 12/14/22 09:40:51.718
    STEP: Destroying namespace "webhook-5213-markers" for this suite. 12/14/22 09:40:51.726
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:40:51.768
Dec 14 09:40:51.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:40:51.769
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:51.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:51.801
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:40:51.818
Dec 14 09:40:51.845: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8029" to be "running and ready"
Dec 14 09:40:51.854: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.259471ms
Dec 14 09:40:51.854: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:40:53.861: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01615234s
Dec 14 09:40:53.861: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:40:53.861: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 12/14/22 09:40:53.868
Dec 14 09:40:53.879: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8029" to be "running and ready"
Dec 14 09:40:53.886: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.868598ms
Dec 14 09:40:53.886: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:40:55.892: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013426709s
Dec 14 09:40:55.892: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Dec 14 09:40:55.892: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 12/14/22 09:40:55.899
Dec 14 09:40:55.907: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 09:40:55.913: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 14 09:40:57.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 09:40:57.921: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 14 09:40:59.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 14 09:40:59.921: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 12/14/22 09:40:59.921
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:40:59.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8029" for this suite. 12/14/22 09:40:59.946
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":196,"skipped":3569,"failed":0}
------------------------------
• [8.185 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:40:51.768
    Dec 14 09:40:51.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:40:51.769
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:51.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:51.801
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:40:51.818
    Dec 14 09:40:51.845: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8029" to be "running and ready"
    Dec 14 09:40:51.854: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 9.259471ms
    Dec 14 09:40:51.854: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:40:53.861: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.01615234s
    Dec 14 09:40:53.861: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:40:53.861: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 12/14/22 09:40:53.868
    Dec 14 09:40:53.879: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8029" to be "running and ready"
    Dec 14 09:40:53.886: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.868598ms
    Dec 14 09:40:53.886: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:40:55.892: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013426709s
    Dec 14 09:40:55.892: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Dec 14 09:40:55.892: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 12/14/22 09:40:55.899
    Dec 14 09:40:55.907: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 09:40:55.913: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec 14 09:40:57.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 09:40:57.921: INFO: Pod pod-with-prestop-exec-hook still exists
    Dec 14 09:40:59.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Dec 14 09:40:59.921: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 12/14/22 09:40:59.921
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:40:59.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8029" for this suite. 12/14/22 09:40:59.946
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:40:59.954
Dec 14 09:40:59.954: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:40:59.955
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:59.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:59.983
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:41:00.01
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:41:00.762
STEP: Deploying the webhook pod 12/14/22 09:41:00.768
STEP: Wait for the deployment to be ready 12/14/22 09:41:00.783
Dec 14 09:41:00.795: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:41:02.814
STEP: Verifying the service has paired with the endpoint 12/14/22 09:41:02.826
Dec 14 09:41:03.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Dec 14 09:41:03.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3044-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:41:04.351
STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:41:04.482
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:41:07.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1807" for this suite. 12/14/22 09:41:07.267
STEP: Destroying namespace "webhook-1807-markers" for this suite. 12/14/22 09:41:07.275
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":197,"skipped":3592,"failed":0}
------------------------------
• [7.359 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:40:59.954
    Dec 14 09:40:59.954: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:40:59.955
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:40:59.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:40:59.983
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:41:00.01
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:41:00.762
    STEP: Deploying the webhook pod 12/14/22 09:41:00.768
    STEP: Wait for the deployment to be ready 12/14/22 09:41:00.783
    Dec 14 09:41:00.795: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:41:02.814
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:41:02.826
    Dec 14 09:41:03.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Dec 14 09:41:03.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3044-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:41:04.351
    STEP: Creating a custom resource that should be mutated by the webhook 12/14/22 09:41:04.482
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:41:07.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1807" for this suite. 12/14/22 09:41:07.267
    STEP: Destroying namespace "webhook-1807-markers" for this suite. 12/14/22 09:41:07.275
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:07.314
Dec 14 09:41:07.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:41:07.315
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:07.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:07.342
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-f1dd2070-b200-4a26-8c66-6a807e9cbd8d 12/14/22 09:41:07.353
STEP: Creating a pod to test consume configMaps 12/14/22 09:41:07.36
Dec 14 09:41:07.373: INFO: Waiting up to 5m0s for pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec" in namespace "configmap-7595" to be "Succeeded or Failed"
Dec 14 09:41:07.379: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689112ms
Dec 14 09:41:09.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013148285s
Dec 14 09:41:11.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013292265s
STEP: Saw pod success 12/14/22 09:41:11.386
Dec 14 09:41:11.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec" satisfied condition "Succeeded or Failed"
Dec 14 09:41:11.392: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec container configmap-volume-test: <nil>
STEP: delete the pod 12/14/22 09:41:11.414
Dec 14 09:41:11.424: INFO: Waiting for pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec to disappear
Dec 14 09:41:11.430: INFO: Pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:41:11.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7595" for this suite. 12/14/22 09:41:11.44
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":198,"skipped":3596,"failed":0}
------------------------------
• [4.134 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:07.314
    Dec 14 09:41:07.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:41:07.315
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:07.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:07.342
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-f1dd2070-b200-4a26-8c66-6a807e9cbd8d 12/14/22 09:41:07.353
    STEP: Creating a pod to test consume configMaps 12/14/22 09:41:07.36
    Dec 14 09:41:07.373: INFO: Waiting up to 5m0s for pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec" in namespace "configmap-7595" to be "Succeeded or Failed"
    Dec 14 09:41:07.379: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689112ms
    Dec 14 09:41:09.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013148285s
    Dec 14 09:41:11.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013292265s
    STEP: Saw pod success 12/14/22 09:41:11.386
    Dec 14 09:41:11.386: INFO: Pod "pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec" satisfied condition "Succeeded or Failed"
    Dec 14 09:41:11.392: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec container configmap-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:41:11.414
    Dec 14 09:41:11.424: INFO: Waiting for pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec to disappear
    Dec 14 09:41:11.430: INFO: Pod pod-configmaps-9552ddce-3f24-43f2-af37-786dc31651ec no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:41:11.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7595" for this suite. 12/14/22 09:41:11.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:11.449
Dec 14 09:41:11.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:41:11.451
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:11.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:11.508
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  12/14/22 09:41:11.518
Dec 14 09:41:11.532: INFO: Waiting up to 5m0s for pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c" in namespace "svcaccounts-3077" to be "Succeeded or Failed"
Dec 14 09:41:11.538: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854618ms
Dec 14 09:41:13.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013343146s
Dec 14 09:41:15.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013358498s
STEP: Saw pod success 12/14/22 09:41:15.545
Dec 14 09:41:15.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c" satisfied condition "Succeeded or Failed"
Dec 14 09:41:15.551: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:41:15.569
Dec 14 09:41:15.578: INFO: Waiting for pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c to disappear
Dec 14 09:41:15.584: INFO: Pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:41:15.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3077" for this suite. 12/14/22 09:41:15.595
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":199,"skipped":3622,"failed":0}
------------------------------
• [4.152 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:11.449
    Dec 14 09:41:11.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:41:11.451
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:11.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:11.508
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  12/14/22 09:41:11.518
    Dec 14 09:41:11.532: INFO: Waiting up to 5m0s for pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c" in namespace "svcaccounts-3077" to be "Succeeded or Failed"
    Dec 14 09:41:11.538: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854618ms
    Dec 14 09:41:13.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013343146s
    Dec 14 09:41:15.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013358498s
    STEP: Saw pod success 12/14/22 09:41:15.545
    Dec 14 09:41:15.545: INFO: Pod "test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c" satisfied condition "Succeeded or Failed"
    Dec 14 09:41:15.551: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:41:15.569
    Dec 14 09:41:15.578: INFO: Waiting for pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c to disappear
    Dec 14 09:41:15.584: INFO: Pod test-pod-5766ad38-13e6-4a0a-9bae-06a34cec104c no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:41:15.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3077" for this suite. 12/14/22 09:41:15.595
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:15.605
Dec 14 09:41:15.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:41:15.606
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:15.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:15.634
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 12/14/22 09:41:15.654
Dec 14 09:41:15.667: INFO: Waiting up to 5m0s for pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a" in namespace "downward-api-3978" to be "running and ready"
Dec 14 09:41:15.673: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854362ms
Dec 14 09:41:15.673: INFO: The phase of Pod annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:41:17.681: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013470484s
Dec 14 09:41:17.681: INFO: The phase of Pod annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a is Running (Ready = true)
Dec 14 09:41:17.681: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a" satisfied condition "running and ready"
Dec 14 09:41:18.234: INFO: Successfully updated pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:41:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3978" for this suite. 12/14/22 09:41:22.299
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":200,"skipped":3688,"failed":0}
------------------------------
• [6.701 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:15.605
    Dec 14 09:41:15.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:41:15.606
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:15.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:15.634
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 12/14/22 09:41:15.654
    Dec 14 09:41:15.667: INFO: Waiting up to 5m0s for pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a" in namespace "downward-api-3978" to be "running and ready"
    Dec 14 09:41:15.673: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.854362ms
    Dec 14 09:41:15.673: INFO: The phase of Pod annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:41:17.681: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a": Phase="Running", Reason="", readiness=true. Elapsed: 2.013470484s
    Dec 14 09:41:17.681: INFO: The phase of Pod annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a is Running (Ready = true)
    Dec 14 09:41:17.681: INFO: Pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a" satisfied condition "running and ready"
    Dec 14 09:41:18.234: INFO: Successfully updated pod "annotationupdate1cce545a-6a8f-479d-8294-3e32a786bb0a"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:41:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3978" for this suite. 12/14/22 09:41:22.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:22.307
Dec 14 09:41:22.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:41:22.308
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:22.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:22.336
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 12/14/22 09:41:22.352
STEP: watching for the Service to be added 12/14/22 09:41:22.362
Dec 14 09:41:22.368: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Dec 14 09:41:22.368: INFO: Service test-service-7lkk4 created
STEP: Getting /status 12/14/22 09:41:22.368
Dec 14 09:41:22.374: INFO: Service test-service-7lkk4 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 12/14/22 09:41:22.374
STEP: watching for the Service to be patched 12/14/22 09:41:22.381
Dec 14 09:41:22.387: INFO: observed Service test-service-7lkk4 in namespace services-1118 with annotations: map[] & LoadBalancer: {[]}
Dec 14 09:41:22.387: INFO: Found Service test-service-7lkk4 in namespace services-1118 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Dec 14 09:41:22.387: INFO: Service test-service-7lkk4 has service status patched
STEP: updating the ServiceStatus 12/14/22 09:41:22.387
Dec 14 09:41:22.400: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 12/14/22 09:41:22.4
Dec 14 09:41:22.405: INFO: Observed Service test-service-7lkk4 in namespace services-1118 with annotations: map[] & Conditions: {[]}
Dec 14 09:41:22.405: INFO: Observed event: &Service{ObjectMeta:{test-service-7lkk4  services-1118  929189f0-7673-41ef-901f-36ce708184d4 41793 0 2022-12-14 09:41:22 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 09:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 09:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.31.83.242,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.31.83.242],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Dec 14 09:41:22.406: INFO: Found Service test-service-7lkk4 in namespace services-1118 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 09:41:22.406: INFO: Service test-service-7lkk4 has service status updated
STEP: patching the service 12/14/22 09:41:22.406
STEP: watching for the Service to be patched 12/14/22 09:41:22.414
Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
Dec 14 09:41:22.419: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service:patched test-service-static:true]
Dec 14 09:41:22.419: INFO: Service test-service-7lkk4 patched
STEP: deleting the service 12/14/22 09:41:22.419
STEP: watching for the Service to be deleted 12/14/22 09:41:22.429
Dec 14 09:41:22.434: INFO: Observed event: ADDED
Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
Dec 14 09:41:22.435: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Dec 14 09:41:22.435: INFO: Service test-service-7lkk4 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:41:22.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1118" for this suite. 12/14/22 09:41:22.442
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":201,"skipped":3712,"failed":0}
------------------------------
• [0.142 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:22.307
    Dec 14 09:41:22.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:41:22.308
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:22.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:22.336
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 12/14/22 09:41:22.352
    STEP: watching for the Service to be added 12/14/22 09:41:22.362
    Dec 14 09:41:22.368: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Dec 14 09:41:22.368: INFO: Service test-service-7lkk4 created
    STEP: Getting /status 12/14/22 09:41:22.368
    Dec 14 09:41:22.374: INFO: Service test-service-7lkk4 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 12/14/22 09:41:22.374
    STEP: watching for the Service to be patched 12/14/22 09:41:22.381
    Dec 14 09:41:22.387: INFO: observed Service test-service-7lkk4 in namespace services-1118 with annotations: map[] & LoadBalancer: {[]}
    Dec 14 09:41:22.387: INFO: Found Service test-service-7lkk4 in namespace services-1118 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Dec 14 09:41:22.387: INFO: Service test-service-7lkk4 has service status patched
    STEP: updating the ServiceStatus 12/14/22 09:41:22.387
    Dec 14 09:41:22.400: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 12/14/22 09:41:22.4
    Dec 14 09:41:22.405: INFO: Observed Service test-service-7lkk4 in namespace services-1118 with annotations: map[] & Conditions: {[]}
    Dec 14 09:41:22.405: INFO: Observed event: &Service{ObjectMeta:{test-service-7lkk4  services-1118  929189f0-7673-41ef-901f-36ce708184d4 41793 0 2022-12-14 09:41:22 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-12-14 09:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-12-14 09:41:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.31.83.242,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.31.83.242],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Dec 14 09:41:22.406: INFO: Found Service test-service-7lkk4 in namespace services-1118 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 09:41:22.406: INFO: Service test-service-7lkk4 has service status updated
    STEP: patching the service 12/14/22 09:41:22.406
    STEP: watching for the Service to be patched 12/14/22 09:41:22.414
    Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
    Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
    Dec 14 09:41:22.419: INFO: observed Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service-static:true]
    Dec 14 09:41:22.419: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service:patched test-service-static:true]
    Dec 14 09:41:22.419: INFO: Service test-service-7lkk4 patched
    STEP: deleting the service 12/14/22 09:41:22.419
    STEP: watching for the Service to be deleted 12/14/22 09:41:22.429
    Dec 14 09:41:22.434: INFO: Observed event: ADDED
    Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
    Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
    Dec 14 09:41:22.435: INFO: Observed event: MODIFIED
    Dec 14 09:41:22.435: INFO: Found Service test-service-7lkk4 in namespace services-1118 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Dec 14 09:41:22.435: INFO: Service test-service-7lkk4 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:41:22.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1118" for this suite. 12/14/22 09:41:22.442
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:22.45
Dec 14 09:41:22.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:41:22.451
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:22.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:22.481
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 12/14/22 09:41:22.491
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:41:22.498
STEP: Creating a ResourceQuota with not terminating scope 12/14/22 09:41:24.506
STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:41:24.512
STEP: Creating a long running pod 12/14/22 09:41:26.519
STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/14/22 09:41:26.535
STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/14/22 09:41:28.548
STEP: Deleting the pod 12/14/22 09:41:30.555
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:41:30.564
STEP: Creating a terminating pod 12/14/22 09:41:32.571
STEP: Ensuring resource quota with terminating scope captures the pod usage 12/14/22 09:41:32.584
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/14/22 09:41:34.592
STEP: Deleting the pod 12/14/22 09:41:36.599
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:41:36.61
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:41:38.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-878" for this suite. 12/14/22 09:41:38.627
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":202,"skipped":3731,"failed":0}
------------------------------
• [16.183 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:22.45
    Dec 14 09:41:22.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:41:22.451
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:22.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:22.481
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 12/14/22 09:41:22.491
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:41:22.498
    STEP: Creating a ResourceQuota with not terminating scope 12/14/22 09:41:24.506
    STEP: Ensuring ResourceQuota status is calculated 12/14/22 09:41:24.512
    STEP: Creating a long running pod 12/14/22 09:41:26.519
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 12/14/22 09:41:26.535
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 12/14/22 09:41:28.548
    STEP: Deleting the pod 12/14/22 09:41:30.555
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:41:30.564
    STEP: Creating a terminating pod 12/14/22 09:41:32.571
    STEP: Ensuring resource quota with terminating scope captures the pod usage 12/14/22 09:41:32.584
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 12/14/22 09:41:34.592
    STEP: Deleting the pod 12/14/22 09:41:36.599
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:41:36.61
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:41:38.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-878" for this suite. 12/14/22 09:41:38.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:38.635
Dec 14 09:41:38.635: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:41:38.636
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:38.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:38.674
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 12/14/22 09:41:38.684
Dec 14 09:41:38.697: INFO: Waiting up to 5m0s for pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c" in namespace "projected-4116" to be "running and ready"
Dec 14 09:41:38.703: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.756881ms
Dec 14 09:41:38.703: INFO: The phase of Pod annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:41:40.710: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013101774s
Dec 14 09:41:40.710: INFO: The phase of Pod annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c is Running (Ready = true)
Dec 14 09:41:40.710: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c" satisfied condition "running and ready"
Dec 14 09:41:41.251: INFO: Successfully updated pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:41:45.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4116" for this suite. 12/14/22 09:41:45.315
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":203,"skipped":3785,"failed":0}
------------------------------
• [6.688 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:38.635
    Dec 14 09:41:38.635: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:41:38.636
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:38.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:38.674
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 12/14/22 09:41:38.684
    Dec 14 09:41:38.697: INFO: Waiting up to 5m0s for pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c" in namespace "projected-4116" to be "running and ready"
    Dec 14 09:41:38.703: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.756881ms
    Dec 14 09:41:38.703: INFO: The phase of Pod annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:41:40.710: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013101774s
    Dec 14 09:41:40.710: INFO: The phase of Pod annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c is Running (Ready = true)
    Dec 14 09:41:40.710: INFO: Pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c" satisfied condition "running and ready"
    Dec 14 09:41:41.251: INFO: Successfully updated pod "annotationupdateeeb8b00f-80a9-4400-a3c0-1395a338463c"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:41:45.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4116" for this suite. 12/14/22 09:41:45.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:45.324
Dec 14 09:41:45.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:41:45.325
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:45.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:45.353
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-7901 12/14/22 09:41:45.363
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[] 12/14/22 09:41:45.373
Dec 14 09:41:45.393: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-7901 12/14/22 09:41:45.393
Dec 14 09:41:45.406: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7901" to be "running and ready"
Dec 14 09:41:45.412: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584743ms
Dec 14 09:41:45.412: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:41:47.419: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012624995s
Dec 14 09:41:47.419: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 09:41:47.419: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod1:[100]] 12/14/22 09:41:47.425
Dec 14 09:41:47.448: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-7901 12/14/22 09:41:47.448
Dec 14 09:41:47.460: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7901" to be "running and ready"
Dec 14 09:41:47.465: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.786724ms
Dec 14 09:41:47.465: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:41:49.473: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013234564s
Dec 14 09:41:49.473: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 09:41:49.473: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod1:[100] pod2:[101]] 12/14/22 09:41:49.479
Dec 14 09:41:49.508: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 12/14/22 09:41:49.508
Dec 14 09:41:49.508: INFO: Creating new exec pod
Dec 14 09:41:49.518: INFO: Waiting up to 5m0s for pod "execpod4xw48" in namespace "services-7901" to be "running"
Dec 14 09:41:49.524: INFO: Pod "execpod4xw48": Phase="Pending", Reason="", readiness=false. Elapsed: 5.757192ms
Dec 14 09:41:51.531: INFO: Pod "execpod4xw48": Phase="Running", Reason="", readiness=true. Elapsed: 2.012989091s
Dec 14 09:41:51.531: INFO: Pod "execpod4xw48" satisfied condition "running"
Dec 14 09:41:52.532: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Dec 14 09:41:53.099: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Dec 14 09:41:53.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:41:53.099: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.194.118 80'
Dec 14 09:41:53.562: INFO: stderr: "+ nc -v -t -w 2 172.29.194.118 80\nConnection to 172.29.194.118 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 14 09:41:53.562: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:41:53.562: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Dec 14 09:41:54.141: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Dec 14 09:41:54.141: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:41:54.141: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.194.118 81'
Dec 14 09:41:54.630: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 172.29.194.118 81\nConnection to 172.29.194.118 81 port [tcp/*] succeeded!\n"
Dec 14 09:41:54.631: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-7901 12/14/22 09:41:54.631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod2:[101]] 12/14/22 09:41:54.64
Dec 14 09:41:55.687: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-7901 12/14/22 09:41:55.687
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[] 12/14/22 09:41:55.697
Dec 14 09:41:55.712: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:41:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7901" for this suite. 12/14/22 09:41:55.733
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":204,"skipped":3790,"failed":0}
------------------------------
• [10.416 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:45.324
    Dec 14 09:41:45.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:41:45.325
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:45.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:45.353
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-7901 12/14/22 09:41:45.363
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[] 12/14/22 09:41:45.373
    Dec 14 09:41:45.393: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-7901 12/14/22 09:41:45.393
    Dec 14 09:41:45.406: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7901" to be "running and ready"
    Dec 14 09:41:45.412: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584743ms
    Dec 14 09:41:45.412: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:41:47.419: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012624995s
    Dec 14 09:41:47.419: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 09:41:47.419: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod1:[100]] 12/14/22 09:41:47.425
    Dec 14 09:41:47.448: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-7901 12/14/22 09:41:47.448
    Dec 14 09:41:47.460: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7901" to be "running and ready"
    Dec 14 09:41:47.465: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.786724ms
    Dec 14 09:41:47.465: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:41:49.473: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013234564s
    Dec 14 09:41:49.473: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 09:41:49.473: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod1:[100] pod2:[101]] 12/14/22 09:41:49.479
    Dec 14 09:41:49.508: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 12/14/22 09:41:49.508
    Dec 14 09:41:49.508: INFO: Creating new exec pod
    Dec 14 09:41:49.518: INFO: Waiting up to 5m0s for pod "execpod4xw48" in namespace "services-7901" to be "running"
    Dec 14 09:41:49.524: INFO: Pod "execpod4xw48": Phase="Pending", Reason="", readiness=false. Elapsed: 5.757192ms
    Dec 14 09:41:51.531: INFO: Pod "execpod4xw48": Phase="Running", Reason="", readiness=true. Elapsed: 2.012989091s
    Dec 14 09:41:51.531: INFO: Pod "execpod4xw48" satisfied condition "running"
    Dec 14 09:41:52.532: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Dec 14 09:41:53.099: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Dec 14 09:41:53.099: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:41:53.099: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.194.118 80'
    Dec 14 09:41:53.562: INFO: stderr: "+ nc -v -t -w 2 172.29.194.118 80\nConnection to 172.29.194.118 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Dec 14 09:41:53.562: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:41:53.562: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Dec 14 09:41:54.141: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Dec 14 09:41:54.141: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:41:54.141: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-7901 exec execpod4xw48 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.194.118 81'
    Dec 14 09:41:54.630: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 172.29.194.118 81\nConnection to 172.29.194.118 81 port [tcp/*] succeeded!\n"
    Dec 14 09:41:54.631: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-7901 12/14/22 09:41:54.631
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[pod2:[101]] 12/14/22 09:41:54.64
    Dec 14 09:41:55.687: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-7901 12/14/22 09:41:55.687
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7901 to expose endpoints map[] 12/14/22 09:41:55.697
    Dec 14 09:41:55.712: INFO: successfully validated that service multi-endpoint-test in namespace services-7901 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:41:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7901" for this suite. 12/14/22 09:41:55.733
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:41:55.742
Dec 14 09:41:55.742: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:41:55.743
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:55.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:55.769
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 12/14/22 09:41:55.779
Dec 14 09:41:55.791: INFO: created test-pod-1
Dec 14 09:41:55.801: INFO: created test-pod-2
Dec 14 09:41:55.812: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 12/14/22 09:41:55.812
Dec 14 09:41:55.812: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4692' to be running and ready
Dec 14 09:41:55.830: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 09:41:55.830: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 09:41:55.830: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 14 09:41:55.830: INFO: 0 / 3 pods in namespace 'pods-4692' are running and ready (0 seconds elapsed)
Dec 14 09:41:55.830: INFO: expected 0 pod replicas in namespace 'pods-4692', 0 are Running and Ready.
Dec 14 09:41:55.830: INFO: POD         NODE                     PHASE    GRACE  CONDITIONS
Dec 14 09:41:55.830: INFO: test-pod-1  izgw8jfcr55yi09nr0a5xaz  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
Dec 14 09:41:55.830: INFO: test-pod-2  izgw8jfcr55yi09nr0a5xaz  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
Dec 14 09:41:55.830: INFO: test-pod-3  izgw8jfcr55yi09nr0a5xaz  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
Dec 14 09:41:55.830: INFO: 
Dec 14 09:41:57.849: INFO: 3 / 3 pods in namespace 'pods-4692' are running and ready (2 seconds elapsed)
Dec 14 09:41:57.849: INFO: expected 0 pod replicas in namespace 'pods-4692', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 12/14/22 09:41:57.865
Dec 14 09:41:57.871: INFO: Pod quantity 3 is different from expected quantity 0
Dec 14 09:41:58.878: INFO: Pod quantity 3 is different from expected quantity 0
Dec 14 09:41:59.879: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:42:00.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4692" for this suite. 12/14/22 09:42:00.888
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":205,"skipped":3864,"failed":0}
------------------------------
• [5.152 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:41:55.742
    Dec 14 09:41:55.742: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:41:55.743
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:41:55.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:41:55.769
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 12/14/22 09:41:55.779
    Dec 14 09:41:55.791: INFO: created test-pod-1
    Dec 14 09:41:55.801: INFO: created test-pod-2
    Dec 14 09:41:55.812: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 12/14/22 09:41:55.812
    Dec 14 09:41:55.812: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-4692' to be running and ready
    Dec 14 09:41:55.830: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 09:41:55.830: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 09:41:55.830: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Dec 14 09:41:55.830: INFO: 0 / 3 pods in namespace 'pods-4692' are running and ready (0 seconds elapsed)
    Dec 14 09:41:55.830: INFO: expected 0 pod replicas in namespace 'pods-4692', 0 are Running and Ready.
    Dec 14 09:41:55.830: INFO: POD         NODE                     PHASE    GRACE  CONDITIONS
    Dec 14 09:41:55.830: INFO: test-pod-1  izgw8jfcr55yi09nr0a5xaz  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
    Dec 14 09:41:55.830: INFO: test-pod-2  izgw8jfcr55yi09nr0a5xaz  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
    Dec 14 09:41:55.830: INFO: test-pod-3  izgw8jfcr55yi09nr0a5xaz  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:41:55 +0000 UTC  }]
    Dec 14 09:41:55.830: INFO: 
    Dec 14 09:41:57.849: INFO: 3 / 3 pods in namespace 'pods-4692' are running and ready (2 seconds elapsed)
    Dec 14 09:41:57.849: INFO: expected 0 pod replicas in namespace 'pods-4692', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 12/14/22 09:41:57.865
    Dec 14 09:41:57.871: INFO: Pod quantity 3 is different from expected quantity 0
    Dec 14 09:41:58.878: INFO: Pod quantity 3 is different from expected quantity 0
    Dec 14 09:41:59.879: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:42:00.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4692" for this suite. 12/14/22 09:42:00.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:00.895
Dec 14 09:42:00.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:42:00.896
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:00.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:00.923
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:42:00.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-624" for this suite. 12/14/22 09:42:00.957
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":206,"skipped":3886,"failed":0}
------------------------------
• [0.071 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:00.895
    Dec 14 09:42:00.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:42:00.896
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:00.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:00.923
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:42:00.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-624" for this suite. 12/14/22 09:42:00.957
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:00.967
Dec 14 09:42:00.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:42:00.968
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:00.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:00.994
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:42:01.016
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:42:01.418
STEP: Deploying the webhook pod 12/14/22 09:42:01.425
STEP: Wait for the deployment to be ready 12/14/22 09:42:01.439
Dec 14 09:42:01.451: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:42:03.471
STEP: Verifying the service has paired with the endpoint 12/14/22 09:42:03.48
Dec 14 09:42:04.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Dec 14 09:42:04.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4517-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:42:05.01
STEP: Creating a custom resource while v1 is storage version 12/14/22 09:42:05.142
STEP: Patching Custom Resource Definition to set v2 as storage 12/14/22 09:42:07.406
STEP: Patching the custom resource while v2 is storage version 12/14/22 09:42:07.422
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:42:08.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3896" for this suite. 12/14/22 09:42:08.018
STEP: Destroying namespace "webhook-3896-markers" for this suite. 12/14/22 09:42:08.025
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":207,"skipped":3904,"failed":0}
------------------------------
• [7.100 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:00.967
    Dec 14 09:42:00.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:42:00.968
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:00.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:00.994
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:42:01.016
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:42:01.418
    STEP: Deploying the webhook pod 12/14/22 09:42:01.425
    STEP: Wait for the deployment to be ready 12/14/22 09:42:01.439
    Dec 14 09:42:01.451: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:42:03.471
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:42:03.48
    Dec 14 09:42:04.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Dec 14 09:42:04.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4517-crds.webhook.example.com via the AdmissionRegistration API 12/14/22 09:42:05.01
    STEP: Creating a custom resource while v1 is storage version 12/14/22 09:42:05.142
    STEP: Patching Custom Resource Definition to set v2 as storage 12/14/22 09:42:07.406
    STEP: Patching the custom resource while v2 is storage version 12/14/22 09:42:07.422
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:42:08.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3896" for this suite. 12/14/22 09:42:08.018
    STEP: Destroying namespace "webhook-3896-markers" for this suite. 12/14/22 09:42:08.025
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:08.068
Dec 14 09:42:08.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:42:08.069
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:08.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:08.095
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 12/14/22 09:42:08.105
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:42:08.478
STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:42:08.485
STEP: Wait for the deployment to be ready 12/14/22 09:42:08.5
Dec 14 09:42:08.512: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:42:10.532
STEP: Verifying the service has paired with the endpoint 12/14/22 09:42:10.542
Dec 14 09:42:11.543: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Dec 14 09:42:11.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource 12/14/22 09:42:14.343
STEP: Create a v2 custom resource 12/14/22 09:42:14.365
STEP: List CRs in v1 12/14/22 09:42:14.474
STEP: List CRs in v2 12/14/22 09:42:14.493
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:42:15.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7358" for this suite. 12/14/22 09:42:15.073
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":208,"skipped":3920,"failed":0}
------------------------------
• [7.047 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:08.068
    Dec 14 09:42:08.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-webhook 12/14/22 09:42:08.069
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:08.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:08.095
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 12/14/22 09:42:08.105
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 12/14/22 09:42:08.478
    STEP: Deploying the custom resource conversion webhook pod 12/14/22 09:42:08.485
    STEP: Wait for the deployment to be ready 12/14/22 09:42:08.5
    Dec 14 09:42:08.512: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:42:10.532
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:42:10.542
    Dec 14 09:42:11.543: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Dec 14 09:42:11.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Creating a v1 custom resource 12/14/22 09:42:14.343
    STEP: Create a v2 custom resource 12/14/22 09:42:14.365
    STEP: List CRs in v1 12/14/22 09:42:14.474
    STEP: List CRs in v2 12/14/22 09:42:14.493
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:42:15.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7358" for this suite. 12/14/22 09:42:15.073
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:15.117
Dec 14 09:42:15.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 09:42:15.118
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:15.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:15.144
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 09:42:15.154: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 09:42:15.168: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 09:42:15.176: INFO: 
Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
Dec 14 09:42:15.188: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 09:42:15.188: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:42:15.188: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:42:15.188: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:42:15.188: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:42:15.188: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 09:42:15.188: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:42:15.188: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:42:15.188: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:42:15.188: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:42:15.188: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 09:42:15.188: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:42:15.188: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 09:42:15.188: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:42:15.188: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:42:15.188: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:42:15.188: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:42:15.188: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:42:15.188: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:42:15.188: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:42:15.188: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:42:15.188: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 09:42:15.188: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 09:42:15.188: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.188: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 14 09:42:15.188: INFO: 
Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
Dec 14 09:42:15.206: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 09:42:15.206: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:42:15.206: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:42:15.206: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:42:15.206: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:42:15.206: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:42:15.206: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 09:42:15.206: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:42:15.206: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 09:42:15.206: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:42:15.206: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:42:15.206: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:42:15.206: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 09:42:15.206: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 09:42:15.206: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:42:15.206: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:42:15.206: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:42:15.206: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:42:15.206: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:42:15.206: INFO: bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 from kubelet-test-624 started at 2022-12-14 09:42:00 +0000 UTC (1 container statuses recorded)
Dec 14 09:42:15.206: INFO: 	Container bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 12/14/22 09:42:15.206
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.17309f979b774f83], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 12/14/22 09:42:15.259
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:42:16.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4705" for this suite. 12/14/22 09:42:16.271
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":209,"skipped":3996,"failed":0}
------------------------------
• [1.161 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:15.117
    Dec 14 09:42:15.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 09:42:15.118
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:15.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:15.144
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 09:42:15.154: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 09:42:15.168: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 09:42:15.176: INFO: 
    Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
    Dec 14 09:42:15.188: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:42:15.188: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.188: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec 14 09:42:15.188: INFO: 
    Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
    Dec 14 09:42:15.206: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:42:15.206: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 09:42:15.206: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 09:42:15.206: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:42:15.206: INFO: bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 from kubelet-test-624 started at 2022-12-14 09:42:00 +0000 UTC (1 container statuses recorded)
    Dec 14 09:42:15.206: INFO: 	Container bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 ready: false, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 12/14/22 09:42:15.206
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.17309f979b774f83], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 12/14/22 09:42:15.259
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:42:16.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4705" for this suite. 12/14/22 09:42:16.271
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:16.279
Dec 14 09:42:16.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:42:16.28
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:16.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:16.307
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-57042409-7ea5-46db-b761-dd2d07bff9bc 12/14/22 09:42:16.317
STEP: Creating a pod to test consume secrets 12/14/22 09:42:16.323
Dec 14 09:42:16.336: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb" in namespace "projected-4373" to be "Succeeded or Failed"
Dec 14 09:42:16.341: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.650902ms
Dec 14 09:42:18.349: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013193322s
Dec 14 09:42:20.348: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012472708s
STEP: Saw pod success 12/14/22 09:42:20.348
Dec 14 09:42:20.348: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb" satisfied condition "Succeeded or Failed"
Dec 14 09:42:20.354: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:42:20.426
Dec 14 09:42:20.436: INFO: Waiting for pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb to disappear
Dec 14 09:42:20.441: INFO: Pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:42:20.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4373" for this suite. 12/14/22 09:42:20.451
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":210,"skipped":4012,"failed":0}
------------------------------
• [4.179 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:16.279
    Dec 14 09:42:16.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:42:16.28
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:16.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:16.307
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-57042409-7ea5-46db-b761-dd2d07bff9bc 12/14/22 09:42:16.317
    STEP: Creating a pod to test consume secrets 12/14/22 09:42:16.323
    Dec 14 09:42:16.336: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb" in namespace "projected-4373" to be "Succeeded or Failed"
    Dec 14 09:42:16.341: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.650902ms
    Dec 14 09:42:18.349: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013193322s
    Dec 14 09:42:20.348: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012472708s
    STEP: Saw pod success 12/14/22 09:42:20.348
    Dec 14 09:42:20.348: INFO: Pod "pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb" satisfied condition "Succeeded or Failed"
    Dec 14 09:42:20.354: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:42:20.426
    Dec 14 09:42:20.436: INFO: Waiting for pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb to disappear
    Dec 14 09:42:20.441: INFO: Pod pod-projected-secrets-14963a81-2b56-4110-a689-1a5d1fae89eb no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:42:20.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4373" for this suite. 12/14/22 09:42:20.451
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:20.459
Dec 14 09:42:20.459: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:42:20.459
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:20.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:20.487
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 12/14/22 09:42:20.497
Dec 14 09:42:20.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version 12/14/22 09:42:28.782
STEP: check the new version name is served 12/14/22 09:42:28.803
STEP: check the old version name is removed 12/14/22 09:42:32.149
STEP: check the other version is not changed 12/14/22 09:42:33.933
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:42:41.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4551" for this suite. 12/14/22 09:42:41.746
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":211,"skipped":4022,"failed":0}
------------------------------
• [21.300 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:20.459
    Dec 14 09:42:20.459: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:42:20.459
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:20.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:20.487
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 12/14/22 09:42:20.497
    Dec 14 09:42:20.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: rename a version 12/14/22 09:42:28.782
    STEP: check the new version name is served 12/14/22 09:42:28.803
    STEP: check the old version name is removed 12/14/22 09:42:32.149
    STEP: check the other version is not changed 12/14/22 09:42:33.933
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:42:41.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4551" for this suite. 12/14/22 09:42:41.746
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:41.76
Dec 14 09:42:41.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:42:41.761
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:41.795
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:41.816
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 12/14/22 09:42:41.837
STEP: Verify that the required pods have come up 12/14/22 09:42:41.849
Dec 14 09:42:41.860: INFO: Pod name sample-pod: Found 1 pods out of 3
Dec 14 09:42:46.873: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 12/14/22 09:42:46.874
Dec 14 09:42:46.885: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 12/14/22 09:42:46.885
STEP: DeleteCollection of the ReplicaSets 12/14/22 09:42:46.897
STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/14/22 09:42:46.91
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:42:46.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1934" for this suite. 12/14/22 09:42:46.943
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":212,"skipped":4059,"failed":0}
------------------------------
• [5.196 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:41.76
    Dec 14 09:42:41.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:42:41.761
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:41.795
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:41.816
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 12/14/22 09:42:41.837
    STEP: Verify that the required pods have come up 12/14/22 09:42:41.849
    Dec 14 09:42:41.860: INFO: Pod name sample-pod: Found 1 pods out of 3
    Dec 14 09:42:46.873: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 12/14/22 09:42:46.874
    Dec 14 09:42:46.885: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 12/14/22 09:42:46.885
    STEP: DeleteCollection of the ReplicaSets 12/14/22 09:42:46.897
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 12/14/22 09:42:46.91
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:42:46.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1934" for this suite. 12/14/22 09:42:46.943
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:42:46.957
Dec 14 09:42:46.957: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator 12/14/22 09:42:46.958
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:46.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:47.014
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Dec 14 09:42:47.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 12/14/22 09:42:47.036
Dec 14 09:42:47.915: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:49.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:51.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:53.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:55.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:57.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:42:59.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:01.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:03.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:05.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:07.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:09.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 09:43:12.248: INFO: Waited 307.912097ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 12/14/22 09:43:12.855
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/14/22 09:43:12.867
STEP: List APIServices 12/14/22 09:43:12.881
Dec 14 09:43:12.896: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Dec 14 09:43:13.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4616" for this suite. 12/14/22 09:43:13.279
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":213,"skipped":4073,"failed":0}
------------------------------
• [26.334 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:42:46.957
    Dec 14 09:42:46.957: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename aggregator 12/14/22 09:42:46.958
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:42:46.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:42:47.014
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Dec 14 09:42:47.035: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 12/14/22 09:42:47.036
    Dec 14 09:42:47.915: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:49.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:51.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:53.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:55.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:57.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:42:59.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:01.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:03.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:05.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:07.929: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:09.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 42, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 09:43:12.248: INFO: Waited 307.912097ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 12/14/22 09:43:12.855
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 12/14/22 09:43:12.867
    STEP: List APIServices 12/14/22 09:43:12.881
    Dec 14 09:43:12.896: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Dec 14 09:43:13.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-4616" for this suite. 12/14/22 09:43:13.279
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:13.292
Dec 14 09:43:13.292: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:43:13.293
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:13.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:13.348
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 12/14/22 09:43:13.369
STEP: creating a watch on configmaps with label B 12/14/22 09:43:13.379
STEP: creating a watch on configmaps with label A or B 12/14/22 09:43:13.39
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.4
Dec 14 09:43:13.412: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42825 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:13.413: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42825 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.413
Dec 14 09:43:13.436: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42826 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:13.437: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42826 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/14/22 09:43:13.437
Dec 14 09:43:13.460: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42827 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:13.460: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42827 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.46
Dec 14 09:43:13.473: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42828 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:13.473: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42828 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/14/22 09:43:13.473
Dec 14 09:43:13.485: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42829 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:13.485: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42829 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/14/22 09:43:23.487
Dec 14 09:43:23.501: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42886 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:43:23.501: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42886 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:43:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7937" for this suite. 12/14/22 09:43:33.526
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":214,"skipped":4083,"failed":0}
------------------------------
• [20.247 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:13.292
    Dec 14 09:43:13.292: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:43:13.293
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:13.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:13.348
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 12/14/22 09:43:13.369
    STEP: creating a watch on configmaps with label B 12/14/22 09:43:13.379
    STEP: creating a watch on configmaps with label A or B 12/14/22 09:43:13.39
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.4
    Dec 14 09:43:13.412: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42825 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:13.413: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42825 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.413
    Dec 14 09:43:13.436: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42826 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:13.437: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42826 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 12/14/22 09:43:13.437
    Dec 14 09:43:13.460: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42827 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:13.460: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42827 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 12/14/22 09:43:13.46
    Dec 14 09:43:13.473: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42828 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:13.473: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-7937  8bccd31b-5e5a-4196-8213-ee43cfe7d840 42828 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 12/14/22 09:43:13.473
    Dec 14 09:43:13.485: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42829 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:13.485: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42829 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 12/14/22 09:43:23.487
    Dec 14 09:43:23.501: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42886 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:43:23.501: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-7937  235aa407-7712-419b-b484-da085935c597 42886 0 2022-12-14 09:43:13 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-12-14 09:43:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:43:33.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7937" for this suite. 12/14/22 09:43:33.526
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:33.543
Dec 14 09:43:33.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:43:33.544
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:33.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:33.6
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 12/14/22 09:43:33.632
STEP: Waiting for all pods to be running 12/14/22 09:43:33.695
Dec 14 09:43:33.717: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:43:35.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1519" for this suite. 12/14/22 09:43:35.762
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":215,"skipped":4106,"failed":0}
------------------------------
• [2.231 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:33.543
    Dec 14 09:43:33.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:43:33.544
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:33.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:33.6
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 12/14/22 09:43:33.632
    STEP: Waiting for all pods to be running 12/14/22 09:43:33.695
    Dec 14 09:43:33.717: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:43:35.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1519" for this suite. 12/14/22 09:43:35.762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:35.775
Dec 14 09:43:35.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 09:43:35.775
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:35.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:35.847
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 09:43:35.867: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 09:43:35.892: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 09:43:35.904: INFO: 
Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
Dec 14 09:43:35.922: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 09:43:35.922: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:43:35.922: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:43:35.922: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:43:35.922: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:43:35.922: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 09:43:35.922: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:43:35.922: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 09:43:35.922: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:43:35.922: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container coredns ready: true, restart count 0
Dec 14 09:43:35.922: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 09:43:35.922: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:43:35.922: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 09:43:35.922: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:43:35.922: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:43:35.922: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:43:35.922: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:43:35.922: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:43:35.922: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:43:35.922: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:43:35.922: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:43:35.922: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 09:43:35.922: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 09:43:35.922: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.922: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 14 09:43:35.922: INFO: 
Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
Dec 14 09:43:35.947: INFO: pod-0 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
Dec 14 09:43:35.947: INFO: pod-1 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
Dec 14 09:43:35.947: INFO: pod-2 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
Dec 14 09:43:35.947: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 09:43:35.947: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container proxy ready: true, restart count 0
Dec 14 09:43:35.947: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 09:43:35.947: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:43:35.947: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 09:43:35.947: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 09:43:35.947: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 09:43:35.947: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 09:43:35.947: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 09:43:35.947: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 09:43:35.947: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 09:43:35.947: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 09:43:35.947: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 09:43:35.947: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 09:43:35.947: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 09:43:35.947: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 09:43:35.947: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 09:43:35.947: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 09:43:35.947: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 09:43:35.947: INFO: bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 from kubelet-test-624 started at 2022-12-14 09:42:00 +0000 UTC (1 container statuses recorded)
Dec 14 09:43:35.947: INFO: 	Container bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node izgw86e9lj0cm6u1hvldynz 12/14/22 09:43:35.987
STEP: verifying the node has the label node izgw8jfcr55yi09nr0a5xaz 12/14/22 09:43:36.019
Dec 14 09:43:36.051: INFO: Pod pod-0 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod pod-1 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod pod-2 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod addons-nginx-ingress-controller-66dcb55f8b-bj75t requesting resource cpu=100m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s requesting resource cpu=0m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod apiserver-proxy-wcs5k requesting resource cpu=40m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod apiserver-proxy-xvwlm requesting resource cpu=40m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod blackbox-exporter-59447f4c55-vzzfw requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod blackbox-exporter-59447f4c55-xvf4k requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod calico-node-79gdj requesting resource cpu=250m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod calico-node-9hshd requesting resource cpu=250m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod calico-node-vertical-autoscaler-6597dd8998-tsbck requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod calico-typha-deploy-65c54d4db6-6mdx6 requesting resource cpu=320m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod calico-typha-vertical-autoscaler-84df655c88-wlqx5 requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod coredns-859d4f7b5b-724vk requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod coredns-859d4f7b5b-zxww6 requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod csi-disk-plugin-alicloud-8lj7g requesting resource cpu=34m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod csi-disk-plugin-alicloud-mz6gw requesting resource cpu=34m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod egress-filter-applier-7bxh8 requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod egress-filter-applier-n76g2 requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod kube-proxy-worker-1-v1.25.4-4k5xr requesting resource cpu=22m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod kube-proxy-worker-1-v1.25.4-t5n5f requesting resource cpu=22m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod metrics-server-5dc78cf6bb-bslwt requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod metrics-server-5dc78cf6bb-h4d4m requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod network-problem-detector-host-b66xb requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod network-problem-detector-host-zrqcc requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod network-problem-detector-pod-ms9lr requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod network-problem-detector-pod-w78cl requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod node-exporter-27gn7 requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod node-exporter-9qtdl requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod node-local-dns-bfkj9 requesting resource cpu=11m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod node-local-dns-rh48z requesting resource cpu=11m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod node-problem-detector-l92rw requesting resource cpu=11m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod node-problem-detector-nf5mp requesting resource cpu=11m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod vpn-shoot-5b86586f48-fbfm5 requesting resource cpu=100m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.051: INFO: Pod dashboard-metrics-scraper-6d54964d4b-jh2jz requesting resource cpu=0m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.051: INFO: Pod kubernetes-dashboard-8494758d8f-lwknh requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
STEP: Starting Pods to consume most of the cluster CPU. 12/14/22 09:43:36.051
Dec 14 09:43:36.051: INFO: Creating a pod which consumes cpu=582m on Node izgw86e9lj0cm6u1hvldynz
Dec 14 09:43:36.070: INFO: Creating a pod which consumes cpu=848m on Node izgw8jfcr55yi09nr0a5xaz
Dec 14 09:43:36.086: INFO: Waiting up to 5m0s for pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5" in namespace "sched-pred-4816" to be "running"
Dec 14 09:43:36.098: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.137077ms
Dec 14 09:43:38.110: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.023848532s
Dec 14 09:43:38.110: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5" satisfied condition "running"
Dec 14 09:43:38.110: INFO: Waiting up to 5m0s for pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540" in namespace "sched-pred-4816" to be "running"
Dec 14 09:43:38.122: INFO: Pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540": Phase="Running", Reason="", readiness=true. Elapsed: 11.400525ms
Dec 14 09:43:38.122: INFO: Pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 12/14/22 09:43:38.122
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa6c63710d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4816/filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5 to izgw86e9lj0cm6u1hvldynz] 12/14/22 09:43:38.134
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa8b1487bd], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:43:38.134
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa8c046360], Reason = [Created], Message = [Created container filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5] 12/14/22 09:43:38.134
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa90d77ffc], Reason = [Started], Message = [Started container filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5] 12/14/22 09:43:38.134
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa6d56b22a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4816/filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540 to izgw8jfcr55yi09nr0a5xaz] 12/14/22 09:43:38.134
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa8bb34bab], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:43:38.135
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa8cf7c4ef], Reason = [Created], Message = [Created container filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540] 12/14/22 09:43:38.135
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa911c7a23], Reason = [Started], Message = [Started container filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540] 12/14/22 09:43:38.135
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17309faae8c98c85], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 12/14/22 09:43:38.165
STEP: removing the label node off the node izgw86e9lj0cm6u1hvldynz 12/14/22 09:43:39.174
STEP: verifying the node doesn't have the label node 12/14/22 09:43:39.214
STEP: removing the label node off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 09:43:39.226
STEP: verifying the node doesn't have the label node 12/14/22 09:43:39.257
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:43:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4816" for this suite. 12/14/22 09:43:39.281
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":216,"skipped":4107,"failed":0}
------------------------------
• [3.520 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:35.775
    Dec 14 09:43:35.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 09:43:35.775
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:35.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:35.847
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 09:43:35.867: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 09:43:35.892: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 09:43:35.904: INFO: 
    Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
    Dec 14 09:43:35.922: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:43:35.922: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.922: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec 14 09:43:35.922: INFO: 
    Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
    Dec 14 09:43:35.947: INFO: pod-0 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: pod-1 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: pod-2 from disruption-1519 started at 2022-12-14 09:43:33 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container donothing ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: addons-nginx-ingress-controller-66dcb55f8b-bj75t from kube-system started at 2022-12-14 08:47:55 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 09:43:35.947: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 09:43:35.947: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 09:43:35.947: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 09:43:35.947: INFO: bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 from kubelet-test-624 started at 2022-12-14 09:42:00 +0000 UTC (1 container statuses recorded)
    Dec 14 09:43:35.947: INFO: 	Container bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 ready: false, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node izgw86e9lj0cm6u1hvldynz 12/14/22 09:43:35.987
    STEP: verifying the node has the label node izgw8jfcr55yi09nr0a5xaz 12/14/22 09:43:36.019
    Dec 14 09:43:36.051: INFO: Pod pod-0 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod pod-1 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod pod-2 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod addons-nginx-ingress-controller-66dcb55f8b-bj75t requesting resource cpu=100m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s requesting resource cpu=0m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod apiserver-proxy-wcs5k requesting resource cpu=40m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod apiserver-proxy-xvwlm requesting resource cpu=40m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod blackbox-exporter-59447f4c55-vzzfw requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod blackbox-exporter-59447f4c55-xvf4k requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod calico-node-79gdj requesting resource cpu=250m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod calico-node-9hshd requesting resource cpu=250m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod calico-node-vertical-autoscaler-6597dd8998-tsbck requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod calico-typha-deploy-65c54d4db6-6mdx6 requesting resource cpu=320m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod calico-typha-vertical-autoscaler-84df655c88-wlqx5 requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod coredns-859d4f7b5b-724vk requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod coredns-859d4f7b5b-zxww6 requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod csi-disk-plugin-alicloud-8lj7g requesting resource cpu=34m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod csi-disk-plugin-alicloud-mz6gw requesting resource cpu=34m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod egress-filter-applier-7bxh8 requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod egress-filter-applier-n76g2 requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod kube-proxy-worker-1-v1.25.4-4k5xr requesting resource cpu=22m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod kube-proxy-worker-1-v1.25.4-t5n5f requesting resource cpu=22m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod metrics-server-5dc78cf6bb-bslwt requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod metrics-server-5dc78cf6bb-h4d4m requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod network-problem-detector-host-b66xb requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod network-problem-detector-host-zrqcc requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod network-problem-detector-pod-ms9lr requesting resource cpu=10m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod network-problem-detector-pod-w78cl requesting resource cpu=10m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod node-exporter-27gn7 requesting resource cpu=50m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod node-exporter-9qtdl requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod node-local-dns-bfkj9 requesting resource cpu=11m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod node-local-dns-rh48z requesting resource cpu=11m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod node-problem-detector-l92rw requesting resource cpu=11m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod node-problem-detector-nf5mp requesting resource cpu=11m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod vpn-shoot-5b86586f48-fbfm5 requesting resource cpu=100m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod bin-false4dcafe72-f6d4-4ea9-8e4c-79376f526820 requesting resource cpu=0m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.051: INFO: Pod dashboard-metrics-scraper-6d54964d4b-jh2jz requesting resource cpu=0m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.051: INFO: Pod kubernetes-dashboard-8494758d8f-lwknh requesting resource cpu=50m on Node izgw86e9lj0cm6u1hvldynz
    STEP: Starting Pods to consume most of the cluster CPU. 12/14/22 09:43:36.051
    Dec 14 09:43:36.051: INFO: Creating a pod which consumes cpu=582m on Node izgw86e9lj0cm6u1hvldynz
    Dec 14 09:43:36.070: INFO: Creating a pod which consumes cpu=848m on Node izgw8jfcr55yi09nr0a5xaz
    Dec 14 09:43:36.086: INFO: Waiting up to 5m0s for pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5" in namespace "sched-pred-4816" to be "running"
    Dec 14 09:43:36.098: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.137077ms
    Dec 14 09:43:38.110: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.023848532s
    Dec 14 09:43:38.110: INFO: Pod "filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5" satisfied condition "running"
    Dec 14 09:43:38.110: INFO: Waiting up to 5m0s for pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540" in namespace "sched-pred-4816" to be "running"
    Dec 14 09:43:38.122: INFO: Pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540": Phase="Running", Reason="", readiness=true. Elapsed: 11.400525ms
    Dec 14 09:43:38.122: INFO: Pod "filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 12/14/22 09:43:38.122
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa6c63710d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4816/filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5 to izgw86e9lj0cm6u1hvldynz] 12/14/22 09:43:38.134
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa8b1487bd], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:43:38.134
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa8c046360], Reason = [Created], Message = [Created container filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5] 12/14/22 09:43:38.134
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5.17309faa90d77ffc], Reason = [Started], Message = [Started container filler-pod-0468aefa-883e-4c1f-bc6c-a4eb2b8c0cc5] 12/14/22 09:43:38.134
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa6d56b22a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4816/filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540 to izgw8jfcr55yi09nr0a5xaz] 12/14/22 09:43:38.134
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa8bb34bab], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 12/14/22 09:43:38.135
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa8cf7c4ef], Reason = [Created], Message = [Created container filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540] 12/14/22 09:43:38.135
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540.17309faa911c7a23], Reason = [Started], Message = [Started container filler-pod-d8e6c882-f8d3-4bd1-b1d4-e64f848b0540] 12/14/22 09:43:38.135
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17309faae8c98c85], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 12/14/22 09:43:38.165
    STEP: removing the label node off the node izgw86e9lj0cm6u1hvldynz 12/14/22 09:43:39.174
    STEP: verifying the node doesn't have the label node 12/14/22 09:43:39.214
    STEP: removing the label node off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 09:43:39.226
    STEP: verifying the node doesn't have the label node 12/14/22 09:43:39.257
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:43:39.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4816" for this suite. 12/14/22 09:43:39.281
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:39.295
Dec 14 09:43:39.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:43:39.296
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:39.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:39.352
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 12/14/22 09:43:39.373
STEP: Creating a ResourceQuota 12/14/22 09:43:44.385
STEP: Ensuring resource quota status is calculated 12/14/22 09:43:44.397
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:43:46.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3544" for this suite. 12/14/22 09:43:46.432
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":217,"skipped":4119,"failed":0}
------------------------------
• [7.149 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:39.295
    Dec 14 09:43:39.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:43:39.296
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:39.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:39.352
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 12/14/22 09:43:39.373
    STEP: Creating a ResourceQuota 12/14/22 09:43:44.385
    STEP: Ensuring resource quota status is calculated 12/14/22 09:43:44.397
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:43:46.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3544" for this suite. 12/14/22 09:43:46.432
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:46.445
Dec 14 09:43:46.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:43:46.446
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:46.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:46.504
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:43:46.575
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:43:46.587
Dec 14 09:43:46.610: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:43:46.610: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:47.644: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:43:47.644: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:48.645: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:43:48.645: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 12/14/22 09:43:48.657
Dec 14 09:43:48.710: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:43:48.710: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:49.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:43:49.743: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:50.744: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:43:50.744: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:51.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:43:51.745: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:43:52.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:43:52.743: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:43:52.754
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4092, will wait for the garbage collector to delete the pods 12/14/22 09:43:52.754
Dec 14 09:43:52.830: INFO: Deleting DaemonSet.extensions daemon-set took: 13.745859ms
Dec 14 09:43:52.930: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.127868ms
Dec 14 09:43:55.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:43:55.342: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:43:55.353: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"43191"},"items":null}

Dec 14 09:43:55.364: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"43191"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:43:55.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4092" for this suite. 12/14/22 09:43:55.42
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":218,"skipped":4130,"failed":0}
------------------------------
• [8.987 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:46.445
    Dec 14 09:43:46.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:43:46.446
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:46.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:46.504
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 12/14/22 09:43:46.575
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:43:46.587
    Dec 14 09:43:46.610: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:43:46.610: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:47.644: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:43:47.644: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:48.645: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:43:48.645: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 12/14/22 09:43:48.657
    Dec 14 09:43:48.710: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:43:48.710: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:49.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:43:49.743: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:50.744: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:43:50.744: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:51.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:43:51.745: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:43:52.743: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:43:52.743: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:43:52.754
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4092, will wait for the garbage collector to delete the pods 12/14/22 09:43:52.754
    Dec 14 09:43:52.830: INFO: Deleting DaemonSet.extensions daemon-set took: 13.745859ms
    Dec 14 09:43:52.930: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.127868ms
    Dec 14 09:43:55.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:43:55.342: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:43:55.353: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"43191"},"items":null}

    Dec 14 09:43:55.364: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"43191"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:43:55.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4092" for this suite. 12/14/22 09:43:55.42
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:55.434
Dec 14 09:43:55.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:43:55.435
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:55.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:55.49
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-db1d95a1-4eed-4049-9a05-c293cec7e3ca 12/14/22 09:43:55.511
STEP: Creating a pod to test consume configMaps 12/14/22 09:43:55.523
Dec 14 09:43:55.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e" in namespace "configmap-428" to be "Succeeded or Failed"
Dec 14 09:43:55.554: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.148387ms
Dec 14 09:43:57.567: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023959953s
Dec 14 09:43:59.566: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02315703s
STEP: Saw pod success 12/14/22 09:43:59.567
Dec 14 09:43:59.567: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e" satisfied condition "Succeeded or Failed"
Dec 14 09:43:59.578: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:43:59.602
Dec 14 09:43:59.616: INFO: Waiting for pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e to disappear
Dec 14 09:43:59.627: INFO: Pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:43:59.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-428" for this suite. 12/14/22 09:43:59.648
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":219,"skipped":4156,"failed":0}
------------------------------
• [4.233 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:55.434
    Dec 14 09:43:55.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:43:55.435
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:55.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:55.49
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-db1d95a1-4eed-4049-9a05-c293cec7e3ca 12/14/22 09:43:55.511
    STEP: Creating a pod to test consume configMaps 12/14/22 09:43:55.523
    Dec 14 09:43:55.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e" in namespace "configmap-428" to be "Succeeded or Failed"
    Dec 14 09:43:55.554: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.148387ms
    Dec 14 09:43:57.567: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023959953s
    Dec 14 09:43:59.566: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02315703s
    STEP: Saw pod success 12/14/22 09:43:59.567
    Dec 14 09:43:59.567: INFO: Pod "pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e" satisfied condition "Succeeded or Failed"
    Dec 14 09:43:59.578: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:43:59.602
    Dec 14 09:43:59.616: INFO: Waiting for pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e to disappear
    Dec 14 09:43:59.627: INFO: Pod pod-configmaps-436c1a21-a764-4da1-b511-e65ea1f1c41e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:43:59.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-428" for this suite. 12/14/22 09:43:59.648
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:59.668
Dec 14 09:43:59.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:43:59.669
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:59.703
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:59.724
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 12/14/22 09:43:59.745
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:43:59.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2474" for this suite. 12/14/22 09:43:59.769
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":220,"skipped":4178,"failed":0}
------------------------------
• [0.115 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:59.668
    Dec 14 09:43:59.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:43:59.669
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:59.703
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:59.724
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 12/14/22 09:43:59.745
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:43:59.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2474" for this suite. 12/14/22 09:43:59.769
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:43:59.785
Dec 14 09:43:59.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:43:59.785
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:59.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:59.841
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:43:59.889
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:44:00.424
STEP: Deploying the webhook pod 12/14/22 09:44:00.436
STEP: Wait for the deployment to be ready 12/14/22 09:44:00.46
Dec 14 09:44:00.498: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 12/14/22 09:44:02.511
STEP: Verifying the service has paired with the endpoint 12/14/22 09:44:02.526
Dec 14 09:44:03.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 09:44:03.538
STEP: create a pod 12/14/22 09:44:03.684
Dec 14 09:44:03.701: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-31" to be "running"
Dec 14 09:44:03.712: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.404044ms
Dec 14 09:44:05.725: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023541864s
Dec 14 09:44:05.725: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 12/14/22 09:44:05.725
Dec 14 09:44:05.725: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=webhook-31 attach --namespace=webhook-31 to-be-attached-pod -i -c=container1'
Dec 14 09:44:06.017: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:44:06.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-31" for this suite. 12/14/22 09:44:06.051
STEP: Destroying namespace "webhook-31-markers" for this suite. 12/14/22 09:44:06.064
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":221,"skipped":4240,"failed":0}
------------------------------
• [6.348 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:43:59.785
    Dec 14 09:43:59.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:43:59.785
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:43:59.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:43:59.841
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:43:59.889
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:44:00.424
    STEP: Deploying the webhook pod 12/14/22 09:44:00.436
    STEP: Wait for the deployment to be ready 12/14/22 09:44:00.46
    Dec 14 09:44:00.498: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 44, 0, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 12/14/22 09:44:02.511
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:44:02.526
    Dec 14 09:44:03.527: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 09:44:03.538
    STEP: create a pod 12/14/22 09:44:03.684
    Dec 14 09:44:03.701: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-31" to be "running"
    Dec 14 09:44:03.712: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.404044ms
    Dec 14 09:44:05.725: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023541864s
    Dec 14 09:44:05.725: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 12/14/22 09:44:05.725
    Dec 14 09:44:05.725: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=webhook-31 attach --namespace=webhook-31 to-be-attached-pod -i -c=container1'
    Dec 14 09:44:06.017: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:44:06.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-31" for this suite. 12/14/22 09:44:06.051
    STEP: Destroying namespace "webhook-31-markers" for this suite. 12/14/22 09:44:06.064
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:06.133
Dec 14 09:44:06.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 09:44:06.134
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:06.19
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Dec 14 09:44:06.255: INFO: Endpoints addresses: [10.243.7.243] , ports: [443]
Dec 14 09:44:06.255: INFO: EndpointSlices addresses: [10.243.7.243] , ports: [443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 09:44:06.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8720" for this suite. 12/14/22 09:44:06.267
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":222,"skipped":4247,"failed":0}
------------------------------
• [0.164 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:06.133
    Dec 14 09:44:06.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 09:44:06.134
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:06.19
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Dec 14 09:44:06.255: INFO: Endpoints addresses: [10.243.7.243] , ports: [443]
    Dec 14 09:44:06.255: INFO: EndpointSlices addresses: [10.243.7.243] , ports: [443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 09:44:06.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8720" for this suite. 12/14/22 09:44:06.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:06.298
Dec 14 09:44:06.298: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 09:44:06.299
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:06.356
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 12/14/22 09:44:06.377
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.412
STEP: Creating a service in the namespace 12/14/22 09:44:06.434
STEP: Deleting the namespace 12/14/22 09:44:06.449
STEP: Waiting for the namespace to be removed. 12/14/22 09:44:06.462
STEP: Recreating the namespace 12/14/22 09:44:12.474
STEP: Verifying there is no service in the namespace 12/14/22 09:44:12.509
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:44:12.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9257" for this suite. 12/14/22 09:44:12.541
STEP: Destroying namespace "nsdeletetest-8355" for this suite. 12/14/22 09:44:12.554
Dec 14 09:44:12.566: INFO: Namespace nsdeletetest-8355 was already deleted
STEP: Destroying namespace "nsdeletetest-3288" for this suite. 12/14/22 09:44:12.566
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":223,"skipped":4268,"failed":0}
------------------------------
• [6.281 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:06.298
    Dec 14 09:44:06.298: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 09:44:06.299
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:06.356
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 12/14/22 09:44:06.377
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:06.412
    STEP: Creating a service in the namespace 12/14/22 09:44:06.434
    STEP: Deleting the namespace 12/14/22 09:44:06.449
    STEP: Waiting for the namespace to be removed. 12/14/22 09:44:06.462
    STEP: Recreating the namespace 12/14/22 09:44:12.474
    STEP: Verifying there is no service in the namespace 12/14/22 09:44:12.509
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:44:12.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9257" for this suite. 12/14/22 09:44:12.541
    STEP: Destroying namespace "nsdeletetest-8355" for this suite. 12/14/22 09:44:12.554
    Dec 14 09:44:12.566: INFO: Namespace nsdeletetest-8355 was already deleted
    STEP: Destroying namespace "nsdeletetest-3288" for this suite. 12/14/22 09:44:12.566
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:12.58
Dec 14 09:44:12.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:44:12.581
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:12.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:12.636
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:44:12.657
Dec 14 09:44:12.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 14 09:44:12.747: INFO: stderr: ""
Dec 14 09:44:12.747: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 12/14/22 09:44:12.747
Dec 14 09:44:12.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Dec 14 09:44:13.634: INFO: stderr: ""
Dec 14 09:44:13.634: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:44:13.634
Dec 14 09:44:13.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 delete pods e2e-test-httpd-pod'
Dec 14 09:44:15.967: INFO: stderr: ""
Dec 14 09:44:15.967: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:44:15.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2403" for this suite. 12/14/22 09:44:15.988
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":224,"skipped":4283,"failed":0}
------------------------------
• [3.421 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:12.58
    Dec 14 09:44:12.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:44:12.581
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:12.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:12.636
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:44:12.657
    Dec 14 09:44:12.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec 14 09:44:12.747: INFO: stderr: ""
    Dec 14 09:44:12.747: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 12/14/22 09:44:12.747
    Dec 14 09:44:12.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Dec 14 09:44:13.634: INFO: stderr: ""
    Dec 14 09:44:13.634: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:44:13.634
    Dec 14 09:44:13.646: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2403 delete pods e2e-test-httpd-pod'
    Dec 14 09:44:15.967: INFO: stderr: ""
    Dec 14 09:44:15.967: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:44:15.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2403" for this suite. 12/14/22 09:44:15.988
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:44:16.002
Dec 14 09:44:16.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:44:16.002
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:16.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:16.059
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-1ddf68db-6ffa-40f4-ba87-8611e595d208 12/14/22 09:44:16.092
STEP: Creating configMap with name cm-test-opt-upd-7eca10f1-ac0d-42d6-b629-2dd88b03c3e2 12/14/22 09:44:16.104
STEP: Creating the pod 12/14/22 09:44:16.116
Dec 14 09:44:16.141: INFO: Waiting up to 5m0s for pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859" in namespace "configmap-9569" to be "running and ready"
Dec 14 09:44:16.152: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859": Phase="Pending", Reason="", readiness=false. Elapsed: 11.449817ms
Dec 14 09:44:16.152: INFO: The phase of Pod pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:44:18.168: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859": Phase="Running", Reason="", readiness=true. Elapsed: 2.026883563s
Dec 14 09:44:18.168: INFO: The phase of Pod pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859 is Running (Ready = true)
Dec 14 09:44:18.168: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-1ddf68db-6ffa-40f4-ba87-8611e595d208 12/14/22 09:44:18.434
STEP: Updating configmap cm-test-opt-upd-7eca10f1-ac0d-42d6-b629-2dd88b03c3e2 12/14/22 09:44:18.446
STEP: Creating configMap with name cm-test-opt-create-0395506a-a546-4a3b-83de-8bb499d89507 12/14/22 09:44:18.459
STEP: waiting to observe update in volume 12/14/22 09:44:18.471
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:45:43.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9569" for this suite. 12/14/22 09:45:43.753
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":225,"skipped":4295,"failed":0}
------------------------------
• [87.763 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:44:16.002
    Dec 14 09:44:16.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:44:16.002
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:44:16.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:44:16.059
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-1ddf68db-6ffa-40f4-ba87-8611e595d208 12/14/22 09:44:16.092
    STEP: Creating configMap with name cm-test-opt-upd-7eca10f1-ac0d-42d6-b629-2dd88b03c3e2 12/14/22 09:44:16.104
    STEP: Creating the pod 12/14/22 09:44:16.116
    Dec 14 09:44:16.141: INFO: Waiting up to 5m0s for pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859" in namespace "configmap-9569" to be "running and ready"
    Dec 14 09:44:16.152: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859": Phase="Pending", Reason="", readiness=false. Elapsed: 11.449817ms
    Dec 14 09:44:16.152: INFO: The phase of Pod pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:44:18.168: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859": Phase="Running", Reason="", readiness=true. Elapsed: 2.026883563s
    Dec 14 09:44:18.168: INFO: The phase of Pod pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859 is Running (Ready = true)
    Dec 14 09:44:18.168: INFO: Pod "pod-configmaps-42011cec-0102-4972-9541-7af85a3ed859" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-1ddf68db-6ffa-40f4-ba87-8611e595d208 12/14/22 09:44:18.434
    STEP: Updating configmap cm-test-opt-upd-7eca10f1-ac0d-42d6-b629-2dd88b03c3e2 12/14/22 09:44:18.446
    STEP: Creating configMap with name cm-test-opt-create-0395506a-a546-4a3b-83de-8bb499d89507 12/14/22 09:44:18.459
    STEP: waiting to observe update in volume 12/14/22 09:44:18.471
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:45:43.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9569" for this suite. 12/14/22 09:45:43.753
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:43.765
Dec 14 09:45:43.765: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:45:43.766
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:43.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:43.821
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 12/14/22 09:45:43.842
Dec 14 09:45:43.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 create -f -'
Dec 14 09:45:44.711: INFO: stderr: ""
Dec 14 09:45:44.712: INFO: stdout: "pod/pause created\n"
Dec 14 09:45:44.712: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 14 09:45:44.712: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-822" to be "running and ready"
Dec 14 09:45:44.722: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.853313ms
Dec 14 09:45:44.722: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'izgw8jfcr55yi09nr0a5xaz' to be 'Running' but was 'Pending'
Dec 14 09:45:46.736: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023983499s
Dec 14 09:45:46.736: INFO: Pod "pause" satisfied condition "running and ready"
Dec 14 09:45:46.736: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 12/14/22 09:45:46.736
Dec 14 09:45:46.736: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 label pods pause testing-label=testing-label-value'
Dec 14 09:45:46.864: INFO: stderr: ""
Dec 14 09:45:46.864: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 12/14/22 09:45:46.864
Dec 14 09:45:46.865: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pod pause -L testing-label'
Dec 14 09:45:46.957: INFO: stderr: ""
Dec 14 09:45:46.957: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 12/14/22 09:45:46.957
Dec 14 09:45:46.958: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 label pods pause testing-label-'
Dec 14 09:45:47.078: INFO: stderr: ""
Dec 14 09:45:47.078: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 12/14/22 09:45:47.078
Dec 14 09:45:47.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pod pause -L testing-label'
Dec 14 09:45:47.162: INFO: stderr: ""
Dec 14 09:45:47.162: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 12/14/22 09:45:47.162
Dec 14 09:45:47.163: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 delete --grace-period=0 --force -f -'
Dec 14 09:45:47.257: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 09:45:47.257: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 14 09:45:47.257: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get rc,svc -l name=pause --no-headers'
Dec 14 09:45:47.379: INFO: stderr: "No resources found in kubectl-822 namespace.\n"
Dec 14 09:45:47.379: INFO: stdout: ""
Dec 14 09:45:47.379: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 09:45:47.469: INFO: stderr: ""
Dec 14 09:45:47.469: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:45:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-822" for this suite. 12/14/22 09:45:47.489
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":226,"skipped":4300,"failed":0}
------------------------------
• [3.737 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:43.765
    Dec 14 09:45:43.765: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:45:43.766
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:43.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:43.821
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 12/14/22 09:45:43.842
    Dec 14 09:45:43.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 create -f -'
    Dec 14 09:45:44.711: INFO: stderr: ""
    Dec 14 09:45:44.712: INFO: stdout: "pod/pause created\n"
    Dec 14 09:45:44.712: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Dec 14 09:45:44.712: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-822" to be "running and ready"
    Dec 14 09:45:44.722: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.853313ms
    Dec 14 09:45:44.722: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'izgw8jfcr55yi09nr0a5xaz' to be 'Running' but was 'Pending'
    Dec 14 09:45:46.736: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.023983499s
    Dec 14 09:45:46.736: INFO: Pod "pause" satisfied condition "running and ready"
    Dec 14 09:45:46.736: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 12/14/22 09:45:46.736
    Dec 14 09:45:46.736: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 label pods pause testing-label=testing-label-value'
    Dec 14 09:45:46.864: INFO: stderr: ""
    Dec 14 09:45:46.864: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 12/14/22 09:45:46.864
    Dec 14 09:45:46.865: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pod pause -L testing-label'
    Dec 14 09:45:46.957: INFO: stderr: ""
    Dec 14 09:45:46.957: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 12/14/22 09:45:46.957
    Dec 14 09:45:46.958: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 label pods pause testing-label-'
    Dec 14 09:45:47.078: INFO: stderr: ""
    Dec 14 09:45:47.078: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 12/14/22 09:45:47.078
    Dec 14 09:45:47.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pod pause -L testing-label'
    Dec 14 09:45:47.162: INFO: stderr: ""
    Dec 14 09:45:47.162: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 12/14/22 09:45:47.162
    Dec 14 09:45:47.163: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 delete --grace-period=0 --force -f -'
    Dec 14 09:45:47.257: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 09:45:47.257: INFO: stdout: "pod \"pause\" force deleted\n"
    Dec 14 09:45:47.257: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get rc,svc -l name=pause --no-headers'
    Dec 14 09:45:47.379: INFO: stderr: "No resources found in kubectl-822 namespace.\n"
    Dec 14 09:45:47.379: INFO: stdout: ""
    Dec 14 09:45:47.379: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-822 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 09:45:47.469: INFO: stderr: ""
    Dec 14 09:45:47.469: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:45:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-822" for this suite. 12/14/22 09:45:47.489
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:47.503
Dec 14 09:45:47.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:45:47.504
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:47.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:47.559
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-f4df0a40-6f9d-4f19-ab59-04ed48cd3dbd 12/14/22 09:45:47.58
STEP: Creating a pod to test consume secrets 12/14/22 09:45:47.592
Dec 14 09:45:47.620: INFO: Waiting up to 5m0s for pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b" in namespace "secrets-753" to be "Succeeded or Failed"
Dec 14 09:45:47.631: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.180405ms
Dec 14 09:45:49.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024198623s
Dec 14 09:45:51.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023468348s
STEP: Saw pod success 12/14/22 09:45:51.644
Dec 14 09:45:51.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b" satisfied condition "Succeeded or Failed"
Dec 14 09:45:51.655: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:45:51.678
Dec 14 09:45:51.698: INFO: Waiting for pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b to disappear
Dec 14 09:45:51.709: INFO: Pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:45:51.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-753" for this suite. 12/14/22 09:45:51.73
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":227,"skipped":4311,"failed":0}
------------------------------
• [4.240 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:47.503
    Dec 14 09:45:47.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:45:47.504
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:47.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:47.559
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-f4df0a40-6f9d-4f19-ab59-04ed48cd3dbd 12/14/22 09:45:47.58
    STEP: Creating a pod to test consume secrets 12/14/22 09:45:47.592
    Dec 14 09:45:47.620: INFO: Waiting up to 5m0s for pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b" in namespace "secrets-753" to be "Succeeded or Failed"
    Dec 14 09:45:47.631: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.180405ms
    Dec 14 09:45:49.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024198623s
    Dec 14 09:45:51.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023468348s
    STEP: Saw pod success 12/14/22 09:45:51.644
    Dec 14 09:45:51.644: INFO: Pod "pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b" satisfied condition "Succeeded or Failed"
    Dec 14 09:45:51.655: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:45:51.678
    Dec 14 09:45:51.698: INFO: Waiting for pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b to disappear
    Dec 14 09:45:51.709: INFO: Pod pod-secrets-de9bbf28-604b-4be2-9f00-caea6051584b no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:45:51.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-753" for this suite. 12/14/22 09:45:51.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:51.743
Dec 14 09:45:51.743: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:45:51.744
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:51.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:51.801
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:45:51.822
Dec 14 09:45:51.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136" in namespace "projected-3531" to be "Succeeded or Failed"
Dec 14 09:45:51.853: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Pending", Reason="", readiness=false. Elapsed: 11.738634ms
Dec 14 09:45:53.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024582624s
Dec 14 09:45:55.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024496988s
STEP: Saw pod success 12/14/22 09:45:55.866
Dec 14 09:45:55.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136" satisfied condition "Succeeded or Failed"
Dec 14 09:45:55.877: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 container client-container: <nil>
STEP: delete the pod 12/14/22 09:45:55.9
Dec 14 09:45:55.919: INFO: Waiting for pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 to disappear
Dec 14 09:45:55.930: INFO: Pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:45:55.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3531" for this suite. 12/14/22 09:45:55.951
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":228,"skipped":4316,"failed":0}
------------------------------
• [4.222 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:51.743
    Dec 14 09:45:51.743: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:45:51.744
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:51.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:51.801
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:45:51.822
    Dec 14 09:45:51.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136" in namespace "projected-3531" to be "Succeeded or Failed"
    Dec 14 09:45:51.853: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Pending", Reason="", readiness=false. Elapsed: 11.738634ms
    Dec 14 09:45:53.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024582624s
    Dec 14 09:45:55.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024496988s
    STEP: Saw pod success 12/14/22 09:45:55.866
    Dec 14 09:45:55.866: INFO: Pod "downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136" satisfied condition "Succeeded or Failed"
    Dec 14 09:45:55.877: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:45:55.9
    Dec 14 09:45:55.919: INFO: Waiting for pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 to disappear
    Dec 14 09:45:55.930: INFO: Pod downwardapi-volume-51cf131d-7633-4dfb-b545-aaf925692136 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:45:55.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3531" for this suite. 12/14/22 09:45:55.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:55.966
Dec 14 09:45:55.966: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:45:55.967
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:56.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:56.021
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Dec 14 09:45:56.041: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:45:56.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7712" for this suite. 12/14/22 09:45:56.618
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":229,"skipped":4322,"failed":0}
------------------------------
• [0.664 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:55.966
    Dec 14 09:45:55.966: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename custom-resource-definition 12/14/22 09:45:55.967
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:56.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:56.021
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Dec 14 09:45:56.041: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:45:56.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7712" for this suite. 12/14/22 09:45:56.618
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:45:56.632
Dec 14 09:45:56.632: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:45:56.633
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:56.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:56.695
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Dec 14 09:45:56.715: INFO: Creating deployment "webserver-deployment"
Dec 14 09:45:56.728: INFO: Waiting for observed generation 1
Dec 14 09:45:58.751: INFO: Waiting for all required pods to come up
Dec 14 09:45:58.788: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 12/14/22 09:45:58.788
Dec 14 09:45:58.788: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 14 09:45:58.811: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 14 09:45:58.835: INFO: Updating deployment webserver-deployment
Dec 14 09:45:58.836: INFO: Waiting for observed generation 2
Dec 14 09:46:00.858: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 14 09:46:00.869: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 14 09:46:00.880: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:46:00.913: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 14 09:46:00.913: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 14 09:46:00.925: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:46:00.947: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 14 09:46:00.947: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 14 09:46:00.971: INFO: Updating deployment webserver-deployment
Dec 14 09:46:00.971: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 14 09:46:00.993: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 14 09:46:03.018: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:46:03.041: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-139  3ff77821-b422-45c2-928d-3071b859b5fd 44376 3 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a3b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:46:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-14 09:46:02 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,},},ReadyReplicas:9,CollisionCount:nil,},}

Dec 14 09:46:03.053: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-139  3a5619d9-8be2-42a7-b62d-f94df9b645eb 44334 3 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3ff77821-b422-45c2-928d-3071b859b5fd 0xc003c7a7f7 0xc003c7a7f8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3ff77821-b422-45c2-928d-3071b859b5fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:46:03.053: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 14 09:46:03.053: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-139  7c20fc0b-de88-47c6-ac83-923b251aab73 44375 3 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3ff77821-b422-45c2-928d-3071b859b5fd 0xc003c7a8f7 0xc003c7a8f8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3ff77821-b422-45c2-928d-3071b859b5fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-2jvqr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2jvqr webserver-deployment-69b7448995- deployment-139  d18b269f-5e24-43bb-b6a1-f77e82587391 44338 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8e621bb76aec69732e9f57391416299ba55179f1ed0f75b9ae100279e74059b9 cni.projectcalico.org/podIP:172.16.0.44/32 cni.projectcalico.org/podIPs:172.16.0.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7af47 0xc003c7af48}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxwwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxwwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.44,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-2p5m2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2p5m2 webserver-deployment-69b7448995- deployment-139  858aab61-81d4-4ad7-99af-5f66872a1145 44339 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ba94154680ea386a5574f136509bcaba516a5c80c28e76e42a76fcb1125afb02 cni.projectcalico.org/podIP:172.16.0.43/32 cni.projectcalico.org/podIPs:172.16.0.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b1a0 0xc003c7b1a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svh59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svh59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.43,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-g5d82" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-g5d82 webserver-deployment-69b7448995- deployment-139  bb74e8df-5ec6-4ec7-ab95-7a410e9c29bc 44348 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b75b1f935c200308ff1ff9b8b2533733e92c63816afbebdd5951788beee334d9 cni.projectcalico.org/podIP:172.16.1.115/32 cni.projectcalico.org/podIPs:172.16.1.115/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b430 0xc003c7b431}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bks9d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bks9d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.115,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-gvbtr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-gvbtr webserver-deployment-69b7448995- deployment-139  bc83dbdb-3b01-4734-aef1-f8bcee99a3b4 44354 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d34c7ded42510a69185a833f680331277e183e41bd7e8a3eb6fb861e5099b366 cni.projectcalico.org/podIP:172.16.1.119/32 cni.projectcalico.org/podIPs:172.16.1.119/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b687 0xc003c7b688}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-425b9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-425b9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-jvp7q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jvp7q webserver-deployment-69b7448995- deployment-139  8c4719b4-4c3f-49cf-bf50-a121b9a560de 44373 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:66cd5c3432c3f939c6711d7f1c52479f0e082a42d7b3e74f85888408e3d69a37 cni.projectcalico.org/podIP:172.16.0.45/32 cni.projectcalico.org/podIPs:172.16.0.45/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b8a7 0xc003c7b8a8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.45\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zw86q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zw86q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.45,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-n7khn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-n7khn webserver-deployment-69b7448995- deployment-139  325bc0c9-2118-46c7-a50a-2179cb96ad3e 44356 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b33e721a89b4a760b61f3e46671f75dd74cc752cb84cfef0958004c25c0f1bec cni.projectcalico.org/podIP:172.16.0.51/32 cni.projectcalico.org/podIPs:172.16.0.51/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7baf0 0xc003c7baf1}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2pxj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2pxj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-q55hk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-q55hk webserver-deployment-69b7448995- deployment-139  e2df2ff9-2a32-48ce-bfda-9b2123d779d1 44353 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0d6d03f0b4e82a5f108d858f07c934ef5f1b63fd866b76e7150ea1ea25cb6136 cni.projectcalico.org/podIP:172.16.0.50/32 cni.projectcalico.org/podIPs:172.16.0.50/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7bd27 0xc003c7bd28}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4zjdw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4zjdw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-r6j72" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-r6j72 webserver-deployment-69b7448995- deployment-139  ee154aea-d306-41a0-9802-be2d5dbbe73e 44346 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e34000ccb30f12cd263f0f4533c71c1186c3663adac352dad8569d284c99f74a cni.projectcalico.org/podIP:172.16.1.116/32 cni.projectcalico.org/podIPs:172.16.1.116/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7bf47 0xc003c7bf48}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4m6g8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4m6g8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-sp6x9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sp6x9 webserver-deployment-69b7448995- deployment-139  099879ff-3a4c-4a26-9ef1-4f194897fcc5 44366 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5a4870132993d7e5b251fb8b60f41b87cfd401408faf23dc4cca4bb055f19264 cni.projectcalico.org/podIP:172.16.0.53/32 cni.projectcalico.org/podIPs:172.16.0.53/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a03a7 0xc0027a03a8}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c8mhj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c8mhj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-x7sk4" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-x7sk4 webserver-deployment-69b7448995- deployment-139  e2300aa5-dea0-4831-aa27-06747a522f91 44351 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2eb48822046850816d0bcd53f6c853c935d0799e06d231cc5e3300f37e29a7fd cni.projectcalico.org/podIP:172.16.1.118/32 cni.projectcalico.org/podIPs:172.16.1.118/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a05d7 0xc0027a05d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6kjzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6kjzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xk52h" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xk52h webserver-deployment-69b7448995- deployment-139  fbb6a578-204d-4f39-b1ef-1415dc42e7b7 44357 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:404861cb8984f3041ac767d5d5cf08ff6e1996e7b0e00071e0abf05d51dd3f80 cni.projectcalico.org/podIP:172.16.1.120/32 cni.projectcalico.org/podIPs:172.16.1.120/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0837 0xc0027a0838}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4mv6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4mv6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xk65k" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xk65k webserver-deployment-69b7448995- deployment-139  04e77be1-e68e-44a8-b263-b0330650341a 44260 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e05b2ddc045c19a26f5af7c039c7f0da6d024d27c73f9af597de93ecfe5193a1 cni.projectcalico.org/podIP:172.16.1.114/32 cni.projectcalico.org/podIPs:172.16.1.114/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0a77 0xc0027a0a78}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fdn2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fdn2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.114,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xn777" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-xn777 webserver-deployment-69b7448995- deployment-139  9a59a1a1-ea9d-405f-bd98-89ab69650fc6 44360 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2e94f82a80bb78c077911905534ba9975f94e7677c50300fdd0210aac818cdd7 cni.projectcalico.org/podIP:172.16.0.52/32 cni.projectcalico.org/podIPs:172.16.0.52/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0cf7 0xc0027a0cf8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w6t8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w6t8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-845c8977d9-4k99v" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4k99v webserver-deployment-845c8977d9- deployment-139  4d8a4e59-aa91-44dd-a5aa-f71bd3d25105 44196 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:18cf16e48103bba145caec564321a32806e07006706c3b81632f3343ff999ee2 cni.projectcalico.org/podIP:172.16.1.111/32 cni.projectcalico.org/podIPs:172.16.1.111/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1097 0xc0027a1098}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqlld,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqlld,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.111,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://32b735efbedfe83f41b32e0ab320ed058e50d13f7e82157e7806ca62a542cade,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-4l5fx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4l5fx webserver-deployment-845c8977d9- deployment-139  3d5a4c4b-21fd-41c2-8858-b4630fd1bd8f 44343 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:de0a8102b116c9faf43553a9e6e2cb7e18ecc6613634492833bc2245d1a132fd cni.projectcalico.org/podIP:172.16.0.46/32 cni.projectcalico.org/podIPs:172.16.0.46/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a12d7 0xc0027a12d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddfrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddfrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-75dl8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-75dl8 webserver-deployment-845c8977d9- deployment-139  a62398ba-75fe-4900-81a0-ccea41009af1 44177 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:97120a240fa4d2a2ddc67d8455fba8bcf76d0f921c8cf4890a539f57e2989be3 cni.projectcalico.org/podIP:172.16.0.42/32 cni.projectcalico.org/podIPs:172.16.0.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1507 0xc0027a1508}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ppxw7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ppxw7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.42,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dce5b67e64d2a4a7665ef91b8acd2fe522083771706a02a5b99dd790eb9a8124,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-9tzw4" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9tzw4 webserver-deployment-845c8977d9- deployment-139  a667bb2d-ef97-4c9b-a1ad-270ff8dbdac9 44367 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:072e98fe84230114c0cde5e930fbfea95052d22bc73ef3f9c6a199cbc8d9fd73 cni.projectcalico.org/podIP:172.16.0.54/32 cni.projectcalico.org/podIPs:172.16.0.54/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1720 0xc0027a1721}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-76k5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-76k5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-b279c" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b279c webserver-deployment-845c8977d9- deployment-139  da162c24-086d-4f40-a485-4c56b5ccc5a9 44361 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:540956b9a1526071b36c639136bae0e3d5d93026fa42c5368b8606ec481509a2 cni.projectcalico.org/podIP:172.16.1.122/32 cni.projectcalico.org/podIPs:172.16.1.122/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1f97 0xc0027a1f98}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rnm2x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rnm2x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-b9gz9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b9gz9 webserver-deployment-845c8977d9- deployment-139  b7233641-8d87-43e3-ae04-bfeab2995111 44368 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c217185ae8bd44f4d8dcfaab5cf4f08f124b8b2ee1d51bfcdafdccf503cd59a cni.projectcalico.org/podIP:172.16.1.123/32 cni.projectcalico.org/podIPs:172.16.1.123/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46197 0xc002e46198}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gbq8v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gbq8v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-bc5dl" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bc5dl webserver-deployment-845c8977d9- deployment-139  1b7e0a2d-90b8-41b2-8f00-b87703b61455 44184 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d21b47c8ef9235de40596f44df1863df2d4f4e3be4a92ce04f0d775c28518da6 cni.projectcalico.org/podIP:172.16.0.40/32 cni.projectcalico.org/podIPs:172.16.0.40/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46397 0xc002e46398}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ztwgc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ztwgc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.40,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b672d1497fcb9d7bf565f0d0619a7eae3923b014b653519c9d765a8ad00d417e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-gqt4f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gqt4f webserver-deployment-845c8977d9- deployment-139  69f76231-28b8-4a35-9eb0-7c3233ee909e 44202 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3dd59702d95bc45a652b33c7c6cf63bcedf831af16a0df174c21635c68caebab cni.projectcalico.org/podIP:172.16.1.110/32 cni.projectcalico.org/podIPs:172.16.1.110/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e465b0 0xc002e465b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6m5vp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6m5vp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.110,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d5ac565c97527792226d83069e7aaf6ac79916185dd5b08850a11a03ecd80048,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-hlt44" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hlt44 webserver-deployment-845c8977d9- deployment-139  25316387-bb94-481d-9ff9-178df7029693 44374 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:dde13c35ad2cf5665b54e4ebc227525e66b4ba2ba4fa98a0e9886423088b066e cni.projectcalico.org/podIP:172.16.1.117/32 cni.projectcalico.org/podIPs:172.16.1.117/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e467d7 0xc002e467d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.117\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92492,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92492,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.117,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:46:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9df6dd218e678c37a5a1249541aac71c3b7088cb223eab23c37431c54f815e34,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-j6f2m" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j6f2m webserver-deployment-845c8977d9- deployment-139  3aae49c1-1302-4f9c-ba0a-4a995651dd48 44205 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d3926a0d936ead578e345172c0992a3c64eeff9dd45662671c5658aa8cab2eef cni.projectcalico.org/podIP:172.16.1.113/32 cni.projectcalico.org/podIPs:172.16.1.113/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e469f7 0xc002e469f8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96l79,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96l79,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.113,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f809a9b6162272d29c8c8e327e6bebadc795898f217521242023a1764008a552,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-kb8rb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kb8rb webserver-deployment-845c8977d9- deployment-139  78b0d2a1-c819-4d8f-86e2-c0b2c39550c5 44371 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e1fdfc990e5e833095f66906421f54f9e4e37099c1436f5a81dbda58d8a25755 cni.projectcalico.org/podIP:172.16.1.125/32 cni.projectcalico.org/podIPs:172.16.1.125/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46c17 0xc002e46c18}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lrbjx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lrbjx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-kpf74" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kpf74 webserver-deployment-845c8977d9- deployment-139  9e2040ef-3a08-4a34-a342-d69b773a325b 44369 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:372e055060c2548c6f0e37c7435984e794a6fb7ac87e3f3935e13245e69d43b3 cni.projectcalico.org/podIP:172.16.1.124/32 cni.projectcalico.org/podIPs:172.16.1.124/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46e17 0xc002e46e18}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sz9wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sz9wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-l9gt9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-l9gt9 webserver-deployment-845c8977d9- deployment-139  add5d9ce-8995-479e-b4f7-c31d7e678ea8 44370 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:afb8d371de01da5ea28e32ae13fa64a951c81910ee1a03014689363ab2b97e3e cni.projectcalico.org/podIP:172.16.0.55/32 cni.projectcalico.org/podIPs:172.16.0.55/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e47017 0xc002e47018}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvqxv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvqxv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-mf974" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mf974 webserver-deployment-845c8977d9- deployment-139  29988cbd-bde5-462e-9a77-9111e43130ed 44350 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6131162872102af8dc157f6ae7485c2e03620d9041ee3e5aea1c861ffa57a0a0 cni.projectcalico.org/podIP:172.16.0.48/32 cni.projectcalico.org/podIPs:172.16.0.48/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e47217 0xc002e47218}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c5fkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c5fkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-n99xk" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-n99xk webserver-deployment-845c8977d9- deployment-139  89263980-d7ec-4a97-8baa-329a91a3fa77 44193 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:29532ed1bada4e0b29890478eabda1ba81b4743711f47378ced889ba1bda29b9 cni.projectcalico.org/podIP:172.16.0.41/32 cni.projectcalico.org/podIPs:172.16.0.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc000472527 0xc000472528}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n8dbk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n8dbk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.41,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://199232e50969a0b9a0fe2e5edd873e880b855f1d694e676fec5be3dc16f6b6c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-rsjc7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rsjc7 webserver-deployment-845c8977d9- deployment-139  2f94d621-03c0-408c-8837-9124d310dc0b 44347 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:37294b9a5f0d7260ff3724fe34782df57c626b1bbcc4c5ac9ecd96eca041c391 cni.projectcalico.org/podIP:172.16.0.47/32 cni.projectcalico.org/podIPs:172.16.0.47/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc000473180 0xc000473181}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-stzpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-stzpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-ssv64" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ssv64 webserver-deployment-845c8977d9- deployment-139  56462c81-d535-456b-b1d3-bbee8f110f08 44359 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:da1fc36cb9ff0946b6a24de7c24cf4eed3e173ee0764ee3bda1815a53d5168c4 cni.projectcalico.org/podIP:172.16.1.121/32 cni.projectcalico.org/podIPs:172.16.1.121/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0023723d7 0xc0023723d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g25nb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g25nb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-tms8c" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tms8c webserver-deployment-845c8977d9- deployment-139  4877ef3d-fa7c-4375-b099-49467d56f104 44199 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:00ba2057d62f7f99b90141f48aa5d8dda6a5f47e6320e75f8b1f075c336591ea cni.projectcalico.org/podIP:172.16.1.112/32 cni.projectcalico.org/podIPs:172.16.1.112/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0023727e7 0xc0023727e8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.112\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-447z7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-447z7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.112,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://228ce45f228ff80dccdeda77436793449d59b954beccf4b6976483fe42d5dfed,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-vjkk9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vjkk9 webserver-deployment-845c8977d9- deployment-139  748198cf-cea1-48b2-a7fb-80f04251089c 44190 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ccdaa270010905cdf8849a88b1e6a174f0890f5b9951af3f15ffdf2e8987afd0 cni.projectcalico.org/podIP:172.16.0.36/32 cni.projectcalico.org/podIPs:172.16.0.36/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002372a07 0xc002372a08}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.36\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-65sp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-65sp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.36,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dc2a05f95bb4397f7f4abee6f857cc975e7ea49e0ef7ccb7c9f23ef465ebee13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-vmwqt" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vmwqt webserver-deployment-845c8977d9- deployment-139  86a09460-0547-4ba5-96bf-9765bb851fc3 44352 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:224c62dd60b30fa55762401f4d5b0f495659646b4365e96aedf4314ba6e0c400 cni.projectcalico.org/podIP:172.16.0.49/32 cni.projectcalico.org/podIPs:172.16.0.49/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002372c20 0xc002372c21}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ks26m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ks26m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:46:03.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-139" for this suite. 12/14/22 09:46:03.115
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":230,"skipped":4357,"failed":0}
------------------------------
• [6.495 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:45:56.632
    Dec 14 09:45:56.632: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:45:56.633
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:45:56.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:45:56.695
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Dec 14 09:45:56.715: INFO: Creating deployment "webserver-deployment"
    Dec 14 09:45:56.728: INFO: Waiting for observed generation 1
    Dec 14 09:45:58.751: INFO: Waiting for all required pods to come up
    Dec 14 09:45:58.788: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 12/14/22 09:45:58.788
    Dec 14 09:45:58.788: INFO: Waiting for deployment "webserver-deployment" to complete
    Dec 14 09:45:58.811: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Dec 14 09:45:58.835: INFO: Updating deployment webserver-deployment
    Dec 14 09:45:58.836: INFO: Waiting for observed generation 2
    Dec 14 09:46:00.858: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Dec 14 09:46:00.869: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Dec 14 09:46:00.880: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:46:00.913: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Dec 14 09:46:00.913: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Dec 14 09:46:00.925: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:46:00.947: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Dec 14 09:46:00.947: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Dec 14 09:46:00.971: INFO: Updating deployment webserver-deployment
    Dec 14 09:46:00.971: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Dec 14 09:46:00.993: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Dec 14 09:46:03.018: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:46:03.041: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-139  3ff77821-b422-45c2-928d-3071b859b5fd 44376 3 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a3b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:46:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-12-14 09:46:02 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,},},ReadyReplicas:9,CollisionCount:nil,},}

    Dec 14 09:46:03.053: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-139  3a5619d9-8be2-42a7-b62d-f94df9b645eb 44334 3 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3ff77821-b422-45c2-928d-3071b859b5fd 0xc003c7a7f7 0xc003c7a7f8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3ff77821-b422-45c2-928d-3071b859b5fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a898 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:46:03.053: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Dec 14 09:46:03.053: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-139  7c20fc0b-de88-47c6-ac83-923b251aab73 44375 3 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3ff77821-b422-45c2-928d-3071b859b5fd 0xc003c7a8f7 0xc003c7a8f8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3ff77821-b422-45c2-928d-3071b859b5fd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003c7a988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-2jvqr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2jvqr webserver-deployment-69b7448995- deployment-139  d18b269f-5e24-43bb-b6a1-f77e82587391 44338 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8e621bb76aec69732e9f57391416299ba55179f1ed0f75b9ae100279e74059b9 cni.projectcalico.org/podIP:172.16.0.44/32 cni.projectcalico.org/podIPs:172.16.0.44/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7af47 0xc003c7af48}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.44\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxwwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxwwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.44,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-2p5m2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2p5m2 webserver-deployment-69b7448995- deployment-139  858aab61-81d4-4ad7-99af-5f66872a1145 44339 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ba94154680ea386a5574f136509bcaba516a5c80c28e76e42a76fcb1125afb02 cni.projectcalico.org/podIP:172.16.0.43/32 cni.projectcalico.org/podIPs:172.16.0.43/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b1a0 0xc003c7b1a1}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-svh59,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-svh59,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.43,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "webserver:404",},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.097: INFO: Pod "webserver-deployment-69b7448995-g5d82" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-g5d82 webserver-deployment-69b7448995- deployment-139  bb74e8df-5ec6-4ec7-ab95-7a410e9c29bc 44348 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b75b1f935c200308ff1ff9b8b2533733e92c63816afbebdd5951788beee334d9 cni.projectcalico.org/podIP:172.16.1.115/32 cni.projectcalico.org/podIPs:172.16.1.115/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b430 0xc003c7b431}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.115\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bks9d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bks9d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.115,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.115,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-gvbtr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-gvbtr webserver-deployment-69b7448995- deployment-139  bc83dbdb-3b01-4734-aef1-f8bcee99a3b4 44354 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d34c7ded42510a69185a833f680331277e183e41bd7e8a3eb6fb861e5099b366 cni.projectcalico.org/podIP:172.16.1.119/32 cni.projectcalico.org/podIPs:172.16.1.119/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b687 0xc003c7b688}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-425b9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-425b9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-jvp7q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jvp7q webserver-deployment-69b7448995- deployment-139  8c4719b4-4c3f-49cf-bf50-a121b9a560de 44373 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:66cd5c3432c3f939c6711d7f1c52479f0e082a42d7b3e74f85888408e3d69a37 cni.projectcalico.org/podIP:172.16.0.45/32 cni.projectcalico.org/podIPs:172.16.0.45/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7b8a7 0xc003c7b8a8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.45\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zw86q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zw86q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.45,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-n7khn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-n7khn webserver-deployment-69b7448995- deployment-139  325bc0c9-2118-46c7-a50a-2179cb96ad3e 44356 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:b33e721a89b4a760b61f3e46671f75dd74cc752cb84cfef0958004c25c0f1bec cni.projectcalico.org/podIP:172.16.0.51/32 cni.projectcalico.org/podIPs:172.16.0.51/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7baf0 0xc003c7baf1}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2pxj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2pxj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.098: INFO: Pod "webserver-deployment-69b7448995-q55hk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-q55hk webserver-deployment-69b7448995- deployment-139  e2df2ff9-2a32-48ce-bfda-9b2123d779d1 44353 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0d6d03f0b4e82a5f108d858f07c934ef5f1b63fd866b76e7150ea1ea25cb6136 cni.projectcalico.org/podIP:172.16.0.50/32 cni.projectcalico.org/podIPs:172.16.0.50/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7bd27 0xc003c7bd28}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4zjdw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4zjdw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-r6j72" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-r6j72 webserver-deployment-69b7448995- deployment-139  ee154aea-d306-41a0-9802-be2d5dbbe73e 44346 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e34000ccb30f12cd263f0f4533c71c1186c3663adac352dad8569d284c99f74a cni.projectcalico.org/podIP:172.16.1.116/32 cni.projectcalico.org/podIPs:172.16.1.116/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc003c7bf47 0xc003c7bf48}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4m6g8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4m6g8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-sp6x9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sp6x9 webserver-deployment-69b7448995- deployment-139  099879ff-3a4c-4a26-9ef1-4f194897fcc5 44366 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5a4870132993d7e5b251fb8b60f41b87cfd401408faf23dc4cca4bb055f19264 cni.projectcalico.org/podIP:172.16.0.53/32 cni.projectcalico.org/podIPs:172.16.0.53/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a03a7 0xc0027a03a8}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c8mhj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c8mhj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-x7sk4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-x7sk4 webserver-deployment-69b7448995- deployment-139  e2300aa5-dea0-4831-aa27-06747a522f91 44351 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2eb48822046850816d0bcd53f6c853c935d0799e06d231cc5e3300f37e29a7fd cni.projectcalico.org/podIP:172.16.1.118/32 cni.projectcalico.org/podIPs:172.16.1.118/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a05d7 0xc0027a05d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6kjzq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6kjzq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xk52h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xk52h webserver-deployment-69b7448995- deployment-139  fbb6a578-204d-4f39-b1ef-1415dc42e7b7 44357 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:404861cb8984f3041ac767d5d5cf08ff6e1996e7b0e00071e0abf05d51dd3f80 cni.projectcalico.org/podIP:172.16.1.120/32 cni.projectcalico.org/podIPs:172.16.1.120/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0837 0xc0027a0838}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4mv6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4mv6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xk65k" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xk65k webserver-deployment-69b7448995- deployment-139  04e77be1-e68e-44a8-b263-b0330650341a 44260 0 2022-12-14 09:45:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:e05b2ddc045c19a26f5af7c039c7f0da6d024d27c73f9af597de93ecfe5193a1 cni.projectcalico.org/podIP:172.16.1.114/32 cni.projectcalico.org/podIPs:172.16.1.114/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0a77 0xc0027a0a78}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:59 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.114\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fdn2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fdn2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.114,StartTime:2022-12-14 09:45:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-69b7448995-xn777" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-xn777 webserver-deployment-69b7448995- deployment-139  9a59a1a1-ea9d-405f-bd98-89ab69650fc6 44360 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2e94f82a80bb78c077911905534ba9975f94e7677c50300fdd0210aac818cdd7 cni.projectcalico.org/podIP:172.16.0.52/32 cni.projectcalico.org/podIPs:172.16.0.52/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 3a5619d9-8be2-42a7-b62d-f94df9b645eb 0xc0027a0cf7 0xc0027a0cf8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a5619d9-8be2-42a7-b62d-f94df9b645eb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w6t8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w6t8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.099: INFO: Pod "webserver-deployment-845c8977d9-4k99v" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4k99v webserver-deployment-845c8977d9- deployment-139  4d8a4e59-aa91-44dd-a5aa-f71bd3d25105 44196 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:18cf16e48103bba145caec564321a32806e07006706c3b81632f3343ff999ee2 cni.projectcalico.org/podIP:172.16.1.111/32 cni.projectcalico.org/podIPs:172.16.1.111/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1097 0xc0027a1098}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.111\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jqlld,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jqlld,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.111,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://32b735efbedfe83f41b32e0ab320ed058e50d13f7e82157e7806ca62a542cade,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-4l5fx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4l5fx webserver-deployment-845c8977d9- deployment-139  3d5a4c4b-21fd-41c2-8858-b4630fd1bd8f 44343 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:de0a8102b116c9faf43553a9e6e2cb7e18ecc6613634492833bc2245d1a132fd cni.projectcalico.org/podIP:172.16.0.46/32 cni.projectcalico.org/podIPs:172.16.0.46/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a12d7 0xc0027a12d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddfrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddfrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-75dl8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-75dl8 webserver-deployment-845c8977d9- deployment-139  a62398ba-75fe-4900-81a0-ccea41009af1 44177 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:97120a240fa4d2a2ddc67d8455fba8bcf76d0f921c8cf4890a539f57e2989be3 cni.projectcalico.org/podIP:172.16.0.42/32 cni.projectcalico.org/podIPs:172.16.0.42/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1507 0xc0027a1508}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ppxw7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ppxw7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.42,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dce5b67e64d2a4a7665ef91b8acd2fe522083771706a02a5b99dd790eb9a8124,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-9tzw4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9tzw4 webserver-deployment-845c8977d9- deployment-139  a667bb2d-ef97-4c9b-a1ad-270ff8dbdac9 44367 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:072e98fe84230114c0cde5e930fbfea95052d22bc73ef3f9c6a199cbc8d9fd73 cni.projectcalico.org/podIP:172.16.0.54/32 cni.projectcalico.org/podIPs:172.16.0.54/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1720 0xc0027a1721}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-76k5p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-76k5p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-b279c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b279c webserver-deployment-845c8977d9- deployment-139  da162c24-086d-4f40-a485-4c56b5ccc5a9 44361 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:540956b9a1526071b36c639136bae0e3d5d93026fa42c5368b8606ec481509a2 cni.projectcalico.org/podIP:172.16.1.122/32 cni.projectcalico.org/podIPs:172.16.1.122/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0027a1f97 0xc0027a1f98}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rnm2x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rnm2x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-b9gz9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b9gz9 webserver-deployment-845c8977d9- deployment-139  b7233641-8d87-43e3-ae04-bfeab2995111 44368 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c217185ae8bd44f4d8dcfaab5cf4f08f124b8b2ee1d51bfcdafdccf503cd59a cni.projectcalico.org/podIP:172.16.1.123/32 cni.projectcalico.org/podIPs:172.16.1.123/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46197 0xc002e46198}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gbq8v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gbq8v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-bc5dl" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bc5dl webserver-deployment-845c8977d9- deployment-139  1b7e0a2d-90b8-41b2-8f00-b87703b61455 44184 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d21b47c8ef9235de40596f44df1863df2d4f4e3be4a92ce04f0d775c28518da6 cni.projectcalico.org/podIP:172.16.0.40/32 cni.projectcalico.org/podIPs:172.16.0.40/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46397 0xc002e46398}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ztwgc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ztwgc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.40,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b672d1497fcb9d7bf565f0d0619a7eae3923b014b653519c9d765a8ad00d417e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.100: INFO: Pod "webserver-deployment-845c8977d9-gqt4f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gqt4f webserver-deployment-845c8977d9- deployment-139  69f76231-28b8-4a35-9eb0-7c3233ee909e 44202 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3dd59702d95bc45a652b33c7c6cf63bcedf831af16a0df174c21635c68caebab cni.projectcalico.org/podIP:172.16.1.110/32 cni.projectcalico.org/podIPs:172.16.1.110/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e465b0 0xc002e465b1}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.110\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6m5vp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6m5vp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.110,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d5ac565c97527792226d83069e7aaf6ac79916185dd5b08850a11a03ecd80048,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-hlt44" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hlt44 webserver-deployment-845c8977d9- deployment-139  25316387-bb94-481d-9ff9-178df7029693 44374 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:dde13c35ad2cf5665b54e4ebc227525e66b4ba2ba4fa98a0e9886423088b066e cni.projectcalico.org/podIP:172.16.1.117/32 cni.projectcalico.org/podIPs:172.16.1.117/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e467d7 0xc002e467d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:02 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.117\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92492,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92492,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.117,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:46:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9df6dd218e678c37a5a1249541aac71c3b7088cb223eab23c37431c54f815e34,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-j6f2m" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j6f2m webserver-deployment-845c8977d9- deployment-139  3aae49c1-1302-4f9c-ba0a-4a995651dd48 44205 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:d3926a0d936ead578e345172c0992a3c64eeff9dd45662671c5658aa8cab2eef cni.projectcalico.org/podIP:172.16.1.113/32 cni.projectcalico.org/podIPs:172.16.1.113/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e469f7 0xc002e469f8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-96l79,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-96l79,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.113,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f809a9b6162272d29c8c8e327e6bebadc795898f217521242023a1764008a552,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-kb8rb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kb8rb webserver-deployment-845c8977d9- deployment-139  78b0d2a1-c819-4d8f-86e2-c0b2c39550c5 44371 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e1fdfc990e5e833095f66906421f54f9e4e37099c1436f5a81dbda58d8a25755 cni.projectcalico.org/podIP:172.16.1.125/32 cni.projectcalico.org/podIPs:172.16.1.125/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46c17 0xc002e46c18}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lrbjx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lrbjx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-kpf74" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kpf74 webserver-deployment-845c8977d9- deployment-139  9e2040ef-3a08-4a34-a342-d69b773a325b 44369 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:372e055060c2548c6f0e37c7435984e794a6fb7ac87e3f3935e13245e69d43b3 cni.projectcalico.org/podIP:172.16.1.124/32 cni.projectcalico.org/podIPs:172.16.1.124/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e46e17 0xc002e46e18}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sz9wt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sz9wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-l9gt9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-l9gt9 webserver-deployment-845c8977d9- deployment-139  add5d9ce-8995-479e-b4f7-c31d7e678ea8 44370 0 2022-12-14 09:46:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:afb8d371de01da5ea28e32ae13fa64a951c81910ee1a03014689363ab2b97e3e cni.projectcalico.org/podIP:172.16.0.55/32 cni.projectcalico.org/podIPs:172.16.0.55/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e47017 0xc002e47018}] [] [{Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvqxv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvqxv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-mf974" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mf974 webserver-deployment-845c8977d9- deployment-139  29988cbd-bde5-462e-9a77-9111e43130ed 44350 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6131162872102af8dc157f6ae7485c2e03620d9041ee3e5aea1c861ffa57a0a0 cni.projectcalico.org/podIP:172.16.0.48/32 cni.projectcalico.org/podIPs:172.16.0.48/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002e47217 0xc002e47218}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c5fkw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c5fkw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.101: INFO: Pod "webserver-deployment-845c8977d9-n99xk" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-n99xk webserver-deployment-845c8977d9- deployment-139  89263980-d7ec-4a97-8baa-329a91a3fa77 44193 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:29532ed1bada4e0b29890478eabda1ba81b4743711f47378ced889ba1bda29b9 cni.projectcalico.org/podIP:172.16.0.41/32 cni.projectcalico.org/podIPs:172.16.0.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc000472527 0xc000472528}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n8dbk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n8dbk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.41,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://199232e50969a0b9a0fe2e5edd873e880b855f1d694e676fec5be3dc16f6b6c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-rsjc7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rsjc7 webserver-deployment-845c8977d9- deployment-139  2f94d621-03c0-408c-8837-9124d310dc0b 44347 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:37294b9a5f0d7260ff3724fe34782df57c626b1bbcc4c5ac9ecd96eca041c391 cni.projectcalico.org/podIP:172.16.0.47/32 cni.projectcalico.org/podIPs:172.16.0.47/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc000473180 0xc000473181}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-stzpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-stzpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-ssv64" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ssv64 webserver-deployment-845c8977d9- deployment-139  56462c81-d535-456b-b1d3-bbee8f110f08 44359 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:da1fc36cb9ff0946b6a24de7c24cf4eed3e173ee0764ee3bda1815a53d5168c4 cni.projectcalico.org/podIP:172.16.1.121/32 cni.projectcalico.org/podIPs:172.16.1.121/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0023723d7 0xc0023723d8}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g25nb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g25nb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:,StartTime:2022-12-14 09:46:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-tms8c" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tms8c webserver-deployment-845c8977d9- deployment-139  4877ef3d-fa7c-4375-b099-49467d56f104 44199 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:00ba2057d62f7f99b90141f48aa5d8dda6a5f47e6320e75f8b1f075c336591ea cni.projectcalico.org/podIP:172.16.1.112/32 cni.projectcalico.org/podIPs:172.16.1.112/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc0023727e7 0xc0023727e8}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.1.112\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-447z7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-447z7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw86e9lj0cm6u1hvldynz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.71,PodIP:172.16.1.112,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://228ce45f228ff80dccdeda77436793449d59b954beccf4b6976483fe42d5dfed,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.1.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-vjkk9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vjkk9 webserver-deployment-845c8977d9- deployment-139  748198cf-cea1-48b2-a7fb-80f04251089c 44190 0 2022-12-14 09:45:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ccdaa270010905cdf8849a88b1e6a174f0890f5b9951af3f15ffdf2e8987afd0 cni.projectcalico.org/podIP:172.16.0.36/32 cni.projectcalico.org/podIPs:172.16.0.36/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002372a07 0xc002372a08}] [] [{kube-controller-manager Update v1 2022-12-14 09:45:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:45:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:45:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.36\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-65sp9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-65sp9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:45:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.36,StartTime:2022-12-14 09:45:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:45:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dc2a05f95bb4397f7f4abee6f857cc975e7ea49e0ef7ccb7c9f23ef465ebee13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Dec 14 09:46:03.102: INFO: Pod "webserver-deployment-845c8977d9-vmwqt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vmwqt webserver-deployment-845c8977d9- deployment-139  86a09460-0547-4ba5-96bf-9765bb851fc3 44352 0 2022-12-14 09:46:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:224c62dd60b30fa55762401f4d5b0f495659646b4365e96aedf4314ba6e0c400 cni.projectcalico.org/podIP:172.16.0.49/32 cni.projectcalico.org/podIPs:172.16.0.49/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 7c20fc0b-de88-47c6-ac83-923b251aab73 0xc002372c20 0xc002372c21}] [] [{kube-controller-manager Update v1 2022-12-14 09:46:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c20fc0b-de88-47c6-ac83-923b251aab73\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 09:46:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ks26m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ks26m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:46:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:46:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:46:03.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-139" for this suite. 12/14/22 09:46:03.115
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:03.129
Dec 14 09:46:03.129: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:46:03.13
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:03.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:03.187
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 12/14/22 09:46:03.208
STEP: creating a new configmap 12/14/22 09:46:03.217
STEP: modifying the configmap once 12/14/22 09:46:03.229
STEP: closing the watch once it receives two notifications 12/14/22 09:46:03.253
Dec 14 09:46:03.253: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44383 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:46:03.253: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44388 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 12/14/22 09:46:03.253
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/14/22 09:46:03.279
STEP: deleting the configmap 12/14/22 09:46:03.289
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/14/22 09:46:03.302
Dec 14 09:46:03.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44392 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:46:03.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44396 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:46:03.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2555" for this suite. 12/14/22 09:46:03.314
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":231,"skipped":4361,"failed":0}
------------------------------
• [0.198 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:03.129
    Dec 14 09:46:03.129: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:46:03.13
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:03.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:03.187
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 12/14/22 09:46:03.208
    STEP: creating a new configmap 12/14/22 09:46:03.217
    STEP: modifying the configmap once 12/14/22 09:46:03.229
    STEP: closing the watch once it receives two notifications 12/14/22 09:46:03.253
    Dec 14 09:46:03.253: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44383 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:46:03.253: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44388 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 12/14/22 09:46:03.253
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 12/14/22 09:46:03.279
    STEP: deleting the configmap 12/14/22 09:46:03.289
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 12/14/22 09:46:03.302
    Dec 14 09:46:03.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44392 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:46:03.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2555  35f6a6e4-a94d-4de1-8fbd-d7ce7aa54047 44396 0 2022-12-14 09:46:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-12-14 09:46:03 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:46:03.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2555" for this suite. 12/14/22 09:46:03.314
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:03.328
Dec 14 09:46:03.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:46:03.329
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:03.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:03.383
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Dec 14 09:46:03.467: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e0cc67e9-0292-4049-94f4-a28ae10ed909", Controller:(*bool)(0xc004eff3f6), BlockOwnerDeletion:(*bool)(0xc004eff3f7)}}
Dec 14 09:46:03.482: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5e3c971d-7364-4f33-8d04-e3a05c9c70c8", Controller:(*bool)(0xc004eff69e), BlockOwnerDeletion:(*bool)(0xc004eff69f)}}
Dec 14 09:46:03.495: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a5300da0-1e96-4b62-bacf-ac0bb998ccee", Controller:(*bool)(0xc004eff93e), BlockOwnerDeletion:(*bool)(0xc004eff93f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:46:08.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3485" for this suite. 12/14/22 09:46:08.542
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":232,"skipped":4365,"failed":0}
------------------------------
• [5.226 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:03.328
    Dec 14 09:46:03.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:46:03.329
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:03.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:03.383
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Dec 14 09:46:03.467: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e0cc67e9-0292-4049-94f4-a28ae10ed909", Controller:(*bool)(0xc004eff3f6), BlockOwnerDeletion:(*bool)(0xc004eff3f7)}}
    Dec 14 09:46:03.482: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5e3c971d-7364-4f33-8d04-e3a05c9c70c8", Controller:(*bool)(0xc004eff69e), BlockOwnerDeletion:(*bool)(0xc004eff69f)}}
    Dec 14 09:46:03.495: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a5300da0-1e96-4b62-bacf-ac0bb998ccee", Controller:(*bool)(0xc004eff93e), BlockOwnerDeletion:(*bool)(0xc004eff93f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:46:08.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3485" for this suite. 12/14/22 09:46:08.542
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:08.554
Dec 14 09:46:08.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:46:08.555
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:08.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:08.609
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-1530 12/14/22 09:46:08.629
Dec 14 09:46:08.645: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1530" to be "running and ready"
Dec 14 09:46:08.656: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.971633ms
Dec 14 09:46:08.656: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:46:10.678: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.032793033s
Dec 14 09:46:10.678: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Dec 14 09:46:10.678: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Dec 14 09:46:10.689: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Dec 14 09:46:11.267: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Dec 14 09:46:11.267: INFO: stdout: "iptables"
Dec 14 09:46:11.267: INFO: proxyMode: iptables
Dec 14 09:46:11.282: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Dec 14 09:46:11.294: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-1530 12/14/22 09:46:11.294
STEP: creating replication controller affinity-nodeport-timeout in namespace services-1530 12/14/22 09:46:11.311
I1214 09:46:11.323451    6248 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1530, replica count: 3
I1214 09:46:14.375338    6248 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:46:14.418: INFO: Creating new exec pod
Dec 14 09:46:14.436: INFO: Waiting up to 5m0s for pod "execpod-affinityvqtzp" in namespace "services-1530" to be "running"
Dec 14 09:46:14.448: INFO: Pod "execpod-affinityvqtzp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.98284ms
Dec 14 09:46:16.460: INFO: Pod "execpod-affinityvqtzp": Phase="Running", Reason="", readiness=true. Elapsed: 2.024094319s
Dec 14 09:46:16.461: INFO: Pod "execpod-affinityvqtzp" satisfied condition "running"
Dec 14 09:46:17.482: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Dec 14 09:46:18.032: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-timeout 80\n+ echo hostName\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Dec 14 09:46:18.032: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:46:18.032: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.58.151 80'
Dec 14 09:46:18.567: INFO: stderr: "+ nc -v -t -w 2 172.29.58.151 80\n+ echo hostName\nConnection to 172.29.58.151 80 port [tcp/http] succeeded!\n"
Dec 14 09:46:18.567: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:46:18.567: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30997'
Dec 14 09:46:19.048: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 30997\nConnection to 10.250.18.71 30997 port [tcp/*] succeeded!\n"
Dec 14 09:46:19.048: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:46:19.048: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30997'
Dec 14 09:46:19.520: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30997\nConnection to 10.250.18.72 30997 port [tcp/*] succeeded!\n"
Dec 14 09:46:19.520: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:46:19.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:30997/ ; done'
Dec 14 09:46:20.142: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
Dec 14 09:46:20.142: INFO: stdout: "\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm"
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
Dec 14 09:46:20.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.18.71:30997/'
Dec 14 09:46:20.637: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
Dec 14 09:46:20.637: INFO: stdout: "affinity-nodeport-timeout-r9rmm"
Dec 14 09:46:40.638: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.18.71:30997/'
Dec 14 09:46:41.196: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
Dec 14 09:46:41.196: INFO: stdout: "affinity-nodeport-timeout-wxc6f"
Dec 14 09:46:41.196: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1530, will wait for the garbage collector to delete the pods 12/14/22 09:46:41.212
Dec 14 09:46:41.288: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 13.456378ms
Dec 14 09:46:41.388: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.530792ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:46:43.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1530" for this suite. 12/14/22 09:46:43.73
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":233,"skipped":4366,"failed":0}
------------------------------
• [35.189 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:08.554
    Dec 14 09:46:08.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:46:08.555
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:08.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:08.609
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-1530 12/14/22 09:46:08.629
    Dec 14 09:46:08.645: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-1530" to be "running and ready"
    Dec 14 09:46:08.656: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 10.971633ms
    Dec 14 09:46:08.656: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:46:10.678: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.032793033s
    Dec 14 09:46:10.678: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Dec 14 09:46:10.678: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Dec 14 09:46:10.689: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Dec 14 09:46:11.267: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Dec 14 09:46:11.267: INFO: stdout: "iptables"
    Dec 14 09:46:11.267: INFO: proxyMode: iptables
    Dec 14 09:46:11.282: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Dec 14 09:46:11.294: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-1530 12/14/22 09:46:11.294
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-1530 12/14/22 09:46:11.311
    I1214 09:46:11.323451    6248 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-1530, replica count: 3
    I1214 09:46:14.375338    6248 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:46:14.418: INFO: Creating new exec pod
    Dec 14 09:46:14.436: INFO: Waiting up to 5m0s for pod "execpod-affinityvqtzp" in namespace "services-1530" to be "running"
    Dec 14 09:46:14.448: INFO: Pod "execpod-affinityvqtzp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.98284ms
    Dec 14 09:46:16.460: INFO: Pod "execpod-affinityvqtzp": Phase="Running", Reason="", readiness=true. Elapsed: 2.024094319s
    Dec 14 09:46:16.461: INFO: Pod "execpod-affinityvqtzp" satisfied condition "running"
    Dec 14 09:46:17.482: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Dec 14 09:46:18.032: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-timeout 80\n+ echo hostName\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Dec 14 09:46:18.032: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:46:18.032: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.58.151 80'
    Dec 14 09:46:18.567: INFO: stderr: "+ nc -v -t -w 2 172.29.58.151 80\n+ echo hostName\nConnection to 172.29.58.151 80 port [tcp/http] succeeded!\n"
    Dec 14 09:46:18.567: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:46:18.567: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30997'
    Dec 14 09:46:19.048: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.71 30997\nConnection to 10.250.18.71 30997 port [tcp/*] succeeded!\n"
    Dec 14 09:46:19.048: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:46:19.048: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30997'
    Dec 14 09:46:19.520: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30997\nConnection to 10.250.18.72 30997 port [tcp/*] succeeded!\n"
    Dec 14 09:46:19.520: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:46:19.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:30997/ ; done'
    Dec 14 09:46:20.142: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
    Dec 14 09:46:20.142: INFO: stdout: "\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm\naffinity-nodeport-timeout-r9rmm"
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Received response from host: affinity-nodeport-timeout-r9rmm
    Dec 14 09:46:20.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.18.71:30997/'
    Dec 14 09:46:20.637: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
    Dec 14 09:46:20.637: INFO: stdout: "affinity-nodeport-timeout-r9rmm"
    Dec 14 09:46:40.638: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-1530 exec execpod-affinityvqtzp -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.250.18.71:30997/'
    Dec 14 09:46:41.196: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.250.18.71:30997/\n"
    Dec 14 09:46:41.196: INFO: stdout: "affinity-nodeport-timeout-wxc6f"
    Dec 14 09:46:41.196: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-1530, will wait for the garbage collector to delete the pods 12/14/22 09:46:41.212
    Dec 14 09:46:41.288: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 13.456378ms
    Dec 14 09:46:41.388: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.530792ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:46:43.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1530" for this suite. 12/14/22 09:46:43.73
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:43.743
Dec 14 09:46:43.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:46:43.744
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:43.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:43.801
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 12/14/22 09:46:43.822
STEP: Ensuring job reaches completions 12/14/22 09:46:43.834
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:46:53.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1149" for this suite. 12/14/22 09:46:53.867
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":234,"skipped":4370,"failed":0}
------------------------------
• [10.137 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:43.743
    Dec 14 09:46:43.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:46:43.744
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:43.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:43.801
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 12/14/22 09:46:43.822
    STEP: Ensuring job reaches completions 12/14/22 09:46:43.834
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:46:53.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1149" for this suite. 12/14/22 09:46:53.867
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:46:53.881
Dec 14 09:46:53.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:46:53.881
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:53.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:53.946
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/14/22 09:46:53.967
Dec 14 09:46:53.968: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:46:57.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:47:12.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-657" for this suite. 12/14/22 09:47:12.408
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":235,"skipped":4374,"failed":0}
------------------------------
• [18.535 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:46:53.881
    Dec 14 09:46:53.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 09:46:53.881
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:46:53.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:46:53.946
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 12/14/22 09:46:53.967
    Dec 14 09:46:53.968: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:46:57.883: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:47:12.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-657" for this suite. 12/14/22 09:47:12.408
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:47:12.417
Dec 14 09:47:12.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime 12/14/22 09:47:12.418
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:12.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:12.451
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/14/22 09:47:12.476
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/14/22 09:47:31.627
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/14/22 09:47:31.634
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/14/22 09:47:31.648
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/14/22 09:47:31.648
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/14/22 09:47:31.683
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/14/22 09:47:34.722
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/14/22 09:47:36.745
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/14/22 09:47:36.759
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/14/22 09:47:36.76
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/14/22 09:47:36.789
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/14/22 09:47:37.803
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/14/22 09:47:39.825
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/14/22 09:47:39.839
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/14/22 09:47:39.839
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Dec 14 09:47:39.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3997" for this suite. 12/14/22 09:47:39.888
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":236,"skipped":4382,"failed":0}
------------------------------
• [27.479 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:47:12.417
    Dec 14 09:47:12.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-runtime 12/14/22 09:47:12.418
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:12.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:12.451
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 12/14/22 09:47:12.476
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 12/14/22 09:47:31.627
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 12/14/22 09:47:31.634
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 12/14/22 09:47:31.648
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 12/14/22 09:47:31.648
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 12/14/22 09:47:31.683
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 12/14/22 09:47:34.722
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 12/14/22 09:47:36.745
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 12/14/22 09:47:36.759
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 12/14/22 09:47:36.76
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 12/14/22 09:47:36.789
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 12/14/22 09:47:37.803
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 12/14/22 09:47:39.825
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 12/14/22 09:47:39.839
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 12/14/22 09:47:39.839
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Dec 14 09:47:39.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3997" for this suite. 12/14/22 09:47:39.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:47:39.897
Dec 14 09:47:39.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:47:39.898
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:39.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:39.93
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Dec 14 09:47:39.955: INFO: Waiting up to 5m0s for pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c" in namespace "pods-1692" to be "running and ready"
Dec 14 09:47:39.962: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.653593ms
Dec 14 09:47:39.962: INFO: The phase of Pod server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:47:41.971: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015063831s
Dec 14 09:47:41.971: INFO: The phase of Pod server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c is Running (Ready = true)
Dec 14 09:47:41.971: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c" satisfied condition "running and ready"
Dec 14 09:47:42.003: INFO: Waiting up to 5m0s for pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86" in namespace "pods-1692" to be "Succeeded or Failed"
Dec 14 09:47:42.009: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Pending", Reason="", readiness=false. Elapsed: 6.671104ms
Dec 14 09:47:44.019: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016515143s
Dec 14 09:47:46.017: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014330767s
STEP: Saw pod success 12/14/22 09:47:46.017
Dec 14 09:47:46.017: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86" satisfied condition "Succeeded or Failed"
Dec 14 09:47:46.024: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 container env3cont: <nil>
STEP: delete the pod 12/14/22 09:47:46.046
Dec 14 09:47:46.057: INFO: Waiting for pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 to disappear
Dec 14 09:47:46.064: INFO: Pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:47:46.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1692" for this suite. 12/14/22 09:47:46.075
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":237,"skipped":4396,"failed":0}
------------------------------
• [6.187 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:47:39.897
    Dec 14 09:47:39.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:47:39.898
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:39.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:39.93
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Dec 14 09:47:39.955: INFO: Waiting up to 5m0s for pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c" in namespace "pods-1692" to be "running and ready"
    Dec 14 09:47:39.962: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.653593ms
    Dec 14 09:47:39.962: INFO: The phase of Pod server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:47:41.971: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015063831s
    Dec 14 09:47:41.971: INFO: The phase of Pod server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c is Running (Ready = true)
    Dec 14 09:47:41.971: INFO: Pod "server-envvars-bd10f7ca-77f1-49fb-b48a-b75deb53843c" satisfied condition "running and ready"
    Dec 14 09:47:42.003: INFO: Waiting up to 5m0s for pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86" in namespace "pods-1692" to be "Succeeded or Failed"
    Dec 14 09:47:42.009: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Pending", Reason="", readiness=false. Elapsed: 6.671104ms
    Dec 14 09:47:44.019: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016515143s
    Dec 14 09:47:46.017: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014330767s
    STEP: Saw pod success 12/14/22 09:47:46.017
    Dec 14 09:47:46.017: INFO: Pod "client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86" satisfied condition "Succeeded or Failed"
    Dec 14 09:47:46.024: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 container env3cont: <nil>
    STEP: delete the pod 12/14/22 09:47:46.046
    Dec 14 09:47:46.057: INFO: Waiting for pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 to disappear
    Dec 14 09:47:46.064: INFO: Pod client-envvars-24001f9c-24ad-4998-9183-04c0458b6b86 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:47:46.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1692" for this suite. 12/14/22 09:47:46.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:47:46.084
Dec 14 09:47:46.084: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 09:47:46.085
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:46.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:46.117
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 12/14/22 09:47:46.136
STEP: delete the rc 12/14/22 09:47:51.15
STEP: wait for the rc to be deleted 12/14/22 09:47:51.159
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/14/22 09:47:56.166
STEP: Gathering metrics 12/14/22 09:48:26.19
W1214 09:48:26.207094    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 09:48:26.207: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Dec 14 09:48:26.207: INFO: Deleting pod "simpletest.rc-285nk" in namespace "gc-9722"
Dec 14 09:48:26.217: INFO: Deleting pod "simpletest.rc-2wjv4" in namespace "gc-9722"
Dec 14 09:48:26.227: INFO: Deleting pod "simpletest.rc-2zjp2" in namespace "gc-9722"
Dec 14 09:48:26.240: INFO: Deleting pod "simpletest.rc-45tr4" in namespace "gc-9722"
Dec 14 09:48:26.251: INFO: Deleting pod "simpletest.rc-4kk8b" in namespace "gc-9722"
Dec 14 09:48:26.264: INFO: Deleting pod "simpletest.rc-4ldg7" in namespace "gc-9722"
Dec 14 09:48:26.274: INFO: Deleting pod "simpletest.rc-4sxc9" in namespace "gc-9722"
Dec 14 09:48:26.285: INFO: Deleting pod "simpletest.rc-54v8l" in namespace "gc-9722"
Dec 14 09:48:26.294: INFO: Deleting pod "simpletest.rc-54z44" in namespace "gc-9722"
Dec 14 09:48:26.304: INFO: Deleting pod "simpletest.rc-5cj5q" in namespace "gc-9722"
Dec 14 09:48:26.323: INFO: Deleting pod "simpletest.rc-665b8" in namespace "gc-9722"
Dec 14 09:48:26.344: INFO: Deleting pod "simpletest.rc-6m4xr" in namespace "gc-9722"
Dec 14 09:48:26.353: INFO: Deleting pod "simpletest.rc-6s8j9" in namespace "gc-9722"
Dec 14 09:48:26.363: INFO: Deleting pod "simpletest.rc-7ftt7" in namespace "gc-9722"
Dec 14 09:48:26.372: INFO: Deleting pod "simpletest.rc-7pt6j" in namespace "gc-9722"
Dec 14 09:48:26.381: INFO: Deleting pod "simpletest.rc-7r726" in namespace "gc-9722"
Dec 14 09:48:26.391: INFO: Deleting pod "simpletest.rc-7s578" in namespace "gc-9722"
Dec 14 09:48:26.401: INFO: Deleting pod "simpletest.rc-7z6gp" in namespace "gc-9722"
Dec 14 09:48:26.411: INFO: Deleting pod "simpletest.rc-84hdl" in namespace "gc-9722"
Dec 14 09:48:26.421: INFO: Deleting pod "simpletest.rc-88s5w" in namespace "gc-9722"
Dec 14 09:48:26.430: INFO: Deleting pod "simpletest.rc-899r5" in namespace "gc-9722"
Dec 14 09:48:26.441: INFO: Deleting pod "simpletest.rc-8k4w6" in namespace "gc-9722"
Dec 14 09:48:26.452: INFO: Deleting pod "simpletest.rc-8lk82" in namespace "gc-9722"
Dec 14 09:48:26.462: INFO: Deleting pod "simpletest.rc-8tgmf" in namespace "gc-9722"
Dec 14 09:48:26.472: INFO: Deleting pod "simpletest.rc-94fgs" in namespace "gc-9722"
Dec 14 09:48:26.481: INFO: Deleting pod "simpletest.rc-9s5pk" in namespace "gc-9722"
Dec 14 09:48:26.490: INFO: Deleting pod "simpletest.rc-9sskh" in namespace "gc-9722"
Dec 14 09:48:26.500: INFO: Deleting pod "simpletest.rc-9x9fl" in namespace "gc-9722"
Dec 14 09:48:26.511: INFO: Deleting pod "simpletest.rc-9z7hx" in namespace "gc-9722"
Dec 14 09:48:26.526: INFO: Deleting pod "simpletest.rc-b945m" in namespace "gc-9722"
Dec 14 09:48:26.537: INFO: Deleting pod "simpletest.rc-bd5z6" in namespace "gc-9722"
Dec 14 09:48:26.549: INFO: Deleting pod "simpletest.rc-brs46" in namespace "gc-9722"
Dec 14 09:48:26.559: INFO: Deleting pod "simpletest.rc-bwpqv" in namespace "gc-9722"
Dec 14 09:48:26.571: INFO: Deleting pod "simpletest.rc-bwwks" in namespace "gc-9722"
Dec 14 09:48:26.580: INFO: Deleting pod "simpletest.rc-bz6ln" in namespace "gc-9722"
Dec 14 09:48:26.591: INFO: Deleting pod "simpletest.rc-cj9pg" in namespace "gc-9722"
Dec 14 09:48:26.605: INFO: Deleting pod "simpletest.rc-ck25f" in namespace "gc-9722"
Dec 14 09:48:26.617: INFO: Deleting pod "simpletest.rc-cpnpj" in namespace "gc-9722"
Dec 14 09:48:26.627: INFO: Deleting pod "simpletest.rc-cpptr" in namespace "gc-9722"
Dec 14 09:48:26.638: INFO: Deleting pod "simpletest.rc-d9xd4" in namespace "gc-9722"
Dec 14 09:48:26.647: INFO: Deleting pod "simpletest.rc-dpn9n" in namespace "gc-9722"
Dec 14 09:48:26.657: INFO: Deleting pod "simpletest.rc-dqccb" in namespace "gc-9722"
Dec 14 09:48:26.668: INFO: Deleting pod "simpletest.rc-f9xpm" in namespace "gc-9722"
Dec 14 09:48:26.679: INFO: Deleting pod "simpletest.rc-ftcjx" in namespace "gc-9722"
Dec 14 09:48:26.690: INFO: Deleting pod "simpletest.rc-fzxbt" in namespace "gc-9722"
Dec 14 09:48:26.700: INFO: Deleting pod "simpletest.rc-g9sd9" in namespace "gc-9722"
Dec 14 09:48:26.710: INFO: Deleting pod "simpletest.rc-gk86n" in namespace "gc-9722"
Dec 14 09:48:26.721: INFO: Deleting pod "simpletest.rc-gkhtv" in namespace "gc-9722"
Dec 14 09:48:26.730: INFO: Deleting pod "simpletest.rc-hrzn8" in namespace "gc-9722"
Dec 14 09:48:26.741: INFO: Deleting pod "simpletest.rc-j56qv" in namespace "gc-9722"
Dec 14 09:48:26.751: INFO: Deleting pod "simpletest.rc-j7r5r" in namespace "gc-9722"
Dec 14 09:48:26.763: INFO: Deleting pod "simpletest.rc-jf5tw" in namespace "gc-9722"
Dec 14 09:48:26.772: INFO: Deleting pod "simpletest.rc-k4llh" in namespace "gc-9722"
Dec 14 09:48:26.783: INFO: Deleting pod "simpletest.rc-k52hq" in namespace "gc-9722"
Dec 14 09:48:26.795: INFO: Deleting pod "simpletest.rc-k5vf9" in namespace "gc-9722"
Dec 14 09:48:26.806: INFO: Deleting pod "simpletest.rc-kbtds" in namespace "gc-9722"
Dec 14 09:48:26.816: INFO: Deleting pod "simpletest.rc-kp42w" in namespace "gc-9722"
Dec 14 09:48:26.825: INFO: Deleting pod "simpletest.rc-lndxn" in namespace "gc-9722"
Dec 14 09:48:26.837: INFO: Deleting pod "simpletest.rc-lqz9r" in namespace "gc-9722"
Dec 14 09:48:26.846: INFO: Deleting pod "simpletest.rc-lrv7f" in namespace "gc-9722"
Dec 14 09:48:26.856: INFO: Deleting pod "simpletest.rc-mgczf" in namespace "gc-9722"
Dec 14 09:48:26.865: INFO: Deleting pod "simpletest.rc-mlmfk" in namespace "gc-9722"
Dec 14 09:48:26.878: INFO: Deleting pod "simpletest.rc-nqjxf" in namespace "gc-9722"
Dec 14 09:48:26.928: INFO: Deleting pod "simpletest.rc-nxs76" in namespace "gc-9722"
Dec 14 09:48:26.977: INFO: Deleting pod "simpletest.rc-nzbpr" in namespace "gc-9722"
Dec 14 09:48:27.027: INFO: Deleting pod "simpletest.rc-nzdhs" in namespace "gc-9722"
Dec 14 09:48:27.078: INFO: Deleting pod "simpletest.rc-pd4ch" in namespace "gc-9722"
Dec 14 09:48:27.127: INFO: Deleting pod "simpletest.rc-pg97t" in namespace "gc-9722"
Dec 14 09:48:27.179: INFO: Deleting pod "simpletest.rc-pnh5h" in namespace "gc-9722"
Dec 14 09:48:27.227: INFO: Deleting pod "simpletest.rc-pqkvn" in namespace "gc-9722"
Dec 14 09:48:27.278: INFO: Deleting pod "simpletest.rc-pshmx" in namespace "gc-9722"
Dec 14 09:48:27.327: INFO: Deleting pod "simpletest.rc-qll9r" in namespace "gc-9722"
Dec 14 09:48:27.377: INFO: Deleting pod "simpletest.rc-qp6ht" in namespace "gc-9722"
Dec 14 09:48:27.427: INFO: Deleting pod "simpletest.rc-qqrkr" in namespace "gc-9722"
Dec 14 09:48:27.476: INFO: Deleting pod "simpletest.rc-qrrmz" in namespace "gc-9722"
Dec 14 09:48:27.528: INFO: Deleting pod "simpletest.rc-qsnhg" in namespace "gc-9722"
Dec 14 09:48:27.578: INFO: Deleting pod "simpletest.rc-rbcjh" in namespace "gc-9722"
Dec 14 09:48:27.627: INFO: Deleting pod "simpletest.rc-rwhh7" in namespace "gc-9722"
Dec 14 09:48:27.678: INFO: Deleting pod "simpletest.rc-sgvxg" in namespace "gc-9722"
Dec 14 09:48:27.728: INFO: Deleting pod "simpletest.rc-sh85s" in namespace "gc-9722"
Dec 14 09:48:27.778: INFO: Deleting pod "simpletest.rc-stgp2" in namespace "gc-9722"
Dec 14 09:48:27.828: INFO: Deleting pod "simpletest.rc-tjbs9" in namespace "gc-9722"
Dec 14 09:48:27.878: INFO: Deleting pod "simpletest.rc-vg46j" in namespace "gc-9722"
Dec 14 09:48:27.928: INFO: Deleting pod "simpletest.rc-vsdww" in namespace "gc-9722"
Dec 14 09:48:27.978: INFO: Deleting pod "simpletest.rc-vwpfm" in namespace "gc-9722"
Dec 14 09:48:28.027: INFO: Deleting pod "simpletest.rc-vzn7g" in namespace "gc-9722"
Dec 14 09:48:28.076: INFO: Deleting pod "simpletest.rc-vzvzn" in namespace "gc-9722"
Dec 14 09:48:28.127: INFO: Deleting pod "simpletest.rc-w2cdx" in namespace "gc-9722"
Dec 14 09:48:28.179: INFO: Deleting pod "simpletest.rc-wv78k" in namespace "gc-9722"
Dec 14 09:48:28.228: INFO: Deleting pod "simpletest.rc-wwj56" in namespace "gc-9722"
Dec 14 09:48:28.278: INFO: Deleting pod "simpletest.rc-x6zhl" in namespace "gc-9722"
Dec 14 09:48:28.329: INFO: Deleting pod "simpletest.rc-xfxdc" in namespace "gc-9722"
Dec 14 09:48:28.378: INFO: Deleting pod "simpletest.rc-xg52l" in namespace "gc-9722"
Dec 14 09:48:28.435: INFO: Deleting pod "simpletest.rc-xxr4w" in namespace "gc-9722"
Dec 14 09:48:28.479: INFO: Deleting pod "simpletest.rc-zcdd8" in namespace "gc-9722"
Dec 14 09:48:28.532: INFO: Deleting pod "simpletest.rc-zgq6g" in namespace "gc-9722"
Dec 14 09:48:28.577: INFO: Deleting pod "simpletest.rc-zkqqb" in namespace "gc-9722"
Dec 14 09:48:28.626: INFO: Deleting pod "simpletest.rc-zmfp8" in namespace "gc-9722"
Dec 14 09:48:28.678: INFO: Deleting pod "simpletest.rc-zmsm6" in namespace "gc-9722"
Dec 14 09:48:28.727: INFO: Deleting pod "simpletest.rc-zxl2p" in namespace "gc-9722"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 09:48:28.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9722" for this suite. 12/14/22 09:48:28.825
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":238,"skipped":4405,"failed":0}
------------------------------
• [42.791 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:47:46.084
    Dec 14 09:47:46.084: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 09:47:46.085
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:47:46.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:47:46.117
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 12/14/22 09:47:46.136
    STEP: delete the rc 12/14/22 09:47:51.15
    STEP: wait for the rc to be deleted 12/14/22 09:47:51.159
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 12/14/22 09:47:56.166
    STEP: Gathering metrics 12/14/22 09:48:26.19
    W1214 09:48:26.207094    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 09:48:26.207: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Dec 14 09:48:26.207: INFO: Deleting pod "simpletest.rc-285nk" in namespace "gc-9722"
    Dec 14 09:48:26.217: INFO: Deleting pod "simpletest.rc-2wjv4" in namespace "gc-9722"
    Dec 14 09:48:26.227: INFO: Deleting pod "simpletest.rc-2zjp2" in namespace "gc-9722"
    Dec 14 09:48:26.240: INFO: Deleting pod "simpletest.rc-45tr4" in namespace "gc-9722"
    Dec 14 09:48:26.251: INFO: Deleting pod "simpletest.rc-4kk8b" in namespace "gc-9722"
    Dec 14 09:48:26.264: INFO: Deleting pod "simpletest.rc-4ldg7" in namespace "gc-9722"
    Dec 14 09:48:26.274: INFO: Deleting pod "simpletest.rc-4sxc9" in namespace "gc-9722"
    Dec 14 09:48:26.285: INFO: Deleting pod "simpletest.rc-54v8l" in namespace "gc-9722"
    Dec 14 09:48:26.294: INFO: Deleting pod "simpletest.rc-54z44" in namespace "gc-9722"
    Dec 14 09:48:26.304: INFO: Deleting pod "simpletest.rc-5cj5q" in namespace "gc-9722"
    Dec 14 09:48:26.323: INFO: Deleting pod "simpletest.rc-665b8" in namespace "gc-9722"
    Dec 14 09:48:26.344: INFO: Deleting pod "simpletest.rc-6m4xr" in namespace "gc-9722"
    Dec 14 09:48:26.353: INFO: Deleting pod "simpletest.rc-6s8j9" in namespace "gc-9722"
    Dec 14 09:48:26.363: INFO: Deleting pod "simpletest.rc-7ftt7" in namespace "gc-9722"
    Dec 14 09:48:26.372: INFO: Deleting pod "simpletest.rc-7pt6j" in namespace "gc-9722"
    Dec 14 09:48:26.381: INFO: Deleting pod "simpletest.rc-7r726" in namespace "gc-9722"
    Dec 14 09:48:26.391: INFO: Deleting pod "simpletest.rc-7s578" in namespace "gc-9722"
    Dec 14 09:48:26.401: INFO: Deleting pod "simpletest.rc-7z6gp" in namespace "gc-9722"
    Dec 14 09:48:26.411: INFO: Deleting pod "simpletest.rc-84hdl" in namespace "gc-9722"
    Dec 14 09:48:26.421: INFO: Deleting pod "simpletest.rc-88s5w" in namespace "gc-9722"
    Dec 14 09:48:26.430: INFO: Deleting pod "simpletest.rc-899r5" in namespace "gc-9722"
    Dec 14 09:48:26.441: INFO: Deleting pod "simpletest.rc-8k4w6" in namespace "gc-9722"
    Dec 14 09:48:26.452: INFO: Deleting pod "simpletest.rc-8lk82" in namespace "gc-9722"
    Dec 14 09:48:26.462: INFO: Deleting pod "simpletest.rc-8tgmf" in namespace "gc-9722"
    Dec 14 09:48:26.472: INFO: Deleting pod "simpletest.rc-94fgs" in namespace "gc-9722"
    Dec 14 09:48:26.481: INFO: Deleting pod "simpletest.rc-9s5pk" in namespace "gc-9722"
    Dec 14 09:48:26.490: INFO: Deleting pod "simpletest.rc-9sskh" in namespace "gc-9722"
    Dec 14 09:48:26.500: INFO: Deleting pod "simpletest.rc-9x9fl" in namespace "gc-9722"
    Dec 14 09:48:26.511: INFO: Deleting pod "simpletest.rc-9z7hx" in namespace "gc-9722"
    Dec 14 09:48:26.526: INFO: Deleting pod "simpletest.rc-b945m" in namespace "gc-9722"
    Dec 14 09:48:26.537: INFO: Deleting pod "simpletest.rc-bd5z6" in namespace "gc-9722"
    Dec 14 09:48:26.549: INFO: Deleting pod "simpletest.rc-brs46" in namespace "gc-9722"
    Dec 14 09:48:26.559: INFO: Deleting pod "simpletest.rc-bwpqv" in namespace "gc-9722"
    Dec 14 09:48:26.571: INFO: Deleting pod "simpletest.rc-bwwks" in namespace "gc-9722"
    Dec 14 09:48:26.580: INFO: Deleting pod "simpletest.rc-bz6ln" in namespace "gc-9722"
    Dec 14 09:48:26.591: INFO: Deleting pod "simpletest.rc-cj9pg" in namespace "gc-9722"
    Dec 14 09:48:26.605: INFO: Deleting pod "simpletest.rc-ck25f" in namespace "gc-9722"
    Dec 14 09:48:26.617: INFO: Deleting pod "simpletest.rc-cpnpj" in namespace "gc-9722"
    Dec 14 09:48:26.627: INFO: Deleting pod "simpletest.rc-cpptr" in namespace "gc-9722"
    Dec 14 09:48:26.638: INFO: Deleting pod "simpletest.rc-d9xd4" in namespace "gc-9722"
    Dec 14 09:48:26.647: INFO: Deleting pod "simpletest.rc-dpn9n" in namespace "gc-9722"
    Dec 14 09:48:26.657: INFO: Deleting pod "simpletest.rc-dqccb" in namespace "gc-9722"
    Dec 14 09:48:26.668: INFO: Deleting pod "simpletest.rc-f9xpm" in namespace "gc-9722"
    Dec 14 09:48:26.679: INFO: Deleting pod "simpletest.rc-ftcjx" in namespace "gc-9722"
    Dec 14 09:48:26.690: INFO: Deleting pod "simpletest.rc-fzxbt" in namespace "gc-9722"
    Dec 14 09:48:26.700: INFO: Deleting pod "simpletest.rc-g9sd9" in namespace "gc-9722"
    Dec 14 09:48:26.710: INFO: Deleting pod "simpletest.rc-gk86n" in namespace "gc-9722"
    Dec 14 09:48:26.721: INFO: Deleting pod "simpletest.rc-gkhtv" in namespace "gc-9722"
    Dec 14 09:48:26.730: INFO: Deleting pod "simpletest.rc-hrzn8" in namespace "gc-9722"
    Dec 14 09:48:26.741: INFO: Deleting pod "simpletest.rc-j56qv" in namespace "gc-9722"
    Dec 14 09:48:26.751: INFO: Deleting pod "simpletest.rc-j7r5r" in namespace "gc-9722"
    Dec 14 09:48:26.763: INFO: Deleting pod "simpletest.rc-jf5tw" in namespace "gc-9722"
    Dec 14 09:48:26.772: INFO: Deleting pod "simpletest.rc-k4llh" in namespace "gc-9722"
    Dec 14 09:48:26.783: INFO: Deleting pod "simpletest.rc-k52hq" in namespace "gc-9722"
    Dec 14 09:48:26.795: INFO: Deleting pod "simpletest.rc-k5vf9" in namespace "gc-9722"
    Dec 14 09:48:26.806: INFO: Deleting pod "simpletest.rc-kbtds" in namespace "gc-9722"
    Dec 14 09:48:26.816: INFO: Deleting pod "simpletest.rc-kp42w" in namespace "gc-9722"
    Dec 14 09:48:26.825: INFO: Deleting pod "simpletest.rc-lndxn" in namespace "gc-9722"
    Dec 14 09:48:26.837: INFO: Deleting pod "simpletest.rc-lqz9r" in namespace "gc-9722"
    Dec 14 09:48:26.846: INFO: Deleting pod "simpletest.rc-lrv7f" in namespace "gc-9722"
    Dec 14 09:48:26.856: INFO: Deleting pod "simpletest.rc-mgczf" in namespace "gc-9722"
    Dec 14 09:48:26.865: INFO: Deleting pod "simpletest.rc-mlmfk" in namespace "gc-9722"
    Dec 14 09:48:26.878: INFO: Deleting pod "simpletest.rc-nqjxf" in namespace "gc-9722"
    Dec 14 09:48:26.928: INFO: Deleting pod "simpletest.rc-nxs76" in namespace "gc-9722"
    Dec 14 09:48:26.977: INFO: Deleting pod "simpletest.rc-nzbpr" in namespace "gc-9722"
    Dec 14 09:48:27.027: INFO: Deleting pod "simpletest.rc-nzdhs" in namespace "gc-9722"
    Dec 14 09:48:27.078: INFO: Deleting pod "simpletest.rc-pd4ch" in namespace "gc-9722"
    Dec 14 09:48:27.127: INFO: Deleting pod "simpletest.rc-pg97t" in namespace "gc-9722"
    Dec 14 09:48:27.179: INFO: Deleting pod "simpletest.rc-pnh5h" in namespace "gc-9722"
    Dec 14 09:48:27.227: INFO: Deleting pod "simpletest.rc-pqkvn" in namespace "gc-9722"
    Dec 14 09:48:27.278: INFO: Deleting pod "simpletest.rc-pshmx" in namespace "gc-9722"
    Dec 14 09:48:27.327: INFO: Deleting pod "simpletest.rc-qll9r" in namespace "gc-9722"
    Dec 14 09:48:27.377: INFO: Deleting pod "simpletest.rc-qp6ht" in namespace "gc-9722"
    Dec 14 09:48:27.427: INFO: Deleting pod "simpletest.rc-qqrkr" in namespace "gc-9722"
    Dec 14 09:48:27.476: INFO: Deleting pod "simpletest.rc-qrrmz" in namespace "gc-9722"
    Dec 14 09:48:27.528: INFO: Deleting pod "simpletest.rc-qsnhg" in namespace "gc-9722"
    Dec 14 09:48:27.578: INFO: Deleting pod "simpletest.rc-rbcjh" in namespace "gc-9722"
    Dec 14 09:48:27.627: INFO: Deleting pod "simpletest.rc-rwhh7" in namespace "gc-9722"
    Dec 14 09:48:27.678: INFO: Deleting pod "simpletest.rc-sgvxg" in namespace "gc-9722"
    Dec 14 09:48:27.728: INFO: Deleting pod "simpletest.rc-sh85s" in namespace "gc-9722"
    Dec 14 09:48:27.778: INFO: Deleting pod "simpletest.rc-stgp2" in namespace "gc-9722"
    Dec 14 09:48:27.828: INFO: Deleting pod "simpletest.rc-tjbs9" in namespace "gc-9722"
    Dec 14 09:48:27.878: INFO: Deleting pod "simpletest.rc-vg46j" in namespace "gc-9722"
    Dec 14 09:48:27.928: INFO: Deleting pod "simpletest.rc-vsdww" in namespace "gc-9722"
    Dec 14 09:48:27.978: INFO: Deleting pod "simpletest.rc-vwpfm" in namespace "gc-9722"
    Dec 14 09:48:28.027: INFO: Deleting pod "simpletest.rc-vzn7g" in namespace "gc-9722"
    Dec 14 09:48:28.076: INFO: Deleting pod "simpletest.rc-vzvzn" in namespace "gc-9722"
    Dec 14 09:48:28.127: INFO: Deleting pod "simpletest.rc-w2cdx" in namespace "gc-9722"
    Dec 14 09:48:28.179: INFO: Deleting pod "simpletest.rc-wv78k" in namespace "gc-9722"
    Dec 14 09:48:28.228: INFO: Deleting pod "simpletest.rc-wwj56" in namespace "gc-9722"
    Dec 14 09:48:28.278: INFO: Deleting pod "simpletest.rc-x6zhl" in namespace "gc-9722"
    Dec 14 09:48:28.329: INFO: Deleting pod "simpletest.rc-xfxdc" in namespace "gc-9722"
    Dec 14 09:48:28.378: INFO: Deleting pod "simpletest.rc-xg52l" in namespace "gc-9722"
    Dec 14 09:48:28.435: INFO: Deleting pod "simpletest.rc-xxr4w" in namespace "gc-9722"
    Dec 14 09:48:28.479: INFO: Deleting pod "simpletest.rc-zcdd8" in namespace "gc-9722"
    Dec 14 09:48:28.532: INFO: Deleting pod "simpletest.rc-zgq6g" in namespace "gc-9722"
    Dec 14 09:48:28.577: INFO: Deleting pod "simpletest.rc-zkqqb" in namespace "gc-9722"
    Dec 14 09:48:28.626: INFO: Deleting pod "simpletest.rc-zmfp8" in namespace "gc-9722"
    Dec 14 09:48:28.678: INFO: Deleting pod "simpletest.rc-zmsm6" in namespace "gc-9722"
    Dec 14 09:48:28.727: INFO: Deleting pod "simpletest.rc-zxl2p" in namespace "gc-9722"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 09:48:28.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9722" for this suite. 12/14/22 09:48:28.825
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:28.875
Dec 14 09:48:28.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 09:48:28.876
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:28.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:28.911
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Dec 14 09:48:28.923: INFO: Creating pod...
Dec 14 09:48:28.936: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3808" to be "running"
Dec 14 09:48:28.943: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.58483ms
Dec 14 09:48:30.951: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014527251s
Dec 14 09:48:32.951: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015133276s
Dec 14 09:48:34.951: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 6.01508098s
Dec 14 09:48:34.951: INFO: Pod "agnhost" satisfied condition "running"
Dec 14 09:48:34.951: INFO: Creating service...
Dec 14 09:48:34.962: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/DELETE
Dec 14 09:48:34.988: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 09:48:34.988: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/GET
Dec 14 09:48:35.040: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 14 09:48:35.040: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/HEAD
Dec 14 09:48:35.052: INFO: http.Client request:HEAD | StatusCode:200
Dec 14 09:48:35.052: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/OPTIONS
Dec 14 09:48:35.065: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 09:48:35.065: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/PATCH
Dec 14 09:48:35.078: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 09:48:35.078: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/POST
Dec 14 09:48:35.090: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 09:48:35.090: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/PUT
Dec 14 09:48:35.102: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 09:48:35.102: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/DELETE
Dec 14 09:48:35.116: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 09:48:35.116: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/GET
Dec 14 09:48:35.129: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Dec 14 09:48:35.129: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/HEAD
Dec 14 09:48:35.142: INFO: http.Client request:HEAD | StatusCode:200
Dec 14 09:48:35.142: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/OPTIONS
Dec 14 09:48:35.155: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 09:48:35.155: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/PATCH
Dec 14 09:48:35.168: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 09:48:35.168: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/POST
Dec 14 09:48:35.181: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 09:48:35.181: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/PUT
Dec 14 09:48:35.195: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 09:48:35.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3808" for this suite. 12/14/22 09:48:35.206
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":239,"skipped":4406,"failed":0}
------------------------------
• [6.339 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:28.875
    Dec 14 09:48:28.875: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 09:48:28.876
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:28.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:28.911
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Dec 14 09:48:28.923: INFO: Creating pod...
    Dec 14 09:48:28.936: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3808" to be "running"
    Dec 14 09:48:28.943: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.58483ms
    Dec 14 09:48:30.951: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014527251s
    Dec 14 09:48:32.951: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015133276s
    Dec 14 09:48:34.951: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 6.01508098s
    Dec 14 09:48:34.951: INFO: Pod "agnhost" satisfied condition "running"
    Dec 14 09:48:34.951: INFO: Creating service...
    Dec 14 09:48:34.962: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/DELETE
    Dec 14 09:48:34.988: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 09:48:34.988: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/GET
    Dec 14 09:48:35.040: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec 14 09:48:35.040: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/HEAD
    Dec 14 09:48:35.052: INFO: http.Client request:HEAD | StatusCode:200
    Dec 14 09:48:35.052: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/OPTIONS
    Dec 14 09:48:35.065: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 09:48:35.065: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/PATCH
    Dec 14 09:48:35.078: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 09:48:35.078: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/POST
    Dec 14 09:48:35.090: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 09:48:35.090: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/pods/agnhost/proxy/some/path/with/PUT
    Dec 14 09:48:35.102: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 09:48:35.102: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/DELETE
    Dec 14 09:48:35.116: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 09:48:35.116: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/GET
    Dec 14 09:48:35.129: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Dec 14 09:48:35.129: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/HEAD
    Dec 14 09:48:35.142: INFO: http.Client request:HEAD | StatusCode:200
    Dec 14 09:48:35.142: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/OPTIONS
    Dec 14 09:48:35.155: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 09:48:35.155: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/PATCH
    Dec 14 09:48:35.168: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 09:48:35.168: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/POST
    Dec 14 09:48:35.181: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 09:48:35.181: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-3808/services/test-service/proxy/some/path/with/PUT
    Dec 14 09:48:35.195: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 09:48:35.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3808" for this suite. 12/14/22 09:48:35.206
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:35.216
Dec 14 09:48:35.216: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:48:35.216
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:35.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:35.25
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 12/14/22 09:48:35.261
Dec 14 09:48:35.275: INFO: Waiting up to 5m0s for pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db" in namespace "emptydir-5816" to be "Succeeded or Failed"
Dec 14 09:48:35.281: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.453094ms
Dec 14 09:48:37.289: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013951322s
Dec 14 09:48:39.290: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015309813s
STEP: Saw pod success 12/14/22 09:48:39.29
Dec 14 09:48:39.290: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db" satisfied condition "Succeeded or Failed"
Dec 14 09:48:39.297: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db container test-container: <nil>
STEP: delete the pod 12/14/22 09:48:39.355
Dec 14 09:48:39.366: INFO: Waiting for pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db to disappear
Dec 14 09:48:39.372: INFO: Pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:48:39.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5816" for this suite. 12/14/22 09:48:39.384
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":240,"skipped":4423,"failed":0}
------------------------------
• [4.176 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:35.216
    Dec 14 09:48:35.216: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:48:35.216
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:35.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:35.25
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 12/14/22 09:48:35.261
    Dec 14 09:48:35.275: INFO: Waiting up to 5m0s for pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db" in namespace "emptydir-5816" to be "Succeeded or Failed"
    Dec 14 09:48:35.281: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.453094ms
    Dec 14 09:48:37.289: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013951322s
    Dec 14 09:48:39.290: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015309813s
    STEP: Saw pod success 12/14/22 09:48:39.29
    Dec 14 09:48:39.290: INFO: Pod "pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db" satisfied condition "Succeeded or Failed"
    Dec 14 09:48:39.297: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db container test-container: <nil>
    STEP: delete the pod 12/14/22 09:48:39.355
    Dec 14 09:48:39.366: INFO: Waiting for pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db to disappear
    Dec 14 09:48:39.372: INFO: Pod pod-a6700fb9-56a3-45b8-bacc-1177f2f4e4db no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:48:39.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5816" for this suite. 12/14/22 09:48:39.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:39.392
Dec 14 09:48:39.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 09:48:39.393
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:39.414
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:39.425
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 12/14/22 09:48:39.437
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 12/14/22 09:48:39.445
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 12/14/22 09:48:39.445
STEP: creating a pod to probe DNS 12/14/22 09:48:39.445
STEP: submitting the pod to kubernetes 12/14/22 09:48:39.445
Dec 14 09:48:39.459: INFO: Waiting up to 15m0s for pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1" in namespace "dns-2451" to be "running"
Dec 14 09:48:39.466: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.538109ms
Dec 14 09:48:41.474: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015068031s
Dec 14 09:48:41.474: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1" satisfied condition "running"
STEP: retrieving the pod 12/14/22 09:48:41.474
STEP: looking for the results for each expected name from probers 12/14/22 09:48:41.482
Dec 14 09:48:41.665: INFO: DNS probes using dns-2451/dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1 succeeded

STEP: deleting the pod 12/14/22 09:48:41.666
STEP: deleting the test headless service 12/14/22 09:48:41.678
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 09:48:41.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2451" for this suite. 12/14/22 09:48:41.699
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":241,"skipped":4431,"failed":0}
------------------------------
• [2.315 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:39.392
    Dec 14 09:48:39.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 09:48:39.393
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:39.414
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:39.425
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 12/14/22 09:48:39.437
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     12/14/22 09:48:39.445
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2451.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     12/14/22 09:48:39.445
    STEP: creating a pod to probe DNS 12/14/22 09:48:39.445
    STEP: submitting the pod to kubernetes 12/14/22 09:48:39.445
    Dec 14 09:48:39.459: INFO: Waiting up to 15m0s for pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1" in namespace "dns-2451" to be "running"
    Dec 14 09:48:39.466: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.538109ms
    Dec 14 09:48:41.474: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015068031s
    Dec 14 09:48:41.474: INFO: Pod "dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 09:48:41.474
    STEP: looking for the results for each expected name from probers 12/14/22 09:48:41.482
    Dec 14 09:48:41.665: INFO: DNS probes using dns-2451/dns-test-25997103-d464-4e4a-80aa-d08d7d04fac1 succeeded

    STEP: deleting the pod 12/14/22 09:48:41.666
    STEP: deleting the test headless service 12/14/22 09:48:41.678
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 09:48:41.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2451" for this suite. 12/14/22 09:48:41.699
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:41.708
Dec 14 09:48:41.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:48:41.708
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:41.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:41.74
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 12/14/22 09:48:41.751
Dec 14 09:48:41.765: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888" in namespace "emptydir-5104" to be "running"
Dec 14 09:48:41.771: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888": Phase="Pending", Reason="", readiness=false. Elapsed: 6.696554ms
Dec 14 09:48:43.780: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888": Phase="Running", Reason="", readiness=false. Elapsed: 2.015486367s
Dec 14 09:48:43.780: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888" satisfied condition "running"
STEP: Reading file content from the nginx-container 12/14/22 09:48:43.78
Dec 14 09:48:43.780: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5104 PodName:pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:48:43.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:48:43.781: INFO: ExecWithOptions: Clientset creation
Dec 14 09:48:43.781: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/emptydir-5104/pods/pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Dec 14 09:48:44.245: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:48:44.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5104" for this suite. 12/14/22 09:48:44.258
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":242,"skipped":4433,"failed":0}
------------------------------
• [2.558 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:41.708
    Dec 14 09:48:41.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:48:41.708
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:41.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:41.74
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 12/14/22 09:48:41.751
    Dec 14 09:48:41.765: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888" in namespace "emptydir-5104" to be "running"
    Dec 14 09:48:41.771: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888": Phase="Pending", Reason="", readiness=false. Elapsed: 6.696554ms
    Dec 14 09:48:43.780: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888": Phase="Running", Reason="", readiness=false. Elapsed: 2.015486367s
    Dec 14 09:48:43.780: INFO: Pod "pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888" satisfied condition "running"
    STEP: Reading file content from the nginx-container 12/14/22 09:48:43.78
    Dec 14 09:48:43.780: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-5104 PodName:pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:48:43.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:48:43.781: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:48:43.781: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/emptydir-5104/pods/pod-sharedvolume-066b8444-acae-4b8c-b859-f3f4b8857888/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Dec 14 09:48:44.245: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:48:44.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5104" for this suite. 12/14/22 09:48:44.258
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:44.266
Dec 14 09:48:44.266: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:48:44.267
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:44.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:44.305
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-08157351-1e1b-4e52-b76e-a8f59393d8bc 12/14/22 09:48:44.316
STEP: Creating a pod to test consume configMaps 12/14/22 09:48:44.324
Dec 14 09:48:44.337: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083" in namespace "projected-7685" to be "Succeeded or Failed"
Dec 14 09:48:44.343: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202406ms
Dec 14 09:48:46.351: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013785313s
Dec 14 09:48:48.352: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014816163s
STEP: Saw pod success 12/14/22 09:48:48.352
Dec 14 09:48:48.352: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083" satisfied condition "Succeeded or Failed"
Dec 14 09:48:48.358: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:48:48.377
Dec 14 09:48:48.386: INFO: Waiting for pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 to disappear
Dec 14 09:48:48.393: INFO: Pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:48:48.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7685" for this suite. 12/14/22 09:48:48.405
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":243,"skipped":4441,"failed":0}
------------------------------
• [4.147 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:44.266
    Dec 14 09:48:44.266: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:48:44.267
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:44.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:44.305
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-08157351-1e1b-4e52-b76e-a8f59393d8bc 12/14/22 09:48:44.316
    STEP: Creating a pod to test consume configMaps 12/14/22 09:48:44.324
    Dec 14 09:48:44.337: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083" in namespace "projected-7685" to be "Succeeded or Failed"
    Dec 14 09:48:44.343: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202406ms
    Dec 14 09:48:46.351: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013785313s
    Dec 14 09:48:48.352: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014816163s
    STEP: Saw pod success 12/14/22 09:48:48.352
    Dec 14 09:48:48.352: INFO: Pod "pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083" satisfied condition "Succeeded or Failed"
    Dec 14 09:48:48.358: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:48:48.377
    Dec 14 09:48:48.386: INFO: Waiting for pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 to disappear
    Dec 14 09:48:48.393: INFO: Pod pod-projected-configmaps-c0bc51d1-8e65-4d01-b2e1-8fddfa4e7083 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:48:48.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7685" for this suite. 12/14/22 09:48:48.405
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:48.413
Dec 14 09:48:48.413: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:48:48.414
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:48.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:48.464
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 12/14/22 09:48:48.475
Dec 14 09:48:48.488: INFO: Waiting up to 5m0s for pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff" in namespace "containers-8695" to be "Succeeded or Failed"
Dec 14 09:48:48.495: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.573042ms
Dec 14 09:48:50.502: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01378804s
Dec 14 09:48:52.503: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014522295s
STEP: Saw pod success 12/14/22 09:48:52.503
Dec 14 09:48:52.503: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff" satisfied condition "Succeeded or Failed"
Dec 14 09:48:52.514: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:48:52.533
Dec 14 09:48:52.543: INFO: Waiting for pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff to disappear
Dec 14 09:48:52.550: INFO: Pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:48:52.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8695" for this suite. 12/14/22 09:48:52.561
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":244,"skipped":4454,"failed":0}
------------------------------
• [4.155 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:48.413
    Dec 14 09:48:48.413: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:48:48.414
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:48.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:48.464
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 12/14/22 09:48:48.475
    Dec 14 09:48:48.488: INFO: Waiting up to 5m0s for pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff" in namespace "containers-8695" to be "Succeeded or Failed"
    Dec 14 09:48:48.495: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.573042ms
    Dec 14 09:48:50.502: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01378804s
    Dec 14 09:48:52.503: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014522295s
    STEP: Saw pod success 12/14/22 09:48:52.503
    Dec 14 09:48:52.503: INFO: Pod "client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff" satisfied condition "Succeeded or Failed"
    Dec 14 09:48:52.514: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:48:52.533
    Dec 14 09:48:52.543: INFO: Waiting for pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff to disappear
    Dec 14 09:48:52.550: INFO: Pod client-containers-36a358b9-0acc-483f-99b7-35e853cf61ff no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:48:52.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8695" for this suite. 12/14/22 09:48:52.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:52.571
Dec 14 09:48:52.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 09:48:52.571
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:52.595
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:52.606
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 12/14/22 09:48:52.625
STEP: Updating PodDisruptionBudget status 12/14/22 09:48:54.639
STEP: Waiting for all pods to be running 12/14/22 09:48:54.652
Dec 14 09:48:54.659: INFO: running pods: 0 < 1
STEP: locating a running pod 12/14/22 09:48:56.668
STEP: Waiting for the pdb to be processed 12/14/22 09:48:56.689
STEP: Patching PodDisruptionBudget status 12/14/22 09:48:56.704
STEP: Waiting for the pdb to be processed 12/14/22 09:48:56.719
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 09:48:56.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9080" for this suite. 12/14/22 09:48:56.738
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":245,"skipped":4498,"failed":0}
------------------------------
• [4.176 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:52.571
    Dec 14 09:48:52.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 09:48:52.571
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:52.595
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:52.606
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 12/14/22 09:48:52.625
    STEP: Updating PodDisruptionBudget status 12/14/22 09:48:54.639
    STEP: Waiting for all pods to be running 12/14/22 09:48:54.652
    Dec 14 09:48:54.659: INFO: running pods: 0 < 1
    STEP: locating a running pod 12/14/22 09:48:56.668
    STEP: Waiting for the pdb to be processed 12/14/22 09:48:56.689
    STEP: Patching PodDisruptionBudget status 12/14/22 09:48:56.704
    STEP: Waiting for the pdb to be processed 12/14/22 09:48:56.719
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 09:48:56.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9080" for this suite. 12/14/22 09:48:56.738
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:56.747
Dec 14 09:48:56.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:48:56.748
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:56.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:56.78
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 12/14/22 09:48:56.792
Dec 14 09:48:56.792: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1420 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 12/14/22 09:48:56.85
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:48:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1420" for this suite. 12/14/22 09:48:56.905
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":246,"skipped":4498,"failed":0}
------------------------------
• [0.167 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:56.747
    Dec 14 09:48:56.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:48:56.748
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:56.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:56.78
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 12/14/22 09:48:56.792
    Dec 14 09:48:56.792: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1420 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 12/14/22 09:48:56.85
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:48:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1420" for this suite. 12/14/22 09:48:56.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:48:56.915
Dec 14 09:48:56.915: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 09:48:56.916
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:56.941
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:56.953
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 12/14/22 09:48:56.976
STEP: creating replication controller proxy-service-cfwl6 in namespace proxy-9461 12/14/22 09:48:56.976
I1214 09:48:56.984103    6248 runners.go:193] Created replication controller with name: proxy-service-cfwl6, namespace: proxy-9461, replica count: 1
I1214 09:48:58.035572    6248 runners.go:193] proxy-service-cfwl6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 09:48:59.036105    6248 runners.go:193] proxy-service-cfwl6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 09:48:59.042: INFO: setup took 2.077297997s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/14/22 09:48:59.043
Dec 14 09:48:59.090: INFO: (0) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 46.931735ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 49.958115ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 49.846187ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 49.8959ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 49.884036ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 49.926425ms)
Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 50.58253ms)
Dec 14 09:48:59.097: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 53.926916ms)
Dec 14 09:48:59.097: INFO: (0) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 53.90456ms)
Dec 14 09:48:59.098: INFO: (0) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 55.380187ms)
Dec 14 09:48:59.098: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 55.389971ms)
Dec 14 09:48:59.105: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 61.882031ms)
Dec 14 09:48:59.105: INFO: (0) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 62.037999ms)
Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 64.618312ms)
Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 64.581204ms)
Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 64.690064ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.425664ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 14.536257ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.763356ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.907204ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.732193ms)
Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.865623ms)
Dec 14 09:48:59.126: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 18.775275ms)
Dec 14 09:48:59.126: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 18.640298ms)
Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 23.401775ms)
Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 23.40589ms)
Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 23.313157ms)
Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 23.41424ms)
Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 27.878363ms)
Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 27.871175ms)
Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 27.94964ms)
Dec 14 09:48:59.141: INFO: (1) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 32.938273ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.590313ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.58985ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.695111ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.801231ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.576968ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.717092ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.622774ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.707982ms)
Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.787806ms)
Dec 14 09:48:59.158: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.316367ms)
Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 19.461849ms)
Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 19.590128ms)
Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 19.556165ms)
Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 19.530408ms)
Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 19.571304ms)
Dec 14 09:48:59.162: INFO: (2) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.145204ms)
Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.60979ms)
Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.816808ms)
Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.667102ms)
Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.625401ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.435411ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.621305ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.499564ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.526222ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.560932ms)
Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.502107ms)
Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.126714ms)
Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.132575ms)
Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.208453ms)
Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.252682ms)
Dec 14 09:48:59.188: INFO: (3) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.785202ms)
Dec 14 09:48:59.188: INFO: (3) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.835273ms)
Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.509788ms)
Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 13.729017ms)
Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.737528ms)
Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.592817ms)
Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.007481ms)
Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.989468ms)
Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.037053ms)
Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.97992ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 19.894904ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 19.902937ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.004405ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 19.916132ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 20.065996ms)
Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.001203ms)
Dec 14 09:48:59.209: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 21.066801ms)
Dec 14 09:48:59.214: INFO: (4) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.581635ms)
Dec 14 09:48:59.227: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.222277ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.692753ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.749958ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.85623ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.737567ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 13.725267ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 13.815019ms)
Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.872735ms)
Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.444067ms)
Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.69198ms)
Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.550206ms)
Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 17.609373ms)
Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 21.888262ms)
Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.932168ms)
Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 22.085278ms)
Dec 14 09:48:59.244: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 30.419026ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.453059ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.38955ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.364669ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.284227ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.31392ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 16.38873ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.877419ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 16.911536ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.872904ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.990826ms)
Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.038665ms)
Dec 14 09:48:59.265: INFO: (6) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.76186ms)
Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.443401ms)
Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.4812ms)
Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.524816ms)
Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.42781ms)
Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.289669ms)
Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.236906ms)
Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 16.323126ms)
Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.308786ms)
Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.324496ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.442471ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.574383ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 17.601925ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.678204ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.597279ms)
Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 17.618567ms)
Dec 14 09:48:59.292: INFO: (7) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.539028ms)
Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.622532ms)
Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.677739ms)
Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.623452ms)
Dec 14 09:48:59.300: INFO: (7) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 29.942164ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.61653ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.686233ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.664168ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.745367ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.851448ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.717913ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.655962ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.797693ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.728812ms)
Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.714312ms)
Dec 14 09:48:59.318: INFO: (8) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.364314ms)
Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.674875ms)
Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 21.704104ms)
Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.878447ms)
Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.695348ms)
Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.781515ms)
Dec 14 09:48:59.335: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 12.832913ms)
Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.363723ms)
Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.379292ms)
Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.391866ms)
Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.428006ms)
Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.551725ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.678444ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 17.781045ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 17.712747ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.854854ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.71607ms)
Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 17.672515ms)
Dec 14 09:48:59.345: INFO: (9) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.569313ms)
Dec 14 09:48:59.345: INFO: (9) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.516552ms)
Dec 14 09:48:59.354: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 31.189344ms)
Dec 14 09:48:59.354: INFO: (9) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 31.203127ms)
Dec 14 09:48:59.368: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.673792ms)
Dec 14 09:48:59.368: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.84655ms)
Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.716195ms)
Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.733268ms)
Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.715515ms)
Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.759706ms)
Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.904927ms)
Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.844894ms)
Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.811848ms)
Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.97131ms)
Dec 14 09:48:59.375: INFO: (10) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 20.953435ms)
Dec 14 09:48:59.375: INFO: (10) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.075512ms)
Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.67905ms)
Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.813936ms)
Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.820882ms)
Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.834376ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.891015ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.864492ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.884974ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.940313ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 13.929333ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 13.928864ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.012699ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.88853ms)
Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.01494ms)
Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 17.329701ms)
Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.41455ms)
Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.266446ms)
Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.689805ms)
Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 21.63042ms)
Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.680871ms)
Dec 14 09:48:59.410: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 30.457414ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.651159ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.660731ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.79314ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.714662ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.629087ms)
Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.80774ms)
Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.318759ms)
Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 17.354615ms)
Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.58263ms)
Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.618657ms)
Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.672564ms)
Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.738689ms)
Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 21.638642ms)
Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.683213ms)
Dec 14 09:48:59.437: INFO: (12) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 26.468654ms)
Dec 14 09:48:59.437: INFO: (12) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 26.51388ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.785051ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.917411ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.995516ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.943657ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 14.901825ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 14.870297ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.844346ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.801889ms)
Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 14.824312ms)
Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 18.340036ms)
Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 18.475892ms)
Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 18.452932ms)
Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 22.752789ms)
Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 22.66415ms)
Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 22.68408ms)
Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.736047ms)
Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.456852ms)
Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.36167ms)
Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.37093ms)
Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.565418ms)
Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.470316ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.323902ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.197303ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.284379ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 17.183351ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.175811ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.170685ms)
Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.256864ms)
Dec 14 09:48:59.481: INFO: (14) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.303807ms)
Dec 14 09:48:59.481: INFO: (14) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 21.387169ms)
Dec 14 09:48:59.486: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 25.776918ms)
Dec 14 09:48:59.486: INFO: (14) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.726233ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.959174ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 15.010582ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 15.112026ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.975205ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 15.0514ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 15.095683ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 15.174044ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 15.087038ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 15.030405ms)
Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 15.07749ms)
Dec 14 09:48:59.503: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.500931ms)
Dec 14 09:48:59.504: INFO: (15) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 18.24251ms)
Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.850534ms)
Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.850159ms)
Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 23.041809ms)
Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 22.814349ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.546794ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.538103ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.568001ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.646755ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.783635ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 14.239459ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.141309ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.21821ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 14.184676ms)
Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.176129ms)
Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 16.83892ms)
Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.925493ms)
Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.03686ms)
Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.000816ms)
Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 20.912902ms)
Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.928553ms)
Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.671087ms)
Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.663036ms)
Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.645862ms)
Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.691735ms)
Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.657283ms)
Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.059635ms)
Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 15.995808ms)
Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.135835ms)
Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.16432ms)
Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 16.056005ms)
Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 20.467496ms)
Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.599783ms)
Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.572944ms)
Dec 14 09:48:59.555: INFO: (17) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.01623ms)
Dec 14 09:48:59.555: INFO: (17) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 24.992681ms)
Dec 14 09:48:59.559: INFO: (17) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 29.114601ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.003944ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.137673ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.008936ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.024704ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.009059ms)
Dec 14 09:48:59.573: INFO: (18) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 13.038423ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.216745ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.006551ms)
Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 12.989546ms)
Dec 14 09:48:59.573: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.032108ms)
Dec 14 09:48:59.577: INFO: (18) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.563777ms)
Dec 14 09:48:59.577: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.511282ms)
Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.937675ms)
Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.953237ms)
Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.00146ms)
Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.021743ms)
Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 19.251854ms)
Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 19.24874ms)
Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 19.263592ms)
Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 19.335297ms)
Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 23.642862ms)
Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 23.677637ms)
Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 23.763926ms)
Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 23.691074ms)
Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 23.693681ms)
Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 28.079716ms)
Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 28.254748ms)
Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 28.117408ms)
Dec 14 09:48:59.614: INFO: (19) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 32.230969ms)
Dec 14 09:48:59.614: INFO: (19) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 32.304573ms)
Dec 14 09:48:59.618: INFO: (19) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 36.593452ms)
Dec 14 09:48:59.618: INFO: (19) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 36.580769ms)
STEP: deleting ReplicationController proxy-service-cfwl6 in namespace proxy-9461, will wait for the garbage collector to delete the pods 12/14/22 09:48:59.618
Dec 14 09:48:59.684: INFO: Deleting ReplicationController proxy-service-cfwl6 took: 7.91358ms
Dec 14 09:48:59.785: INFO: Terminating ReplicationController proxy-service-cfwl6 pods took: 101.051701ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 09:49:02.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9461" for this suite. 12/14/22 09:49:02.198
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":247,"skipped":4512,"failed":0}
------------------------------
• [5.291 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:48:56.915
    Dec 14 09:48:56.915: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 09:48:56.916
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:48:56.941
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:48:56.953
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 12/14/22 09:48:56.976
    STEP: creating replication controller proxy-service-cfwl6 in namespace proxy-9461 12/14/22 09:48:56.976
    I1214 09:48:56.984103    6248 runners.go:193] Created replication controller with name: proxy-service-cfwl6, namespace: proxy-9461, replica count: 1
    I1214 09:48:58.035572    6248 runners.go:193] proxy-service-cfwl6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 09:48:59.036105    6248 runners.go:193] proxy-service-cfwl6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 09:48:59.042: INFO: setup took 2.077297997s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 12/14/22 09:48:59.043
    Dec 14 09:48:59.090: INFO: (0) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 46.931735ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 49.958115ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 49.846187ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 49.8959ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 49.884036ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 49.926425ms)
    Dec 14 09:48:59.093: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 50.58253ms)
    Dec 14 09:48:59.097: INFO: (0) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 53.926916ms)
    Dec 14 09:48:59.097: INFO: (0) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 53.90456ms)
    Dec 14 09:48:59.098: INFO: (0) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 55.380187ms)
    Dec 14 09:48:59.098: INFO: (0) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 55.389971ms)
    Dec 14 09:48:59.105: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 61.882031ms)
    Dec 14 09:48:59.105: INFO: (0) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 62.037999ms)
    Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 64.618312ms)
    Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 64.581204ms)
    Dec 14 09:48:59.107: INFO: (0) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 64.690064ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.425664ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 14.536257ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.763356ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.907204ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.732193ms)
    Dec 14 09:48:59.122: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.865623ms)
    Dec 14 09:48:59.126: INFO: (1) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 18.775275ms)
    Dec 14 09:48:59.126: INFO: (1) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 18.640298ms)
    Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 23.401775ms)
    Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 23.40589ms)
    Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 23.313157ms)
    Dec 14 09:48:59.131: INFO: (1) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 23.41424ms)
    Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 27.878363ms)
    Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 27.871175ms)
    Dec 14 09:48:59.136: INFO: (1) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 27.94964ms)
    Dec 14 09:48:59.141: INFO: (1) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 32.938273ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.590313ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.58985ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.695111ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.801231ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.576968ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.717092ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.622774ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.707982ms)
    Dec 14 09:48:59.154: INFO: (2) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.787806ms)
    Dec 14 09:48:59.158: INFO: (2) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.316367ms)
    Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 19.461849ms)
    Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 19.590128ms)
    Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 19.556165ms)
    Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 19.530408ms)
    Dec 14 09:48:59.160: INFO: (2) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 19.571304ms)
    Dec 14 09:48:59.162: INFO: (2) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.145204ms)
    Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.60979ms)
    Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.816808ms)
    Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.667102ms)
    Dec 14 09:48:59.177: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.625401ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.435411ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.621305ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.499564ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.526222ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.560932ms)
    Dec 14 09:48:59.179: INFO: (3) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.502107ms)
    Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.126714ms)
    Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.132575ms)
    Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.208453ms)
    Dec 14 09:48:59.183: INFO: (3) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.252682ms)
    Dec 14 09:48:59.188: INFO: (3) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.785202ms)
    Dec 14 09:48:59.188: INFO: (3) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.835273ms)
    Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.509788ms)
    Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 13.729017ms)
    Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.737528ms)
    Dec 14 09:48:59.202: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.592817ms)
    Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.007481ms)
    Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.989468ms)
    Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.037053ms)
    Dec 14 09:48:59.205: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.97992ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 19.894904ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 19.902937ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.004405ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 19.916132ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 20.065996ms)
    Dec 14 09:48:59.208: INFO: (4) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.001203ms)
    Dec 14 09:48:59.209: INFO: (4) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 21.066801ms)
    Dec 14 09:48:59.214: INFO: (4) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.581635ms)
    Dec 14 09:48:59.227: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.222277ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.692753ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.749958ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.85623ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.737567ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 13.725267ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 13.815019ms)
    Dec 14 09:48:59.228: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.872735ms)
    Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.444067ms)
    Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.69198ms)
    Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.550206ms)
    Dec 14 09:48:59.231: INFO: (5) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 17.609373ms)
    Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 21.888262ms)
    Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.932168ms)
    Dec 14 09:48:59.236: INFO: (5) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 22.085278ms)
    Dec 14 09:48:59.244: INFO: (5) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 30.419026ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.453059ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.38955ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.364669ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.284227ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.31392ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 16.38873ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.877419ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 16.911536ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.872904ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.990826ms)
    Dec 14 09:48:59.261: INFO: (6) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.038665ms)
    Dec 14 09:48:59.265: INFO: (6) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.76186ms)
    Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.443401ms)
    Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.4812ms)
    Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.524816ms)
    Dec 14 09:48:59.270: INFO: (6) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.42781ms)
    Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.289669ms)
    Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 16.236906ms)
    Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 16.323126ms)
    Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.308786ms)
    Dec 14 09:48:59.287: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.324496ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.442471ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.574383ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 17.601925ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 17.678204ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.597279ms)
    Dec 14 09:48:59.288: INFO: (7) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 17.618567ms)
    Dec 14 09:48:59.292: INFO: (7) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.539028ms)
    Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.622532ms)
    Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.677739ms)
    Dec 14 09:48:59.296: INFO: (7) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.623452ms)
    Dec 14 09:48:59.300: INFO: (7) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 29.942164ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.61653ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.686233ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.664168ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.745367ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.851448ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.717913ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.655962ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.797693ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.728812ms)
    Dec 14 09:48:59.314: INFO: (8) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.714312ms)
    Dec 14 09:48:59.318: INFO: (8) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.364314ms)
    Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.674875ms)
    Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 21.704104ms)
    Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.878447ms)
    Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.695348ms)
    Dec 14 09:48:59.322: INFO: (8) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.781515ms)
    Dec 14 09:48:59.335: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 12.832913ms)
    Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.363723ms)
    Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.379292ms)
    Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.391866ms)
    Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.428006ms)
    Dec 14 09:48:59.336: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.551725ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.678444ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 17.781045ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 17.712747ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.854854ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.71607ms)
    Dec 14 09:48:59.340: INFO: (9) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 17.672515ms)
    Dec 14 09:48:59.345: INFO: (9) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.569313ms)
    Dec 14 09:48:59.345: INFO: (9) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.516552ms)
    Dec 14 09:48:59.354: INFO: (9) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 31.189344ms)
    Dec 14 09:48:59.354: INFO: (9) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 31.203127ms)
    Dec 14 09:48:59.368: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.673792ms)
    Dec 14 09:48:59.368: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.84655ms)
    Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.716195ms)
    Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.733268ms)
    Dec 14 09:48:59.369: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.715515ms)
    Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 16.759706ms)
    Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.904927ms)
    Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 16.844894ms)
    Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.811848ms)
    Dec 14 09:48:59.371: INFO: (10) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.97131ms)
    Dec 14 09:48:59.375: INFO: (10) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 20.953435ms)
    Dec 14 09:48:59.375: INFO: (10) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.075512ms)
    Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 25.67905ms)
    Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 25.813936ms)
    Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.820882ms)
    Dec 14 09:48:59.380: INFO: (10) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.834376ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.891015ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.864492ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.884974ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.940313ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 13.929333ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 13.928864ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.012699ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.88853ms)
    Dec 14 09:48:59.394: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.01494ms)
    Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 17.329701ms)
    Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.41455ms)
    Dec 14 09:48:59.397: INFO: (11) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.266446ms)
    Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.689805ms)
    Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 21.63042ms)
    Dec 14 09:48:59.402: INFO: (11) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.680871ms)
    Dec 14 09:48:59.410: INFO: (11) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 30.457414ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.651159ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.660731ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.79314ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.714662ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.629087ms)
    Dec 14 09:48:59.424: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 13.80774ms)
    Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.318759ms)
    Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 17.354615ms)
    Dec 14 09:48:59.428: INFO: (12) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.58263ms)
    Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 21.618657ms)
    Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.672564ms)
    Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 21.738689ms)
    Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 21.638642ms)
    Dec 14 09:48:59.432: INFO: (12) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.683213ms)
    Dec 14 09:48:59.437: INFO: (12) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 26.468654ms)
    Dec 14 09:48:59.437: INFO: (12) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 26.51388ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.785051ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.917411ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 14.995516ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.943657ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 14.901825ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 14.870297ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.844346ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.801889ms)
    Dec 14 09:48:59.452: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 14.824312ms)
    Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 18.340036ms)
    Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 18.475892ms)
    Dec 14 09:48:59.455: INFO: (13) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 18.452932ms)
    Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 22.752789ms)
    Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 22.66415ms)
    Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 22.68408ms)
    Dec 14 09:48:59.460: INFO: (13) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.736047ms)
    Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.456852ms)
    Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.36167ms)
    Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.37093ms)
    Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.565418ms)
    Dec 14 09:48:59.473: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.470316ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.323902ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 17.197303ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.284379ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 17.183351ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.175811ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 17.170685ms)
    Dec 14 09:48:59.477: INFO: (14) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.256864ms)
    Dec 14 09:48:59.481: INFO: (14) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.303807ms)
    Dec 14 09:48:59.481: INFO: (14) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 21.387169ms)
    Dec 14 09:48:59.486: INFO: (14) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 25.776918ms)
    Dec 14 09:48:59.486: INFO: (14) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 25.726233ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.959174ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 15.010582ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 15.112026ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.975205ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 15.0514ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 15.095683ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 15.174044ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 15.087038ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 15.030405ms)
    Dec 14 09:48:59.501: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 15.07749ms)
    Dec 14 09:48:59.503: INFO: (15) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 17.500931ms)
    Dec 14 09:48:59.504: INFO: (15) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 18.24251ms)
    Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.850534ms)
    Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.850159ms)
    Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 23.041809ms)
    Dec 14 09:48:59.509: INFO: (15) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 22.814349ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.546794ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.538103ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.568001ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.646755ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 13.783635ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 14.239459ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.141309ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 14.21821ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 14.184676ms)
    Dec 14 09:48:59.523: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 14.176129ms)
    Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 16.83892ms)
    Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.925493ms)
    Dec 14 09:48:59.526: INFO: (16) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 17.03686ms)
    Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 21.000816ms)
    Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 20.912902ms)
    Dec 14 09:48:59.530: INFO: (16) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.928553ms)
    Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.671087ms)
    Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 14.663036ms)
    Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 14.645862ms)
    Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 14.691735ms)
    Dec 14 09:48:59.545: INFO: (17) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 14.657283ms)
    Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 16.059635ms)
    Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 15.995808ms)
    Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 16.135835ms)
    Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 16.16432ms)
    Dec 14 09:48:59.546: INFO: (17) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 16.056005ms)
    Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 20.467496ms)
    Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 20.599783ms)
    Dec 14 09:48:59.551: INFO: (17) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 20.572944ms)
    Dec 14 09:48:59.555: INFO: (17) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 25.01623ms)
    Dec 14 09:48:59.555: INFO: (17) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 24.992681ms)
    Dec 14 09:48:59.559: INFO: (17) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 29.114601ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.003944ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.137673ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 13.008936ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 13.024704ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 13.009059ms)
    Dec 14 09:48:59.573: INFO: (18) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 13.038423ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 13.216745ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 13.006551ms)
    Dec 14 09:48:59.572: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 12.989546ms)
    Dec 14 09:48:59.573: INFO: (18) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 13.032108ms)
    Dec 14 09:48:59.577: INFO: (18) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 17.563777ms)
    Dec 14 09:48:59.577: INFO: (18) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 17.511282ms)
    Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 21.937675ms)
    Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 21.953237ms)
    Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 22.00146ms)
    Dec 14 09:48:59.581: INFO: (18) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 22.021743ms)
    Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:443/proxy/tlsrewritem... (200; 19.251854ms)
    Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 19.24874ms)
    Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">test<... (200; 19.263592ms)
    Dec 14 09:48:59.601: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:160/proxy/: foo (200; 19.335297ms)
    Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:462/proxy/: tls qux (200; 23.642862ms)
    Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/https:proxy-service-cfwl6-kqlsx:460/proxy/: tls baz (200; 23.677637ms)
    Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:1080/proxy/rewriteme">... (200; 23.763926ms)
    Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 23.691074ms)
    Dec 14 09:48:59.605: INFO: (19) /api/v1/namespaces/proxy-9461/pods/http:proxy-service-cfwl6-kqlsx:162/proxy/: bar (200; 23.693681ms)
    Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname2/proxy/: tls qux (200; 28.079716ms)
    Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/: <a href="/api/v1/namespaces/proxy-9461/pods/proxy-service-cfwl6-kqlsx/proxy/rewriteme">test</a> (200; 28.254748ms)
    Dec 14 09:48:59.610: INFO: (19) /api/v1/namespaces/proxy-9461/services/https:proxy-service-cfwl6:tlsportname1/proxy/: tls baz (200; 28.117408ms)
    Dec 14 09:48:59.614: INFO: (19) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname1/proxy/: foo (200; 32.230969ms)
    Dec 14 09:48:59.614: INFO: (19) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname1/proxy/: foo (200; 32.304573ms)
    Dec 14 09:48:59.618: INFO: (19) /api/v1/namespaces/proxy-9461/services/http:proxy-service-cfwl6:portname2/proxy/: bar (200; 36.593452ms)
    Dec 14 09:48:59.618: INFO: (19) /api/v1/namespaces/proxy-9461/services/proxy-service-cfwl6:portname2/proxy/: bar (200; 36.580769ms)
    STEP: deleting ReplicationController proxy-service-cfwl6 in namespace proxy-9461, will wait for the garbage collector to delete the pods 12/14/22 09:48:59.618
    Dec 14 09:48:59.684: INFO: Deleting ReplicationController proxy-service-cfwl6 took: 7.91358ms
    Dec 14 09:48:59.785: INFO: Terminating ReplicationController proxy-service-cfwl6 pods took: 101.051701ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 09:49:02.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9461" for this suite. 12/14/22 09:49:02.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:02.207
Dec 14 09:49:02.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:49:02.208
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:02.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:02.24
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 12/14/22 09:49:02.252
Dec 14 09:49:02.266: INFO: Waiting up to 5m0s for pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227" in namespace "var-expansion-5711" to be "Succeeded or Failed"
Dec 14 09:49:02.272: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Pending", Reason="", readiness=false. Elapsed: 6.360835ms
Dec 14 09:49:04.281: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015090457s
Dec 14 09:49:06.280: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014222038s
STEP: Saw pod success 12/14/22 09:49:06.28
Dec 14 09:49:06.280: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227" satisfied condition "Succeeded or Failed"
Dec 14 09:49:06.287: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:49:06.304
Dec 14 09:49:06.315: INFO: Waiting for pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 to disappear
Dec 14 09:49:06.322: INFO: Pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:49:06.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5711" for this suite. 12/14/22 09:49:06.334
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":248,"skipped":4552,"failed":0}
------------------------------
• [4.135 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:02.207
    Dec 14 09:49:02.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:49:02.208
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:02.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:02.24
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 12/14/22 09:49:02.252
    Dec 14 09:49:02.266: INFO: Waiting up to 5m0s for pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227" in namespace "var-expansion-5711" to be "Succeeded or Failed"
    Dec 14 09:49:02.272: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Pending", Reason="", readiness=false. Elapsed: 6.360835ms
    Dec 14 09:49:04.281: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015090457s
    Dec 14 09:49:06.280: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014222038s
    STEP: Saw pod success 12/14/22 09:49:06.28
    Dec 14 09:49:06.280: INFO: Pod "var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227" satisfied condition "Succeeded or Failed"
    Dec 14 09:49:06.287: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:49:06.304
    Dec 14 09:49:06.315: INFO: Waiting for pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 to disappear
    Dec 14 09:49:06.322: INFO: Pod var-expansion-b84745f6-fe72-412f-ac91-d760c1d6a227 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:49:06.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5711" for this suite. 12/14/22 09:49:06.334
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:06.344
Dec 14 09:49:06.344: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 09:49:06.345
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:06.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:06.379
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-2625 12/14/22 09:49:06.391
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[] 12/14/22 09:49:06.403
Dec 14 09:49:06.422: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2625 12/14/22 09:49:06.422
Dec 14 09:49:06.435: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2625" to be "running and ready"
Dec 14 09:49:06.442: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.617318ms
Dec 14 09:49:06.442: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:49:08.451: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01593335s
Dec 14 09:49:08.451: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 09:49:08.451: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod1:[80]] 12/14/22 09:49:08.458
Dec 14 09:49:08.485: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 12/14/22 09:49:08.485
Dec 14 09:49:08.486: INFO: Creating new exec pod
Dec 14 09:49:08.496: INFO: Waiting up to 5m0s for pod "execpodmqm4h" in namespace "services-2625" to be "running"
Dec 14 09:49:08.503: INFO: Pod "execpodmqm4h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.71903ms
Dec 14 09:49:10.510: INFO: Pod "execpodmqm4h": Phase="Running", Reason="", readiness=true. Elapsed: 2.013769549s
Dec 14 09:49:10.510: INFO: Pod "execpodmqm4h" satisfied condition "running"
Dec 14 09:49:11.511: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:49:12.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:49:12.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:49:12.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
Dec 14 09:49:12.597: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n"
Dec 14 09:49:12.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2625 12/14/22 09:49:12.597
Dec 14 09:49:12.609: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2625" to be "running and ready"
Dec 14 09:49:12.616: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.517147ms
Dec 14 09:49:12.616: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:49:14.623: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013888492s
Dec 14 09:49:14.623: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 09:49:14.623: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod1:[80] pod2:[80]] 12/14/22 09:49:14.633
Dec 14 09:49:14.668: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 12/14/22 09:49:14.668
Dec 14 09:49:15.668: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:49:16.125: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:49:16.125: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:49:16.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
Dec 14 09:49:16.677: INFO: stderr: "+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Dec 14 09:49:16.677: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2625 12/14/22 09:49:16.677
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod2:[80]] 12/14/22 09:49:16.688
Dec 14 09:49:16.718: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 12/14/22 09:49:16.718
Dec 14 09:49:17.718: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Dec 14 09:49:18.243: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Dec 14 09:49:18.243: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 09:49:18.243: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
Dec 14 09:49:18.732: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n"
Dec 14 09:49:18.732: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2625 12/14/22 09:49:18.732
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[] 12/14/22 09:49:18.743
Dec 14 09:49:18.761: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 09:49:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2625" for this suite. 12/14/22 09:49:18.785
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":249,"skipped":4572,"failed":0}
------------------------------
• [12.449 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:06.344
    Dec 14 09:49:06.344: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 09:49:06.345
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:06.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:06.379
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-2625 12/14/22 09:49:06.391
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[] 12/14/22 09:49:06.403
    Dec 14 09:49:06.422: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2625 12/14/22 09:49:06.422
    Dec 14 09:49:06.435: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2625" to be "running and ready"
    Dec 14 09:49:06.442: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.617318ms
    Dec 14 09:49:06.442: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:49:08.451: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.01593335s
    Dec 14 09:49:08.451: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 09:49:08.451: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod1:[80]] 12/14/22 09:49:08.458
    Dec 14 09:49:08.485: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 12/14/22 09:49:08.485
    Dec 14 09:49:08.486: INFO: Creating new exec pod
    Dec 14 09:49:08.496: INFO: Waiting up to 5m0s for pod "execpodmqm4h" in namespace "services-2625" to be "running"
    Dec 14 09:49:08.503: INFO: Pod "execpodmqm4h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.71903ms
    Dec 14 09:49:10.510: INFO: Pod "execpodmqm4h": Phase="Running", Reason="", readiness=true. Elapsed: 2.013769549s
    Dec 14 09:49:10.510: INFO: Pod "execpodmqm4h" satisfied condition "running"
    Dec 14 09:49:11.511: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:49:12.004: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:49:12.004: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:49:12.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
    Dec 14 09:49:12.597: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n"
    Dec 14 09:49:12.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-2625 12/14/22 09:49:12.597
    Dec 14 09:49:12.609: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2625" to be "running and ready"
    Dec 14 09:49:12.616: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.517147ms
    Dec 14 09:49:12.616: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:49:14.623: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013888492s
    Dec 14 09:49:14.623: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 09:49:14.623: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod1:[80] pod2:[80]] 12/14/22 09:49:14.633
    Dec 14 09:49:14.668: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 12/14/22 09:49:14.668
    Dec 14 09:49:15.668: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:49:16.125: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:49:16.125: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:49:16.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
    Dec 14 09:49:16.677: INFO: stderr: "+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Dec 14 09:49:16.677: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2625 12/14/22 09:49:16.677
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[pod2:[80]] 12/14/22 09:49:16.688
    Dec 14 09:49:16.718: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 12/14/22 09:49:16.718
    Dec 14 09:49:17.718: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Dec 14 09:49:18.243: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Dec 14 09:49:18.243: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 09:49:18.243: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-2625 exec execpodmqm4h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.29.244.197 80'
    Dec 14 09:49:18.732: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.29.244.197 80\nConnection to 172.29.244.197 80 port [tcp/http] succeeded!\n"
    Dec 14 09:49:18.732: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-2625 12/14/22 09:49:18.732
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2625 to expose endpoints map[] 12/14/22 09:49:18.743
    Dec 14 09:49:18.761: INFO: successfully validated that service endpoint-test2 in namespace services-2625 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 09:49:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2625" for this suite. 12/14/22 09:49:18.785
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:18.793
Dec 14 09:49:18.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:49:18.794
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:18.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:18.825
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:49:18.836
Dec 14 09:49:18.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91" in namespace "projected-617" to be "Succeeded or Failed"
Dec 14 09:49:18.855: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Pending", Reason="", readiness=false. Elapsed: 6.405427ms
Dec 14 09:49:20.863: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013731903s
Dec 14 09:49:22.863: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014605238s
STEP: Saw pod success 12/14/22 09:49:22.863
Dec 14 09:49:22.864: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91" satisfied condition "Succeeded or Failed"
Dec 14 09:49:22.870: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 container client-container: <nil>
STEP: delete the pod 12/14/22 09:49:22.931
Dec 14 09:49:22.941: INFO: Waiting for pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 to disappear
Dec 14 09:49:22.948: INFO: Pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:49:22.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-617" for this suite. 12/14/22 09:49:22.96
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":250,"skipped":4578,"failed":0}
------------------------------
• [4.174 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:18.793
    Dec 14 09:49:18.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:49:18.794
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:18.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:18.825
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:49:18.836
    Dec 14 09:49:18.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91" in namespace "projected-617" to be "Succeeded or Failed"
    Dec 14 09:49:18.855: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Pending", Reason="", readiness=false. Elapsed: 6.405427ms
    Dec 14 09:49:20.863: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013731903s
    Dec 14 09:49:22.863: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014605238s
    STEP: Saw pod success 12/14/22 09:49:22.863
    Dec 14 09:49:22.864: INFO: Pod "downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91" satisfied condition "Succeeded or Failed"
    Dec 14 09:49:22.870: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:49:22.931
    Dec 14 09:49:22.941: INFO: Waiting for pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 to disappear
    Dec 14 09:49:22.948: INFO: Pod downwardapi-volume-4219cfb1-8f22-490c-9db9-1c691ee08b91 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:49:22.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-617" for this suite. 12/14/22 09:49:22.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:22.969
Dec 14 09:49:22.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:49:22.97
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:22.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:23.002
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 12/14/22 09:49:23.014
Dec 14 09:49:23.014: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 14 09:49:23.107: INFO: stderr: ""
Dec 14 09:49:23.107: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 12/14/22 09:49:23.107
Dec 14 09:49:23.107: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 14 09:49:23.107: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-993" to be "running and ready, or succeeded"
Dec 14 09:49:23.114: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.179596ms
Dec 14 09:49:23.114: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'izgw8jfcr55yi09nr0a5xaz' to be 'Running' but was 'Pending'
Dec 14 09:49:25.122: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01506175s
Dec 14 09:49:25.122: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 14 09:49:25.122: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 12/14/22 09:49:25.122
Dec 14 09:49:25.122: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator'
Dec 14 09:49:25.257: INFO: stderr: ""
Dec 14 09:49:25.257: INFO: stdout: "I1214 09:49:23.724707       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/ggs 567\nI1214 09:49:23.925077       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/6z45 504\nI1214 09:49:24.125470       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/bh5 532\nI1214 09:49:24.324763       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/w6vk 541\nI1214 09:49:24.525185       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/qnqd 529\nI1214 09:49:24.725504       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/frb 419\nI1214 09:49:24.925664       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tjw7 580\nI1214 09:49:25.124972       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/l5rz 313\n"
STEP: limiting log lines 12/14/22 09:49:25.258
Dec 14 09:49:25.258: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --tail=1'
Dec 14 09:49:25.394: INFO: stderr: ""
Dec 14 09:49:25.394: INFO: stdout: "I1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\n"
Dec 14 09:49:25.394: INFO: got output "I1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\n"
STEP: limiting log bytes 12/14/22 09:49:25.394
Dec 14 09:49:25.394: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --limit-bytes=1'
Dec 14 09:49:25.497: INFO: stderr: ""
Dec 14 09:49:25.497: INFO: stdout: "I"
Dec 14 09:49:25.497: INFO: got output "I"
STEP: exposing timestamps 12/14/22 09:49:25.497
Dec 14 09:49:25.497: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --tail=1 --timestamps'
Dec 14 09:49:25.632: INFO: stderr: ""
Dec 14 09:49:25.632: INFO: stdout: "2022-12-14T09:49:25.525763550Z I1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\n"
Dec 14 09:49:25.632: INFO: got output "2022-12-14T09:49:25.525763550Z I1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\n"
STEP: restricting to a time range 12/14/22 09:49:25.632
Dec 14 09:49:28.133: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --since=1s'
Dec 14 09:49:28.251: INFO: stderr: ""
Dec 14 09:49:28.251: INFO: stdout: "I1214 09:49:27.325255       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zqll 588\nI1214 09:49:27.525643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/prp 442\nI1214 09:49:27.724914       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/4cj 261\nI1214 09:49:27.925303       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/njz 432\nI1214 09:49:28.125598       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/78z7 588\n"
Dec 14 09:49:28.251: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --since=24h'
Dec 14 09:49:28.394: INFO: stderr: ""
Dec 14 09:49:28.394: INFO: stdout: "I1214 09:49:23.724707       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/ggs 567\nI1214 09:49:23.925077       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/6z45 504\nI1214 09:49:24.125470       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/bh5 532\nI1214 09:49:24.324763       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/w6vk 541\nI1214 09:49:24.525185       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/qnqd 529\nI1214 09:49:24.725504       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/frb 419\nI1214 09:49:24.925664       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tjw7 580\nI1214 09:49:25.124972       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/l5rz 313\nI1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\nI1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\nI1214 09:49:25.724830       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/shxt 262\nI1214 09:49:25.925135       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lwfb 472\nI1214 09:49:26.125433       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/g45d 355\nI1214 09:49:26.325799       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/hbv 330\nI1214 09:49:26.525021       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/lwd 230\nI1214 09:49:26.725368       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/6bl 514\nI1214 09:49:26.925654       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/f6px 223\nI1214 09:49:27.124939       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/mzss 566\nI1214 09:49:27.325255       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zqll 588\nI1214 09:49:27.525643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/prp 442\nI1214 09:49:27.724914       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/4cj 261\nI1214 09:49:27.925303       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/njz 432\nI1214 09:49:28.125598       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/78z7 588\nI1214 09:49:28.324792       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/qtmm 431\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Dec 14 09:49:28.394: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 delete pod logs-generator'
Dec 14 09:49:29.287: INFO: stderr: ""
Dec 14 09:49:29.287: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:49:29.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-993" for this suite. 12/14/22 09:49:29.298
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":251,"skipped":4633,"failed":0}
------------------------------
• [6.337 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:22.969
    Dec 14 09:49:22.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:49:22.97
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:22.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:23.002
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 12/14/22 09:49:23.014
    Dec 14 09:49:23.014: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Dec 14 09:49:23.107: INFO: stderr: ""
    Dec 14 09:49:23.107: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 12/14/22 09:49:23.107
    Dec 14 09:49:23.107: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Dec 14 09:49:23.107: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-993" to be "running and ready, or succeeded"
    Dec 14 09:49:23.114: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.179596ms
    Dec 14 09:49:23.114: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'izgw8jfcr55yi09nr0a5xaz' to be 'Running' but was 'Pending'
    Dec 14 09:49:25.122: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.01506175s
    Dec 14 09:49:25.122: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Dec 14 09:49:25.122: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 12/14/22 09:49:25.122
    Dec 14 09:49:25.122: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator'
    Dec 14 09:49:25.257: INFO: stderr: ""
    Dec 14 09:49:25.257: INFO: stdout: "I1214 09:49:23.724707       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/ggs 567\nI1214 09:49:23.925077       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/6z45 504\nI1214 09:49:24.125470       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/bh5 532\nI1214 09:49:24.324763       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/w6vk 541\nI1214 09:49:24.525185       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/qnqd 529\nI1214 09:49:24.725504       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/frb 419\nI1214 09:49:24.925664       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tjw7 580\nI1214 09:49:25.124972       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/l5rz 313\n"
    STEP: limiting log lines 12/14/22 09:49:25.258
    Dec 14 09:49:25.258: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --tail=1'
    Dec 14 09:49:25.394: INFO: stderr: ""
    Dec 14 09:49:25.394: INFO: stdout: "I1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\n"
    Dec 14 09:49:25.394: INFO: got output "I1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\n"
    STEP: limiting log bytes 12/14/22 09:49:25.394
    Dec 14 09:49:25.394: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --limit-bytes=1'
    Dec 14 09:49:25.497: INFO: stderr: ""
    Dec 14 09:49:25.497: INFO: stdout: "I"
    Dec 14 09:49:25.497: INFO: got output "I"
    STEP: exposing timestamps 12/14/22 09:49:25.497
    Dec 14 09:49:25.497: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --tail=1 --timestamps'
    Dec 14 09:49:25.632: INFO: stderr: ""
    Dec 14 09:49:25.632: INFO: stdout: "2022-12-14T09:49:25.525763550Z I1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\n"
    Dec 14 09:49:25.632: INFO: got output "2022-12-14T09:49:25.525763550Z I1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\n"
    STEP: restricting to a time range 12/14/22 09:49:25.632
    Dec 14 09:49:28.133: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --since=1s'
    Dec 14 09:49:28.251: INFO: stderr: ""
    Dec 14 09:49:28.251: INFO: stdout: "I1214 09:49:27.325255       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zqll 588\nI1214 09:49:27.525643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/prp 442\nI1214 09:49:27.724914       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/4cj 261\nI1214 09:49:27.925303       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/njz 432\nI1214 09:49:28.125598       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/78z7 588\n"
    Dec 14 09:49:28.251: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 logs logs-generator logs-generator --since=24h'
    Dec 14 09:49:28.394: INFO: stderr: ""
    Dec 14 09:49:28.394: INFO: stdout: "I1214 09:49:23.724707       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/ggs 567\nI1214 09:49:23.925077       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/6z45 504\nI1214 09:49:24.125470       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/bh5 532\nI1214 09:49:24.324763       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/w6vk 541\nI1214 09:49:24.525185       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/qnqd 529\nI1214 09:49:24.725504       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/frb 419\nI1214 09:49:24.925664       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tjw7 580\nI1214 09:49:25.124972       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/l5rz 313\nI1214 09:49:25.325326       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/hpx 332\nI1214 09:49:25.525608       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/ghs 280\nI1214 09:49:25.724830       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/shxt 262\nI1214 09:49:25.925135       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lwfb 472\nI1214 09:49:26.125433       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/g45d 355\nI1214 09:49:26.325799       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/hbv 330\nI1214 09:49:26.525021       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/lwd 230\nI1214 09:49:26.725368       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/6bl 514\nI1214 09:49:26.925654       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/f6px 223\nI1214 09:49:27.124939       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/mzss 566\nI1214 09:49:27.325255       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/zqll 588\nI1214 09:49:27.525643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/prp 442\nI1214 09:49:27.724914       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/4cj 261\nI1214 09:49:27.925303       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/njz 432\nI1214 09:49:28.125598       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/78z7 588\nI1214 09:49:28.324792       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/qtmm 431\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Dec 14 09:49:28.394: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-993 delete pod logs-generator'
    Dec 14 09:49:29.287: INFO: stderr: ""
    Dec 14 09:49:29.287: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:49:29.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-993" for this suite. 12/14/22 09:49:29.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:29.307
Dec 14 09:49:29.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:49:29.308
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:29.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:29.34
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Dec 14 09:49:29.352: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod 12/14/22 09:49:29.352
STEP: submitting the pod to kubernetes 12/14/22 09:49:29.352
Dec 14 09:49:29.367: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c" in namespace "pods-5969" to be "running and ready"
Dec 14 09:49:29.373: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.729166ms
Dec 14 09:49:29.373: INFO: The phase of Pod pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:49:31.382: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014927626s
Dec 14 09:49:31.382: INFO: The phase of Pod pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c is Running (Ready = true)
Dec 14 09:49:31.382: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:49:31.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5969" for this suite. 12/14/22 09:49:31.473
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":252,"skipped":4644,"failed":0}
------------------------------
• [2.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:29.307
    Dec 14 09:49:29.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:49:29.308
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:29.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:29.34
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Dec 14 09:49:29.352: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating the pod 12/14/22 09:49:29.352
    STEP: submitting the pod to kubernetes 12/14/22 09:49:29.352
    Dec 14 09:49:29.367: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c" in namespace "pods-5969" to be "running and ready"
    Dec 14 09:49:29.373: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.729166ms
    Dec 14 09:49:29.373: INFO: The phase of Pod pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:49:31.382: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014927626s
    Dec 14 09:49:31.382: INFO: The phase of Pod pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c is Running (Ready = true)
    Dec 14 09:49:31.382: INFO: Pod "pod-logs-websocket-a4b283b0-1d98-400b-9b69-5006d639120c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:49:31.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5969" for this suite. 12/14/22 09:49:31.473
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:31.481
Dec 14 09:49:31.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/14/22 09:49:31.482
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:31.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:31.515
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 12/14/22 09:49:31.527
STEP: Creating hostNetwork=false pod 12/14/22 09:49:31.527
Dec 14 09:49:31.542: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-7610" to be "running and ready"
Dec 14 09:49:31.549: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.153315ms
Dec 14 09:49:31.552: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:49:33.560: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018133398s
Dec 14 09:49:33.560: INFO: The phase of Pod test-pod is Running (Ready = true)
Dec 14 09:49:33.560: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 12/14/22 09:49:33.567
Dec 14 09:49:33.578: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-7610" to be "running and ready"
Dec 14 09:49:33.585: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522552ms
Dec 14 09:49:33.585: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:49:35.592: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013966045s
Dec 14 09:49:35.592: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Dec 14 09:49:35.592: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 12/14/22 09:49:35.599
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/14/22 09:49:35.599
Dec 14 09:49:35.599: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:35.599: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:35.600: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:35.600: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 09:49:36.049: INFO: Exec stderr: ""
Dec 14 09:49:36.049: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:36.049: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:36.050: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:36.050: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 09:49:36.555: INFO: Exec stderr: ""
Dec 14 09:49:36.555: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:36.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:36.556: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:36.556: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 09:49:36.988: INFO: Exec stderr: ""
Dec 14 09:49:36.988: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:36.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:36.988: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:36.988: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 09:49:37.452: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/14/22 09:49:37.452
Dec 14 09:49:37.452: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:37.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:37.453: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:37.453: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec 14 09:49:37.856: INFO: Exec stderr: ""
Dec 14 09:49:37.856: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:37.856: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:37.857: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:37.857: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Dec 14 09:49:38.417: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/14/22 09:49:38.417
Dec 14 09:49:38.417: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:38.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:38.418: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:38.418: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 09:49:38.880: INFO: Exec stderr: ""
Dec 14 09:49:38.880: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:38.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:38.880: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:38.881: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Dec 14 09:49:39.325: INFO: Exec stderr: ""
Dec 14 09:49:39.325: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:39.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:39.325: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:39.326: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 09:49:39.825: INFO: Exec stderr: ""
Dec 14 09:49:39.825: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:49:39.825: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:49:39.825: INFO: ExecWithOptions: Clientset creation
Dec 14 09:49:39.825: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Dec 14 09:49:40.221: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Dec 14 09:49:40.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7610" for this suite. 12/14/22 09:49:40.233
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":253,"skipped":4650,"failed":0}
------------------------------
• [8.760 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:31.481
    Dec 14 09:49:31.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 12/14/22 09:49:31.482
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:31.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:31.515
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 12/14/22 09:49:31.527
    STEP: Creating hostNetwork=false pod 12/14/22 09:49:31.527
    Dec 14 09:49:31.542: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-7610" to be "running and ready"
    Dec 14 09:49:31.549: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.153315ms
    Dec 14 09:49:31.552: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:49:33.560: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018133398s
    Dec 14 09:49:33.560: INFO: The phase of Pod test-pod is Running (Ready = true)
    Dec 14 09:49:33.560: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 12/14/22 09:49:33.567
    Dec 14 09:49:33.578: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-7610" to be "running and ready"
    Dec 14 09:49:33.585: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.522552ms
    Dec 14 09:49:33.585: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:49:35.592: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013966045s
    Dec 14 09:49:35.592: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Dec 14 09:49:35.592: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 12/14/22 09:49:35.599
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 12/14/22 09:49:35.599
    Dec 14 09:49:35.599: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:35.599: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:35.600: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:35.600: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 09:49:36.049: INFO: Exec stderr: ""
    Dec 14 09:49:36.049: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:36.049: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:36.050: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:36.050: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 09:49:36.555: INFO: Exec stderr: ""
    Dec 14 09:49:36.555: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:36.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:36.556: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:36.556: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 09:49:36.988: INFO: Exec stderr: ""
    Dec 14 09:49:36.988: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:36.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:36.988: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:36.988: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 09:49:37.452: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 12/14/22 09:49:37.452
    Dec 14 09:49:37.452: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:37.452: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:37.453: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:37.453: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec 14 09:49:37.856: INFO: Exec stderr: ""
    Dec 14 09:49:37.856: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:37.856: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:37.857: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:37.857: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Dec 14 09:49:38.417: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 12/14/22 09:49:38.417
    Dec 14 09:49:38.417: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:38.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:38.418: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:38.418: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 09:49:38.880: INFO: Exec stderr: ""
    Dec 14 09:49:38.880: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:38.880: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:38.880: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:38.881: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Dec 14 09:49:39.325: INFO: Exec stderr: ""
    Dec 14 09:49:39.325: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:39.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:39.325: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:39.326: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 09:49:39.825: INFO: Exec stderr: ""
    Dec 14 09:49:39.825: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7610 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:49:39.825: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:49:39.825: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:49:39.825: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/e2e-kubelet-etc-hosts-7610/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Dec 14 09:49:40.221: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Dec 14 09:49:40.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-7610" for this suite. 12/14/22 09:49:40.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:40.242
Dec 14 09:49:40.242: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:49:40.243
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:40.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:40.276
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Dec 14 09:49:40.317: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:49:40.325
Dec 14 09:49:40.340: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:49:40.340: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:49:41.360: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:49:41.360: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image. 12/14/22 09:49:41.389
STEP: Check that daemon pods images are updated. 12/14/22 09:49:41.407
Dec 14 09:49:41.414: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 09:49:42.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 09:49:43.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 09:49:44.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Dec 14 09:49:44.430: INFO: Pod daemon-set-sfsm7 is not available
Dec 14 09:49:46.430: INFO: Pod daemon-set-csr9r is not available
STEP: Check that daemon pods are still running on every node of the cluster. 12/14/22 09:49:46.441
Dec 14 09:49:46.456: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 09:49:46.456: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:49:47.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:49:47.476: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:49:47.509
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4274, will wait for the garbage collector to delete the pods 12/14/22 09:49:47.51
Dec 14 09:49:47.576: INFO: Deleting DaemonSet.extensions daemon-set took: 8.883805ms
Dec 14 09:49:47.677: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.429511ms
Dec 14 09:49:50.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:49:50.284: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:49:50.291: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47235"},"items":null}

Dec 14 09:49:50.297: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47235"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:49:50.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4274" for this suite. 12/14/22 09:49:50.33
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":254,"skipped":4672,"failed":0}
------------------------------
• [10.095 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:40.242
    Dec 14 09:49:40.242: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:49:40.243
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:40.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:40.276
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Dec 14 09:49:40.317: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:49:40.325
    Dec 14 09:49:40.340: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:49:40.340: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:49:41.360: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:49:41.360: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Update daemon pods image. 12/14/22 09:49:41.389
    STEP: Check that daemon pods images are updated. 12/14/22 09:49:41.407
    Dec 14 09:49:41.414: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 09:49:42.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 09:49:43.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 09:49:44.430: INFO: Wrong image for pod: daemon-set-mr5zz. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Dec 14 09:49:44.430: INFO: Pod daemon-set-sfsm7 is not available
    Dec 14 09:49:46.430: INFO: Pod daemon-set-csr9r is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 12/14/22 09:49:46.441
    Dec 14 09:49:46.456: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 09:49:46.456: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:49:47.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:49:47.476: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:49:47.509
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4274, will wait for the garbage collector to delete the pods 12/14/22 09:49:47.51
    Dec 14 09:49:47.576: INFO: Deleting DaemonSet.extensions daemon-set took: 8.883805ms
    Dec 14 09:49:47.677: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.429511ms
    Dec 14 09:49:50.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:49:50.284: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:49:50.291: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"47235"},"items":null}

    Dec 14 09:49:50.297: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"47235"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:49:50.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4274" for this suite. 12/14/22 09:49:50.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:50.339
Dec 14 09:49:50.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:49:50.34
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:50.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:50.372
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:49:50.383
Dec 14 09:49:50.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Dec 14 09:49:50.490: INFO: stderr: ""
Dec 14 09:49:50.490: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 12/14/22 09:49:50.49
STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:49:55.541
Dec 14 09:49:55.542: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 get pod e2e-test-httpd-pod -o json'
Dec 14 09:49:55.667: INFO: stderr: ""
Dec 14 09:49:55.667: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"3d190b70c6ab8d35d818692bab0806cd2a5448cdc835ad095608f3fa6b042fc3\",\n            \"cni.projectcalico.org/podIP\": \"172.16.0.138/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.16.0.138/32\"\n        },\n        \"creationTimestamp\": \"2022-12-14T09:49:50Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8977\",\n        \"resourceVersion\": \"47252\",\n        \"uid\": \"6029d09f-6b02-4803-a516-7235e15fa95f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zkq55\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"izgw8jfcr55yi09nr0a5xaz\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zkq55\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://be468c938b2ce742fe00eae7e13414dbe36a4f789ecdb92a1b2bba57e5488378\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-14T09:49:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.18.72\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.0.138\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.0.138\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-14T09:49:50Z\"\n    }\n}\n"
STEP: replace the image in the pod 12/14/22 09:49:55.667
Dec 14 09:49:55.667: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 replace -f -'
Dec 14 09:49:56.317: INFO: stderr: ""
Dec 14 09:49:56.317: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/14/22 09:49:56.317
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Dec 14 09:49:56.323: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 delete pods e2e-test-httpd-pod'
Dec 14 09:49:58.385: INFO: stderr: ""
Dec 14 09:49:58.385: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:49:58.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8977" for this suite. 12/14/22 09:49:58.396
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":255,"skipped":4690,"failed":0}
------------------------------
• [8.065 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:50.339
    Dec 14 09:49:50.339: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:49:50.34
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:50.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:50.372
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 12/14/22 09:49:50.383
    Dec 14 09:49:50.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Dec 14 09:49:50.490: INFO: stderr: ""
    Dec 14 09:49:50.490: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 12/14/22 09:49:50.49
    STEP: verifying the pod e2e-test-httpd-pod was created 12/14/22 09:49:55.541
    Dec 14 09:49:55.542: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 get pod e2e-test-httpd-pod -o json'
    Dec 14 09:49:55.667: INFO: stderr: ""
    Dec 14 09:49:55.667: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"3d190b70c6ab8d35d818692bab0806cd2a5448cdc835ad095608f3fa6b042fc3\",\n            \"cni.projectcalico.org/podIP\": \"172.16.0.138/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.16.0.138/32\"\n        },\n        \"creationTimestamp\": \"2022-12-14T09:49:50Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8977\",\n        \"resourceVersion\": \"47252\",\n        \"uid\": \"6029d09f-6b02-4803-a516-7235e15fa95f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zkq55\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"izgw8jfcr55yi09nr0a5xaz\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zkq55\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-12-14T09:49:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://be468c938b2ce742fe00eae7e13414dbe36a4f789ecdb92a1b2bba57e5488378\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-12-14T09:49:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.18.72\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.0.138\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.0.138\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-12-14T09:49:50Z\"\n    }\n}\n"
    STEP: replace the image in the pod 12/14/22 09:49:55.667
    Dec 14 09:49:55.667: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 replace -f -'
    Dec 14 09:49:56.317: INFO: stderr: ""
    Dec 14 09:49:56.317: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 12/14/22 09:49:56.317
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Dec 14 09:49:56.323: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-8977 delete pods e2e-test-httpd-pod'
    Dec 14 09:49:58.385: INFO: stderr: ""
    Dec 14 09:49:58.385: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:49:58.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8977" for this suite. 12/14/22 09:49:58.396
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:58.405
Dec 14 09:49:58.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:49:58.406
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:58.427
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:58.439
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 12/14/22 09:49:58.451
STEP: watching for the ServiceAccount to be added 12/14/22 09:49:58.465
STEP: patching the ServiceAccount 12/14/22 09:49:58.471
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/14/22 09:49:58.48
STEP: deleting the ServiceAccount 12/14/22 09:49:58.488
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:49:58.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4633" for this suite. 12/14/22 09:49:58.507
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":256,"skipped":4694,"failed":0}
------------------------------
• [0.110 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:58.405
    Dec 14 09:49:58.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:49:58.406
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:58.427
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:58.439
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 12/14/22 09:49:58.451
    STEP: watching for the ServiceAccount to be added 12/14/22 09:49:58.465
    STEP: patching the ServiceAccount 12/14/22 09:49:58.471
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 12/14/22 09:49:58.48
    STEP: deleting the ServiceAccount 12/14/22 09:49:58.488
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:49:58.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4633" for this suite. 12/14/22 09:49:58.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:49:58.517
Dec 14 09:49:58.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:49:58.518
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:58.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:58.551
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-0c16ae63-afa4-44cd-9e1f-487dd72cf4b5 12/14/22 09:49:58.564
STEP: Creating a pod to test consume configMaps 12/14/22 09:49:58.571
Dec 14 09:49:58.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57" in namespace "projected-3796" to be "Succeeded or Failed"
Dec 14 09:49:58.591: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.628664ms
Dec 14 09:50:00.598: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013938372s
Dec 14 09:50:02.599: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014801438s
STEP: Saw pod success 12/14/22 09:50:02.599
Dec 14 09:50:02.599: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57" satisfied condition "Succeeded or Failed"
Dec 14 09:50:02.606: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:50:02.624
Dec 14 09:50:02.634: INFO: Waiting for pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 to disappear
Dec 14 09:50:02.641: INFO: Pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Dec 14 09:50:02.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3796" for this suite. 12/14/22 09:50:02.653
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":257,"skipped":4737,"failed":0}
------------------------------
• [4.144 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:49:58.517
    Dec 14 09:49:58.517: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:49:58.518
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:49:58.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:49:58.551
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-0c16ae63-afa4-44cd-9e1f-487dd72cf4b5 12/14/22 09:49:58.564
    STEP: Creating a pod to test consume configMaps 12/14/22 09:49:58.571
    Dec 14 09:49:58.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57" in namespace "projected-3796" to be "Succeeded or Failed"
    Dec 14 09:49:58.591: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.628664ms
    Dec 14 09:50:00.598: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013938372s
    Dec 14 09:50:02.599: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014801438s
    STEP: Saw pod success 12/14/22 09:50:02.599
    Dec 14 09:50:02.599: INFO: Pod "pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57" satisfied condition "Succeeded or Failed"
    Dec 14 09:50:02.606: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:50:02.624
    Dec 14 09:50:02.634: INFO: Waiting for pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 to disappear
    Dec 14 09:50:02.641: INFO: Pod pod-projected-configmaps-24de8a6c-4292-4f1f-81d1-1f81387c4f57 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Dec 14 09:50:02.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3796" for this suite. 12/14/22 09:50:02.653
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:02.662
Dec 14 09:50:02.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller 12/14/22 09:50:02.663
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:02.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:02.695
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 12/14/22 09:50:02.714
STEP: waiting for RC to be added 12/14/22 09:50:02.721
STEP: waiting for available Replicas 12/14/22 09:50:02.721
STEP: patching ReplicationController 12/14/22 09:50:04.397
STEP: waiting for RC to be modified 12/14/22 09:50:04.407
STEP: patching ReplicationController status 12/14/22 09:50:04.408
STEP: waiting for RC to be modified 12/14/22 09:50:04.416
STEP: waiting for available Replicas 12/14/22 09:50:04.416
STEP: fetching ReplicationController status 12/14/22 09:50:04.42
STEP: patching ReplicationController scale 12/14/22 09:50:04.426
STEP: waiting for RC to be modified 12/14/22 09:50:04.435
STEP: waiting for ReplicationController's scale to be the max amount 12/14/22 09:50:04.435
STEP: fetching ReplicationController; ensuring that it's patched 12/14/22 09:50:05.216
STEP: updating ReplicationController status 12/14/22 09:50:05.223
STEP: waiting for RC to be modified 12/14/22 09:50:05.231
STEP: listing all ReplicationControllers 12/14/22 09:50:05.232
STEP: checking that ReplicationController has expected values 12/14/22 09:50:05.238
STEP: deleting ReplicationControllers by collection 12/14/22 09:50:05.238
STEP: waiting for ReplicationController to have a DELETED watchEvent 12/14/22 09:50:05.248
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Dec 14 09:50:05.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8667" for this suite. 12/14/22 09:50:05.304
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":258,"skipped":4742,"failed":0}
------------------------------
• [2.650 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:02.662
    Dec 14 09:50:02.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replication-controller 12/14/22 09:50:02.663
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:02.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:02.695
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 12/14/22 09:50:02.714
    STEP: waiting for RC to be added 12/14/22 09:50:02.721
    STEP: waiting for available Replicas 12/14/22 09:50:02.721
    STEP: patching ReplicationController 12/14/22 09:50:04.397
    STEP: waiting for RC to be modified 12/14/22 09:50:04.407
    STEP: patching ReplicationController status 12/14/22 09:50:04.408
    STEP: waiting for RC to be modified 12/14/22 09:50:04.416
    STEP: waiting for available Replicas 12/14/22 09:50:04.416
    STEP: fetching ReplicationController status 12/14/22 09:50:04.42
    STEP: patching ReplicationController scale 12/14/22 09:50:04.426
    STEP: waiting for RC to be modified 12/14/22 09:50:04.435
    STEP: waiting for ReplicationController's scale to be the max amount 12/14/22 09:50:04.435
    STEP: fetching ReplicationController; ensuring that it's patched 12/14/22 09:50:05.216
    STEP: updating ReplicationController status 12/14/22 09:50:05.223
    STEP: waiting for RC to be modified 12/14/22 09:50:05.231
    STEP: listing all ReplicationControllers 12/14/22 09:50:05.232
    STEP: checking that ReplicationController has expected values 12/14/22 09:50:05.238
    STEP: deleting ReplicationControllers by collection 12/14/22 09:50:05.238
    STEP: waiting for ReplicationController to have a DELETED watchEvent 12/14/22 09:50:05.248
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Dec 14 09:50:05.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8667" for this suite. 12/14/22 09:50:05.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:05.313
Dec 14 09:50:05.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:50:05.314
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:05.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:05.345
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-6059 12/14/22 09:50:05.358
STEP: creating a selector 12/14/22 09:50:05.358
STEP: Creating the service pods in kubernetes 12/14/22 09:50:05.358
Dec 14 09:50:05.358: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 09:50:05.398: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6059" to be "running and ready"
Dec 14 09:50:05.404: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0984ms
Dec 14 09:50:05.405: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:50:07.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014151946s
Dec 14 09:50:07.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:09.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014161308s
Dec 14 09:50:09.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:11.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013664313s
Dec 14 09:50:11.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:13.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014827466s
Dec 14 09:50:13.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:15.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01385404s
Dec 14 09:50:15.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:17.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013836385s
Dec 14 09:50:17.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:19.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014705135s
Dec 14 09:50:19.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:21.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.014632206s
Dec 14 09:50:21.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:23.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.013391993s
Dec 14 09:50:23.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:25.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013195317s
Dec 14 09:50:25.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 09:50:27.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014342755s
Dec 14 09:50:27.413: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 09:50:27.413: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 09:50:27.420: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6059" to be "running and ready"
Dec 14 09:50:27.427: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.785228ms
Dec 14 09:50:27.427: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 09:50:27.427: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 09:50:27.433
Dec 14 09:50:27.445: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6059" to be "running"
Dec 14 09:50:27.452: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.728527ms
Dec 14 09:50:29.466: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021264021s
Dec 14 09:50:29.466: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 09:50:29.473: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 09:50:29.473: INFO: Breadth first check of 172.16.1.179 on host 10.250.18.71...
Dec 14 09:50:29.480: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.142:9080/dial?request=hostname&protocol=udp&host=172.16.1.179&port=8081&tries=1'] Namespace:pod-network-test-6059 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:50:29.480: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:50:29.481: INFO: ExecWithOptions: Clientset creation
Dec 14 09:50:29.481: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-6059/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.142%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.1.179%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:50:29.928: INFO: Waiting for responses: map[]
Dec 14 09:50:29.928: INFO: reached 172.16.1.179 after 0/1 tries
Dec 14 09:50:29.928: INFO: Breadth first check of 172.16.0.141 on host 10.250.18.72...
Dec 14 09:50:29.935: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.142:9080/dial?request=hostname&protocol=udp&host=172.16.0.141&port=8081&tries=1'] Namespace:pod-network-test-6059 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 09:50:29.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 09:50:29.935: INFO: ExecWithOptions: Clientset creation
Dec 14 09:50:29.935: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-6059/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.142%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.141%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Dec 14 09:50:30.405: INFO: Waiting for responses: map[]
Dec 14 09:50:30.405: INFO: reached 172.16.0.141 after 0/1 tries
Dec 14 09:50:30.405: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 09:50:30.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6059" for this suite. 12/14/22 09:50:30.417
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":259,"skipped":4755,"failed":0}
------------------------------
• [25.112 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:05.313
    Dec 14 09:50:05.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 09:50:05.314
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:05.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:05.345
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-6059 12/14/22 09:50:05.358
    STEP: creating a selector 12/14/22 09:50:05.358
    STEP: Creating the service pods in kubernetes 12/14/22 09:50:05.358
    Dec 14 09:50:05.358: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 09:50:05.398: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6059" to be "running and ready"
    Dec 14 09:50:05.404: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0984ms
    Dec 14 09:50:05.405: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:50:07.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014151946s
    Dec 14 09:50:07.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:09.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014161308s
    Dec 14 09:50:09.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:11.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013664313s
    Dec 14 09:50:11.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:13.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014827466s
    Dec 14 09:50:13.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:15.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01385404s
    Dec 14 09:50:15.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:17.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013836385s
    Dec 14 09:50:17.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:19.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014705135s
    Dec 14 09:50:19.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:21.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.014632206s
    Dec 14 09:50:21.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:23.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.013391993s
    Dec 14 09:50:23.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:25.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013195317s
    Dec 14 09:50:25.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 09:50:27.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014342755s
    Dec 14 09:50:27.413: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 09:50:27.413: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 09:50:27.420: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6059" to be "running and ready"
    Dec 14 09:50:27.427: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 6.785228ms
    Dec 14 09:50:27.427: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 09:50:27.427: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 09:50:27.433
    Dec 14 09:50:27.445: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6059" to be "running"
    Dec 14 09:50:27.452: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.728527ms
    Dec 14 09:50:29.466: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.021264021s
    Dec 14 09:50:29.466: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 09:50:29.473: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 09:50:29.473: INFO: Breadth first check of 172.16.1.179 on host 10.250.18.71...
    Dec 14 09:50:29.480: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.142:9080/dial?request=hostname&protocol=udp&host=172.16.1.179&port=8081&tries=1'] Namespace:pod-network-test-6059 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:50:29.480: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:50:29.481: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:50:29.481: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-6059/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.142%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.1.179%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:50:29.928: INFO: Waiting for responses: map[]
    Dec 14 09:50:29.928: INFO: reached 172.16.1.179 after 0/1 tries
    Dec 14 09:50:29.928: INFO: Breadth first check of 172.16.0.141 on host 10.250.18.72...
    Dec 14 09:50:29.935: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.0.142:9080/dial?request=hostname&protocol=udp&host=172.16.0.141&port=8081&tries=1'] Namespace:pod-network-test-6059 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 09:50:29.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 09:50:29.935: INFO: ExecWithOptions: Clientset creation
    Dec 14 09:50:29.935: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-6059/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.0.142%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.0.141%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Dec 14 09:50:30.405: INFO: Waiting for responses: map[]
    Dec 14 09:50:30.405: INFO: reached 172.16.0.141 after 0/1 tries
    Dec 14 09:50:30.405: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 09:50:30.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6059" for this suite. 12/14/22 09:50:30.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:30.427
Dec 14 09:50:30.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:50:30.427
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:30.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:30.461
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:50:30.473
Dec 14 09:50:30.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e" in namespace "projected-1248" to be "Succeeded or Failed"
Dec 14 09:50:30.493: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.573018ms
Dec 14 09:50:32.504: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017379369s
Dec 14 09:50:34.502: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015080634s
STEP: Saw pod success 12/14/22 09:50:34.502
Dec 14 09:50:34.502: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e" satisfied condition "Succeeded or Failed"
Dec 14 09:50:34.509: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e container client-container: <nil>
STEP: delete the pod 12/14/22 09:50:34.526
Dec 14 09:50:34.537: INFO: Waiting for pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e to disappear
Dec 14 09:50:34.545: INFO: Pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 09:50:34.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1248" for this suite. 12/14/22 09:50:34.557
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":260,"skipped":4802,"failed":0}
------------------------------
• [4.138 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:30.427
    Dec 14 09:50:30.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:50:30.427
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:30.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:30.461
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:50:30.473
    Dec 14 09:50:30.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e" in namespace "projected-1248" to be "Succeeded or Failed"
    Dec 14 09:50:30.493: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.573018ms
    Dec 14 09:50:32.504: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017379369s
    Dec 14 09:50:34.502: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015080634s
    STEP: Saw pod success 12/14/22 09:50:34.502
    Dec 14 09:50:34.502: INFO: Pod "downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e" satisfied condition "Succeeded or Failed"
    Dec 14 09:50:34.509: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e container client-container: <nil>
    STEP: delete the pod 12/14/22 09:50:34.526
    Dec 14 09:50:34.537: INFO: Waiting for pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e to disappear
    Dec 14 09:50:34.545: INFO: Pod downwardapi-volume-e100ef7e-a00f-4990-9259-f00613f2d19e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 09:50:34.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1248" for this suite. 12/14/22 09:50:34.557
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:34.565
Dec 14 09:50:34.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job 12/14/22 09:50:34.566
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:34.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:34.597
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 12/14/22 09:50:34.609
STEP: Ensuring active pods == parallelism 12/14/22 09:50:34.616
STEP: Orphaning one of the Job's Pods 12/14/22 09:50:36.625
Dec 14 09:50:37.150: INFO: Successfully updated pod "adopt-release-kqjl4"
STEP: Checking that the Job readopts the Pod 12/14/22 09:50:37.15
Dec 14 09:50:37.151: INFO: Waiting up to 15m0s for pod "adopt-release-kqjl4" in namespace "job-3484" to be "adopted"
Dec 14 09:50:37.157: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 6.703868ms
Dec 14 09:50:39.165: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014625254s
Dec 14 09:50:39.165: INFO: Pod "adopt-release-kqjl4" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 12/14/22 09:50:39.165
Dec 14 09:50:39.681: INFO: Successfully updated pod "adopt-release-kqjl4"
STEP: Checking that the Job releases the Pod 12/14/22 09:50:39.681
Dec 14 09:50:39.681: INFO: Waiting up to 15m0s for pod "adopt-release-kqjl4" in namespace "job-3484" to be "released"
Dec 14 09:50:39.688: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 6.271503ms
Dec 14 09:50:41.695: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.013362349s
Dec 14 09:50:41.695: INFO: Pod "adopt-release-kqjl4" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Dec 14 09:50:41.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3484" for this suite. 12/14/22 09:50:41.706
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":261,"skipped":4804,"failed":0}
------------------------------
• [7.149 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:34.565
    Dec 14 09:50:34.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename job 12/14/22 09:50:34.566
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:34.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:34.597
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 12/14/22 09:50:34.609
    STEP: Ensuring active pods == parallelism 12/14/22 09:50:34.616
    STEP: Orphaning one of the Job's Pods 12/14/22 09:50:36.625
    Dec 14 09:50:37.150: INFO: Successfully updated pod "adopt-release-kqjl4"
    STEP: Checking that the Job readopts the Pod 12/14/22 09:50:37.15
    Dec 14 09:50:37.151: INFO: Waiting up to 15m0s for pod "adopt-release-kqjl4" in namespace "job-3484" to be "adopted"
    Dec 14 09:50:37.157: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 6.703868ms
    Dec 14 09:50:39.165: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014625254s
    Dec 14 09:50:39.165: INFO: Pod "adopt-release-kqjl4" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 12/14/22 09:50:39.165
    Dec 14 09:50:39.681: INFO: Successfully updated pod "adopt-release-kqjl4"
    STEP: Checking that the Job releases the Pod 12/14/22 09:50:39.681
    Dec 14 09:50:39.681: INFO: Waiting up to 15m0s for pod "adopt-release-kqjl4" in namespace "job-3484" to be "released"
    Dec 14 09:50:39.688: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 6.271503ms
    Dec 14 09:50:41.695: INFO: Pod "adopt-release-kqjl4": Phase="Running", Reason="", readiness=true. Elapsed: 2.013362349s
    Dec 14 09:50:41.695: INFO: Pod "adopt-release-kqjl4" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Dec 14 09:50:41.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3484" for this suite. 12/14/22 09:50:41.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:50:41.715
Dec 14 09:50:41.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods 12/14/22 09:50:41.716
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:41.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:41.747
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Dec 14 09:50:41.759: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 09:51:41.822: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Dec 14 09:51:41.830: INFO: Starting informer...
STEP: Starting pods... 12/14/22 09:51:41.83
Dec 14 09:51:41.857: INFO: Pod1 is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
Dec 14 09:51:41.875: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8277" to be "running"
Dec 14 09:51:41.882: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.695671ms
Dec 14 09:51:43.889: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013711149s
Dec 14 09:51:43.889: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Dec 14 09:51:43.889: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8277" to be "running"
Dec 14 09:51:43.896: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 6.944841ms
Dec 14 09:51:43.896: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Dec 14 09:51:43.896: INFO: Pod2 is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
STEP: Trying to apply a taint on the Node 12/14/22 09:51:43.896
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:51:43.92
STEP: Waiting for Pod1 and Pod2 to be deleted 12/14/22 09:51:43.927
Dec 14 09:51:49.710: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 14 09:52:09.722: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:52:09.744
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:52:09.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8277" for this suite. 12/14/22 09:52:09.759
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":262,"skipped":4827,"failed":0}
------------------------------
• [88.052 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:50:41.715
    Dec 14 09:50:41.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename taint-multiple-pods 12/14/22 09:50:41.716
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:50:41.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:50:41.747
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Dec 14 09:50:41.759: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 09:51:41.822: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Dec 14 09:51:41.830: INFO: Starting informer...
    STEP: Starting pods... 12/14/22 09:51:41.83
    Dec 14 09:51:41.857: INFO: Pod1 is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
    Dec 14 09:51:41.875: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-8277" to be "running"
    Dec 14 09:51:41.882: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.695671ms
    Dec 14 09:51:43.889: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013711149s
    Dec 14 09:51:43.889: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Dec 14 09:51:43.889: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-8277" to be "running"
    Dec 14 09:51:43.896: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 6.944841ms
    Dec 14 09:51:43.896: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Dec 14 09:51:43.896: INFO: Pod2 is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
    STEP: Trying to apply a taint on the Node 12/14/22 09:51:43.896
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:51:43.92
    STEP: Waiting for Pod1 and Pod2 to be deleted 12/14/22 09:51:43.927
    Dec 14 09:51:49.710: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Dec 14 09:52:09.722: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:52:09.744
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:52:09.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-8277" for this suite. 12/14/22 09:52:09.759
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:09.767
Dec 14 09:52:09.767: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:52:09.768
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:09.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:09.8
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-6351/secret-test-99f705ea-6451-4197-8535-66f97936256c 12/14/22 09:52:09.812
STEP: Creating a pod to test consume secrets 12/14/22 09:52:09.819
Dec 14 09:52:09.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab" in namespace "secrets-6351" to be "Succeeded or Failed"
Dec 14 09:52:09.840: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.214288ms
Dec 14 09:52:11.848: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014186827s
Dec 14 09:52:13.854: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020289699s
STEP: Saw pod success 12/14/22 09:52:13.854
Dec 14 09:52:13.854: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab" satisfied condition "Succeeded or Failed"
Dec 14 09:52:13.861: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab container env-test: <nil>
STEP: delete the pod 12/14/22 09:52:13.879
Dec 14 09:52:13.890: INFO: Waiting for pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab to disappear
Dec 14 09:52:13.897: INFO: Pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:52:13.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6351" for this suite. 12/14/22 09:52:13.908
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":263,"skipped":4827,"failed":0}
------------------------------
• [4.150 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:09.767
    Dec 14 09:52:09.767: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:52:09.768
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:09.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:09.8
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-6351/secret-test-99f705ea-6451-4197-8535-66f97936256c 12/14/22 09:52:09.812
    STEP: Creating a pod to test consume secrets 12/14/22 09:52:09.819
    Dec 14 09:52:09.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab" in namespace "secrets-6351" to be "Succeeded or Failed"
    Dec 14 09:52:09.840: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.214288ms
    Dec 14 09:52:11.848: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014186827s
    Dec 14 09:52:13.854: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020289699s
    STEP: Saw pod success 12/14/22 09:52:13.854
    Dec 14 09:52:13.854: INFO: Pod "pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab" satisfied condition "Succeeded or Failed"
    Dec 14 09:52:13.861: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab container env-test: <nil>
    STEP: delete the pod 12/14/22 09:52:13.879
    Dec 14 09:52:13.890: INFO: Waiting for pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab to disappear
    Dec 14 09:52:13.897: INFO: Pod pod-configmaps-c5ba4c19-6d3c-4378-8471-05b2222c0dab no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:52:13.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6351" for this suite. 12/14/22 09:52:13.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:13.918
Dec 14 09:52:13.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:52:13.918
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:13.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:13.95
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 12/14/22 09:52:13.97
STEP: Verify that the required pods have come up. 12/14/22 09:52:13.978
Dec 14 09:52:13.985: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 14 09:52:18.999: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 09:52:18.999
STEP: Getting /status 12/14/22 09:52:18.999
Dec 14 09:52:19.006: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 12/14/22 09:52:19.006
Dec 14 09:52:19.021: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 12/14/22 09:52:19.021
Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: ADDED
Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.027: INFO: Found replicaset test-rs in namespace replicaset-4848 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Dec 14 09:52:19.027: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 12/14/22 09:52:19.027
Dec 14 09:52:19.027: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 09:52:19.034: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 12/14/22 09:52:19.035
Dec 14 09:52:19.040: INFO: Observed &ReplicaSet event: ADDED
Dec 14 09:52:19.040: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.041: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.045: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.045: INFO: Observed replicaset test-rs in namespace replicaset-4848 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:52:19.045: INFO: Observed &ReplicaSet event: MODIFIED
Dec 14 09:52:19.045: INFO: Found replicaset test-rs in namespace replicaset-4848 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Dec 14 09:52:19.045: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:52:19.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4848" for this suite. 12/14/22 09:52:19.062
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":264,"skipped":4849,"failed":0}
------------------------------
• [5.152 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:13.918
    Dec 14 09:52:13.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:52:13.918
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:13.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:13.95
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 12/14/22 09:52:13.97
    STEP: Verify that the required pods have come up. 12/14/22 09:52:13.978
    Dec 14 09:52:13.985: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec 14 09:52:18.999: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 09:52:18.999
    STEP: Getting /status 12/14/22 09:52:18.999
    Dec 14 09:52:19.006: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 12/14/22 09:52:19.006
    Dec 14 09:52:19.021: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 12/14/22 09:52:19.021
    Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: ADDED
    Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.027: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.027: INFO: Found replicaset test-rs in namespace replicaset-4848 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Dec 14 09:52:19.027: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 12/14/22 09:52:19.027
    Dec 14 09:52:19.027: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 09:52:19.034: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 12/14/22 09:52:19.035
    Dec 14 09:52:19.040: INFO: Observed &ReplicaSet event: ADDED
    Dec 14 09:52:19.040: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.041: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.045: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.045: INFO: Observed replicaset test-rs in namespace replicaset-4848 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:52:19.045: INFO: Observed &ReplicaSet event: MODIFIED
    Dec 14 09:52:19.045: INFO: Found replicaset test-rs in namespace replicaset-4848 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Dec 14 09:52:19.045: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:52:19.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4848" for this suite. 12/14/22 09:52:19.062
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:19.071
Dec 14 09:52:19.071: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 09:52:19.072
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:19.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:19.104
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Dec 14 09:52:19.152: INFO: Create a RollingUpdate DaemonSet
Dec 14 09:52:19.160: INFO: Check that daemon pods launch on every node of the cluster
Dec 14 09:52:19.174: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:52:19.174: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:52:20.194: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:52:20.194: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:52:21.201: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Dec 14 09:52:21.201: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Dec 14 09:52:21.201: INFO: Update the DaemonSet to trigger a rollout
Dec 14 09:52:21.215: INFO: Updating DaemonSet daemon-set
Dec 14 09:52:24.247: INFO: Roll back the DaemonSet before rollout is complete
Dec 14 09:52:24.261: INFO: Updating DaemonSet daemon-set
Dec 14 09:52:24.261: INFO: Make sure DaemonSet rollback is complete
Dec 14 09:52:24.268: INFO: Wrong image for pod: daemon-set-d27bf. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Dec 14 09:52:24.268: INFO: Pod daemon-set-d27bf is not available
Dec 14 09:52:27.283: INFO: Pod daemon-set-fnwvm is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:52:27.31
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3483, will wait for the garbage collector to delete the pods 12/14/22 09:52:27.31
Dec 14 09:52:27.374: INFO: Deleting DaemonSet.extensions daemon-set took: 7.75027ms
Dec 14 09:52:27.475: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.74425ms
Dec 14 09:52:29.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 09:52:29.882: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 09:52:29.889: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"48482"},"items":null}

Dec 14 09:52:29.895: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"48482"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:52:29.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3483" for this suite. 12/14/22 09:52:29.929
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":265,"skipped":4890,"failed":0}
------------------------------
• [10.865 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:19.071
    Dec 14 09:52:19.071: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 09:52:19.072
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:19.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:19.104
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Dec 14 09:52:19.152: INFO: Create a RollingUpdate DaemonSet
    Dec 14 09:52:19.160: INFO: Check that daemon pods launch on every node of the cluster
    Dec 14 09:52:19.174: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:52:19.174: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:52:20.194: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:52:20.194: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:52:21.201: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Dec 14 09:52:21.201: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    Dec 14 09:52:21.201: INFO: Update the DaemonSet to trigger a rollout
    Dec 14 09:52:21.215: INFO: Updating DaemonSet daemon-set
    Dec 14 09:52:24.247: INFO: Roll back the DaemonSet before rollout is complete
    Dec 14 09:52:24.261: INFO: Updating DaemonSet daemon-set
    Dec 14 09:52:24.261: INFO: Make sure DaemonSet rollback is complete
    Dec 14 09:52:24.268: INFO: Wrong image for pod: daemon-set-d27bf. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Dec 14 09:52:24.268: INFO: Pod daemon-set-d27bf is not available
    Dec 14 09:52:27.283: INFO: Pod daemon-set-fnwvm is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 09:52:27.31
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3483, will wait for the garbage collector to delete the pods 12/14/22 09:52:27.31
    Dec 14 09:52:27.374: INFO: Deleting DaemonSet.extensions daemon-set took: 7.75027ms
    Dec 14 09:52:27.475: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.74425ms
    Dec 14 09:52:29.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 09:52:29.882: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 09:52:29.889: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"48482"},"items":null}

    Dec 14 09:52:29.895: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"48482"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:52:29.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3483" for this suite. 12/14/22 09:52:29.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:29.939
Dec 14 09:52:29.939: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:52:29.94
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:29.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:29.972
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 12/14/22 09:52:29.984
STEP: Creating a ResourceQuota 12/14/22 09:52:34.991
STEP: Ensuring resource quota status is calculated 12/14/22 09:52:35.001
STEP: Creating a Pod that fits quota 12/14/22 09:52:37.008
STEP: Ensuring ResourceQuota status captures the pod usage 12/14/22 09:52:37.026
STEP: Not allowing a pod to be created that exceeds remaining quota 12/14/22 09:52:39.034
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/14/22 09:52:39.045
STEP: Ensuring a pod cannot update its resource requirements 12/14/22 09:52:39.055
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/14/22 09:52:39.063
STEP: Deleting the pod 12/14/22 09:52:41.071
STEP: Ensuring resource quota status released the pod usage 12/14/22 09:52:41.082
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:52:43.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7610" for this suite. 12/14/22 09:52:43.124
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":266,"skipped":4932,"failed":0}
------------------------------
• [13.194 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:29.939
    Dec 14 09:52:29.939: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:52:29.94
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:29.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:29.972
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 12/14/22 09:52:29.984
    STEP: Creating a ResourceQuota 12/14/22 09:52:34.991
    STEP: Ensuring resource quota status is calculated 12/14/22 09:52:35.001
    STEP: Creating a Pod that fits quota 12/14/22 09:52:37.008
    STEP: Ensuring ResourceQuota status captures the pod usage 12/14/22 09:52:37.026
    STEP: Not allowing a pod to be created that exceeds remaining quota 12/14/22 09:52:39.034
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 12/14/22 09:52:39.045
    STEP: Ensuring a pod cannot update its resource requirements 12/14/22 09:52:39.055
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 12/14/22 09:52:39.063
    STEP: Deleting the pod 12/14/22 09:52:41.071
    STEP: Ensuring resource quota status released the pod usage 12/14/22 09:52:41.082
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:52:43.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7610" for this suite. 12/14/22 09:52:43.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:43.133
Dec 14 09:52:43.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test 12/14/22 09:52:43.134
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:43.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:43.165
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Dec 14 09:52:43.190: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2" in namespace "security-context-test-4482" to be "Succeeded or Failed"
Dec 14 09:52:43.197: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.470259ms
Dec 14 09:52:45.204: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013865662s
Dec 14 09:52:47.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015029847s
Dec 14 09:52:49.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01455448s
Dec 14 09:52:49.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 09:52:49.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4482" for this suite. 12/14/22 09:52:49.241
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":267,"skipped":4948,"failed":0}
------------------------------
• [6.115 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:43.133
    Dec 14 09:52:43.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context-test 12/14/22 09:52:43.134
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:43.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:43.165
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Dec 14 09:52:43.190: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2" in namespace "security-context-test-4482" to be "Succeeded or Failed"
    Dec 14 09:52:43.197: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.470259ms
    Dec 14 09:52:45.204: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013865662s
    Dec 14 09:52:47.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015029847s
    Dec 14 09:52:49.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01455448s
    Dec 14 09:52:49.205: INFO: Pod "alpine-nnp-false-bc4ece6e-1edf-4117-bcb8-bf79979d51d2" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 09:52:49.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4482" for this suite. 12/14/22 09:52:49.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:52:49.249
Dec 14 09:52:49.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 09:52:49.25
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:49.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:49.283
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 12/14/22 09:52:54.371
STEP: referencing matching pods with named port 12/14/22 09:52:59.386
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/14/22 09:53:04.401
STEP: recreating EndpointSlices after they've been deleted 12/14/22 09:53:09.415
Dec 14 09:53:09.447: INFO: EndpointSlice for Service endpointslice-5846/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 09:53:19.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5846" for this suite. 12/14/22 09:53:19.474
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":268,"skipped":4953,"failed":0}
------------------------------
• [30.233 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:52:49.249
    Dec 14 09:52:49.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 09:52:49.25
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:52:49.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:52:49.283
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 12/14/22 09:52:54.371
    STEP: referencing matching pods with named port 12/14/22 09:52:59.386
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 12/14/22 09:53:04.401
    STEP: recreating EndpointSlices after they've been deleted 12/14/22 09:53:09.415
    Dec 14 09:53:09.447: INFO: EndpointSlice for Service endpointslice-5846/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 09:53:19.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5846" for this suite. 12/14/22 09:53:19.474
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:19.483
Dec 14 09:53:19.483: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:53:19.484
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:19.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:19.516
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-8475/configmap-test-effb5d9a-0ca1-4e4e-bb6b-970558edb62f 12/14/22 09:53:19.528
STEP: Creating a pod to test consume configMaps 12/14/22 09:53:19.535
Dec 14 09:53:19.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc" in namespace "configmap-8475" to be "Succeeded or Failed"
Dec 14 09:53:19.554: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511593ms
Dec 14 09:53:21.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015147553s
Dec 14 09:53:23.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01520703s
STEP: Saw pod success 12/14/22 09:53:23.563
Dec 14 09:53:23.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc" satisfied condition "Succeeded or Failed"
Dec 14 09:53:23.570: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc container env-test: <nil>
STEP: delete the pod 12/14/22 09:53:23.587
Dec 14 09:53:23.597: INFO: Waiting for pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc to disappear
Dec 14 09:53:23.604: INFO: Pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:53:23.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8475" for this suite. 12/14/22 09:53:23.615
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":269,"skipped":4961,"failed":0}
------------------------------
• [4.140 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:19.483
    Dec 14 09:53:19.483: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:53:19.484
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:19.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:19.516
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-8475/configmap-test-effb5d9a-0ca1-4e4e-bb6b-970558edb62f 12/14/22 09:53:19.528
    STEP: Creating a pod to test consume configMaps 12/14/22 09:53:19.535
    Dec 14 09:53:19.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc" in namespace "configmap-8475" to be "Succeeded or Failed"
    Dec 14 09:53:19.554: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.511593ms
    Dec 14 09:53:21.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015147553s
    Dec 14 09:53:23.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01520703s
    STEP: Saw pod success 12/14/22 09:53:23.563
    Dec 14 09:53:23.563: INFO: Pod "pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc" satisfied condition "Succeeded or Failed"
    Dec 14 09:53:23.570: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc container env-test: <nil>
    STEP: delete the pod 12/14/22 09:53:23.587
    Dec 14 09:53:23.597: INFO: Waiting for pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc to disappear
    Dec 14 09:53:23.604: INFO: Pod pod-configmaps-0410d613-5e67-4ad9-ad3c-f0fe66cbdedc no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:53:23.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8475" for this suite. 12/14/22 09:53:23.615
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:23.623
Dec 14 09:53:23.623: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 09:53:23.624
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:23.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:23.656
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-1063cc03-1b28-445d-a971-13c53d887be6 12/14/22 09:53:23.667
STEP: Creating a pod to test consume configMaps 12/14/22 09:53:23.674
Dec 14 09:53:23.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7" in namespace "configmap-2002" to be "Succeeded or Failed"
Dec 14 09:53:23.693: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.587056ms
Dec 14 09:53:25.701: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014138562s
Dec 14 09:53:27.702: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015221726s
STEP: Saw pod success 12/14/22 09:53:27.702
Dec 14 09:53:27.702: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7" satisfied condition "Succeeded or Failed"
Dec 14 09:53:27.709: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:53:27.727
Dec 14 09:53:27.737: INFO: Waiting for pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 to disappear
Dec 14 09:53:27.743: INFO: Pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 09:53:27.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2002" for this suite. 12/14/22 09:53:27.755
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":270,"skipped":4968,"failed":0}
------------------------------
• [4.140 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:23.623
    Dec 14 09:53:23.623: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 09:53:23.624
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:23.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:23.656
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-1063cc03-1b28-445d-a971-13c53d887be6 12/14/22 09:53:23.667
    STEP: Creating a pod to test consume configMaps 12/14/22 09:53:23.674
    Dec 14 09:53:23.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7" in namespace "configmap-2002" to be "Succeeded or Failed"
    Dec 14 09:53:23.693: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.587056ms
    Dec 14 09:53:25.701: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014138562s
    Dec 14 09:53:27.702: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015221726s
    STEP: Saw pod success 12/14/22 09:53:27.702
    Dec 14 09:53:27.702: INFO: Pod "pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7" satisfied condition "Succeeded or Failed"
    Dec 14 09:53:27.709: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:53:27.727
    Dec 14 09:53:27.737: INFO: Waiting for pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 to disappear
    Dec 14 09:53:27.743: INFO: Pod pod-configmaps-954c77ba-da08-4164-8508-82432c3218f7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 09:53:27.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2002" for this suite. 12/14/22 09:53:27.755
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:27.764
Dec 14 09:53:27.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:53:27.765
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:27.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:27.796
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Dec 14 09:53:27.829: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 14 09:53:32.839: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 09:53:32.839
STEP: Scaling up "test-rs" replicaset  12/14/22 09:53:32.839
Dec 14 09:53:32.854: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 12/14/22 09:53:32.854
W1214 09:53:32.870051    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 09:53:32.875: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:53:32.877: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:53:32.918: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:53:32.930: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
Dec 14 09:53:33.944: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 2, AvailableReplicas 2
Dec 14 09:53:34.711: INFO: observed Replicaset test-rs in namespace replicaset-4931 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:53:34.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4931" for this suite. 12/14/22 09:53:34.722
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":271,"skipped":4968,"failed":0}
------------------------------
• [6.967 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:27.764
    Dec 14 09:53:27.764: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:53:27.765
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:27.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:27.796
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Dec 14 09:53:27.829: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec 14 09:53:32.839: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 09:53:32.839
    STEP: Scaling up "test-rs" replicaset  12/14/22 09:53:32.839
    Dec 14 09:53:32.854: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 12/14/22 09:53:32.854
    W1214 09:53:32.870051    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 09:53:32.875: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:53:32.877: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:53:32.918: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:53:32.930: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 1, AvailableReplicas 1
    Dec 14 09:53:33.944: INFO: observed ReplicaSet test-rs in namespace replicaset-4931 with ReadyReplicas 2, AvailableReplicas 2
    Dec 14 09:53:34.711: INFO: observed Replicaset test-rs in namespace replicaset-4931 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:53:34.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4931" for this suite. 12/14/22 09:53:34.722
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:34.733
Dec 14 09:53:34.733: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename server-version 12/14/22 09:53:34.733
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:34.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:34.765
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 12/14/22 09:53:34.777
STEP: Confirm major version 12/14/22 09:53:34.782
Dec 14 09:53:34.782: INFO: Major version: 1
STEP: Confirm minor version 12/14/22 09:53:34.782
Dec 14 09:53:34.782: INFO: cleanMinorVersion: 25
Dec 14 09:53:34.782: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Dec 14 09:53:34.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1543" for this suite. 12/14/22 09:53:34.79
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":272,"skipped":5008,"failed":0}
------------------------------
• [0.066 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:34.733
    Dec 14 09:53:34.733: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename server-version 12/14/22 09:53:34.733
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:34.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:34.765
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 12/14/22 09:53:34.777
    STEP: Confirm major version 12/14/22 09:53:34.782
    Dec 14 09:53:34.782: INFO: Major version: 1
    STEP: Confirm minor version 12/14/22 09:53:34.782
    Dec 14 09:53:34.782: INFO: cleanMinorVersion: 25
    Dec 14 09:53:34.782: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Dec 14 09:53:34.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1543" for this suite. 12/14/22 09:53:34.79
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:34.799
Dec 14 09:53:34.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:53:34.8
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:34.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:34.831
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 12/14/22 09:53:34.856
Dec 14 09:53:34.856: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20" in namespace "kubelet-test-3170" to be "completed"
Dec 14 09:53:34.863: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586659ms
Dec 14 09:53:36.871: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014672608s
Dec 14 09:53:38.872: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01579856s
Dec 14 09:53:38.872: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:53:38.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3170" for this suite. 12/14/22 09:53:38.902
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":273,"skipped":5016,"failed":0}
------------------------------
• [4.112 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:34.799
    Dec 14 09:53:34.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:53:34.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:34.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:34.831
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 12/14/22 09:53:34.856
    Dec 14 09:53:34.856: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20" in namespace "kubelet-test-3170" to be "completed"
    Dec 14 09:53:34.863: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586659ms
    Dec 14 09:53:36.871: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014672608s
    Dec 14 09:53:38.872: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01579856s
    Dec 14 09:53:38.872: INFO: Pod "agnhost-host-aliasescb72e2db-a0e2-48ad-b200-18940891fc20" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:53:38.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3170" for this suite. 12/14/22 09:53:38.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:38.912
Dec 14 09:53:38.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:53:38.913
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:38.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:38.945
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1977 12/14/22 09:53:38.957
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Dec 14 09:53:38.979: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:53:48.989: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 12/14/22 09:53:49.003
W1214 09:53:49.015723    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Dec 14 09:53:49.030: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:53:49.030: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
Dec 14 09:53:59.040: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:53:59.040: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 12/14/22 09:53:59.055
STEP: Delete all of the StatefulSets 12/14/22 09:53:59.062
STEP: Verify that StatefulSets have been deleted 12/14/22 09:53:59.071
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:53:59.077: INFO: Deleting all statefulset in ns statefulset-1977
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:53:59.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1977" for this suite. 12/14/22 09:53:59.108
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":274,"skipped":5028,"failed":0}
------------------------------
• [20.205 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:38.912
    Dec 14 09:53:38.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:53:38.913
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:38.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:38.945
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1977 12/14/22 09:53:38.957
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Dec 14 09:53:38.979: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:53:48.989: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 12/14/22 09:53:49.003
    W1214 09:53:49.015723    6248 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Dec 14 09:53:49.030: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:53:49.030: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
    Dec 14 09:53:59.040: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:53:59.040: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 12/14/22 09:53:59.055
    STEP: Delete all of the StatefulSets 12/14/22 09:53:59.062
    STEP: Verify that StatefulSets have been deleted 12/14/22 09:53:59.071
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:53:59.077: INFO: Deleting all statefulset in ns statefulset-1977
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:53:59.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1977" for this suite. 12/14/22 09:53:59.108
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:53:59.117
Dec 14 09:53:59.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:53:59.118
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:59.137
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:59.149
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1289 12/14/22 09:53:59.16
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-1289 12/14/22 09:53:59.168
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1289 12/14/22 09:53:59.175
Dec 14 09:53:59.182: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:54:09.193: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/14/22 09:54:09.193
Dec 14 09:54:09.200: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:54:09.786: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:54:09.786: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:54:09.786: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:54:09.793: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 14 09:54:19.805: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:54:19.805: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:54:19.835: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec 14 09:54:19.835: INFO: ss-0  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  }]
Dec 14 09:54:19.835: INFO: 
Dec 14 09:54:19.835: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 14 09:54:20.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99253087s
Dec 14 09:54:21.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985138794s
Dec 14 09:54:22.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973890404s
Dec 14 09:54:23.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965857252s
Dec 14 09:54:24.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.95843006s
Dec 14 09:54:25.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949804355s
Dec 14 09:54:26.893: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942006943s
Dec 14 09:54:27.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933834031s
Dec 14 09:54:28.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 925.796072ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1289 12/14/22 09:54:29.909
Dec 14 09:54:29.917: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:54:30.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 09:54:30.400: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:54:30.400: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:54:30.400: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:54:30.992: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 14 09:54:30.992: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:54:30.992: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:54:30.992: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 09:54:31.536: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 14 09:54:31.536: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 09:54:31.536: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 14 09:54:31.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:54:31.543: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 09:54:31.543: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 12/14/22 09:54:31.543
Dec 14 09:54:31.551: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:54:32.074: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:54:32.074: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:54:32.074: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:54:32.075: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:54:32.691: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:54:32.691: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:54:32.691: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:54:32.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 09:54:33.195: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 09:54:33.195: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 09:54:33.195: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 09:54:33.195: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:54:33.202: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 14 09:54:43.217: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:54:43.217: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:54:43.217: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 14 09:54:43.238: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec 14 09:54:43.238: INFO: ss-0  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  }]
Dec 14 09:54:43.238: INFO: ss-1  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  }]
Dec 14 09:54:43.238: INFO: ss-2  izgw86e9lj0cm6u1hvldynz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  }]
Dec 14 09:54:43.238: INFO: 
Dec 14 09:54:43.238: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 14 09:54:44.245: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.99256273s
Dec 14 09:54:45.253: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.985021297s
Dec 14 09:54:46.261: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.977228642s
Dec 14 09:54:47.268: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.969250091s
Dec 14 09:54:48.276: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.962313174s
Dec 14 09:54:49.282: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.955234372s
Dec 14 09:54:50.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.948334283s
Dec 14 09:54:51.297: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.94094365s
Dec 14 09:54:52.305: INFO: Verifying statefulset ss doesn't scale past 0 for another 933.219953ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1289 12/14/22 09:54:53.306
Dec 14 09:54:53.313: INFO: Scaling statefulset ss to 0
Dec 14 09:54:53.334: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:54:53.340: INFO: Deleting all statefulset in ns statefulset-1289
Dec 14 09:54:53.347: INFO: Scaling statefulset ss to 0
Dec 14 09:54:53.369: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:54:53.375: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:54:53.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1289" for this suite. 12/14/22 09:54:53.408
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":275,"skipped":5049,"failed":0}
------------------------------
• [54.301 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:53:59.117
    Dec 14 09:53:59.117: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:53:59.118
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:53:59.137
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:53:59.149
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1289 12/14/22 09:53:59.16
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-1289 12/14/22 09:53:59.168
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1289 12/14/22 09:53:59.175
    Dec 14 09:53:59.182: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:54:09.193: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 12/14/22 09:54:09.193
    Dec 14 09:54:09.200: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:54:09.786: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:54:09.786: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:54:09.786: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:54:09.793: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Dec 14 09:54:19.805: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:54:19.805: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:54:19.835: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
    Dec 14 09:54:19.835: INFO: ss-0  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:10 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  }]
    Dec 14 09:54:19.835: INFO: 
    Dec 14 09:54:19.835: INFO: StatefulSet ss has not reached scale 3, at 1
    Dec 14 09:54:20.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99253087s
    Dec 14 09:54:21.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985138794s
    Dec 14 09:54:22.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.973890404s
    Dec 14 09:54:23.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.965857252s
    Dec 14 09:54:24.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.95843006s
    Dec 14 09:54:25.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949804355s
    Dec 14 09:54:26.893: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942006943s
    Dec 14 09:54:27.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933834031s
    Dec 14 09:54:28.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 925.796072ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1289 12/14/22 09:54:29.909
    Dec 14 09:54:29.917: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:54:30.399: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 09:54:30.400: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:54:30.400: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:54:30.400: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:54:30.992: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec 14 09:54:30.992: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:54:30.992: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:54:30.992: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 09:54:31.536: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Dec 14 09:54:31.536: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 09:54:31.536: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Dec 14 09:54:31.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:54:31.543: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 09:54:31.543: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 12/14/22 09:54:31.543
    Dec 14 09:54:31.551: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:54:32.074: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:54:32.074: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:54:32.074: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:54:32.075: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:54:32.691: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:54:32.691: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:54:32.691: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:54:32.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1289 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 09:54:33.195: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 09:54:33.195: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 09:54:33.195: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 09:54:33.195: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:54:33.202: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Dec 14 09:54:43.217: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:54:43.217: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:54:43.217: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Dec 14 09:54:43.238: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
    Dec 14 09:54:43.238: INFO: ss-0  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:53:59 +0000 UTC  }]
    Dec 14 09:54:43.238: INFO: ss-1  izgw8jfcr55yi09nr0a5xaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  }]
    Dec 14 09:54:43.238: INFO: ss-2  izgw86e9lj0cm6u1hvldynz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-12-14 09:54:19 +0000 UTC  }]
    Dec 14 09:54:43.238: INFO: 
    Dec 14 09:54:43.238: INFO: StatefulSet ss has not reached scale 0, at 3
    Dec 14 09:54:44.245: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.99256273s
    Dec 14 09:54:45.253: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.985021297s
    Dec 14 09:54:46.261: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.977228642s
    Dec 14 09:54:47.268: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.969250091s
    Dec 14 09:54:48.276: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.962313174s
    Dec 14 09:54:49.282: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.955234372s
    Dec 14 09:54:50.290: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.948334283s
    Dec 14 09:54:51.297: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.94094365s
    Dec 14 09:54:52.305: INFO: Verifying statefulset ss doesn't scale past 0 for another 933.219953ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1289 12/14/22 09:54:53.306
    Dec 14 09:54:53.313: INFO: Scaling statefulset ss to 0
    Dec 14 09:54:53.334: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:54:53.340: INFO: Deleting all statefulset in ns statefulset-1289
    Dec 14 09:54:53.347: INFO: Scaling statefulset ss to 0
    Dec 14 09:54:53.369: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:54:53.375: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:54:53.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1289" for this suite. 12/14/22 09:54:53.408
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:54:53.419
Dec 14 09:54:53.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop 12/14/22 09:54:53.42
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:54:53.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:54:53.452
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-9074 12/14/22 09:54:53.463
STEP: Waiting for pods to come up. 12/14/22 09:54:53.477
Dec 14 09:54:53.477: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9074" to be "running"
Dec 14 09:54:53.484: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 6.648706ms
Dec 14 09:54:55.492: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.014775662s
Dec 14 09:54:55.492: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-9074 12/14/22 09:54:55.499
Dec 14 09:54:55.510: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9074" to be "running"
Dec 14 09:54:55.517: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477993ms
Dec 14 09:54:57.524: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.014018438s
Dec 14 09:54:57.524: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 12/14/22 09:54:57.524
Dec 14 09:55:02.651: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 12/14/22 09:55:02.651
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Dec 14 09:55:02.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9074" for this suite. 12/14/22 09:55:02.674
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":276,"skipped":5058,"failed":0}
------------------------------
• [9.263 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:54:53.419
    Dec 14 09:54:53.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename prestop 12/14/22 09:54:53.42
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:54:53.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:54:53.452
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-9074 12/14/22 09:54:53.463
    STEP: Waiting for pods to come up. 12/14/22 09:54:53.477
    Dec 14 09:54:53.477: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9074" to be "running"
    Dec 14 09:54:53.484: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 6.648706ms
    Dec 14 09:54:55.492: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.014775662s
    Dec 14 09:54:55.492: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-9074 12/14/22 09:54:55.499
    Dec 14 09:54:55.510: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9074" to be "running"
    Dec 14 09:54:55.517: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477993ms
    Dec 14 09:54:57.524: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.014018438s
    Dec 14 09:54:57.524: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 12/14/22 09:54:57.524
    Dec 14 09:55:02.651: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 12/14/22 09:55:02.651
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Dec 14 09:55:02.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-9074" for this suite. 12/14/22 09:55:02.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:02.683
Dec 14 09:55:02.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:55:02.684
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:02.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:02.716
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 09:55:06.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1059" for this suite. 12/14/22 09:55:06.77
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":277,"skipped":5073,"failed":0}
------------------------------
• [4.095 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:02.683
    Dec 14 09:55:02.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 09:55:02.684
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:02.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:02.716
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 09:55:06.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1059" for this suite. 12/14/22 09:55:06.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:06.78
Dec 14 09:55:06.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers 12/14/22 09:55:06.78
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:06.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:06.812
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 12/14/22 09:55:06.824
Dec 14 09:55:06.836: INFO: Waiting up to 5m0s for pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95" in namespace "containers-5197" to be "Succeeded or Failed"
Dec 14 09:55:06.843: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Pending", Reason="", readiness=false. Elapsed: 6.372494ms
Dec 14 09:55:08.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014766698s
Dec 14 09:55:10.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014191534s
STEP: Saw pod success 12/14/22 09:55:10.851
Dec 14 09:55:10.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95" satisfied condition "Succeeded or Failed"
Dec 14 09:55:10.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 09:55:10.897
Dec 14 09:55:10.907: INFO: Waiting for pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 to disappear
Dec 14 09:55:10.915: INFO: Pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Dec 14 09:55:10.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5197" for this suite. 12/14/22 09:55:10.927
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":278,"skipped":5115,"failed":0}
------------------------------
• [4.156 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:06.78
    Dec 14 09:55:06.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename containers 12/14/22 09:55:06.78
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:06.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:06.812
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 12/14/22 09:55:06.824
    Dec 14 09:55:06.836: INFO: Waiting up to 5m0s for pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95" in namespace "containers-5197" to be "Succeeded or Failed"
    Dec 14 09:55:06.843: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Pending", Reason="", readiness=false. Elapsed: 6.372494ms
    Dec 14 09:55:08.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014766698s
    Dec 14 09:55:10.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014191534s
    STEP: Saw pod success 12/14/22 09:55:10.851
    Dec 14 09:55:10.851: INFO: Pod "client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:10.858: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 09:55:10.897
    Dec 14 09:55:10.907: INFO: Waiting for pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 to disappear
    Dec 14 09:55:10.915: INFO: Pod client-containers-0a0ac6ec-ffca-46f1-99da-06f9000dca95 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Dec 14 09:55:10.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-5197" for this suite. 12/14/22 09:55:10.927
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:10.936
Dec 14 09:55:10.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 09:55:10.937
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:10.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:10.969
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-a63d76be-04f6-4b90-92e1-3532dc76a68e 12/14/22 09:55:10.98
STEP: Creating a pod to test consume secrets 12/14/22 09:55:10.987
Dec 14 09:55:11.001: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e" in namespace "projected-2335" to be "Succeeded or Failed"
Dec 14 09:55:11.008: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.88777ms
Dec 14 09:55:13.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01479617s
Dec 14 09:55:15.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014798383s
STEP: Saw pod success 12/14/22 09:55:15.016
Dec 14 09:55:15.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e" satisfied condition "Succeeded or Failed"
Dec 14 09:55:15.023: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e container projected-secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:55:15.041
Dec 14 09:55:15.051: INFO: Waiting for pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e to disappear
Dec 14 09:55:15.058: INFO: Pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 09:55:15.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2335" for this suite. 12/14/22 09:55:15.07
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":279,"skipped":5117,"failed":0}
------------------------------
• [4.144 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:10.936
    Dec 14 09:55:10.936: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 09:55:10.937
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:10.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:10.969
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-a63d76be-04f6-4b90-92e1-3532dc76a68e 12/14/22 09:55:10.98
    STEP: Creating a pod to test consume secrets 12/14/22 09:55:10.987
    Dec 14 09:55:11.001: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e" in namespace "projected-2335" to be "Succeeded or Failed"
    Dec 14 09:55:11.008: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.88777ms
    Dec 14 09:55:13.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01479617s
    Dec 14 09:55:15.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014798383s
    STEP: Saw pod success 12/14/22 09:55:15.016
    Dec 14 09:55:15.016: INFO: Pod "pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:15.023: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e container projected-secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:55:15.041
    Dec 14 09:55:15.051: INFO: Waiting for pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e to disappear
    Dec 14 09:55:15.058: INFO: Pod pod-projected-secrets-610261d2-d8e9-4ff9-a48c-41ef1750027e no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 09:55:15.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2335" for this suite. 12/14/22 09:55:15.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:15.08
Dec 14 09:55:15.080: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:55:15.081
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:15.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:15.115
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 12/14/22 09:55:15.133
Dec 14 09:55:15.134: INFO: Creating simple deployment test-deployment-jvwm6
Dec 14 09:55:15.154: INFO: deployment "test-deployment-jvwm6" doesn't have the required revision set
STEP: Getting /status 12/14/22 09:55:17.182
Dec 14 09:55:17.190: INFO: Deployment test-deployment-jvwm6 has Conditions: [{Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 12/14/22 09:55:17.19
Dec 14 09:55:17.206: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 55, 15, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-jvwm6-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 12/14/22 09:55:17.206
Dec 14 09:55:17.212: INFO: Observed &Deployment event: ADDED
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-jvwm6-777898ffcc" is progressing.}
Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
Dec 14 09:55:17.212: INFO: Found Deployment test-deployment-jvwm6 in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:55:17.213: INFO: Deployment test-deployment-jvwm6 has an updated status
STEP: patching the Statefulset Status 12/14/22 09:55:17.213
Dec 14 09:55:17.213: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 09:55:17.222: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 12/14/22 09:55:17.222
Dec 14 09:55:17.228: INFO: Observed &Deployment event: ADDED
Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
Dec 14 09:55:17.228: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 09:55:17.228: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-jvwm6-777898ffcc" is progressing.}
Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
Dec 14 09:55:17.229: INFO: Found deployment test-deployment-jvwm6 in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Dec 14 09:55:17.229: INFO: Deployment test-deployment-jvwm6 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:55:17.237: INFO: Deployment "test-deployment-jvwm6":
&Deployment{ObjectMeta:{test-deployment-jvwm6  deployment-2202  3050c692-9824-4844-9913-9e928ad51bb5 49857 1 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-14 09:55:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-14 09:55:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00556c258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 09:55:17 +0000 UTC,LastTransitionTime:2022-12-14 09:55:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.,LastUpdateTime:2022-12-14 09:55:17 +0000 UTC,LastTransitionTime:2022-12-14 09:55:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 09:55:17.244: INFO: New ReplicaSet "test-deployment-jvwm6-777898ffcc" of Deployment "test-deployment-jvwm6":
&ReplicaSet{ObjectMeta:{test-deployment-jvwm6-777898ffcc  deployment-2202  5e18733a-08dc-400a-9ca5-5584e6be7cc7 49848 1 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-jvwm6 3050c692-9824-4844-9913-9e928ad51bb5 0xc00556c6b0 0xc00556c6b1}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3050c692-9824-4844-9913-9e928ad51bb5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:55:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00556c758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:55:17.252: INFO: Pod "test-deployment-jvwm6-777898ffcc-7227t" is available:
&Pod{ObjectMeta:{test-deployment-jvwm6-777898ffcc-7227t test-deployment-jvwm6-777898ffcc- deployment-2202  9e89084b-7feb-46ef-8c34-a7987d24c0e4 49847 0 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:826af48e0e5ca1d31bd83ade7458a7b83001b00626d5d75786f2730f108b107a cni.projectcalico.org/podIP:172.16.0.172/32 cni.projectcalico.org/podIPs:172.16.0.172/32] [{apps/v1 ReplicaSet test-deployment-jvwm6-777898ffcc 5e18733a-08dc-400a-9ca5-5584e6be7cc7 0xc00556cb40 0xc00556cb41}] [] [{Go-http-client Update v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5e18733a-08dc-400a-9ca5-5584e6be7cc7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:55:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kqd2b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kqd2b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.172,StartTime:2022-12-14 09:55:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:55:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f4a1fefc6a5f0df7a562a693253e8d2201156f38aa7ca8dfa0a302833915b684,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:55:17.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2202" for this suite. 12/14/22 09:55:17.26
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":280,"skipped":5144,"failed":0}
------------------------------
• [2.188 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:15.08
    Dec 14 09:55:15.080: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:55:15.081
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:15.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:15.115
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 12/14/22 09:55:15.133
    Dec 14 09:55:15.134: INFO: Creating simple deployment test-deployment-jvwm6
    Dec 14 09:55:15.154: INFO: deployment "test-deployment-jvwm6" doesn't have the required revision set
    STEP: Getting /status 12/14/22 09:55:17.182
    Dec 14 09:55:17.190: INFO: Deployment test-deployment-jvwm6 has Conditions: [{Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 12/14/22 09:55:17.19
    Dec 14 09:55:17.206: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 9, 55, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 9, 55, 15, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-jvwm6-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 12/14/22 09:55:17.206
    Dec 14 09:55:17.212: INFO: Observed &Deployment event: ADDED
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
    Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-jvwm6-777898ffcc" is progressing.}
    Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
    Dec 14 09:55:17.212: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 09:55:17.212: INFO: Observed Deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
    Dec 14 09:55:17.212: INFO: Found Deployment test-deployment-jvwm6 in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:55:17.213: INFO: Deployment test-deployment-jvwm6 has an updated status
    STEP: patching the Statefulset Status 12/14/22 09:55:17.213
    Dec 14 09:55:17.213: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 09:55:17.222: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 12/14/22 09:55:17.222
    Dec 14 09:55:17.228: INFO: Observed &Deployment event: ADDED
    Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
    Dec 14 09:55:17.228: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-jvwm6-777898ffcc"}
    Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 09:55:17.228: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Dec 14 09:55:17.228: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:15 +0000 UTC 2022-12-14 09:55:15 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-jvwm6-777898ffcc" is progressing.}
    Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
    Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:16 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-12-14 09:55:16 +0000 UTC 2022-12-14 09:55:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.}
    Dec 14 09:55:17.229: INFO: Observed deployment test-deployment-jvwm6 in namespace deployment-2202 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:55:17.229: INFO: Observed &Deployment event: MODIFIED
    Dec 14 09:55:17.229: INFO: Found deployment test-deployment-jvwm6 in namespace deployment-2202 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Dec 14 09:55:17.229: INFO: Deployment test-deployment-jvwm6 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:55:17.237: INFO: Deployment "test-deployment-jvwm6":
    &Deployment{ObjectMeta:{test-deployment-jvwm6  deployment-2202  3050c692-9824-4844-9913-9e928ad51bb5 49857 1 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-12-14 09:55:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-12-14 09:55:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00556c258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 09:55:17 +0000 UTC,LastTransitionTime:2022-12-14 09:55:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-deployment-jvwm6-777898ffcc" has successfully progressed.,LastUpdateTime:2022-12-14 09:55:17 +0000 UTC,LastTransitionTime:2022-12-14 09:55:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 09:55:17.244: INFO: New ReplicaSet "test-deployment-jvwm6-777898ffcc" of Deployment "test-deployment-jvwm6":
    &ReplicaSet{ObjectMeta:{test-deployment-jvwm6-777898ffcc  deployment-2202  5e18733a-08dc-400a-9ca5-5584e6be7cc7 49848 1 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-jvwm6 3050c692-9824-4844-9913-9e928ad51bb5 0xc00556c6b0 0xc00556c6b1}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3050c692-9824-4844-9913-9e928ad51bb5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:55:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00556c758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:55:17.252: INFO: Pod "test-deployment-jvwm6-777898ffcc-7227t" is available:
    &Pod{ObjectMeta:{test-deployment-jvwm6-777898ffcc-7227t test-deployment-jvwm6-777898ffcc- deployment-2202  9e89084b-7feb-46ef-8c34-a7987d24c0e4 49847 0 2022-12-14 09:55:15 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:826af48e0e5ca1d31bd83ade7458a7b83001b00626d5d75786f2730f108b107a cni.projectcalico.org/podIP:172.16.0.172/32 cni.projectcalico.org/podIPs:172.16.0.172/32] [{apps/v1 ReplicaSet test-deployment-jvwm6-777898ffcc 5e18733a-08dc-400a-9ca5-5584e6be7cc7 0xc00556cb40 0xc00556cb41}] [] [{Go-http-client Update v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 09:55:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5e18733a-08dc-400a-9ca5-5584e6be7cc7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:55:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.172\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kqd2b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kqd2b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:55:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.172,StartTime:2022-12-14 09:55:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 09:55:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f4a1fefc6a5f0df7a562a693253e8d2201156f38aa7ca8dfa0a302833915b684,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.172,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:55:17.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2202" for this suite. 12/14/22 09:55:17.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:17.269
Dec 14 09:55:17.269: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 09:55:17.27
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:17.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:17.303
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Dec 14 09:55:17.315: INFO: Creating ReplicaSet my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a
Dec 14 09:55:17.329: INFO: Pod name my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Found 0 pods out of 1
Dec 14 09:55:22.336: INFO: Pod name my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Found 1 pods out of 1
Dec 14 09:55:22.336: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a" is running
Dec 14 09:55:22.336: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" in namespace "replicaset-6583" to be "running"
Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs": Phase="Running", Reason="", readiness=true. Elapsed: 7.550679ms
Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" satisfied condition "running"
Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:17 +0000 UTC Reason: Message:}])
Dec 14 09:55:22.344: INFO: Trying to dial the pod
Dec 14 09:55:27.475: INFO: Controller my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Got expected result from replica 1 [my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs]: "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 09:55:27.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6583" for this suite. 12/14/22 09:55:27.486
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":281,"skipped":5170,"failed":0}
------------------------------
• [10.227 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:17.269
    Dec 14 09:55:17.269: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 09:55:17.27
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:17.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:17.303
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Dec 14 09:55:17.315: INFO: Creating ReplicaSet my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a
    Dec 14 09:55:17.329: INFO: Pod name my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Found 0 pods out of 1
    Dec 14 09:55:22.336: INFO: Pod name my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Found 1 pods out of 1
    Dec 14 09:55:22.336: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a" is running
    Dec 14 09:55:22.336: INFO: Waiting up to 5m0s for pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" in namespace "replicaset-6583" to be "running"
    Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs": Phase="Running", Reason="", readiness=true. Elapsed: 7.550679ms
    Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" satisfied condition "running"
    Dec 14 09:55:22.344: INFO: Pod "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-12-14 09:55:17 +0000 UTC Reason: Message:}])
    Dec 14 09:55:22.344: INFO: Trying to dial the pod
    Dec 14 09:55:27.475: INFO: Controller my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a: Got expected result from replica 1 [my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs]: "my-hostname-basic-d90f914e-473c-4c6b-a0e0-64400f7fc87a-fcrvs", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 09:55:27.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6583" for this suite. 12/14/22 09:55:27.486
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:27.497
Dec 14 09:55:27.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:55:27.498
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:27.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:27.529
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 09:55:27.54
Dec 14 09:55:27.554: INFO: Waiting up to 5m0s for pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920" in namespace "emptydir-9408" to be "Succeeded or Failed"
Dec 14 09:55:27.560: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Pending", Reason="", readiness=false. Elapsed: 6.49002ms
Dec 14 09:55:29.569: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014983739s
Dec 14 09:55:31.568: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014306396s
STEP: Saw pod success 12/14/22 09:55:31.568
Dec 14 09:55:31.568: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920" satisfied condition "Succeeded or Failed"
Dec 14 09:55:31.575: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 container test-container: <nil>
STEP: delete the pod 12/14/22 09:55:31.593
Dec 14 09:55:31.603: INFO: Waiting for pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 to disappear
Dec 14 09:55:31.609: INFO: Pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:55:31.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9408" for this suite. 12/14/22 09:55:31.622
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":282,"skipped":5174,"failed":0}
------------------------------
• [4.133 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:27.497
    Dec 14 09:55:27.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:55:27.498
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:27.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:27.529
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 09:55:27.54
    Dec 14 09:55:27.554: INFO: Waiting up to 5m0s for pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920" in namespace "emptydir-9408" to be "Succeeded or Failed"
    Dec 14 09:55:27.560: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Pending", Reason="", readiness=false. Elapsed: 6.49002ms
    Dec 14 09:55:29.569: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014983739s
    Dec 14 09:55:31.568: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014306396s
    STEP: Saw pod success 12/14/22 09:55:31.568
    Dec 14 09:55:31.568: INFO: Pod "pod-a48ee4c0-2713-4234-80dd-f290546b1920" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:31.575: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 container test-container: <nil>
    STEP: delete the pod 12/14/22 09:55:31.593
    Dec 14 09:55:31.603: INFO: Waiting for pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 to disappear
    Dec 14 09:55:31.609: INFO: Pod pod-a48ee4c0-2713-4234-80dd-f290546b1920 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:55:31.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9408" for this suite. 12/14/22 09:55:31.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:31.63
Dec 14 09:55:31.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 09:55:31.631
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:31.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:31.662
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-18e2b8c3-8c49-41dd-9da9-b4bb1b19d79e 12/14/22 09:55:31.673
STEP: Creating a pod to test consume secrets 12/14/22 09:55:31.681
Dec 14 09:55:31.694: INFO: Waiting up to 5m0s for pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc" in namespace "secrets-8543" to be "Succeeded or Failed"
Dec 14 09:55:31.701: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.701053ms
Dec 14 09:55:33.709: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014566637s
Dec 14 09:55:35.709: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015383816s
STEP: Saw pod success 12/14/22 09:55:35.709
Dec 14 09:55:35.710: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc" satisfied condition "Succeeded or Failed"
Dec 14 09:55:35.716: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 09:55:35.734
Dec 14 09:55:35.745: INFO: Waiting for pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc to disappear
Dec 14 09:55:35.752: INFO: Pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 09:55:35.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8543" for this suite. 12/14/22 09:55:35.763
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":283,"skipped":5179,"failed":0}
------------------------------
• [4.140 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:31.63
    Dec 14 09:55:31.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 09:55:31.631
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:31.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:31.662
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-18e2b8c3-8c49-41dd-9da9-b4bb1b19d79e 12/14/22 09:55:31.673
    STEP: Creating a pod to test consume secrets 12/14/22 09:55:31.681
    Dec 14 09:55:31.694: INFO: Waiting up to 5m0s for pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc" in namespace "secrets-8543" to be "Succeeded or Failed"
    Dec 14 09:55:31.701: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.701053ms
    Dec 14 09:55:33.709: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014566637s
    Dec 14 09:55:35.709: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015383816s
    STEP: Saw pod success 12/14/22 09:55:35.709
    Dec 14 09:55:35.710: INFO: Pod "pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:35.716: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 09:55:35.734
    Dec 14 09:55:35.745: INFO: Waiting for pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc to disappear
    Dec 14 09:55:35.752: INFO: Pod pod-secrets-fb74fc8e-53fe-47de-9652-d542bfcaebdc no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 09:55:35.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8543" for this suite. 12/14/22 09:55:35.763
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:35.771
Dec 14 09:55:35.771: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota 12/14/22 09:55:35.772
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:35.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:35.803
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 12/14/22 09:55:35.814
STEP: Getting a ResourceQuota 12/14/22 09:55:35.823
STEP: Listing all ResourceQuotas with LabelSelector 12/14/22 09:55:35.83
STEP: Patching the ResourceQuota 12/14/22 09:55:35.837
STEP: Deleting a Collection of ResourceQuotas 12/14/22 09:55:35.846
STEP: Verifying the deleted ResourceQuota 12/14/22 09:55:35.855
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Dec 14 09:55:35.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1661" for this suite. 12/14/22 09:55:35.869
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":284,"skipped":5190,"failed":0}
------------------------------
• [0.106 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:35.771
    Dec 14 09:55:35.771: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename resourcequota 12/14/22 09:55:35.772
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:35.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:35.803
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 12/14/22 09:55:35.814
    STEP: Getting a ResourceQuota 12/14/22 09:55:35.823
    STEP: Listing all ResourceQuotas with LabelSelector 12/14/22 09:55:35.83
    STEP: Patching the ResourceQuota 12/14/22 09:55:35.837
    STEP: Deleting a Collection of ResourceQuotas 12/14/22 09:55:35.846
    STEP: Verifying the deleted ResourceQuota 12/14/22 09:55:35.855
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Dec 14 09:55:35.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1661" for this suite. 12/14/22 09:55:35.869
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:35.878
Dec 14 09:55:35.878: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:55:35.879
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:35.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:35.91
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:55:35.922
Dec 14 09:55:35.936: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0" in namespace "downward-api-9486" to be "Succeeded or Failed"
Dec 14 09:55:35.942: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.66615ms
Dec 14 09:55:37.950: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014310151s
Dec 14 09:55:39.951: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015474405s
STEP: Saw pod success 12/14/22 09:55:39.951
Dec 14 09:55:39.951: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0" satisfied condition "Succeeded or Failed"
Dec 14 09:55:39.958: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 container client-container: <nil>
STEP: delete the pod 12/14/22 09:55:39.976
Dec 14 09:55:39.987: INFO: Waiting for pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 to disappear
Dec 14 09:55:39.993: INFO: Pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:55:39.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9486" for this suite. 12/14/22 09:55:40.005
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":285,"skipped":5208,"failed":0}
------------------------------
• [4.136 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:35.878
    Dec 14 09:55:35.878: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:55:35.879
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:35.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:35.91
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:55:35.922
    Dec 14 09:55:35.936: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0" in namespace "downward-api-9486" to be "Succeeded or Failed"
    Dec 14 09:55:35.942: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.66615ms
    Dec 14 09:55:37.950: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014310151s
    Dec 14 09:55:39.951: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015474405s
    STEP: Saw pod success 12/14/22 09:55:39.951
    Dec 14 09:55:39.951: INFO: Pod "downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0" satisfied condition "Succeeded or Failed"
    Dec 14 09:55:39.958: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:55:39.976
    Dec 14 09:55:39.987: INFO: Waiting for pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 to disappear
    Dec 14 09:55:39.993: INFO: Pod downwardapi-volume-a32f0d84-4943-4369-a9af-df025fad42c0 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:55:39.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9486" for this suite. 12/14/22 09:55:40.005
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:40.014
Dec 14 09:55:40.014: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch 12/14/22 09:55:40.015
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.046
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 12/14/22 09:55:40.057
STEP: modifying the configmap once 12/14/22 09:55:40.065
STEP: modifying the configmap a second time 12/14/22 09:55:40.078
STEP: deleting the configmap 12/14/22 09:55:40.092
STEP: creating a watch on configmaps from the resource version returned by the first update 12/14/22 09:55:40.1
STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/14/22 09:55:40.105
Dec 14 09:55:40.105: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8485  db47c285-3972-4397-a40b-b6e1a98c7423 50071 0 2022-12-14 09:55:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:55:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Dec 14 09:55:40.105: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8485  db47c285-3972-4397-a40b-b6e1a98c7423 50072 0 2022-12-14 09:55:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:55:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Dec 14 09:55:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8485" for this suite. 12/14/22 09:55:40.113
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":286,"skipped":5208,"failed":0}
------------------------------
• [0.107 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:40.014
    Dec 14 09:55:40.014: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename watch 12/14/22 09:55:40.015
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.046
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 12/14/22 09:55:40.057
    STEP: modifying the configmap once 12/14/22 09:55:40.065
    STEP: modifying the configmap a second time 12/14/22 09:55:40.078
    STEP: deleting the configmap 12/14/22 09:55:40.092
    STEP: creating a watch on configmaps from the resource version returned by the first update 12/14/22 09:55:40.1
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 12/14/22 09:55:40.105
    Dec 14 09:55:40.105: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8485  db47c285-3972-4397-a40b-b6e1a98c7423 50071 0 2022-12-14 09:55:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:55:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Dec 14 09:55:40.105: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8485  db47c285-3972-4397-a40b-b6e1a98c7423 50072 0 2022-12-14 09:55:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-12-14 09:55:40 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Dec 14 09:55:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8485" for this suite. 12/14/22 09:55:40.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:40.122
Dec 14 09:55:40.122: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:55:40.123
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.155
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:55:40.173
Dec 14 09:55:40.186: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1262" to be "running and ready"
Dec 14 09:55:40.192: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092028ms
Dec 14 09:55:40.193: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:55:42.204: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.017246361s
Dec 14 09:55:42.204: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Dec 14 09:55:42.204: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 12/14/22 09:55:42.211
Dec 14 09:55:42.224: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1262" to be "running and ready"
Dec 14 09:55:42.230: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380108ms
Dec 14 09:55:42.230: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Dec 14 09:55:44.239: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015216861s
Dec 14 09:55:44.239: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Dec 14 09:55:44.239: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 12/14/22 09:55:44.246
STEP: delete the pod with lifecycle hook 12/14/22 09:55:44.311
Dec 14 09:55:44.319: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:55:44.325: INFO: Pod pod-with-poststart-http-hook still exists
Dec 14 09:55:46.326: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:55:46.333: INFO: Pod pod-with-poststart-http-hook still exists
Dec 14 09:55:48.327: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 14 09:55:48.334: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Dec 14 09:55:48.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1262" for this suite. 12/14/22 09:55:48.346
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":287,"skipped":5232,"failed":0}
------------------------------
• [8.232 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:40.122
    Dec 14 09:55:40.122: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename container-lifecycle-hook 12/14/22 09:55:40.123
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:40.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:40.155
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 12/14/22 09:55:40.173
    Dec 14 09:55:40.186: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1262" to be "running and ready"
    Dec 14 09:55:40.192: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092028ms
    Dec 14 09:55:40.193: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:55:42.204: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.017246361s
    Dec 14 09:55:42.204: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Dec 14 09:55:42.204: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 12/14/22 09:55:42.211
    Dec 14 09:55:42.224: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1262" to be "running and ready"
    Dec 14 09:55:42.230: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380108ms
    Dec 14 09:55:42.230: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 09:55:44.239: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015216861s
    Dec 14 09:55:44.239: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Dec 14 09:55:44.239: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 12/14/22 09:55:44.246
    STEP: delete the pod with lifecycle hook 12/14/22 09:55:44.311
    Dec 14 09:55:44.319: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:55:44.325: INFO: Pod pod-with-poststart-http-hook still exists
    Dec 14 09:55:46.326: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:55:46.333: INFO: Pod pod-with-poststart-http-hook still exists
    Dec 14 09:55:48.327: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Dec 14 09:55:48.334: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Dec 14 09:55:48.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1262" for this suite. 12/14/22 09:55:48.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:55:48.355
Dec 14 09:55:48.355: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 09:55:48.356
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:48.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:48.389
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6043 12/14/22 09:55:48.4
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-6043 12/14/22 09:55:48.414
Dec 14 09:55:48.428: INFO: Found 0 stateful pods, waiting for 1
Dec 14 09:55:58.436: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 12/14/22 09:55:58.45
STEP: Getting /status 12/14/22 09:55:58.458
Dec 14 09:55:58.466: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 12/14/22 09:55:58.466
Dec 14 09:55:58.482: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 12/14/22 09:55:58.482
Dec 14 09:55:58.488: INFO: Observed &StatefulSet event: ADDED
Dec 14 09:55:58.488: INFO: Found Statefulset ss in namespace statefulset-6043 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Dec 14 09:55:58.488: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 12/14/22 09:55:58.488
Dec 14 09:55:58.488: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Dec 14 09:55:58.498: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 12/14/22 09:55:58.498
Dec 14 09:55:58.504: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 09:55:58.504: INFO: Deleting all statefulset in ns statefulset-6043
Dec 14 09:55:58.510: INFO: Scaling statefulset ss to 0
Dec 14 09:56:08.543: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 09:56:08.550: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 09:56:08.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6043" for this suite. 12/14/22 09:56:08.595
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":288,"skipped":5244,"failed":0}
------------------------------
• [20.248 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:55:48.355
    Dec 14 09:55:48.355: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 09:55:48.356
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:55:48.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:55:48.389
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6043 12/14/22 09:55:48.4
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-6043 12/14/22 09:55:48.414
    Dec 14 09:55:48.428: INFO: Found 0 stateful pods, waiting for 1
    Dec 14 09:55:58.436: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 12/14/22 09:55:58.45
    STEP: Getting /status 12/14/22 09:55:58.458
    Dec 14 09:55:58.466: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 12/14/22 09:55:58.466
    Dec 14 09:55:58.482: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 12/14/22 09:55:58.482
    Dec 14 09:55:58.488: INFO: Observed &StatefulSet event: ADDED
    Dec 14 09:55:58.488: INFO: Found Statefulset ss in namespace statefulset-6043 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Dec 14 09:55:58.488: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 12/14/22 09:55:58.488
    Dec 14 09:55:58.488: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Dec 14 09:55:58.498: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 12/14/22 09:55:58.498
    Dec 14 09:55:58.504: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 09:55:58.504: INFO: Deleting all statefulset in ns statefulset-6043
    Dec 14 09:55:58.510: INFO: Scaling statefulset ss to 0
    Dec 14 09:56:08.543: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 09:56:08.550: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 09:56:08.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6043" for this suite. 12/14/22 09:56:08.595
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:08.605
Dec 14 09:56:08.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:56:08.606
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:08.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:08.638
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:56:08.666
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:56:09.035
STEP: Deploying the webhook pod 12/14/22 09:56:09.043
STEP: Wait for the deployment to be ready 12/14/22 09:56:09.058
Dec 14 09:56:09.072: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:56:11.093
STEP: Verifying the service has paired with the endpoint 12/14/22 09:56:11.104
Dec 14 09:56:12.104: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/14/22 09:56:12.111
STEP: create a pod that should be updated by the webhook 12/14/22 09:56:12.203
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:56:12.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2982" for this suite. 12/14/22 09:56:12.362
STEP: Destroying namespace "webhook-2982-markers" for this suite. 12/14/22 09:56:12.371
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":289,"skipped":5273,"failed":0}
------------------------------
• [3.812 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:08.605
    Dec 14 09:56:08.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:56:08.606
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:08.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:08.638
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:56:08.666
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:56:09.035
    STEP: Deploying the webhook pod 12/14/22 09:56:09.043
    STEP: Wait for the deployment to be ready 12/14/22 09:56:09.058
    Dec 14 09:56:09.072: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:56:11.093
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:56:11.104
    Dec 14 09:56:12.104: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 12/14/22 09:56:12.111
    STEP: create a pod that should be updated by the webhook 12/14/22 09:56:12.203
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:56:12.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2982" for this suite. 12/14/22 09:56:12.362
    STEP: Destroying namespace "webhook-2982-markers" for this suite. 12/14/22 09:56:12.371
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:12.417
Dec 14 09:56:12.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 09:56:12.418
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:12.438
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:12.449
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 12/14/22 09:56:12.461
STEP: setting up watch 12/14/22 09:56:12.461
STEP: submitting the pod to kubernetes 12/14/22 09:56:12.568
STEP: verifying the pod is in kubernetes 12/14/22 09:56:12.581
STEP: verifying pod creation was observed 12/14/22 09:56:12.588
Dec 14 09:56:12.589: INFO: Waiting up to 5m0s for pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23" in namespace "pods-9373" to be "running"
Dec 14 09:56:12.595: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542654ms
Dec 14 09:56:14.604: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23": Phase="Running", Reason="", readiness=true. Elapsed: 2.015198475s
Dec 14 09:56:14.604: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23" satisfied condition "running"
STEP: deleting the pod gracefully 12/14/22 09:56:14.615
STEP: verifying pod deletion was observed 12/14/22 09:56:14.623
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 09:56:16.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9373" for this suite. 12/14/22 09:56:16.419
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":290,"skipped":5281,"failed":0}
------------------------------
• [4.010 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:12.417
    Dec 14 09:56:12.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 09:56:12.418
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:12.438
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:12.449
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 12/14/22 09:56:12.461
    STEP: setting up watch 12/14/22 09:56:12.461
    STEP: submitting the pod to kubernetes 12/14/22 09:56:12.568
    STEP: verifying the pod is in kubernetes 12/14/22 09:56:12.581
    STEP: verifying pod creation was observed 12/14/22 09:56:12.588
    Dec 14 09:56:12.589: INFO: Waiting up to 5m0s for pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23" in namespace "pods-9373" to be "running"
    Dec 14 09:56:12.595: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23": Phase="Pending", Reason="", readiness=false. Elapsed: 6.542654ms
    Dec 14 09:56:14.604: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23": Phase="Running", Reason="", readiness=true. Elapsed: 2.015198475s
    Dec 14 09:56:14.604: INFO: Pod "pod-submit-remove-6a795915-2506-4d6f-bf21-a6a29ec48b23" satisfied condition "running"
    STEP: deleting the pod gracefully 12/14/22 09:56:14.615
    STEP: verifying pod deletion was observed 12/14/22 09:56:14.623
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 09:56:16.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9373" for this suite. 12/14/22 09:56:16.419
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:16.432
Dec 14 09:56:16.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 09:56:16.433
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:16.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:16.465
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 12/14/22 09:56:16.477
Dec 14 09:56:16.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3187 create -f -'
Dec 14 09:56:17.191: INFO: stderr: ""
Dec 14 09:56:17.191: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 09:56:17.191
Dec 14 09:56:18.199: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:56:18.253: INFO: Found 0 / 1
Dec 14 09:56:19.199: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:56:19.199: INFO: Found 1 / 1
Dec 14 09:56:19.199: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 12/14/22 09:56:19.199
Dec 14 09:56:19.206: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:56:19.207: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 09:56:19.207: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3187 patch pod agnhost-primary-d65kw -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 14 09:56:19.356: INFO: stderr: ""
Dec 14 09:56:19.356: INFO: stdout: "pod/agnhost-primary-d65kw patched\n"
STEP: checking annotations 12/14/22 09:56:19.356
Dec 14 09:56:19.363: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 09:56:19.363: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 09:56:19.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3187" for this suite. 12/14/22 09:56:19.375
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":291,"skipped":5306,"failed":0}
------------------------------
• [2.951 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:16.432
    Dec 14 09:56:16.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 09:56:16.433
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:16.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:16.465
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 12/14/22 09:56:16.477
    Dec 14 09:56:16.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3187 create -f -'
    Dec 14 09:56:17.191: INFO: stderr: ""
    Dec 14 09:56:17.191: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 09:56:17.191
    Dec 14 09:56:18.199: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:56:18.253: INFO: Found 0 / 1
    Dec 14 09:56:19.199: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:56:19.199: INFO: Found 1 / 1
    Dec 14 09:56:19.199: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 12/14/22 09:56:19.199
    Dec 14 09:56:19.206: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:56:19.207: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 09:56:19.207: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3187 patch pod agnhost-primary-d65kw -p {"metadata":{"annotations":{"x":"y"}}}'
    Dec 14 09:56:19.356: INFO: stderr: ""
    Dec 14 09:56:19.356: INFO: stdout: "pod/agnhost-primary-d65kw patched\n"
    STEP: checking annotations 12/14/22 09:56:19.356
    Dec 14 09:56:19.363: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 09:56:19.363: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 09:56:19.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3187" for this suite. 12/14/22 09:56:19.375
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:19.383
Dec 14 09:56:19.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 09:56:19.384
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:19.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:19.416
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 12/14/22 09:56:19.428
Dec 14 09:56:19.445: INFO: Waiting up to 5m0s for pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385" in namespace "var-expansion-3145" to be "Succeeded or Failed"
Dec 14 09:56:19.452: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Pending", Reason="", readiness=false. Elapsed: 6.825713ms
Dec 14 09:56:21.459: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014200272s
Dec 14 09:56:23.460: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014403632s
STEP: Saw pod success 12/14/22 09:56:23.46
Dec 14 09:56:23.460: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385" satisfied condition "Succeeded or Failed"
Dec 14 09:56:23.467: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 container dapi-container: <nil>
STEP: delete the pod 12/14/22 09:56:23.485
Dec 14 09:56:23.494: INFO: Waiting for pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 to disappear
Dec 14 09:56:23.501: INFO: Pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 09:56:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3145" for this suite. 12/14/22 09:56:23.513
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":292,"skipped":5309,"failed":0}
------------------------------
• [4.137 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:19.383
    Dec 14 09:56:19.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 09:56:19.384
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:19.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:19.416
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 12/14/22 09:56:19.428
    Dec 14 09:56:19.445: INFO: Waiting up to 5m0s for pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385" in namespace "var-expansion-3145" to be "Succeeded or Failed"
    Dec 14 09:56:19.452: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Pending", Reason="", readiness=false. Elapsed: 6.825713ms
    Dec 14 09:56:21.459: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014200272s
    Dec 14 09:56:23.460: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014403632s
    STEP: Saw pod success 12/14/22 09:56:23.46
    Dec 14 09:56:23.460: INFO: Pod "var-expansion-b3609e35-8537-4e25-89d7-30fd54653385" satisfied condition "Succeeded or Failed"
    Dec 14 09:56:23.467: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 09:56:23.485
    Dec 14 09:56:23.494: INFO: Waiting for pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 to disappear
    Dec 14 09:56:23.501: INFO: Pod var-expansion-b3609e35-8537-4e25-89d7-30fd54653385 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 09:56:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3145" for this suite. 12/14/22 09:56:23.513
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:56:23.522
Dec 14 09:56:23.522: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod 12/14/22 09:56:23.522
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:23.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:23.554
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Dec 14 09:56:23.566: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 09:57:23.629: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Dec 14 09:57:23.636: INFO: Starting informer...
STEP: Starting pod... 12/14/22 09:57:23.636
Dec 14 09:57:23.657: INFO: Pod is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
STEP: Trying to apply a taint on the Node 12/14/22 09:57:23.657
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:57:23.677
STEP: Waiting short time to make sure Pod is queued for deletion 12/14/22 09:57:23.684
Dec 14 09:57:23.684: INFO: Pod wasn't evicted. Proceeding
Dec 14 09:57:23.684: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:57:23.707
STEP: Waiting some time to make sure that toleration time passed. 12/14/22 09:57:23.713
Dec 14 09:58:38.717: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:58:38.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9946" for this suite. 12/14/22 09:58:38.73
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":293,"skipped":5340,"failed":0}
------------------------------
• [135.216 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:56:23.522
    Dec 14 09:56:23.522: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename taint-single-pod 12/14/22 09:56:23.522
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:56:23.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:56:23.554
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Dec 14 09:56:23.566: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 09:57:23.629: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Dec 14 09:57:23.636: INFO: Starting informer...
    STEP: Starting pod... 12/14/22 09:57:23.636
    Dec 14 09:57:23.657: INFO: Pod is running on izgw8jfcr55yi09nr0a5xaz. Tainting Node
    STEP: Trying to apply a taint on the Node 12/14/22 09:57:23.657
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:57:23.677
    STEP: Waiting short time to make sure Pod is queued for deletion 12/14/22 09:57:23.684
    Dec 14 09:57:23.684: INFO: Pod wasn't evicted. Proceeding
    Dec 14 09:57:23.684: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 12/14/22 09:57:23.707
    STEP: Waiting some time to make sure that toleration time passed. 12/14/22 09:57:23.713
    Dec 14 09:58:38.717: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:58:38.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-9946" for this suite. 12/14/22 09:58:38.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:38.739
Dec 14 09:58:38.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 09:58:38.74
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:38.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:38.774
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 12/14/22 09:58:38.785
Dec 14 09:58:38.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0" in namespace "downward-api-8947" to be "Succeeded or Failed"
Dec 14 09:58:38.808: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.086449ms
Dec 14 09:58:40.815: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014197947s
Dec 14 09:58:42.816: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015291268s
STEP: Saw pod success 12/14/22 09:58:42.816
Dec 14 09:58:42.816: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0" satisfied condition "Succeeded or Failed"
Dec 14 09:58:42.823: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 container client-container: <nil>
STEP: delete the pod 12/14/22 09:58:42.848
Dec 14 09:58:42.858: INFO: Waiting for pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 to disappear
Dec 14 09:58:42.865: INFO: Pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 09:58:42.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8947" for this suite. 12/14/22 09:58:42.876
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":294,"skipped":5374,"failed":0}
------------------------------
• [4.146 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:38.739
    Dec 14 09:58:38.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 09:58:38.74
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:38.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:38.774
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 12/14/22 09:58:38.785
    Dec 14 09:58:38.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0" in namespace "downward-api-8947" to be "Succeeded or Failed"
    Dec 14 09:58:38.808: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.086449ms
    Dec 14 09:58:40.815: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014197947s
    Dec 14 09:58:42.816: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015291268s
    STEP: Saw pod success 12/14/22 09:58:42.816
    Dec 14 09:58:42.816: INFO: Pod "downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0" satisfied condition "Succeeded or Failed"
    Dec 14 09:58:42.823: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 container client-container: <nil>
    STEP: delete the pod 12/14/22 09:58:42.848
    Dec 14 09:58:42.858: INFO: Waiting for pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 to disappear
    Dec 14 09:58:42.865: INFO: Pod downwardapi-volume-9f163fbd-967f-4c79-9a88-82039f3ae5a0 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 09:58:42.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8947" for this suite. 12/14/22 09:58:42.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:42.886
Dec 14 09:58:42.886: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 09:58:42.887
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:42.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:42.919
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 09:58:42.948
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:58:44.003
STEP: Deploying the webhook pod 12/14/22 09:58:44.016
STEP: Wait for the deployment to be ready 12/14/22 09:58:44.035
Dec 14 09:58:44.050: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 09:58:46.072
STEP: Verifying the service has paired with the endpoint 12/14/22 09:58:46.083
Dec 14 09:58:47.084: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 09:58:47.091
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 09:58:47.223
STEP: Creating a dummy validating-webhook-configuration object 12/14/22 09:58:47.355
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/14/22 09:58:47.463
STEP: Creating a dummy mutating-webhook-configuration object 12/14/22 09:58:47.471
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/14/22 09:58:47.543
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 09:58:47.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3331" for this suite. 12/14/22 09:58:47.578
STEP: Destroying namespace "webhook-3331-markers" for this suite. 12/14/22 09:58:47.586
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":295,"skipped":5389,"failed":0}
------------------------------
• [4.745 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:42.886
    Dec 14 09:58:42.886: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 09:58:42.887
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:42.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:42.919
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 09:58:42.948
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 09:58:44.003
    STEP: Deploying the webhook pod 12/14/22 09:58:44.016
    STEP: Wait for the deployment to be ready 12/14/22 09:58:44.035
    Dec 14 09:58:44.050: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 09:58:46.072
    STEP: Verifying the service has paired with the endpoint 12/14/22 09:58:46.083
    Dec 14 09:58:47.084: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 09:58:47.091
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 12/14/22 09:58:47.223
    STEP: Creating a dummy validating-webhook-configuration object 12/14/22 09:58:47.355
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 12/14/22 09:58:47.463
    STEP: Creating a dummy mutating-webhook-configuration object 12/14/22 09:58:47.471
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 12/14/22 09:58:47.543
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 09:58:47.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3331" for this suite. 12/14/22 09:58:47.578
    STEP: Destroying namespace "webhook-3331-markers" for this suite. 12/14/22 09:58:47.586
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:47.632
Dec 14 09:58:47.632: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:58:47.633
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:47.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:47.668
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Dec 14 09:58:47.686: INFO: Got root ca configmap in namespace "svcaccounts-7768"
Dec 14 09:58:47.694: INFO: Deleted root ca configmap in namespace "svcaccounts-7768"
STEP: waiting for a new root ca configmap created 12/14/22 09:58:48.194
Dec 14 09:58:48.201: INFO: Recreated root ca configmap in namespace "svcaccounts-7768"
Dec 14 09:58:48.209: INFO: Updated root ca configmap in namespace "svcaccounts-7768"
STEP: waiting for the root ca configmap reconciled 12/14/22 09:58:48.71
Dec 14 09:58:48.717: INFO: Reconciled root ca configmap in namespace "svcaccounts-7768"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Dec 14 09:58:48.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7768" for this suite. 12/14/22 09:58:48.728
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":296,"skipped":5389,"failed":0}
------------------------------
• [1.104 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:47.632
    Dec 14 09:58:47.632: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svcaccounts 12/14/22 09:58:47.633
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:47.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:47.668
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Dec 14 09:58:47.686: INFO: Got root ca configmap in namespace "svcaccounts-7768"
    Dec 14 09:58:47.694: INFO: Deleted root ca configmap in namespace "svcaccounts-7768"
    STEP: waiting for a new root ca configmap created 12/14/22 09:58:48.194
    Dec 14 09:58:48.201: INFO: Recreated root ca configmap in namespace "svcaccounts-7768"
    Dec 14 09:58:48.209: INFO: Updated root ca configmap in namespace "svcaccounts-7768"
    STEP: waiting for the root ca configmap reconciled 12/14/22 09:58:48.71
    Dec 14 09:58:48.717: INFO: Reconciled root ca configmap in namespace "svcaccounts-7768"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Dec 14 09:58:48.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-7768" for this suite. 12/14/22 09:58:48.728
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:48.737
Dec 14 09:58:48.737: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 09:58:48.738
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:48.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:48.769
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Dec 14 09:58:48.781: INFO: Creating deployment "test-recreate-deployment"
Dec 14 09:58:48.789: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 14 09:58:48.803: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 14 09:58:50.818: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 14 09:58:50.825: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 14 09:58:50.840: INFO: Updating deployment test-recreate-deployment
Dec 14 09:58:50.840: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 09:58:50.906: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1648  d0163d1c-303c-460c-991c-930f2467cede 51432 2 2022-12-14 09:58:48 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00335c198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:58:50 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-14 09:58:50 +0000 UTC,LastTransitionTime:2022-12-14 09:58:48 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 14 09:58:50.914: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1648  f2d2e04c-8992-4813-8a58-ddd559132fc9 51431 1 2022-12-14 09:58:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d0163d1c-303c-460c-991c-930f2467cede 0xc005304300 0xc005304301}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0163d1c-303c-460c-991c-930f2467cede\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005304398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:58:50.914: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 14 09:58:50.914: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1648  66a64096-faf8-48ad-8751-1cf74ea46bb2 51424 2 2022-12-14 09:58:48 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d0163d1c-303c-460c-991c-930f2467cede 0xc0053041e7 0xc0053041e8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0163d1c-303c-460c-991c-930f2467cede\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005304298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 09:58:50.922: INFO: Pod "test-recreate-deployment-9d58999df-jrsb6" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-jrsb6 test-recreate-deployment-9d58999df- deployment-1648  af924719-3192-4b99-9fe9-21413f536eeb 51433 0 2022-12-14 09:58:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f2d2e04c-8992-4813-8a58-ddd559132fc9 0xc00335c550 0xc00335c551}] [] [{kube-controller-manager Update v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2d2e04c-8992-4813-8a58-ddd559132fc9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4cv22,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4cv22,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:58:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 09:58:50.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1648" for this suite. 12/14/22 09:58:50.933
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":297,"skipped":5410,"failed":0}
------------------------------
• [2.210 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:48.737
    Dec 14 09:58:48.737: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 09:58:48.738
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:48.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:48.769
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Dec 14 09:58:48.781: INFO: Creating deployment "test-recreate-deployment"
    Dec 14 09:58:48.789: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Dec 14 09:58:48.803: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Dec 14 09:58:50.818: INFO: Waiting deployment "test-recreate-deployment" to complete
    Dec 14 09:58:50.825: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Dec 14 09:58:50.840: INFO: Updating deployment test-recreate-deployment
    Dec 14 09:58:50.840: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 09:58:50.906: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-1648  d0163d1c-303c-460c-991c-930f2467cede 51432 2 2022-12-14 09:58:48 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00335c198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-12-14 09:58:50 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-12-14 09:58:50 +0000 UTC,LastTransitionTime:2022-12-14 09:58:48 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Dec 14 09:58:50.914: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-1648  f2d2e04c-8992-4813-8a58-ddd559132fc9 51431 1 2022-12-14 09:58:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d0163d1c-303c-460c-991c-930f2467cede 0xc005304300 0xc005304301}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0163d1c-303c-460c-991c-930f2467cede\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005304398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:58:50.914: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Dec 14 09:58:50.914: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-1648  66a64096-faf8-48ad-8751-1cf74ea46bb2 51424 2 2022-12-14 09:58:48 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d0163d1c-303c-460c-991c-930f2467cede 0xc0053041e7 0xc0053041e8}] [] [{kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0163d1c-303c-460c-991c-930f2467cede\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005304298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 09:58:50.922: INFO: Pod "test-recreate-deployment-9d58999df-jrsb6" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-jrsb6 test-recreate-deployment-9d58999df- deployment-1648  af924719-3192-4b99-9fe9-21413f536eeb 51433 0 2022-12-14 09:58:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f2d2e04c-8992-4813-8a58-ddd559132fc9 0xc00335c550 0xc00335c551}] [] [{kube-controller-manager Update v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2d2e04c-8992-4813-8a58-ddd559132fc9\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 09:58:50 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4cv22,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4cv22,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 09:58:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:,StartTime:2022-12-14 09:58:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 09:58:50.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1648" for this suite. 12/14/22 09:58:50.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:50.947
Dec 14 09:58:50.948: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 09:58:50.949
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:50.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:50.987
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 09:58:50.999
Dec 14 09:58:51.013: INFO: Waiting up to 5m0s for pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c" in namespace "emptydir-1462" to be "Succeeded or Failed"
Dec 14 09:58:51.021: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.62454ms
Dec 14 09:58:53.028: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015070766s
Dec 14 09:58:55.028: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015412244s
STEP: Saw pod success 12/14/22 09:58:55.028
Dec 14 09:58:55.029: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c" satisfied condition "Succeeded or Failed"
Dec 14 09:58:55.035: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c container test-container: <nil>
STEP: delete the pod 12/14/22 09:58:55.065
Dec 14 09:58:55.077: INFO: Waiting for pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c to disappear
Dec 14 09:58:55.084: INFO: Pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 09:58:55.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1462" for this suite. 12/14/22 09:58:55.096
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":298,"skipped":5419,"failed":0}
------------------------------
• [4.157 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:50.947
    Dec 14 09:58:50.948: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 09:58:50.949
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:50.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:50.987
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 12/14/22 09:58:50.999
    Dec 14 09:58:51.013: INFO: Waiting up to 5m0s for pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c" in namespace "emptydir-1462" to be "Succeeded or Failed"
    Dec 14 09:58:51.021: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.62454ms
    Dec 14 09:58:53.028: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015070766s
    Dec 14 09:58:55.028: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015412244s
    STEP: Saw pod success 12/14/22 09:58:55.028
    Dec 14 09:58:55.029: INFO: Pod "pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c" satisfied condition "Succeeded or Failed"
    Dec 14 09:58:55.035: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c container test-container: <nil>
    STEP: delete the pod 12/14/22 09:58:55.065
    Dec 14 09:58:55.077: INFO: Waiting for pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c to disappear
    Dec 14 09:58:55.084: INFO: Pod pod-ad3a6436-e64b-49f8-808b-fe9b134dd86c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 09:58:55.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1462" for this suite. 12/14/22 09:58:55.096
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:55.105
Dec 14 09:58:55.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:58:55.106
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.144
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6725-delete-me 12/14/22 09:58:55.162
STEP: Waiting for the RuntimeClass to disappear 12/14/22 09:58:55.17
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 09:58:55.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6725" for this suite. 12/14/22 09:58:55.195
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":299,"skipped":5429,"failed":0}
------------------------------
• [0.098 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:55.105
    Dec 14 09:58:55.105: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 09:58:55.106
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.144
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6725-delete-me 12/14/22 09:58:55.162
    STEP: Waiting for the RuntimeClass to disappear 12/14/22 09:58:55.17
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 09:58:55.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6725" for this suite. 12/14/22 09:58:55.195
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:55.203
Dec 14 09:58:55.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces 12/14/22 09:58:55.204
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.247
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 12/14/22 09:58:55.259
STEP: patching the Namespace 12/14/22 09:58:55.279
STEP: get the Namespace and ensuring it has the label 12/14/22 09:58:55.286
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:58:55.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5295" for this suite. 12/14/22 09:58:55.304
STEP: Destroying namespace "nspatchtest-9a27bd7f-6c5a-44a1-a540-d9a8f14e38a2-8242" for this suite. 12/14/22 09:58:55.313
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":300,"skipped":5435,"failed":0}
------------------------------
• [0.118 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:55.203
    Dec 14 09:58:55.204: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename namespaces 12/14/22 09:58:55.204
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.247
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 12/14/22 09:58:55.259
    STEP: patching the Namespace 12/14/22 09:58:55.279
    STEP: get the Namespace and ensuring it has the label 12/14/22 09:58:55.286
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:58:55.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-5295" for this suite. 12/14/22 09:58:55.304
    STEP: Destroying namespace "nspatchtest-9a27bd7f-6c5a-44a1-a540-d9a8f14e38a2-8242" for this suite. 12/14/22 09:58:55.313
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:55.322
Dec 14 09:58:55.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename controllerrevisions 12/14/22 09:58:55.323
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.355
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-69bwb-daemon-set" 12/14/22 09:58:55.397
STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:58:55.405
Dec 14 09:58:55.418: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
Dec 14 09:58:55.418: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:58:56.438: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
Dec 14 09:58:56.438: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
Dec 14 09:58:57.437: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 2
Dec 14 09:58:57.437: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-69bwb-daemon-set
STEP: Confirm DaemonSet "e2e-69bwb-daemon-set" successfully created with "daemonset-name=e2e-69bwb-daemon-set" label 12/14/22 09:58:57.444
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-69bwb-daemon-set" 12/14/22 09:58:57.458
Dec 14 09:58:57.466: INFO: Located ControllerRevision: "e2e-69bwb-daemon-set-55645686c5"
STEP: Patching ControllerRevision "e2e-69bwb-daemon-set-55645686c5" 12/14/22 09:58:57.473
Dec 14 09:58:57.483: INFO: e2e-69bwb-daemon-set-55645686c5 has been patched
STEP: Create a new ControllerRevision 12/14/22 09:58:57.483
Dec 14 09:58:57.490: INFO: Created ControllerRevision: e2e-69bwb-daemon-set-85dd5586b7
STEP: Confirm that there are two ControllerRevisions 12/14/22 09:58:57.49
Dec 14 09:58:57.490: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 09:58:57.497: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-69bwb-daemon-set-55645686c5" 12/14/22 09:58:57.497
STEP: Confirm that there is only one ControllerRevision 12/14/22 09:58:57.505
Dec 14 09:58:57.505: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 09:58:57.511: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-69bwb-daemon-set-85dd5586b7" 12/14/22 09:58:57.518
Dec 14 09:58:57.532: INFO: e2e-69bwb-daemon-set-85dd5586b7 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 12/14/22 09:58:57.532
W1214 09:58:57.540518    6248 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 12/14/22 09:58:57.54
Dec 14 09:58:57.540: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 09:58:58.547: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 09:58:58.554: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-69bwb-daemon-set-85dd5586b7=updated" 12/14/22 09:58:58.554
STEP: Confirm that there is only one ControllerRevision 12/14/22 09:58:58.563
Dec 14 09:58:58.563: INFO: Requesting list of ControllerRevisions to confirm quantity
Dec 14 09:58:58.570: INFO: Found 1 ControllerRevisions
Dec 14 09:58:58.577: INFO: ControllerRevision "e2e-69bwb-daemon-set-7fc7d8fb66" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-69bwb-daemon-set" 12/14/22 09:58:58.584
STEP: deleting DaemonSet.extensions e2e-69bwb-daemon-set in namespace controllerrevisions-6718, will wait for the garbage collector to delete the pods 12/14/22 09:58:58.584
Dec 14 09:58:58.650: INFO: Deleting DaemonSet.extensions e2e-69bwb-daemon-set took: 8.130726ms
Dec 14 09:58:58.750: INFO: Terminating DaemonSet.extensions e2e-69bwb-daemon-set pods took: 100.382937ms
Dec 14 09:58:59.858: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
Dec 14 09:58:59.858: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-69bwb-daemon-set
Dec 14 09:58:59.865: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"51595"},"items":null}

Dec 14 09:58:59.872: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"51595"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Dec 14 09:58:59.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-6718" for this suite. 12/14/22 09:58:59.905
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":301,"skipped":5438,"failed":0}
------------------------------
• [4.591 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:55.322
    Dec 14 09:58:55.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename controllerrevisions 12/14/22 09:58:55.323
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:55.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:55.355
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-69bwb-daemon-set" 12/14/22 09:58:55.397
    STEP: Check that daemon pods launch on every node of the cluster. 12/14/22 09:58:55.405
    Dec 14 09:58:55.418: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
    Dec 14 09:58:55.418: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:58:56.438: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
    Dec 14 09:58:56.438: INFO: Node izgw86e9lj0cm6u1hvldynz is running 0 daemon pod, expected 1
    Dec 14 09:58:57.437: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 2
    Dec 14 09:58:57.437: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-69bwb-daemon-set
    STEP: Confirm DaemonSet "e2e-69bwb-daemon-set" successfully created with "daemonset-name=e2e-69bwb-daemon-set" label 12/14/22 09:58:57.444
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-69bwb-daemon-set" 12/14/22 09:58:57.458
    Dec 14 09:58:57.466: INFO: Located ControllerRevision: "e2e-69bwb-daemon-set-55645686c5"
    STEP: Patching ControllerRevision "e2e-69bwb-daemon-set-55645686c5" 12/14/22 09:58:57.473
    Dec 14 09:58:57.483: INFO: e2e-69bwb-daemon-set-55645686c5 has been patched
    STEP: Create a new ControllerRevision 12/14/22 09:58:57.483
    Dec 14 09:58:57.490: INFO: Created ControllerRevision: e2e-69bwb-daemon-set-85dd5586b7
    STEP: Confirm that there are two ControllerRevisions 12/14/22 09:58:57.49
    Dec 14 09:58:57.490: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 09:58:57.497: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-69bwb-daemon-set-55645686c5" 12/14/22 09:58:57.497
    STEP: Confirm that there is only one ControllerRevision 12/14/22 09:58:57.505
    Dec 14 09:58:57.505: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 09:58:57.511: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-69bwb-daemon-set-85dd5586b7" 12/14/22 09:58:57.518
    Dec 14 09:58:57.532: INFO: e2e-69bwb-daemon-set-85dd5586b7 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 12/14/22 09:58:57.532
    W1214 09:58:57.540518    6248 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 12/14/22 09:58:57.54
    Dec 14 09:58:57.540: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 09:58:58.547: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 09:58:58.554: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-69bwb-daemon-set-85dd5586b7=updated" 12/14/22 09:58:58.554
    STEP: Confirm that there is only one ControllerRevision 12/14/22 09:58:58.563
    Dec 14 09:58:58.563: INFO: Requesting list of ControllerRevisions to confirm quantity
    Dec 14 09:58:58.570: INFO: Found 1 ControllerRevisions
    Dec 14 09:58:58.577: INFO: ControllerRevision "e2e-69bwb-daemon-set-7fc7d8fb66" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-69bwb-daemon-set" 12/14/22 09:58:58.584
    STEP: deleting DaemonSet.extensions e2e-69bwb-daemon-set in namespace controllerrevisions-6718, will wait for the garbage collector to delete the pods 12/14/22 09:58:58.584
    Dec 14 09:58:58.650: INFO: Deleting DaemonSet.extensions e2e-69bwb-daemon-set took: 8.130726ms
    Dec 14 09:58:58.750: INFO: Terminating DaemonSet.extensions e2e-69bwb-daemon-set pods took: 100.382937ms
    Dec 14 09:58:59.858: INFO: Number of nodes with available pods controlled by daemonset e2e-69bwb-daemon-set: 0
    Dec 14 09:58:59.858: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-69bwb-daemon-set
    Dec 14 09:58:59.865: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"51595"},"items":null}

    Dec 14 09:58:59.872: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"51595"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 09:58:59.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-6718" for this suite. 12/14/22 09:58:59.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 09:58:59.916
Dec 14 09:58:59.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 09:58:59.917
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:59.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:59.949
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 09:58:59.987: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 10:00:00.058: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:00.065
Dec 14 10:00:00.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 10:00:00.066
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:00.086
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:00.097
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 12/14/22 10:00:00.108
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:00:00.108
Dec 14 10:00:00.122: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4226" to be "running"
Dec 14 10:00:00.135: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.093203ms
Dec 14 10:00:02.142: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.020330682s
Dec 14 10:00:02.142: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:00:02.149
Dec 14 10:00:02.159: INFO: found a healthy node: izgw8jfcr55yi09nr0a5xaz
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Dec 14 10:00:16.277: INFO: pods created so far: [1 1 1]
Dec 14 10:00:16.277: INFO: length of pods created so far: 3
Dec 14 10:00:18.296: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Dec 14 10:00:25.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4226" for this suite. 12/14/22 10:00:25.312
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:00:25.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3848" for this suite. 12/14/22 10:00:25.374
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":302,"skipped":5496,"failed":0}
------------------------------
• [85.519 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 09:58:59.916
    Dec 14 09:58:59.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 09:58:59.917
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 09:58:59.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 09:58:59.949
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 09:58:59.987: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 10:00:00.058: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:00.065
    Dec 14 10:00:00.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 10:00:00.066
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:00.086
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:00.097
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 12/14/22 10:00:00.108
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:00:00.108
    Dec 14 10:00:00.122: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-4226" to be "running"
    Dec 14 10:00:00.135: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 13.093203ms
    Dec 14 10:00:02.142: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.020330682s
    Dec 14 10:00:02.142: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:00:02.149
    Dec 14 10:00:02.159: INFO: found a healthy node: izgw8jfcr55yi09nr0a5xaz
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Dec 14 10:00:16.277: INFO: pods created so far: [1 1 1]
    Dec 14 10:00:16.277: INFO: length of pods created so far: 3
    Dec 14 10:00:18.296: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Dec 14 10:00:25.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-4226" for this suite. 12/14/22 10:00:25.312
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:00:25.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3848" for this suite. 12/14/22 10:00:25.374
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:25.436
Dec 14 10:00:25.436: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 10:00:25.437
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:25.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:25.469
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/14/22 10:00:25.481
Dec 14 10:00:25.496: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 14 10:00:30.502: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 10:00:30.502
STEP: getting scale subresource 12/14/22 10:00:30.502
STEP: updating a scale subresource 12/14/22 10:00:30.509
STEP: verifying the replicaset Spec.Replicas was modified 12/14/22 10:00:30.516
STEP: Patch a scale subresource 12/14/22 10:00:30.523
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 10:00:30.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7018" for this suite. 12/14/22 10:00:30.55
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":303,"skipped":5510,"failed":0}
------------------------------
• [5.124 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:25.436
    Dec 14 10:00:25.436: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 10:00:25.437
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:25.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:25.469
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 12/14/22 10:00:25.481
    Dec 14 10:00:25.496: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec 14 10:00:30.502: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 10:00:30.502
    STEP: getting scale subresource 12/14/22 10:00:30.502
    STEP: updating a scale subresource 12/14/22 10:00:30.509
    STEP: verifying the replicaset Spec.Replicas was modified 12/14/22 10:00:30.516
    STEP: Patch a scale subresource 12/14/22 10:00:30.523
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 10:00:30.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7018" for this suite. 12/14/22 10:00:30.55
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:30.559
Dec 14 10:00:30.560: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 10:00:30.561
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:30.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:30.592
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 12/14/22 10:00:30.603
Dec 14 10:00:30.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def" in namespace "projected-9232" to be "Succeeded or Failed"
Dec 14 10:00:30.623: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Pending", Reason="", readiness=false. Elapsed: 6.388364ms
Dec 14 10:00:32.631: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013793765s
Dec 14 10:00:34.632: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014692545s
STEP: Saw pod success 12/14/22 10:00:34.632
Dec 14 10:00:34.632: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def" satisfied condition "Succeeded or Failed"
Dec 14 10:00:34.639: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def container client-container: <nil>
STEP: delete the pod 12/14/22 10:00:34.657
Dec 14 10:00:34.668: INFO: Waiting for pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def to disappear
Dec 14 10:00:34.674: INFO: Pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 10:00:34.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9232" for this suite. 12/14/22 10:00:34.686
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":304,"skipped":5512,"failed":0}
------------------------------
• [4.135 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:30.559
    Dec 14 10:00:30.560: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 10:00:30.561
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:30.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:30.592
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 12/14/22 10:00:30.603
    Dec 14 10:00:30.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def" in namespace "projected-9232" to be "Succeeded or Failed"
    Dec 14 10:00:30.623: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Pending", Reason="", readiness=false. Elapsed: 6.388364ms
    Dec 14 10:00:32.631: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013793765s
    Dec 14 10:00:34.632: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014692545s
    STEP: Saw pod success 12/14/22 10:00:34.632
    Dec 14 10:00:34.632: INFO: Pod "downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def" satisfied condition "Succeeded or Failed"
    Dec 14 10:00:34.639: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def container client-container: <nil>
    STEP: delete the pod 12/14/22 10:00:34.657
    Dec 14 10:00:34.668: INFO: Waiting for pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def to disappear
    Dec 14 10:00:34.674: INFO: Pod downwardapi-volume-c0883c4e-3834-43bc-841d-4441b8f74def no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 10:00:34.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9232" for this suite. 12/14/22 10:00:34.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:00:34.695
Dec 14 10:00:34.695: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 10:00:34.696
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:34.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:34.727
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1495 12/14/22 10:00:34.739
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 12/14/22 10:00:34.746
Dec 14 10:00:34.760: INFO: Found 0 stateful pods, waiting for 3
Dec 14 10:00:44.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:00:44.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:00:44.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:00:44.790: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 10:00:45.360: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 10:00:45.360: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 10:00:45.360: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 10:00:55.401
Dec 14 10:00:55.432: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/14/22 10:00:55.432
STEP: Updating Pods in reverse ordinal order 12/14/22 10:01:05.462
Dec 14 10:01:05.469: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 10:01:06.068: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 10:01:06.068: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 10:01:06.068: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 12/14/22 10:01:26.11
Dec 14 10:01:26.110: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 14 10:01:26.723: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 14 10:01:26.723: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 14 10:01:26.723: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 14 10:01:36.778: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 12/14/22 10:01:46.806
Dec 14 10:01:46.813: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 14 10:01:47.357: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 14 10:01:47.357: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 14 10:01:47.357: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 10:01:57.405: INFO: Deleting all statefulset in ns statefulset-1495
Dec 14 10:01:57.412: INFO: Scaling statefulset ss2 to 0
Dec 14 10:02:07.443: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 10:02:07.450: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 10:02:07.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1495" for this suite. 12/14/22 10:02:07.483
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":305,"skipped":5517,"failed":0}
------------------------------
• [92.796 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:00:34.695
    Dec 14 10:00:34.695: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 10:00:34.696
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:00:34.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:00:34.727
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1495 12/14/22 10:00:34.739
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 12/14/22 10:00:34.746
    Dec 14 10:00:34.760: INFO: Found 0 stateful pods, waiting for 3
    Dec 14 10:00:44.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:00:44.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:00:44.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:00:44.790: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 10:00:45.360: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 10:00:45.360: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 10:00:45.360: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 10:00:55.401
    Dec 14 10:00:55.432: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/14/22 10:00:55.432
    STEP: Updating Pods in reverse ordinal order 12/14/22 10:01:05.462
    Dec 14 10:01:05.469: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 10:01:06.068: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 10:01:06.068: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 10:01:06.068: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 12/14/22 10:01:26.11
    Dec 14 10:01:26.110: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Dec 14 10:01:26.723: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Dec 14 10:01:26.723: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Dec 14 10:01:26.723: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Dec 14 10:01:36.778: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 12/14/22 10:01:46.806
    Dec 14 10:01:46.813: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=statefulset-1495 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Dec 14 10:01:47.357: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Dec 14 10:01:47.357: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Dec 14 10:01:47.357: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 10:01:57.405: INFO: Deleting all statefulset in ns statefulset-1495
    Dec 14 10:01:57.412: INFO: Scaling statefulset ss2 to 0
    Dec 14 10:02:07.443: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 10:02:07.450: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 10:02:07.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1495" for this suite. 12/14/22 10:02:07.483
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:02:07.491
Dec 14 10:02:07.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 10:02:07.492
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:07.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:07.524
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 10:02:07.536
Dec 14 10:02:07.559: INFO: Waiting up to 5m0s for pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677" in namespace "emptydir-9851" to be "Succeeded or Failed"
Dec 14 10:02:07.566: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Pending", Reason="", readiness=false. Elapsed: 6.502416ms
Dec 14 10:02:09.574: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014801659s
Dec 14 10:02:11.575: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01546799s
STEP: Saw pod success 12/14/22 10:02:11.575
Dec 14 10:02:11.575: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677" satisfied condition "Succeeded or Failed"
Dec 14 10:02:11.582: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 container test-container: <nil>
STEP: delete the pod 12/14/22 10:02:11.643
Dec 14 10:02:11.655: INFO: Waiting for pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 to disappear
Dec 14 10:02:11.662: INFO: Pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 10:02:11.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9851" for this suite. 12/14/22 10:02:11.674
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":306,"skipped":5517,"failed":0}
------------------------------
• [4.191 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:02:07.491
    Dec 14 10:02:07.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 10:02:07.492
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:07.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:07.524
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 12/14/22 10:02:07.536
    Dec 14 10:02:07.559: INFO: Waiting up to 5m0s for pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677" in namespace "emptydir-9851" to be "Succeeded or Failed"
    Dec 14 10:02:07.566: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Pending", Reason="", readiness=false. Elapsed: 6.502416ms
    Dec 14 10:02:09.574: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014801659s
    Dec 14 10:02:11.575: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01546799s
    STEP: Saw pod success 12/14/22 10:02:11.575
    Dec 14 10:02:11.575: INFO: Pod "pod-12d6088c-a930-48ad-8539-6a0ed1814677" satisfied condition "Succeeded or Failed"
    Dec 14 10:02:11.582: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 container test-container: <nil>
    STEP: delete the pod 12/14/22 10:02:11.643
    Dec 14 10:02:11.655: INFO: Waiting for pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 to disappear
    Dec 14 10:02:11.662: INFO: Pod pod-12d6088c-a930-48ad-8539-6a0ed1814677 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:02:11.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9851" for this suite. 12/14/22 10:02:11.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:02:11.683
Dec 14 10:02:11.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename podtemplate 12/14/22 10:02:11.684
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:11.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:11.715
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 12/14/22 10:02:11.727
STEP: Replace a pod template 12/14/22 10:02:11.735
Dec 14 10:02:11.749: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Dec 14 10:02:11.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4706" for this suite. 12/14/22 10:02:11.761
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":307,"skipped":5531,"failed":0}
------------------------------
• [0.086 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:02:11.683
    Dec 14 10:02:11.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename podtemplate 12/14/22 10:02:11.684
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:11.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:11.715
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 12/14/22 10:02:11.727
    STEP: Replace a pod template 12/14/22 10:02:11.735
    Dec 14 10:02:11.749: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Dec 14 10:02:11.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-4706" for this suite. 12/14/22 10:02:11.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:02:11.77
Dec 14 10:02:11.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred 12/14/22 10:02:11.77
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:11.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:11.802
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Dec 14 10:02:11.814: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 14 10:02:11.829: INFO: Waiting for terminating namespaces to be deleted...
Dec 14 10:02:11.835: INFO: 
Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
Dec 14 10:02:11.850: INFO: addons-nginx-ingress-controller-66dcb55f8b-cqwc8 from kube-system started at 2022-12-14 09:51:43 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 14 10:02:11.850: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec 14 10:02:11.850: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container proxy ready: true, restart count 0
Dec 14 10:02:11.850: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 10:02:11.850: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 10:02:11.850: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 10:02:11.850: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container calico-typha ready: true, restart count 0
Dec 14 10:02:11.850: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 10:02:11.850: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
Dec 14 10:02:11.850: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container coredns ready: true, restart count 0
Dec 14 10:02:11.850: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container coredns ready: true, restart count 0
Dec 14 10:02:11.850: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 10:02:11.850: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:02:11.850: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 10:02:11.850: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 10:02:11.850: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 10:02:11.850: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 10:02:11.850: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 10:02:11.850: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 10:02:11.850: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 10:02:11.850: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 10:02:11.850: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec 14 10:02:11.850: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec 14 10:02:11.850: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Dec 14 10:02:11.850: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.850: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 14 10:02:11.850: INFO: 
Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
Dec 14 10:02:11.867: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container proxy ready: true, restart count 0
Dec 14 10:02:11.867: INFO: 	Container sidecar ready: true, restart count 0
Dec 14 10:02:11.867: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 10:02:11.867: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec 14 10:02:11.867: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container calico-node ready: true, restart count 0
Dec 14 10:02:11.867: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec 14 10:02:11.867: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Dec 14 10:02:11.867: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 14 10:02:11.867: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container egress-filter-applier ready: true, restart count 1
Dec 14 10:02:11.867: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container conntrack-fix ready: true, restart count 0
Dec 14 10:02:11.867: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 14 10:02:11.867: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 10:02:11.867: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container metrics-server ready: true, restart count 2
Dec 14 10:02:11.867: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container network-problem-detector-host ready: true, restart count 0
Dec 14 10:02:11.867: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
Dec 14 10:02:11.867: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container node-exporter ready: true, restart count 0
Dec 14 10:02:11.867: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container node-cache ready: true, restart count 0
Dec 14 10:02:11.867: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
Dec 14 10:02:11.867: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:02:11.867
Dec 14 10:02:11.881: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-592" to be "running"
Dec 14 10:02:11.887: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.75765ms
Dec 14 10:02:13.896: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014871355s
Dec 14 10:02:13.896: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:02:13.903
STEP: Trying to apply a random label on the found node. 12/14/22 10:02:13.915
STEP: verifying the node has the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 42 12/14/22 10:02:13.957
STEP: Trying to relaunch the pod, now with labels. 12/14/22 10:02:13.965
Dec 14 10:02:13.978: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-592" to be "not pending"
Dec 14 10:02:13.984: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.408255ms
Dec 14 10:02:15.992: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.01400816s
Dec 14 10:02:15.992: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 10:02:15.999
STEP: verifying the node doesn't have the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 12/14/22 10:02:16.026
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:02:16.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-592" for this suite. 12/14/22 10:02:16.041
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":308,"skipped":5547,"failed":0}
------------------------------
• [4.280 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:02:11.77
    Dec 14 10:02:11.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-pred 12/14/22 10:02:11.77
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:11.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:11.802
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Dec 14 10:02:11.814: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Dec 14 10:02:11.829: INFO: Waiting for terminating namespaces to be deleted...
    Dec 14 10:02:11.835: INFO: 
    Logging pods the apiserver thinks is on node izgw86e9lj0cm6u1hvldynz before test
    Dec 14 10:02:11.850: INFO: addons-nginx-ingress-controller-66dcb55f8b-cqwc8 from kube-system started at 2022-12-14 09:51:43 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: apiserver-proxy-wcs5k from kube-system started at 2022-12-14 08:02:42 +0000 UTC (2 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: calico-node-79gdj from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: calico-node-vertical-autoscaler-6597dd8998-tsbck from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: calico-typha-deploy-65c54d4db6-6mdx6 from kube-system started at 2022-12-14 08:04:24 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container calico-typha ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: calico-typha-vertical-autoscaler-84df655c88-wlqx5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container autoscaler ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: coredns-859d4f7b5b-724vk from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: coredns-859d4f7b5b-zxww6 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container coredns ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: csi-disk-plugin-alicloud-mz6gw from kube-system started at 2022-12-14 08:02:42 +0000 UTC (3 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: egress-filter-applier-n76g2 from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 10:02:11.850: INFO: kube-proxy-worker-1-v1.25.4-4k5xr from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: network-problem-detector-host-zrqcc from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: network-problem-detector-pod-ms9lr from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: node-exporter-9qtdl from kube-system started at 2022-12-14 08:02:42 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: node-local-dns-bfkj9 from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: node-problem-detector-l92rw from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container node-problem-detector ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: vpn-shoot-5b86586f48-fbfm5 from kube-system started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container vpn-shoot ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: dashboard-metrics-scraper-6d54964d4b-jh2jz from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: kubernetes-dashboard-8494758d8f-lwknh from kubernetes-dashboard started at 2022-12-14 08:03:23 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.850: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Dec 14 10:02:11.850: INFO: 
    Logging pods the apiserver thinks is on node izgw8jfcr55yi09nr0a5xaz before test
    Dec 14 10:02:11.867: INFO: apiserver-proxy-xvwlm from kube-system started at 2022-12-14 08:02:50 +0000 UTC (2 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container proxy ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: 	Container sidecar ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: blackbox-exporter-59447f4c55-vzzfw from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: blackbox-exporter-59447f4c55-xvf4k from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: calico-node-9hshd from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container calico-node ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: csi-disk-plugin-alicloud-8lj7g from kube-system started at 2022-12-14 08:02:50 +0000 UTC (3 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container csi-diskplugin ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: 	Container driver-registrar ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: egress-filter-applier-7bxh8 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container egress-filter-applier ready: true, restart count 1
    Dec 14 10:02:11.867: INFO: kube-proxy-worker-1-v1.25.4-t5n5f from kube-system started at 2022-12-14 08:13:56 +0000 UTC (2 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container conntrack-fix ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: 	Container kube-proxy ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: metrics-server-5dc78cf6bb-bslwt from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 10:02:11.867: INFO: metrics-server-5dc78cf6bb-h4d4m from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container metrics-server ready: true, restart count 2
    Dec 14 10:02:11.867: INFO: network-problem-detector-host-b66xb from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container network-problem-detector-host ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: network-problem-detector-pod-w78cl from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container network-problem-detector-pod ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: node-exporter-27gn7 from kube-system started at 2022-12-14 08:02:50 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container node-exporter ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: node-local-dns-rh48z from kube-system started at 2022-12-14 08:17:57 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container node-cache ready: true, restart count 0
    Dec 14 10:02:11.867: INFO: node-problem-detector-nf5mp from kube-system started at 2022-12-14 08:53:56 +0000 UTC (1 container statuses recorded)
    Dec 14 10:02:11.867: INFO: 	Container node-problem-detector ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 12/14/22 10:02:11.867
    Dec 14 10:02:11.881: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-592" to be "running"
    Dec 14 10:02:11.887: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.75765ms
    Dec 14 10:02:13.896: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014871355s
    Dec 14 10:02:13.896: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 12/14/22 10:02:13.903
    STEP: Trying to apply a random label on the found node. 12/14/22 10:02:13.915
    STEP: verifying the node has the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 42 12/14/22 10:02:13.957
    STEP: Trying to relaunch the pod, now with labels. 12/14/22 10:02:13.965
    Dec 14 10:02:13.978: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-592" to be "not pending"
    Dec 14 10:02:13.984: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.408255ms
    Dec 14 10:02:15.992: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.01400816s
    Dec 14 10:02:15.992: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 off the node izgw8jfcr55yi09nr0a5xaz 12/14/22 10:02:15.999
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-34d385a6-2ba9-4c28-9042-f4f91cf184f3 12/14/22 10:02:16.026
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:02:16.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-592" for this suite. 12/14/22 10:02:16.041
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:02:16.05
Dec 14 10:02:16.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 10:02:16.051
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:16.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:16.084
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Dec 14 10:02:16.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod 12/14/22 10:02:16.096
STEP: submitting the pod to kubernetes 12/14/22 10:02:16.096
Dec 14 10:02:16.109: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37" in namespace "pods-2521" to be "running and ready"
Dec 14 10:02:16.116: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.429269ms
Dec 14 10:02:16.116: INFO: The phase of Pod pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:02:18.124: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37": Phase="Running", Reason="", readiness=true. Elapsed: 2.014833822s
Dec 14 10:02:18.124: INFO: The phase of Pod pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37 is Running (Ready = true)
Dec 14 10:02:18.124: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 10:02:18.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2521" for this suite. 12/14/22 10:02:18.35
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":309,"skipped":5554,"failed":0}
------------------------------
• [2.307 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:02:16.05
    Dec 14 10:02:16.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 10:02:16.051
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:16.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:16.084
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Dec 14 10:02:16.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating the pod 12/14/22 10:02:16.096
    STEP: submitting the pod to kubernetes 12/14/22 10:02:16.096
    Dec 14 10:02:16.109: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37" in namespace "pods-2521" to be "running and ready"
    Dec 14 10:02:16.116: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.429269ms
    Dec 14 10:02:16.116: INFO: The phase of Pod pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:02:18.124: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37": Phase="Running", Reason="", readiness=true. Elapsed: 2.014833822s
    Dec 14 10:02:18.124: INFO: The phase of Pod pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37 is Running (Ready = true)
    Dec 14 10:02:18.124: INFO: Pod "pod-exec-websocket-534bc773-ba2d-44a1-8048-1bdceda02f37" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 10:02:18.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2521" for this suite. 12/14/22 10:02:18.35
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:02:18.359
Dec 14 10:02:18.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 10:02:18.36
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:18.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:18.393
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 12/14/22 10:02:18.404
STEP: Ensuring more than one job is running at a time 12/14/22 10:02:18.412
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/14/22 10:04:00.419
STEP: Removing cronjob 12/14/22 10:04:00.427
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 10:04:00.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3902" for this suite. 12/14/22 10:04:00.446
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":310,"skipped":5573,"failed":0}
------------------------------
• [102.095 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:02:18.359
    Dec 14 10:02:18.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 10:02:18.36
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:02:18.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:02:18.393
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 12/14/22 10:02:18.404
    STEP: Ensuring more than one job is running at a time 12/14/22 10:02:18.412
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 12/14/22 10:04:00.419
    STEP: Removing cronjob 12/14/22 10:04:00.427
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 10:04:00.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3902" for this suite. 12/14/22 10:04:00.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:00.456
Dec 14 10:04:00.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:04:00.457
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:00.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:00.489
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 10:04:00.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9596" for this suite. 12/14/22 10:04:00.517
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":311,"skipped":5615,"failed":0}
------------------------------
• [0.069 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:00.456
    Dec 14 10:04:00.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:04:00.457
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:00.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:00.489
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 10:04:00.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9596" for this suite. 12/14/22 10:04:00.517
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:00.526
Dec 14 10:04:00.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:00.526
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:00.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:00.557
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 10:04:00.569
Dec 14 10:04:00.601: INFO: Waiting up to 5m0s for pod "pod-b492f062-808b-4c7b-9723-a83701f0274b" in namespace "emptydir-987" to be "Succeeded or Failed"
Dec 14 10:04:00.607: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.42455ms
Dec 14 10:04:02.615: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013673974s
Dec 14 10:04:04.615: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014464768s
STEP: Saw pod success 12/14/22 10:04:04.615
Dec 14 10:04:04.616: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b" satisfied condition "Succeeded or Failed"
Dec 14 10:04:04.622: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-b492f062-808b-4c7b-9723-a83701f0274b container test-container: <nil>
STEP: delete the pod 12/14/22 10:04:04.644
Dec 14 10:04:04.656: INFO: Waiting for pod pod-b492f062-808b-4c7b-9723-a83701f0274b to disappear
Dec 14 10:04:04.662: INFO: Pod pod-b492f062-808b-4c7b-9723-a83701f0274b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 10:04:04.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-987" for this suite. 12/14/22 10:04:04.674
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":312,"skipped":5631,"failed":0}
------------------------------
• [4.156 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:00.526
    Dec 14 10:04:00.526: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:00.526
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:00.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:00.557
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 12/14/22 10:04:00.569
    Dec 14 10:04:00.601: INFO: Waiting up to 5m0s for pod "pod-b492f062-808b-4c7b-9723-a83701f0274b" in namespace "emptydir-987" to be "Succeeded or Failed"
    Dec 14 10:04:00.607: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.42455ms
    Dec 14 10:04:02.615: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013673974s
    Dec 14 10:04:04.615: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014464768s
    STEP: Saw pod success 12/14/22 10:04:04.615
    Dec 14 10:04:04.616: INFO: Pod "pod-b492f062-808b-4c7b-9723-a83701f0274b" satisfied condition "Succeeded or Failed"
    Dec 14 10:04:04.622: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-b492f062-808b-4c7b-9723-a83701f0274b container test-container: <nil>
    STEP: delete the pod 12/14/22 10:04:04.644
    Dec 14 10:04:04.656: INFO: Waiting for pod pod-b492f062-808b-4c7b-9723-a83701f0274b to disappear
    Dec 14 10:04:04.662: INFO: Pod pod-b492f062-808b-4c7b-9723-a83701f0274b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:04:04.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-987" for this suite. 12/14/22 10:04:04.674
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:04.683
Dec 14 10:04:04.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:04.684
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:04.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:04.722
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 10:04:04.733
Dec 14 10:04:04.747: INFO: Waiting up to 5m0s for pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935" in namespace "emptydir-7374" to be "Succeeded or Failed"
Dec 14 10:04:04.754: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Pending", Reason="", readiness=false. Elapsed: 6.863513ms
Dec 14 10:04:06.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015554758s
Dec 14 10:04:08.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015768257s
STEP: Saw pod success 12/14/22 10:04:08.763
Dec 14 10:04:08.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935" satisfied condition "Succeeded or Failed"
Dec 14 10:04:08.770: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 container test-container: <nil>
STEP: delete the pod 12/14/22 10:04:08.788
Dec 14 10:04:08.799: INFO: Waiting for pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 to disappear
Dec 14 10:04:08.805: INFO: Pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 10:04:08.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7374" for this suite. 12/14/22 10:04:08.817
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":313,"skipped":5653,"failed":0}
------------------------------
• [4.142 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:04.683
    Dec 14 10:04:04.683: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:04.684
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:04.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:04.722
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 12/14/22 10:04:04.733
    Dec 14 10:04:04.747: INFO: Waiting up to 5m0s for pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935" in namespace "emptydir-7374" to be "Succeeded or Failed"
    Dec 14 10:04:04.754: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Pending", Reason="", readiness=false. Elapsed: 6.863513ms
    Dec 14 10:04:06.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015554758s
    Dec 14 10:04:08.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015768257s
    STEP: Saw pod success 12/14/22 10:04:08.763
    Dec 14 10:04:08.763: INFO: Pod "pod-7f9c38cf-7511-4dd5-ba11-623641ee5935" satisfied condition "Succeeded or Failed"
    Dec 14 10:04:08.770: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 container test-container: <nil>
    STEP: delete the pod 12/14/22 10:04:08.788
    Dec 14 10:04:08.799: INFO: Waiting for pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 to disappear
    Dec 14 10:04:08.805: INFO: Pod pod-7f9c38cf-7511-4dd5-ba11-623641ee5935 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:04:08.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7374" for this suite. 12/14/22 10:04:08.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:08.827
Dec 14 10:04:08.827: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 10:04:08.828
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:08.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:08.859
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 12/14/22 10:04:08.87
Dec 14 10:04:08.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62" in namespace "projected-6940" to be "Succeeded or Failed"
Dec 14 10:04:08.890: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.6305ms
Dec 14 10:04:10.898: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014607556s
Dec 14 10:04:12.899: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01562753s
STEP: Saw pod success 12/14/22 10:04:12.899
Dec 14 10:04:12.899: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62" satisfied condition "Succeeded or Failed"
Dec 14 10:04:12.906: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 container client-container: <nil>
STEP: delete the pod 12/14/22 10:04:12.925
Dec 14 10:04:12.937: INFO: Waiting for pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 to disappear
Dec 14 10:04:12.944: INFO: Pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Dec 14 10:04:12.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6940" for this suite. 12/14/22 10:04:12.955
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":314,"skipped":5697,"failed":0}
------------------------------
• [4.136 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:08.827
    Dec 14 10:04:08.827: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 10:04:08.828
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:08.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:08.859
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 12/14/22 10:04:08.87
    Dec 14 10:04:08.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62" in namespace "projected-6940" to be "Succeeded or Failed"
    Dec 14 10:04:08.890: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.6305ms
    Dec 14 10:04:10.898: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014607556s
    Dec 14 10:04:12.899: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01562753s
    STEP: Saw pod success 12/14/22 10:04:12.899
    Dec 14 10:04:12.899: INFO: Pod "downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62" satisfied condition "Succeeded or Failed"
    Dec 14 10:04:12.906: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 container client-container: <nil>
    STEP: delete the pod 12/14/22 10:04:12.925
    Dec 14 10:04:12.937: INFO: Waiting for pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 to disappear
    Dec 14 10:04:12.944: INFO: Pod downwardapi-volume-e744144e-184d-4893-a64b-711f4059ee62 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Dec 14 10:04:12.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6940" for this suite. 12/14/22 10:04:12.955
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:12.963
Dec 14 10:04:12.964: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 10:04:12.964
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:12.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:13.008
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 12/14/22 10:04:13.02
STEP: submitting the pod to kubernetes 12/14/22 10:04:13.02
STEP: verifying QOS class is set on the pod 12/14/22 10:04:13.035
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Dec 14 10:04:13.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9856" for this suite. 12/14/22 10:04:13.05
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":315,"skipped":5697,"failed":0}
------------------------------
• [0.094 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:12.963
    Dec 14 10:04:12.964: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 10:04:12.964
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:12.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:13.008
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 12/14/22 10:04:13.02
    STEP: submitting the pod to kubernetes 12/14/22 10:04:13.02
    STEP: verifying QOS class is set on the pod 12/14/22 10:04:13.035
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Dec 14 10:04:13.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9856" for this suite. 12/14/22 10:04:13.05
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:13.058
Dec 14 10:04:13.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 10:04:13.059
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:13.079
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:13.09
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-adab3e84-b979-4a48-8c40-c39e56d44252 12/14/22 10:04:13.102
STEP: Creating a pod to test consume configMaps 12/14/22 10:04:13.109
Dec 14 10:04:13.122: INFO: Waiting up to 5m0s for pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1" in namespace "configmap-6305" to be "Succeeded or Failed"
Dec 14 10:04:13.128: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066471ms
Dec 14 10:04:15.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013835139s
Dec 14 10:04:17.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013713774s
STEP: Saw pod success 12/14/22 10:04:17.136
Dec 14 10:04:17.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1" satisfied condition "Succeeded or Failed"
Dec 14 10:04:17.142: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 container agnhost-container: <nil>
STEP: delete the pod 12/14/22 10:04:17.161
Dec 14 10:04:17.175: INFO: Waiting for pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 to disappear
Dec 14 10:04:17.182: INFO: Pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 10:04:17.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6305" for this suite. 12/14/22 10:04:17.193
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":316,"skipped":5699,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:13.058
    Dec 14 10:04:13.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 10:04:13.059
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:13.079
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:13.09
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-adab3e84-b979-4a48-8c40-c39e56d44252 12/14/22 10:04:13.102
    STEP: Creating a pod to test consume configMaps 12/14/22 10:04:13.109
    Dec 14 10:04:13.122: INFO: Waiting up to 5m0s for pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1" in namespace "configmap-6305" to be "Succeeded or Failed"
    Dec 14 10:04:13.128: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066471ms
    Dec 14 10:04:15.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013835139s
    Dec 14 10:04:17.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013713774s
    STEP: Saw pod success 12/14/22 10:04:17.136
    Dec 14 10:04:17.136: INFO: Pod "pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1" satisfied condition "Succeeded or Failed"
    Dec 14 10:04:17.142: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 container agnhost-container: <nil>
    STEP: delete the pod 12/14/22 10:04:17.161
    Dec 14 10:04:17.175: INFO: Waiting for pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 to disappear
    Dec 14 10:04:17.182: INFO: Pod pod-configmaps-a21c84a8-85d8-47d3-94fa-44ee517a6ae1 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 10:04:17.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6305" for this suite. 12/14/22 10:04:17.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:17.202
Dec 14 10:04:17.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods 12/14/22 10:04:17.203
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:17.224
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:17.235
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 12/14/22 10:04:17.246
STEP: submitting the pod to kubernetes 12/14/22 10:04:17.247
Dec 14 10:04:17.261: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" in namespace "pods-7471" to be "running and ready"
Dec 14 10:04:17.268: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736194ms
Dec 14 10:04:17.268: INFO: The phase of Pod pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:19.276: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 2.015266366s
Dec 14 10:04:19.276: INFO: The phase of Pod pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80 is Running (Ready = true)
Dec 14 10:04:19.276: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 12/14/22 10:04:19.284
STEP: updating the pod 12/14/22 10:04:19.291
Dec 14 10:04:19.808: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80"
Dec 14 10:04:19.808: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" in namespace "pods-7471" to be "terminated with reason DeadlineExceeded"
Dec 14 10:04:19.814: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 6.243926ms
Dec 14 10:04:21.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 2.014601434s
Dec 14 10:04:23.823: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=false. Elapsed: 4.015178553s
Dec 14 10:04:25.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.014451265s
Dec 14 10:04:25.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Dec 14 10:04:25.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7471" for this suite. 12/14/22 10:04:25.834
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":317,"skipped":5737,"failed":0}
------------------------------
• [8.640 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:17.202
    Dec 14 10:04:17.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pods 12/14/22 10:04:17.203
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:17.224
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:17.235
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 12/14/22 10:04:17.246
    STEP: submitting the pod to kubernetes 12/14/22 10:04:17.247
    Dec 14 10:04:17.261: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" in namespace "pods-7471" to be "running and ready"
    Dec 14 10:04:17.268: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736194ms
    Dec 14 10:04:17.268: INFO: The phase of Pod pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:19.276: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 2.015266366s
    Dec 14 10:04:19.276: INFO: The phase of Pod pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80 is Running (Ready = true)
    Dec 14 10:04:19.276: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 12/14/22 10:04:19.284
    STEP: updating the pod 12/14/22 10:04:19.291
    Dec 14 10:04:19.808: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80"
    Dec 14 10:04:19.808: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" in namespace "pods-7471" to be "terminated with reason DeadlineExceeded"
    Dec 14 10:04:19.814: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 6.243926ms
    Dec 14 10:04:21.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=true. Elapsed: 2.014601434s
    Dec 14 10:04:23.823: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Running", Reason="", readiness=false. Elapsed: 4.015178553s
    Dec 14 10:04:25.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.014451265s
    Dec 14 10:04:25.822: INFO: Pod "pod-update-activedeadlineseconds-4a887354-b3ea-4e8e-95c8-6719b9806f80" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Dec 14 10:04:25.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7471" for this suite. 12/14/22 10:04:25.834
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:25.844
Dec 14 10:04:25.844: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test 12/14/22 10:04:25.845
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:25.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:25.878
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Dec 14 10:04:25.903: INFO: Waiting up to 5m0s for pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008" in namespace "kubelet-test-8320" to be "running and ready"
Dec 14 10:04:25.916: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008": Phase="Pending", Reason="", readiness=false. Elapsed: 13.710399ms
Dec 14 10:04:25.916: INFO: The phase of Pod busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:27.924: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008": Phase="Running", Reason="", readiness=true. Elapsed: 2.021342252s
Dec 14 10:04:27.924: INFO: The phase of Pod busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008 is Running (Ready = true)
Dec 14 10:04:27.924: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Dec 14 10:04:27.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8320" for this suite. 12/14/22 10:04:27.961
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":318,"skipped":5766,"failed":0}
------------------------------
• [2.125 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:25.844
    Dec 14 10:04:25.844: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubelet-test 12/14/22 10:04:25.845
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:25.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:25.878
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Dec 14 10:04:25.903: INFO: Waiting up to 5m0s for pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008" in namespace "kubelet-test-8320" to be "running and ready"
    Dec 14 10:04:25.916: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008": Phase="Pending", Reason="", readiness=false. Elapsed: 13.710399ms
    Dec 14 10:04:25.916: INFO: The phase of Pod busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:27.924: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008": Phase="Running", Reason="", readiness=true. Elapsed: 2.021342252s
    Dec 14 10:04:27.924: INFO: The phase of Pod busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008 is Running (Ready = true)
    Dec 14 10:04:27.924: INFO: Pod "busybox-scheduling-fa39ba98-e860-4e76-8ea6-f4bdb0955008" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Dec 14 10:04:27.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8320" for this suite. 12/14/22 10:04:27.961
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:27.97
Dec 14 10:04:27.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:27.97
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:27.991
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:28.002
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 10:04:28.013
Dec 14 10:04:28.031: INFO: Waiting up to 5m0s for pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c" in namespace "emptydir-2463" to be "Succeeded or Failed"
Dec 14 10:04:28.038: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.897793ms
Dec 14 10:04:30.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015198869s
Dec 14 10:04:32.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015135905s
STEP: Saw pod success 12/14/22 10:04:32.046
Dec 14 10:04:32.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c" satisfied condition "Succeeded or Failed"
Dec 14 10:04:32.053: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c container test-container: <nil>
STEP: delete the pod 12/14/22 10:04:32.072
Dec 14 10:04:32.083: INFO: Waiting for pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c to disappear
Dec 14 10:04:32.089: INFO: Pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 10:04:32.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2463" for this suite. 12/14/22 10:04:32.101
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":319,"skipped":5783,"failed":0}
------------------------------
• [4.139 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:27.97
    Dec 14 10:04:27.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 10:04:27.97
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:27.991
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:28.002
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 10:04:28.013
    Dec 14 10:04:28.031: INFO: Waiting up to 5m0s for pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c" in namespace "emptydir-2463" to be "Succeeded or Failed"
    Dec 14 10:04:28.038: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.897793ms
    Dec 14 10:04:30.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015198869s
    Dec 14 10:04:32.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015135905s
    STEP: Saw pod success 12/14/22 10:04:32.046
    Dec 14 10:04:32.046: INFO: Pod "pod-60a88d7b-d3da-4d84-a6e0-740e799b744c" satisfied condition "Succeeded or Failed"
    Dec 14 10:04:32.053: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c container test-container: <nil>
    STEP: delete the pod 12/14/22 10:04:32.072
    Dec 14 10:04:32.083: INFO: Waiting for pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c to disappear
    Dec 14 10:04:32.089: INFO: Pod pod-60a88d7b-d3da-4d84-a6e0-740e799b744c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:04:32.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2463" for this suite. 12/14/22 10:04:32.101
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:32.11
Dec 14 10:04:32.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostport 12/14/22 10:04:32.111
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:32.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:32.142
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/14/22 10:04:32.16
Dec 14 10:04:32.174: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-9224" to be "running and ready"
Dec 14 10:04:32.180: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.350992ms
Dec 14 10:04:32.180: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:34.187: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013554603s
Dec 14 10:04:34.187: INFO: The phase of Pod pod1 is Running (Ready = true)
Dec 14 10:04:34.187: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.18.71 on the node which pod1 resides and expect scheduled 12/14/22 10:04:34.187
Dec 14 10:04:34.199: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-9224" to be "running and ready"
Dec 14 10:04:34.206: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.952541ms
Dec 14 10:04:34.206: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:36.213: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013861851s
Dec 14 10:04:36.213: INFO: The phase of Pod pod2 is Running (Ready = true)
Dec 14 10:04:36.213: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.18.71 but use UDP protocol on the node which pod2 resides 12/14/22 10:04:36.213
Dec 14 10:04:36.224: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-9224" to be "running and ready"
Dec 14 10:04:36.231: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.539409ms
Dec 14 10:04:36.231: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:38.239: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.014543047s
Dec 14 10:04:38.239: INFO: The phase of Pod pod3 is Running (Ready = true)
Dec 14 10:04:38.239: INFO: Pod "pod3" satisfied condition "running and ready"
Dec 14 10:04:38.251: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-9224" to be "running and ready"
Dec 14 10:04:38.257: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.199255ms
Dec 14 10:04:38.257: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:04:40.265: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.014510596s
Dec 14 10:04:40.266: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Dec 14 10:04:40.266: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/14/22 10:04:40.273
Dec 14 10:04:40.273: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.18.71 http://127.0.0.1:54323/hostname] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 10:04:40.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:04:40.273: INFO: ExecWithOptions: Clientset creation
Dec 14 10:04:40.274: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.18.71+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.18.71, port: 54323 12/14/22 10:04:40.61
Dec 14 10:04:40.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.18.71:54323/hostname] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 10:04:40.610: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:04:40.610: INFO: ExecWithOptions: Clientset creation
Dec 14 10:04:40.610: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.18.71%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.18.71, port: 54323 UDP 12/14/22 10:04:41.111
Dec 14 10:04:41.111: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.18.71 54323] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 10:04:41.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:04:41.112: INFO: ExecWithOptions: Clientset creation
Dec 14 10:04:41.112: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.18.71+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Dec 14 10:04:46.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-9224" for this suite. 12/14/22 10:04:46.353
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":320,"skipped":5795,"failed":0}
------------------------------
• [14.252 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:32.11
    Dec 14 10:04:32.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename hostport 12/14/22 10:04:32.111
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:32.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:32.142
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 12/14/22 10:04:32.16
    Dec 14 10:04:32.174: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-9224" to be "running and ready"
    Dec 14 10:04:32.180: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.350992ms
    Dec 14 10:04:32.180: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:34.187: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013554603s
    Dec 14 10:04:34.187: INFO: The phase of Pod pod1 is Running (Ready = true)
    Dec 14 10:04:34.187: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.18.71 on the node which pod1 resides and expect scheduled 12/14/22 10:04:34.187
    Dec 14 10:04:34.199: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-9224" to be "running and ready"
    Dec 14 10:04:34.206: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.952541ms
    Dec 14 10:04:34.206: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:36.213: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013861851s
    Dec 14 10:04:36.213: INFO: The phase of Pod pod2 is Running (Ready = true)
    Dec 14 10:04:36.213: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.18.71 but use UDP protocol on the node which pod2 resides 12/14/22 10:04:36.213
    Dec 14 10:04:36.224: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-9224" to be "running and ready"
    Dec 14 10:04:36.231: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.539409ms
    Dec 14 10:04:36.231: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:38.239: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.014543047s
    Dec 14 10:04:38.239: INFO: The phase of Pod pod3 is Running (Ready = true)
    Dec 14 10:04:38.239: INFO: Pod "pod3" satisfied condition "running and ready"
    Dec 14 10:04:38.251: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-9224" to be "running and ready"
    Dec 14 10:04:38.257: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.199255ms
    Dec 14 10:04:38.257: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:04:40.265: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.014510596s
    Dec 14 10:04:40.266: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Dec 14 10:04:40.266: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 12/14/22 10:04:40.273
    Dec 14 10:04:40.273: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.18.71 http://127.0.0.1:54323/hostname] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 10:04:40.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:04:40.273: INFO: ExecWithOptions: Clientset creation
    Dec 14 10:04:40.274: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.18.71+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.18.71, port: 54323 12/14/22 10:04:40.61
    Dec 14 10:04:40.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.18.71:54323/hostname] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 10:04:40.610: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:04:40.610: INFO: ExecWithOptions: Clientset creation
    Dec 14 10:04:40.610: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.18.71%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.18.71, port: 54323 UDP 12/14/22 10:04:41.111
    Dec 14 10:04:41.111: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.18.71 54323] Namespace:hostport-9224 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 10:04:41.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:04:41.112: INFO: ExecWithOptions: Clientset creation
    Dec 14 10:04:41.112: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/hostport-9224/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.18.71+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Dec 14 10:04:46.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-9224" for this suite. 12/14/22 10:04:46.353
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:46.362
Dec 14 10:04:46.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:04:46.363
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:46.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:46.395
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Dec 14 10:04:46.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/14/22 10:04:49.412
Dec 14 10:04:49.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
Dec 14 10:04:50.132: INFO: stderr: ""
Dec 14 10:04:50.132: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 14 10:04:50.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-9426-crds test-foo'
Dec 14 10:04:50.245: INFO: stderr: ""
Dec 14 10:04:50.245: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 14 10:04:50.245: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
Dec 14 10:04:50.942: INFO: stderr: ""
Dec 14 10:04:50.942: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 14 10:04:50.942: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-9426-crds test-foo'
Dec 14 10:04:51.037: INFO: stderr: ""
Dec 14 10:04:51.037: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/14/22 10:04:51.037
Dec 14 10:04:51.038: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
Dec 14 10:04:51.277: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/14/22 10:04:51.277
Dec 14 10:04:51.277: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
Dec 14 10:04:51.491: INFO: rc: 1
Dec 14 10:04:51.491: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
Dec 14 10:04:51.726: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/14/22 10:04:51.726
Dec 14 10:04:51.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
Dec 14 10:04:51.971: INFO: rc: 1
Dec 14 10:04:51.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
Dec 14 10:04:52.203: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 12/14/22 10:04:52.204
Dec 14 10:04:52.204: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds'
Dec 14 10:04:52.438: INFO: stderr: ""
Dec 14 10:04:52.438: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 12/14/22 10:04:52.438
Dec 14 10:04:52.438: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.metadata'
Dec 14 10:04:52.658: INFO: stderr: ""
Dec 14 10:04:52.658: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 14 10:04:52.659: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec'
Dec 14 10:04:52.906: INFO: stderr: ""
Dec 14 10:04:52.906: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 14 10:04:52.906: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec.bars'
Dec 14 10:04:53.128: INFO: stderr: ""
Dec 14 10:04:53.128: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/14/22 10:04:53.128
Dec 14 10:04:53.128: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec.bars2'
Dec 14 10:04:53.359: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:04:57.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4199" for this suite. 12/14/22 10:04:57.303
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":321,"skipped":5801,"failed":0}
------------------------------
• [10.953 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:46.362
    Dec 14 10:04:46.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:04:46.363
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:46.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:46.395
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Dec 14 10:04:46.406: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 12/14/22 10:04:49.412
    Dec 14 10:04:49.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
    Dec 14 10:04:50.132: INFO: stderr: ""
    Dec 14 10:04:50.132: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec 14 10:04:50.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-9426-crds test-foo'
    Dec 14 10:04:50.245: INFO: stderr: ""
    Dec 14 10:04:50.245: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Dec 14 10:04:50.245: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
    Dec 14 10:04:50.942: INFO: stderr: ""
    Dec 14 10:04:50.942: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Dec 14 10:04:50.942: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-9426-crds test-foo'
    Dec 14 10:04:51.037: INFO: stderr: ""
    Dec 14 10:04:51.037: INFO: stdout: "e2e-test-crd-publish-openapi-9426-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 12/14/22 10:04:51.037
    Dec 14 10:04:51.038: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
    Dec 14 10:04:51.277: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 12/14/22 10:04:51.277
    Dec 14 10:04:51.277: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
    Dec 14 10:04:51.491: INFO: rc: 1
    Dec 14 10:04:51.491: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
    Dec 14 10:04:51.726: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 12/14/22 10:04:51.726
    Dec 14 10:04:51.726: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 create -f -'
    Dec 14 10:04:51.971: INFO: rc: 1
    Dec 14 10:04:51.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 --namespace=crd-publish-openapi-4199 apply -f -'
    Dec 14 10:04:52.203: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 12/14/22 10:04:52.204
    Dec 14 10:04:52.204: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds'
    Dec 14 10:04:52.438: INFO: stderr: ""
    Dec 14 10:04:52.438: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 12/14/22 10:04:52.438
    Dec 14 10:04:52.438: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.metadata'
    Dec 14 10:04:52.658: INFO: stderr: ""
    Dec 14 10:04:52.658: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Dec 14 10:04:52.659: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec'
    Dec 14 10:04:52.906: INFO: stderr: ""
    Dec 14 10:04:52.906: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Dec 14 10:04:52.906: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec.bars'
    Dec 14 10:04:53.128: INFO: stderr: ""
    Dec 14 10:04:53.128: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9426-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 12/14/22 10:04:53.128
    Dec 14 10:04:53.128: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-4199 explain e2e-test-crd-publish-openapi-9426-crds.spec.bars2'
    Dec 14 10:04:53.359: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:04:57.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4199" for this suite. 12/14/22 10:04:57.303
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:04:57.315
Dec 14 10:04:57.316: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 10:04:57.316
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:57.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:57.375
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 12/14/22 10:04:57.397
Dec 14 10:04:57.414: INFO: Waiting up to 5m0s for pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b" in namespace "downward-api-1963" to be "Succeeded or Failed"
Dec 14 10:04:57.426: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.227227ms
Dec 14 10:04:59.439: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02440058s
Dec 14 10:05:01.439: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024799714s
STEP: Saw pod success 12/14/22 10:05:01.439
Dec 14 10:05:01.441: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b" satisfied condition "Succeeded or Failed"
Dec 14 10:05:01.453: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b container dapi-container: <nil>
STEP: delete the pod 12/14/22 10:05:01.476
Dec 14 10:05:01.492: INFO: Waiting for pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b to disappear
Dec 14 10:05:01.503: INFO: Pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Dec 14 10:05:01.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1963" for this suite. 12/14/22 10:05:01.525
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":322,"skipped":5807,"failed":0}
------------------------------
• [4.223 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:04:57.315
    Dec 14 10:04:57.316: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 10:04:57.316
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:04:57.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:04:57.375
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 12/14/22 10:04:57.397
    Dec 14 10:04:57.414: INFO: Waiting up to 5m0s for pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b" in namespace "downward-api-1963" to be "Succeeded or Failed"
    Dec 14 10:04:57.426: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.227227ms
    Dec 14 10:04:59.439: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02440058s
    Dec 14 10:05:01.439: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024799714s
    STEP: Saw pod success 12/14/22 10:05:01.439
    Dec 14 10:05:01.441: INFO: Pod "downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b" satisfied condition "Succeeded or Failed"
    Dec 14 10:05:01.453: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b container dapi-container: <nil>
    STEP: delete the pod 12/14/22 10:05:01.476
    Dec 14 10:05:01.492: INFO: Waiting for pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b to disappear
    Dec 14 10:05:01.503: INFO: Pod downward-api-e6761a39-aca6-4331-8755-0a832dc9db5b no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Dec 14 10:05:01.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1963" for this suite. 12/14/22 10:05:01.525
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:01.539
Dec 14 10:05:01.539: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:05:01.54
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:01.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:01.598
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Dec 14 10:05:01.654: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4390 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Dec 14 10:05:01.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4390" for this suite. 12/14/22 10:05:01.693
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":323,"skipped":5828,"failed":0}
------------------------------
• [0.167 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:01.539
    Dec 14 10:05:01.539: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename runtimeclass 12/14/22 10:05:01.54
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:01.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:01.598
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Dec 14 10:05:01.654: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4390 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Dec 14 10:05:01.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4390" for this suite. 12/14/22 10:05:01.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:01.707
Dec 14 10:05:01.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename lease-test 12/14/22 10:05:01.708
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:01.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:01.766
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Dec 14 10:05:01.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2631" for this suite. 12/14/22 10:05:01.966
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":324,"skipped":5846,"failed":0}
------------------------------
• [0.274 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:01.707
    Dec 14 10:05:01.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename lease-test 12/14/22 10:05:01.708
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:01.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:01.766
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Dec 14 10:05:01.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-2631" for this suite. 12/14/22 10:05:01.966
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:01.981
Dec 14 10:05:01.981: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test 12/14/22 10:05:01.982
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:02.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:02.042
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-7503 12/14/22 10:05:02.064
STEP: creating a selector 12/14/22 10:05:02.064
STEP: Creating the service pods in kubernetes 12/14/22 10:05:02.064
Dec 14 10:05:02.064: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Dec 14 10:05:02.125: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7503" to be "running and ready"
Dec 14 10:05:02.137: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.512111ms
Dec 14 10:05:02.137: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:05:04.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.024585085s
Dec 14 10:05:04.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 10:05:06.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.024355662s
Dec 14 10:05:06.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 10:05:08.152: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.026165859s
Dec 14 10:05:08.152: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 10:05:10.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.024350264s
Dec 14 10:05:10.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 10:05:12.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02472928s
Dec 14 10:05:12.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Dec 14 10:05:14.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.024502346s
Dec 14 10:05:14.150: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Dec 14 10:05:14.150: INFO: Pod "netserver-0" satisfied condition "running and ready"
Dec 14 10:05:14.161: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7503" to be "running and ready"
Dec 14 10:05:14.172: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.179608ms
Dec 14 10:05:14.172: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Dec 14 10:05:14.172: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 12/14/22 10:05:14.184
Dec 14 10:05:14.215: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7503" to be "running"
Dec 14 10:05:14.226: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.779278ms
Dec 14 10:05:16.238: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023821123s
Dec 14 10:05:16.238: INFO: Pod "test-container-pod" satisfied condition "running"
Dec 14 10:05:16.250: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7503" to be "running"
Dec 14 10:05:16.262: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.662697ms
Dec 14 10:05:16.262: INFO: Pod "host-test-container-pod" satisfied condition "running"
Dec 14 10:05:16.274: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Dec 14 10:05:16.274: INFO: Going to poll 172.16.1.193 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 14 10:05:16.286: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.1.193:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7503 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 10:05:16.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:05:16.286: INFO: ExecWithOptions: Clientset creation
Dec 14 10:05:16.287: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-7503/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.1.193%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 10:05:16.754: INFO: Found all 1 expected endpoints: [netserver-0]
Dec 14 10:05:16.754: INFO: Going to poll 172.16.0.215 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Dec 14 10:05:16.766: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.215:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7503 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Dec 14 10:05:16.766: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:05:16.767: INFO: ExecWithOptions: Clientset creation
Dec 14 10:05:16.767: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-7503/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.215%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Dec 14 10:05:17.047: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Dec 14 10:05:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7503" for this suite. 12/14/22 10:05:17.069
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":325,"skipped":5850,"failed":0}
------------------------------
• [15.101 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:01.981
    Dec 14 10:05:01.981: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename pod-network-test 12/14/22 10:05:01.982
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:02.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:02.042
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-7503 12/14/22 10:05:02.064
    STEP: creating a selector 12/14/22 10:05:02.064
    STEP: Creating the service pods in kubernetes 12/14/22 10:05:02.064
    Dec 14 10:05:02.064: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Dec 14 10:05:02.125: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7503" to be "running and ready"
    Dec 14 10:05:02.137: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.512111ms
    Dec 14 10:05:02.137: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:05:04.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.024585085s
    Dec 14 10:05:04.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 10:05:06.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.024355662s
    Dec 14 10:05:06.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 10:05:08.152: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.026165859s
    Dec 14 10:05:08.152: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 10:05:10.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.024350264s
    Dec 14 10:05:10.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 10:05:12.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02472928s
    Dec 14 10:05:12.150: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Dec 14 10:05:14.150: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.024502346s
    Dec 14 10:05:14.150: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Dec 14 10:05:14.150: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Dec 14 10:05:14.161: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7503" to be "running and ready"
    Dec 14 10:05:14.172: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.179608ms
    Dec 14 10:05:14.172: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Dec 14 10:05:14.172: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 12/14/22 10:05:14.184
    Dec 14 10:05:14.215: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7503" to be "running"
    Dec 14 10:05:14.226: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.779278ms
    Dec 14 10:05:16.238: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023821123s
    Dec 14 10:05:16.238: INFO: Pod "test-container-pod" satisfied condition "running"
    Dec 14 10:05:16.250: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7503" to be "running"
    Dec 14 10:05:16.262: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 11.662697ms
    Dec 14 10:05:16.262: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Dec 14 10:05:16.274: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Dec 14 10:05:16.274: INFO: Going to poll 172.16.1.193 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 10:05:16.286: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.1.193:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7503 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 10:05:16.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:05:16.286: INFO: ExecWithOptions: Clientset creation
    Dec 14 10:05:16.287: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-7503/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.1.193%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 10:05:16.754: INFO: Found all 1 expected endpoints: [netserver-0]
    Dec 14 10:05:16.754: INFO: Going to poll 172.16.0.215 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Dec 14 10:05:16.766: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.0.215:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7503 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Dec 14 10:05:16.766: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:05:16.767: INFO: ExecWithOptions: Clientset creation
    Dec 14 10:05:16.767: INFO: ExecWithOptions: execute(POST https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/pod-network-test-7503/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.0.215%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Dec 14 10:05:17.047: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Dec 14 10:05:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7503" for this suite. 12/14/22 10:05:17.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:17.083
Dec 14 10:05:17.083: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:05:17.084
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:17.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:17.143
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-688 12/14/22 10:05:17.165
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 10:05:17.185
STEP: creating service externalsvc in namespace services-688 12/14/22 10:05:17.185
STEP: creating replication controller externalsvc in namespace services-688 12/14/22 10:05:17.201
I1214 10:05:17.213996    6248 runners.go:193] Created replication controller with name: externalsvc, namespace: services-688, replica count: 2
I1214 10:05:20.265621    6248 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 12/14/22 10:05:20.277
Dec 14 10:05:20.309: INFO: Creating new exec pod
Dec 14 10:05:20.326: INFO: Waiting up to 5m0s for pod "execpod4t6dp" in namespace "services-688" to be "running"
Dec 14 10:05:20.337: INFO: Pod "execpod4t6dp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.702455ms
Dec 14 10:05:22.350: INFO: Pod "execpod4t6dp": Phase="Running", Reason="", readiness=true. Elapsed: 2.024644522s
Dec 14 10:05:22.350: INFO: Pod "execpod4t6dp" satisfied condition "running"
Dec 14 10:05:22.350: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-688 exec execpod4t6dp -- /bin/sh -x -c nslookup nodeport-service.services-688.svc.cluster.local'
Dec 14 10:05:22.852: INFO: stderr: "+ nslookup nodeport-service.services-688.svc.cluster.local\n"
Dec 14 10:05:22.852: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nnodeport-service.services-688.svc.cluster.local\tcanonical name = externalsvc.services-688.svc.cluster.local.\nName:\texternalsvc.services-688.svc.cluster.local\nAddress: 172.27.251.17\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-688, will wait for the garbage collector to delete the pods 12/14/22 10:05:22.852
Dec 14 10:05:22.928: INFO: Deleting ReplicationController externalsvc took: 13.256583ms
Dec 14 10:05:23.029: INFO: Terminating ReplicationController externalsvc pods took: 100.677323ms
Dec 14 10:05:24.947: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:05:24.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-688" for this suite. 12/14/22 10:05:24.983
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":326,"skipped":5867,"failed":0}
------------------------------
• [7.914 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:17.083
    Dec 14 10:05:17.083: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:05:17.084
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:17.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:17.143
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-688 12/14/22 10:05:17.165
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 12/14/22 10:05:17.185
    STEP: creating service externalsvc in namespace services-688 12/14/22 10:05:17.185
    STEP: creating replication controller externalsvc in namespace services-688 12/14/22 10:05:17.201
    I1214 10:05:17.213996    6248 runners.go:193] Created replication controller with name: externalsvc, namespace: services-688, replica count: 2
    I1214 10:05:20.265621    6248 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 12/14/22 10:05:20.277
    Dec 14 10:05:20.309: INFO: Creating new exec pod
    Dec 14 10:05:20.326: INFO: Waiting up to 5m0s for pod "execpod4t6dp" in namespace "services-688" to be "running"
    Dec 14 10:05:20.337: INFO: Pod "execpod4t6dp": Phase="Pending", Reason="", readiness=false. Elapsed: 11.702455ms
    Dec 14 10:05:22.350: INFO: Pod "execpod4t6dp": Phase="Running", Reason="", readiness=true. Elapsed: 2.024644522s
    Dec 14 10:05:22.350: INFO: Pod "execpod4t6dp" satisfied condition "running"
    Dec 14 10:05:22.350: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-688 exec execpod4t6dp -- /bin/sh -x -c nslookup nodeport-service.services-688.svc.cluster.local'
    Dec 14 10:05:22.852: INFO: stderr: "+ nslookup nodeport-service.services-688.svc.cluster.local\n"
    Dec 14 10:05:22.852: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nnodeport-service.services-688.svc.cluster.local\tcanonical name = externalsvc.services-688.svc.cluster.local.\nName:\texternalsvc.services-688.svc.cluster.local\nAddress: 172.27.251.17\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-688, will wait for the garbage collector to delete the pods 12/14/22 10:05:22.852
    Dec 14 10:05:22.928: INFO: Deleting ReplicationController externalsvc took: 13.256583ms
    Dec 14 10:05:23.029: INFO: Terminating ReplicationController externalsvc pods took: 100.677323ms
    Dec 14 10:05:24.947: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:05:24.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-688" for this suite. 12/14/22 10:05:24.983
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:24.997
Dec 14 10:05:24.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets 12/14/22 10:05:24.998
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:25.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:25.056
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Dec 14 10:05:25.130: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 12/14/22 10:05:25.143
Dec 14 10:05:25.156: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:25.156: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 12/14/22 10:05:25.156
Dec 14 10:05:25.219: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:25.219: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:26.231: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:26.231: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:27.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:05:27.232: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 12/14/22 10:05:27.244
Dec 14 10:05:27.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:27.304: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/14/22 10:05:27.304
Dec 14 10:05:27.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:27.330: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:28.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:28.343: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:29.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:29.342: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:30.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:30.342: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
Dec 14 10:05:31.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Dec 14 10:05:31.342: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:05:31.367
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-250, will wait for the garbage collector to delete the pods 12/14/22 10:05:31.368
Dec 14 10:05:31.444: INFO: Deleting DaemonSet.extensions daemon-set took: 13.384556ms
Dec 14 10:05:31.545: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.172128ms
Dec 14 10:05:33.957: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Dec 14 10:05:33.957: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Dec 14 10:05:33.981: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"54749"},"items":null}

Dec 14 10:05:33.993: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"54749"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:05:34.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-250" for this suite. 12/14/22 10:05:34.078
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":327,"skipped":5881,"failed":0}
------------------------------
• [9.095 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:24.997
    Dec 14 10:05:24.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename daemonsets 12/14/22 10:05:24.998
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:25.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:25.056
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Dec 14 10:05:25.130: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 12/14/22 10:05:25.143
    Dec 14 10:05:25.156: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:25.156: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 12/14/22 10:05:25.156
    Dec 14 10:05:25.219: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:25.219: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:26.231: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:26.231: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:27.232: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:05:27.232: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 12/14/22 10:05:27.244
    Dec 14 10:05:27.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:27.304: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 12/14/22 10:05:27.304
    Dec 14 10:05:27.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:27.330: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:28.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:28.343: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:29.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:29.342: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:30.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:30.342: INFO: Node izgw8jfcr55yi09nr0a5xaz is running 0 daemon pod, expected 1
    Dec 14 10:05:31.342: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Dec 14 10:05:31.342: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 12/14/22 10:05:31.367
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-250, will wait for the garbage collector to delete the pods 12/14/22 10:05:31.368
    Dec 14 10:05:31.444: INFO: Deleting DaemonSet.extensions daemon-set took: 13.384556ms
    Dec 14 10:05:31.545: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.172128ms
    Dec 14 10:05:33.957: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Dec 14 10:05:33.957: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Dec 14 10:05:33.981: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"54749"},"items":null}

    Dec 14 10:05:33.993: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"54749"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:05:34.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-250" for this suite. 12/14/22 10:05:34.078
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:34.093
Dec 14 10:05:34.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename disruption 12/14/22 10:05:34.094
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:34.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:34.157
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 12/14/22 10:05:34.178
STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.191
STEP: updating the pdb 12/14/22 10:05:34.203
STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.228
STEP: patching the pdb 12/14/22 10:05:34.24
STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.265
STEP: Waiting for the pdb to be deleted 12/14/22 10:05:34.29
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Dec 14 10:05:34.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8247" for this suite. 12/14/22 10:05:34.315
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":328,"skipped":5881,"failed":0}
------------------------------
• [0.236 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:34.093
    Dec 14 10:05:34.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename disruption 12/14/22 10:05:34.094
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:34.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:34.157
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 12/14/22 10:05:34.178
    STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.191
    STEP: updating the pdb 12/14/22 10:05:34.203
    STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.228
    STEP: patching the pdb 12/14/22 10:05:34.24
    STEP: Waiting for the pdb to be processed 12/14/22 10:05:34.265
    STEP: Waiting for the pdb to be deleted 12/14/22 10:05:34.29
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Dec 14 10:05:34.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8247" for this suite. 12/14/22 10:05:34.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:34.329
Dec 14 10:05:34.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:34.33
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:34.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:34.388
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 12/14/22 10:05:34.41
Dec 14 10:05:34.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde" in namespace "downward-api-2458" to be "Succeeded or Failed"
Dec 14 10:05:34.440: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Pending", Reason="", readiness=false. Elapsed: 11.520816ms
Dec 14 10:05:36.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024245559s
Dec 14 10:05:38.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023870276s
STEP: Saw pod success 12/14/22 10:05:38.453
Dec 14 10:05:38.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde" satisfied condition "Succeeded or Failed"
Dec 14 10:05:38.465: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde container client-container: <nil>
STEP: delete the pod 12/14/22 10:05:38.489
Dec 14 10:05:38.503: INFO: Waiting for pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde to disappear
Dec 14 10:05:38.515: INFO: Pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 10:05:38.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2458" for this suite. 12/14/22 10:05:38.537
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":329,"skipped":5890,"failed":0}
------------------------------
• [4.223 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:34.329
    Dec 14 10:05:34.329: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:34.33
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:34.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:34.388
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 12/14/22 10:05:34.41
    Dec 14 10:05:34.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde" in namespace "downward-api-2458" to be "Succeeded or Failed"
    Dec 14 10:05:34.440: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Pending", Reason="", readiness=false. Elapsed: 11.520816ms
    Dec 14 10:05:36.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024245559s
    Dec 14 10:05:38.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023870276s
    STEP: Saw pod success 12/14/22 10:05:38.453
    Dec 14 10:05:38.453: INFO: Pod "downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde" satisfied condition "Succeeded or Failed"
    Dec 14 10:05:38.465: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde container client-container: <nil>
    STEP: delete the pod 12/14/22 10:05:38.489
    Dec 14 10:05:38.503: INFO: Waiting for pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde to disappear
    Dec 14 10:05:38.515: INFO: Pod downwardapi-volume-4a497288-ba32-4f76-a186-4f54da9fdbde no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 10:05:38.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2458" for this suite. 12/14/22 10:05:38.537
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:38.552
Dec 14 10:05:38.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 10:05:38.553
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:38.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:38.615
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-32aa8dec-f400-4ce8-9821-df5a49f34655 12/14/22 10:05:38.647
STEP: Creating a pod to test consume secrets 12/14/22 10:05:38.659
Dec 14 10:05:38.678: INFO: Waiting up to 5m0s for pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b" in namespace "secrets-927" to be "Succeeded or Failed"
Dec 14 10:05:38.690: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.912479ms
Dec 14 10:05:40.702: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024258369s
Dec 14 10:05:42.704: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02577286s
STEP: Saw pod success 12/14/22 10:05:42.704
Dec 14 10:05:42.704: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b" satisfied condition "Succeeded or Failed"
Dec 14 10:05:42.717: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 10:05:42.74
Dec 14 10:05:42.755: INFO: Waiting for pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b to disappear
Dec 14 10:05:42.767: INFO: Pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 10:05:42.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-927" for this suite. 12/14/22 10:05:42.789
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":330,"skipped":5899,"failed":0}
------------------------------
• [4.250 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:38.552
    Dec 14 10:05:38.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 10:05:38.553
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:38.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:38.615
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-32aa8dec-f400-4ce8-9821-df5a49f34655 12/14/22 10:05:38.647
    STEP: Creating a pod to test consume secrets 12/14/22 10:05:38.659
    Dec 14 10:05:38.678: INFO: Waiting up to 5m0s for pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b" in namespace "secrets-927" to be "Succeeded or Failed"
    Dec 14 10:05:38.690: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.912479ms
    Dec 14 10:05:40.702: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024258369s
    Dec 14 10:05:42.704: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02577286s
    STEP: Saw pod success 12/14/22 10:05:42.704
    Dec 14 10:05:42.704: INFO: Pod "pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b" satisfied condition "Succeeded or Failed"
    Dec 14 10:05:42.717: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 10:05:42.74
    Dec 14 10:05:42.755: INFO: Waiting for pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b to disappear
    Dec 14 10:05:42.767: INFO: Pod pod-secrets-c1129ec0-7e4e-424d-a2e8-c9c5aa75358b no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 10:05:42.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-927" for this suite. 12/14/22 10:05:42.789
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:42.805
Dec 14 10:05:42.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:42.806
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:42.842
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:42.863
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 12/14/22 10:05:42.885
Dec 14 10:05:42.910: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d" in namespace "downward-api-6510" to be "Succeeded or Failed"
Dec 14 10:05:42.922: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.761678ms
Dec 14 10:05:44.936: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02601667s
Dec 14 10:05:46.935: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024731215s
STEP: Saw pod success 12/14/22 10:05:46.935
Dec 14 10:05:46.935: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d" satisfied condition "Succeeded or Failed"
Dec 14 10:05:46.947: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d container client-container: <nil>
STEP: delete the pod 12/14/22 10:05:46.974
Dec 14 10:05:46.990: INFO: Waiting for pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d to disappear
Dec 14 10:05:47.002: INFO: Pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Dec 14 10:05:47.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6510" for this suite. 12/14/22 10:05:47.024
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":331,"skipped":5999,"failed":0}
------------------------------
• [4.232 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:42.805
    Dec 14 10:05:42.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename downward-api 12/14/22 10:05:42.806
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:42.842
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:42.863
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 12/14/22 10:05:42.885
    Dec 14 10:05:42.910: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d" in namespace "downward-api-6510" to be "Succeeded or Failed"
    Dec 14 10:05:42.922: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.761678ms
    Dec 14 10:05:44.936: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02601667s
    Dec 14 10:05:46.935: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024731215s
    STEP: Saw pod success 12/14/22 10:05:46.935
    Dec 14 10:05:46.935: INFO: Pod "downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d" satisfied condition "Succeeded or Failed"
    Dec 14 10:05:46.947: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d container client-container: <nil>
    STEP: delete the pod 12/14/22 10:05:46.974
    Dec 14 10:05:46.990: INFO: Waiting for pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d to disappear
    Dec 14 10:05:47.002: INFO: Pod downwardapi-volume-33cc76c4-16a6-41c2-bda6-bba02899925d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Dec 14 10:05:47.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6510" for this suite. 12/14/22 10:05:47.024
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:47.038
Dec 14 10:05:47.038: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 10:05:47.038
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:47.074
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:47.096
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 12/14/22 10:05:47.117
Dec 14 10:05:47.117: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 create -f -'
Dec 14 10:05:47.799: INFO: stderr: ""
Dec 14 10:05:47.799: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 12/14/22 10:05:47.799
Dec 14 10:05:47.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 diff -f -'
Dec 14 10:05:48.415: INFO: rc: 1
Dec 14 10:05:48.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 delete -f -'
Dec 14 10:05:48.539: INFO: stderr: ""
Dec 14 10:05:48.539: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 10:05:48.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2871" for this suite. 12/14/22 10:05:48.561
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":332,"skipped":6001,"failed":0}
------------------------------
• [1.536 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:47.038
    Dec 14 10:05:47.038: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 10:05:47.038
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:47.074
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:47.096
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 12/14/22 10:05:47.117
    Dec 14 10:05:47.117: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 create -f -'
    Dec 14 10:05:47.799: INFO: stderr: ""
    Dec 14 10:05:47.799: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 12/14/22 10:05:47.799
    Dec 14 10:05:47.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 diff -f -'
    Dec 14 10:05:48.415: INFO: rc: 1
    Dec 14 10:05:48.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-2871 delete -f -'
    Dec 14 10:05:48.539: INFO: stderr: ""
    Dec 14 10:05:48.539: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 10:05:48.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2871" for this suite. 12/14/22 10:05:48.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:48.575
Dec 14 10:05:48.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy 12/14/22 10:05:48.576
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:48.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:48.634
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Dec 14 10:05:48.677: INFO: Creating pod...
Dec 14 10:05:48.697: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4056" to be "running"
Dec 14 10:05:48.708: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.652671ms
Dec 14 10:05:50.721: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.024157196s
Dec 14 10:05:50.721: INFO: Pod "agnhost" satisfied condition "running"
Dec 14 10:05:50.721: INFO: Creating service...
Dec 14 10:05:50.737: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=DELETE
Dec 14 10:05:50.860: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 10:05:50.860: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=OPTIONS
Dec 14 10:05:50.910: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 10:05:50.910: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=PATCH
Dec 14 10:05:50.927: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 10:05:50.927: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=POST
Dec 14 10:05:50.950: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 10:05:50.950: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=PUT
Dec 14 10:05:50.969: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 10:05:50.969: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=DELETE
Dec 14 10:05:50.998: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Dec 14 10:05:50.998: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=OPTIONS
Dec 14 10:05:51.021: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Dec 14 10:05:51.021: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=PATCH
Dec 14 10:05:51.040: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Dec 14 10:05:51.040: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=POST
Dec 14 10:05:51.059: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Dec 14 10:05:51.059: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=PUT
Dec 14 10:05:51.078: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Dec 14 10:05:51.078: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=GET
Dec 14 10:05:51.090: INFO: http.Client request:GET StatusCode:301
Dec 14 10:05:51.090: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=GET
Dec 14 10:05:51.102: INFO: http.Client request:GET StatusCode:301
Dec 14 10:05:51.102: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=HEAD
Dec 14 10:05:51.114: INFO: http.Client request:HEAD StatusCode:301
Dec 14 10:05:51.114: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=HEAD
Dec 14 10:05:51.127: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Dec 14 10:05:51.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4056" for this suite. 12/14/22 10:05:51.149
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":333,"skipped":6025,"failed":0}
------------------------------
• [2.587 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:48.575
    Dec 14 10:05:48.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename proxy 12/14/22 10:05:48.576
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:48.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:48.634
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Dec 14 10:05:48.677: INFO: Creating pod...
    Dec 14 10:05:48.697: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4056" to be "running"
    Dec 14 10:05:48.708: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.652671ms
    Dec 14 10:05:50.721: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.024157196s
    Dec 14 10:05:50.721: INFO: Pod "agnhost" satisfied condition "running"
    Dec 14 10:05:50.721: INFO: Creating service...
    Dec 14 10:05:50.737: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=DELETE
    Dec 14 10:05:50.860: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 10:05:50.860: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=OPTIONS
    Dec 14 10:05:50.910: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 10:05:50.910: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=PATCH
    Dec 14 10:05:50.927: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 10:05:50.927: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=POST
    Dec 14 10:05:50.950: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 10:05:50.950: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=PUT
    Dec 14 10:05:50.969: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 10:05:50.969: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=DELETE
    Dec 14 10:05:50.998: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Dec 14 10:05:50.998: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Dec 14 10:05:51.021: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Dec 14 10:05:51.021: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=PATCH
    Dec 14 10:05:51.040: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Dec 14 10:05:51.040: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=POST
    Dec 14 10:05:51.059: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Dec 14 10:05:51.059: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=PUT
    Dec 14 10:05:51.078: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Dec 14 10:05:51.078: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=GET
    Dec 14 10:05:51.090: INFO: http.Client request:GET StatusCode:301
    Dec 14 10:05:51.090: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=GET
    Dec 14 10:05:51.102: INFO: http.Client request:GET StatusCode:301
    Dec 14 10:05:51.102: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/pods/agnhost/proxy?method=HEAD
    Dec 14 10:05:51.114: INFO: http.Client request:HEAD StatusCode:301
    Dec 14 10:05:51.114: INFO: Starting http.Client for https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com/api/v1/namespaces/proxy-4056/services/e2e-proxy-test-service/proxy?method=HEAD
    Dec 14 10:05:51.127: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Dec 14 10:05:51.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4056" for this suite. 12/14/22 10:05:51.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:05:51.163
Dec 14 10:05:51.163: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:05:51.163
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:51.199
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:51.221
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/14/22 10:05:51.242
Dec 14 10:05:51.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec 14 10:05:54.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:06:09.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7609" for this suite. 12/14/22 10:06:09.83
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":334,"skipped":6030,"failed":0}
------------------------------
• [18.677 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:05:51.163
    Dec 14 10:05:51.163: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename crd-publish-openapi 12/14/22 10:05:51.163
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:05:51.199
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:05:51.221
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 12/14/22 10:05:51.242
    Dec 14 10:05:51.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    Dec 14 10:05:54.571: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:06:09.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7609" for this suite. 12/14/22 10:06:09.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:09.841
Dec 14 10:06:09.842: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 10:06:09.842
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:09.865
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:09.877
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Dec 14 10:06:09.889: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 14 10:06:09.905: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 14 10:06:14.916: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 10:06:14.916
Dec 14 10:06:14.916: INFO: Creating deployment "test-rolling-update-deployment"
Dec 14 10:06:14.923: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 14 10:06:14.938: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Dec 14 10:06:16.953: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 14 10:06:16.960: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 10:06:16.983: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5436  4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 55166 1 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b1ae88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 10:06:14 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-14 10:06:16 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 10:06:16.990: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-5436  62109130-a828-49fc-baa4-9c47d8a092bf 55159 1 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 0xc008b1b397 0xc008b1b398}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d80ca2a-1c6d-41b1-b0d9-29106902b8e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b1b448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 10:06:16.990: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 14 10:06:16.990: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5436  f49b45dc-1e27-43fe-a827-3061848e3e2f 55165 2 2022-12-14 10:06:09 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 0xc008b1b267 0xc008b1b268}] [] [{e2e.test Update apps/v1 2022-12-14 10:06:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d80ca2a-1c6d-41b1-b0d9-29106902b8e7\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc008b1b328 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 10:06:16.998: INFO: Pod "test-rolling-update-deployment-78f575d8ff-hjsqm" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-hjsqm test-rolling-update-deployment-78f575d8ff- deployment-5436  0bea9465-cfa8-4442-8dfa-431c5d69f411 55158 0 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:0c810ea5a0a7cdb7cb713639f5e4943f4f7c99acceb026e3a25dab221739940d cni.projectcalico.org/podIP:172.16.0.227/32 cni.projectcalico.org/podIPs:172.16.0.227/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 62109130-a828-49fc-baa4-9c47d8a092bf 0xc007cc9987 0xc007cc9988}] [] [{kube-controller-manager Update v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62109130-a828-49fc-baa4-9c47d8a092bf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 10:06:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.227\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skrw6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skrw6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.227,StartTime:2022-12-14 10:06:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 10:06:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e36d9116258d43220ef9d087ea5ef9e406cc8f6c2a48c4c0fbe4e68ea53122ab,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 10:06:16.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5436" for this suite. 12/14/22 10:06:17.019
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":335,"skipped":6089,"failed":0}
------------------------------
• [7.186 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:09.841
    Dec 14 10:06:09.842: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 10:06:09.842
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:09.865
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:09.877
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Dec 14 10:06:09.889: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Dec 14 10:06:09.905: INFO: Pod name sample-pod: Found 0 pods out of 1
    Dec 14 10:06:14.916: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 10:06:14.916
    Dec 14 10:06:14.916: INFO: Creating deployment "test-rolling-update-deployment"
    Dec 14 10:06:14.923: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Dec 14 10:06:14.938: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
    Dec 14 10:06:16.953: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Dec 14 10:06:16.960: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 10:06:16.983: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5436  4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 55166 1 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b1ae88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 10:06:14 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-12-14 10:06:16 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 10:06:16.990: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-5436  62109130-a828-49fc-baa4-9c47d8a092bf 55159 1 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 0xc008b1b397 0xc008b1b398}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d80ca2a-1c6d-41b1-b0d9-29106902b8e7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc008b1b448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 10:06:16.990: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Dec 14 10:06:16.990: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5436  f49b45dc-1e27-43fe-a827-3061848e3e2f 55165 2 2022-12-14 10:06:09 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4d80ca2a-1c6d-41b1-b0d9-29106902b8e7 0xc008b1b267 0xc008b1b268}] [] [{e2e.test Update apps/v1 2022-12-14 10:06:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d80ca2a-1c6d-41b1-b0d9-29106902b8e7\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc008b1b328 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 10:06:16.998: INFO: Pod "test-rolling-update-deployment-78f575d8ff-hjsqm" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-hjsqm test-rolling-update-deployment-78f575d8ff- deployment-5436  0bea9465-cfa8-4442-8dfa-431c5d69f411 55158 0 2022-12-14 10:06:14 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:0c810ea5a0a7cdb7cb713639f5e4943f4f7c99acceb026e3a25dab221739940d cni.projectcalico.org/podIP:172.16.0.227/32 cni.projectcalico.org/podIPs:172.16.0.227/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 62109130-a828-49fc-baa4-9c47d8a092bf 0xc007cc9987 0xc007cc9988}] [] [{kube-controller-manager Update v1 2022-12-14 10:06:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"62109130-a828-49fc-baa4-9c47d8a092bf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {Go-http-client Update v1 2022-12-14 10:06:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-12-14 10:06:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.227\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skrw6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skrw6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:06:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.227,StartTime:2022-12-14 10:06:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 10:06:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e36d9116258d43220ef9d087ea5ef9e406cc8f6c2a48c4c0fbe4e68ea53122ab,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 10:06:16.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5436" for this suite. 12/14/22 10:06:17.019
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:06:17.028
Dec 14 10:06:17.028: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption 12/14/22 10:06:17.029
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:17.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:17.064
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Dec 14 10:06:17.099: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 14 10:07:17.179: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:17.186
Dec 14 10:07:17.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 10:07:17.187
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:17.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:17.222
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Dec 14 10:07:17.265: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Dec 14 10:07:17.273: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Dec 14 10:07:17.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-9423" for this suite. 12/14/22 10:07:17.335
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Dec 14 10:07:17.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8831" for this suite. 12/14/22 10:07:17.364
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":336,"skipped":6091,"failed":0}
------------------------------
• [60.401 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:06:17.028
    Dec 14 10:06:17.028: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption 12/14/22 10:06:17.029
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:06:17.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:06:17.064
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Dec 14 10:06:17.099: INFO: Waiting up to 1m0s for all nodes to be ready
    Dec 14 10:07:17.179: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:17.186
    Dec 14 10:07:17.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename sched-preemption-path 12/14/22 10:07:17.187
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:17.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:17.222
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Dec 14 10:07:17.265: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Dec 14 10:07:17.273: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Dec 14 10:07:17.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-9423" for this suite. 12/14/22 10:07:17.335
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Dec 14 10:07:17.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8831" for this suite. 12/14/22 10:07:17.364
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:17.43
Dec 14 10:07:17.430: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:07:17.43
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:17.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:17.466
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-4834 12/14/22 10:07:17.481
STEP: creating service affinity-nodeport in namespace services-4834 12/14/22 10:07:17.481
STEP: creating replication controller affinity-nodeport in namespace services-4834 12/14/22 10:07:17.494
I1214 10:07:17.502583    6248 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4834, replica count: 3
I1214 10:07:20.554495    6248 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 10:07:20.582: INFO: Creating new exec pod
Dec 14 10:07:20.593: INFO: Waiting up to 5m0s for pod "execpod-affinitygbfvm" in namespace "services-4834" to be "running"
Dec 14 10:07:20.600: INFO: Pod "execpod-affinitygbfvm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.890961ms
Dec 14 10:07:22.611: INFO: Pod "execpod-affinitygbfvm": Phase="Running", Reason="", readiness=true. Elapsed: 2.018161479s
Dec 14 10:07:22.611: INFO: Pod "execpod-affinitygbfvm" satisfied condition "running"
Dec 14 10:07:23.625: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Dec 14 10:07:24.180: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Dec 14 10:07:24.180: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:24.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.181.176 80'
Dec 14 10:07:24.731: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.24.181.176 80\nConnection to 172.24.181.176 80 port [tcp/http] succeeded!\n"
Dec 14 10:07:24.731: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:24.731: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30481'
Dec 14 10:07:25.278: INFO: stderr: "+ nc -v -t -w 2 10.250.18.71 30481\n+ echo hostName\nConnection to 10.250.18.71 30481 port [tcp/*] succeeded!\n"
Dec 14 10:07:25.278: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:25.278: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30481'
Dec 14 10:07:25.856: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30481\nConnection to 10.250.18.72 30481 port [tcp/*] succeeded!\n"
Dec 14 10:07:25.856: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:07:25.856: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:30481/ ; done'
Dec 14 10:07:26.528: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n"
Dec 14 10:07:26.529: INFO: stdout: "\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b"
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
Dec 14 10:07:26.529: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4834, will wait for the garbage collector to delete the pods 12/14/22 10:07:26.539
Dec 14 10:07:26.606: INFO: Deleting ReplicationController affinity-nodeport took: 8.567369ms
Dec 14 10:07:26.707: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.794485ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:07:28.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4834" for this suite. 12/14/22 10:07:28.836
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":337,"skipped":6107,"failed":0}
------------------------------
• [11.429 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:17.43
    Dec 14 10:07:17.430: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:07:17.43
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:17.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:17.466
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-4834 12/14/22 10:07:17.481
    STEP: creating service affinity-nodeport in namespace services-4834 12/14/22 10:07:17.481
    STEP: creating replication controller affinity-nodeport in namespace services-4834 12/14/22 10:07:17.494
    I1214 10:07:17.502583    6248 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4834, replica count: 3
    I1214 10:07:20.554495    6248 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 10:07:20.582: INFO: Creating new exec pod
    Dec 14 10:07:20.593: INFO: Waiting up to 5m0s for pod "execpod-affinitygbfvm" in namespace "services-4834" to be "running"
    Dec 14 10:07:20.600: INFO: Pod "execpod-affinitygbfvm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.890961ms
    Dec 14 10:07:22.611: INFO: Pod "execpod-affinitygbfvm": Phase="Running", Reason="", readiness=true. Elapsed: 2.018161479s
    Dec 14 10:07:22.611: INFO: Pod "execpod-affinitygbfvm" satisfied condition "running"
    Dec 14 10:07:23.625: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Dec 14 10:07:24.180: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Dec 14 10:07:24.180: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:24.180: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.24.181.176 80'
    Dec 14 10:07:24.731: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.24.181.176 80\nConnection to 172.24.181.176 80 port [tcp/http] succeeded!\n"
    Dec 14 10:07:24.731: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:24.731: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.71 30481'
    Dec 14 10:07:25.278: INFO: stderr: "+ nc -v -t -w 2 10.250.18.71 30481\n+ echo hostName\nConnection to 10.250.18.71 30481 port [tcp/*] succeeded!\n"
    Dec 14 10:07:25.278: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:25.278: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.18.72 30481'
    Dec 14 10:07:25.856: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.18.72 30481\nConnection to 10.250.18.72 30481 port [tcp/*] succeeded!\n"
    Dec 14 10:07:25.856: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:07:25.856: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-4834 exec execpod-affinitygbfvm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.18.71:30481/ ; done'
    Dec 14 10:07:26.528: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.18.71:30481/\n"
    Dec 14 10:07:26.529: INFO: stdout: "\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b\naffinity-nodeport-qvv7b"
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Received response from host: affinity-nodeport-qvv7b
    Dec 14 10:07:26.529: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4834, will wait for the garbage collector to delete the pods 12/14/22 10:07:26.539
    Dec 14 10:07:26.606: INFO: Deleting ReplicationController affinity-nodeport took: 8.567369ms
    Dec 14 10:07:26.707: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.794485ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:07:28.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4834" for this suite. 12/14/22 10:07:28.836
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:28.86
Dec 14 10:07:28.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment 12/14/22 10:07:28.861
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:28.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:28.894
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Dec 14 10:07:28.920: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 14 10:07:33.928: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 12/14/22 10:07:33.928
Dec 14 10:07:33.928: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 14 10:07:35.937: INFO: Creating deployment "test-rollover-deployment"
Dec 14 10:07:35.953: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 14 10:07:37.968: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 14 10:07:37.984: INFO: Ensure that both replica sets have 1 created replica
Dec 14 10:07:37.999: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 14 10:07:38.015: INFO: Updating deployment test-rollover-deployment
Dec 14 10:07:38.015: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 14 10:07:40.031: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 14 10:07:40.046: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 14 10:07:40.061: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 10:07:40.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 10:07:42.077: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 10:07:42.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 10:07:44.077: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 10:07:44.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 10:07:46.077: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 10:07:46.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 10:07:48.079: INFO: all replica sets need to contain the pod-template-hash label
Dec 14 10:07:48.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 14 10:07:50.077: INFO: 
Dec 14 10:07:50.077: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Dec 14 10:07:50.098: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7075  f818ddfe-e757-4e9a-b325-d827ae3899c4 55832 2 2022-12-14 10:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd0988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 10:07:35 +0000 UTC,LastTransitionTime:2022-12-14 10:07:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-14 10:07:49 +0000 UTC,LastTransitionTime:2022-12-14 10:07:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 14 10:07:50.106: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7075  b4328f96-2a64-47d7-884d-f1872a6f9efc 55825 2 2022-12-14 10:07:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0f87 0xc003bd0f88}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd1038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 14 10:07:50.106: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 14 10:07:50.106: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7075  68f26c67-c8dc-4e9f-924b-8cd1bc4d68bb 55831 2 2022-12-14 10:07:28 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0d37 0xc003bd0d38}] [] [{e2e.test Update apps/v1 2022-12-14 10:07:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003bd0df8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 10:07:50.106: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7075  29442996-35db-4305-8890-5b8dc6e0a803 55760 2 2022-12-14 10:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0e67 0xc003bd0e68}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd0f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 14 10:07:50.114: INFO: Pod "test-rollover-deployment-6d45fd857b-q4m2c" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-q4m2c test-rollover-deployment-6d45fd857b- deployment-7075  53c04c66-4d4f-4a71-9308-6306a80483a4 55773 0 2022-12-14 10:07:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:fd9aa8a4a45d3d018fdfdbc1abd09341d419cd6cdbfc323a10be13511ac85e05 cni.projectcalico.org/podIP:172.16.0.233/32 cni.projectcalico.org/podIPs:172.16.0.233/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b b4328f96-2a64-47d7-884d-f1872a6f9efc 0xc003bd15b7 0xc003bd15b8}] [] [{Go-http-client Update v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4328f96-2a64-47d7-884d-f1872a6f9efc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 10:07:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x2vxr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x2vxr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.233,StartTime:2022-12-14 10:07:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 10:07:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://51e89d21e110470853d61313fabdb1ad7ee9941ea1876e25705c8470c1c6df08,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Dec 14 10:07:50.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7075" for this suite. 12/14/22 10:07:50.127
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":338,"skipped":6162,"failed":0}
------------------------------
• [21.275 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:28.86
    Dec 14 10:07:28.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename deployment 12/14/22 10:07:28.861
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:28.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:28.894
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Dec 14 10:07:28.920: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Dec 14 10:07:33.928: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 12/14/22 10:07:33.928
    Dec 14 10:07:33.928: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Dec 14 10:07:35.937: INFO: Creating deployment "test-rollover-deployment"
    Dec 14 10:07:35.953: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Dec 14 10:07:37.968: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Dec 14 10:07:37.984: INFO: Ensure that both replica sets have 1 created replica
    Dec 14 10:07:37.999: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Dec 14 10:07:38.015: INFO: Updating deployment test-rollover-deployment
    Dec 14 10:07:38.015: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Dec 14 10:07:40.031: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Dec 14 10:07:40.046: INFO: Make sure deployment "test-rollover-deployment" is complete
    Dec 14 10:07:40.061: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 10:07:40.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 10:07:42.077: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 10:07:42.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 10:07:44.077: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 10:07:44.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 10:07:46.077: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 10:07:46.077: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 10:07:48.079: INFO: all replica sets need to contain the pod-template-hash label
    Dec 14 10:07:48.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.December, 14, 10, 7, 39, 0, time.Local), LastTransitionTime:time.Date(2022, time.December, 14, 10, 7, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Dec 14 10:07:50.077: INFO: 
    Dec 14 10:07:50.077: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Dec 14 10:07:50.098: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-7075  f818ddfe-e757-4e9a-b325-d827ae3899c4 55832 2 2022-12-14 10:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd0988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-12-14 10:07:35 +0000 UTC,LastTransitionTime:2022-12-14 10:07:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-12-14 10:07:49 +0000 UTC,LastTransitionTime:2022-12-14 10:07:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Dec 14 10:07:50.106: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-7075  b4328f96-2a64-47d7-884d-f1872a6f9efc 55825 2 2022-12-14 10:07:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0f87 0xc003bd0f88}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd1038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 10:07:50.106: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Dec 14 10:07:50.106: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7075  68f26c67-c8dc-4e9f-924b-8cd1bc4d68bb 55831 2 2022-12-14 10:07:28 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0d37 0xc003bd0d38}] [] [{e2e.test Update apps/v1 2022-12-14 10:07:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003bd0df8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 10:07:50.106: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-7075  29442996-35db-4305-8890-5b8dc6e0a803 55760 2 2022-12-14 10:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment f818ddfe-e757-4e9a-b325-d827ae3899c4 0xc003bd0e67 0xc003bd0e68}] [] [{kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f818ddfe-e757-4e9a-b325-d827ae3899c4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003bd0f18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Dec 14 10:07:50.114: INFO: Pod "test-rollover-deployment-6d45fd857b-q4m2c" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-q4m2c test-rollover-deployment-6d45fd857b- deployment-7075  53c04c66-4d4f-4a71-9308-6306a80483a4 55773 0 2022-12-14 10:07:38 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:fd9aa8a4a45d3d018fdfdbc1abd09341d419cd6cdbfc323a10be13511ac85e05 cni.projectcalico.org/podIP:172.16.0.233/32 cni.projectcalico.org/podIPs:172.16.0.233/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b b4328f96-2a64-47d7-884d-f1872a6f9efc 0xc003bd15b7 0xc003bd15b8}] [] [{Go-http-client Update v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2022-12-14 10:07:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b4328f96-2a64-47d7-884d-f1872a6f9efc\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-12-14 10:07:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.0.233\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x2vxr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x2vxr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8jfcr55yi09nr0a5xaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-12-14 10:07:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.18.72,PodIP:172.16.0.233,StartTime:2022-12-14 10:07:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-12-14 10:07:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://51e89d21e110470853d61313fabdb1ad7ee9941ea1876e25705c8470c1c6df08,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.0.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Dec 14 10:07:50.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7075" for this suite. 12/14/22 10:07:50.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:50.137
Dec 14 10:07:50.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 10:07:50.138
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:50.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:50.171
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-5b25757d-c10c-41fb-9e19-e39d16f99022 12/14/22 10:07:50.21
STEP: Creating a pod to test consume secrets 12/14/22 10:07:50.224
Dec 14 10:07:50.238: INFO: Waiting up to 5m0s for pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f" in namespace "secrets-9957" to be "Succeeded or Failed"
Dec 14 10:07:50.244: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.754159ms
Dec 14 10:07:52.252: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014173825s
Dec 14 10:07:54.253: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01572947s
STEP: Saw pod success 12/14/22 10:07:54.254
Dec 14 10:07:54.254: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f" satisfied condition "Succeeded or Failed"
Dec 14 10:07:54.261: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 10:07:54.28
Dec 14 10:07:54.292: INFO: Waiting for pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f to disappear
Dec 14 10:07:54.298: INFO: Pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 10:07:54.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9957" for this suite. 12/14/22 10:07:54.311
STEP: Destroying namespace "secret-namespace-4027" for this suite. 12/14/22 10:07:54.319
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":339,"skipped":6185,"failed":0}
------------------------------
• [4.191 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:50.137
    Dec 14 10:07:50.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 10:07:50.138
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:50.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:50.171
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-5b25757d-c10c-41fb-9e19-e39d16f99022 12/14/22 10:07:50.21
    STEP: Creating a pod to test consume secrets 12/14/22 10:07:50.224
    Dec 14 10:07:50.238: INFO: Waiting up to 5m0s for pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f" in namespace "secrets-9957" to be "Succeeded or Failed"
    Dec 14 10:07:50.244: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.754159ms
    Dec 14 10:07:52.252: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014173825s
    Dec 14 10:07:54.253: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01572947s
    STEP: Saw pod success 12/14/22 10:07:54.254
    Dec 14 10:07:54.254: INFO: Pod "pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f" satisfied condition "Succeeded or Failed"
    Dec 14 10:07:54.261: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 10:07:54.28
    Dec 14 10:07:54.292: INFO: Waiting for pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f to disappear
    Dec 14 10:07:54.298: INFO: Pod pod-secrets-6d9ae4da-189e-486a-81e7-450c922aa48f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 10:07:54.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9957" for this suite. 12/14/22 10:07:54.311
    STEP: Destroying namespace "secret-namespace-4027" for this suite. 12/14/22 10:07:54.319
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:07:54.328
Dec 14 10:07:54.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath 12/14/22 10:07:54.329
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:54.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:54.363
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 12/14/22 10:07:54.376
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-c7zs 12/14/22 10:07:54.391
STEP: Creating a pod to test atomic-volume-subpath 12/14/22 10:07:54.391
Dec 14 10:07:54.405: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-c7zs" in namespace "subpath-5140" to be "Succeeded or Failed"
Dec 14 10:07:54.412: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896231ms
Dec 14 10:07:56.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.015108279s
Dec 14 10:07:58.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 4.015491695s
Dec 14 10:08:00.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 6.015454033s
Dec 14 10:08:02.421: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 8.016075102s
Dec 14 10:08:04.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 10.015171918s
Dec 14 10:08:06.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 12.01510713s
Dec 14 10:08:08.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 14.015458474s
Dec 14 10:08:10.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 16.014872984s
Dec 14 10:08:12.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 18.015253642s
Dec 14 10:08:14.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 20.015267814s
Dec 14 10:08:16.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=false. Elapsed: 22.014914158s
Dec 14 10:08:18.419: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014525137s
STEP: Saw pod success 12/14/22 10:08:18.419
Dec 14 10:08:18.420: INFO: Pod "pod-subpath-test-projected-c7zs" satisfied condition "Succeeded or Failed"
Dec 14 10:08:18.427: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-projected-c7zs container test-container-subpath-projected-c7zs: <nil>
STEP: delete the pod 12/14/22 10:08:18.446
Dec 14 10:08:18.458: INFO: Waiting for pod pod-subpath-test-projected-c7zs to disappear
Dec 14 10:08:18.465: INFO: Pod pod-subpath-test-projected-c7zs no longer exists
STEP: Deleting pod pod-subpath-test-projected-c7zs 12/14/22 10:08:18.465
Dec 14 10:08:18.465: INFO: Deleting pod "pod-subpath-test-projected-c7zs" in namespace "subpath-5140"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Dec 14 10:08:18.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5140" for this suite. 12/14/22 10:08:18.485
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":340,"skipped":6197,"failed":0}
------------------------------
• [24.166 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:07:54.328
    Dec 14 10:07:54.328: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename subpath 12/14/22 10:07:54.329
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:07:54.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:07:54.363
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 12/14/22 10:07:54.376
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-c7zs 12/14/22 10:07:54.391
    STEP: Creating a pod to test atomic-volume-subpath 12/14/22 10:07:54.391
    Dec 14 10:07:54.405: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-c7zs" in namespace "subpath-5140" to be "Succeeded or Failed"
    Dec 14 10:07:54.412: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.896231ms
    Dec 14 10:07:56.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 2.015108279s
    Dec 14 10:07:58.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 4.015491695s
    Dec 14 10:08:00.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 6.015454033s
    Dec 14 10:08:02.421: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 8.016075102s
    Dec 14 10:08:04.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 10.015171918s
    Dec 14 10:08:06.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 12.01510713s
    Dec 14 10:08:08.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 14.015458474s
    Dec 14 10:08:10.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 16.014872984s
    Dec 14 10:08:12.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 18.015253642s
    Dec 14 10:08:14.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=true. Elapsed: 20.015267814s
    Dec 14 10:08:16.420: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Running", Reason="", readiness=false. Elapsed: 22.014914158s
    Dec 14 10:08:18.419: INFO: Pod "pod-subpath-test-projected-c7zs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014525137s
    STEP: Saw pod success 12/14/22 10:08:18.419
    Dec 14 10:08:18.420: INFO: Pod "pod-subpath-test-projected-c7zs" satisfied condition "Succeeded or Failed"
    Dec 14 10:08:18.427: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-subpath-test-projected-c7zs container test-container-subpath-projected-c7zs: <nil>
    STEP: delete the pod 12/14/22 10:08:18.446
    Dec 14 10:08:18.458: INFO: Waiting for pod pod-subpath-test-projected-c7zs to disappear
    Dec 14 10:08:18.465: INFO: Pod pod-subpath-test-projected-c7zs no longer exists
    STEP: Deleting pod pod-subpath-test-projected-c7zs 12/14/22 10:08:18.465
    Dec 14 10:08:18.465: INFO: Deleting pod "pod-subpath-test-projected-c7zs" in namespace "subpath-5140"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Dec 14 10:08:18.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5140" for this suite. 12/14/22 10:08:18.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:08:18.494
Dec 14 10:08:18.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename discovery 12/14/22 10:08:18.496
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:18.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:18.531
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 12/14/22 10:08:18.549
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Dec 14 10:08:18.886: INFO: Checking APIGroup: apiregistration.k8s.io
Dec 14 10:08:18.893: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Dec 14 10:08:18.893: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Dec 14 10:08:18.893: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Dec 14 10:08:18.893: INFO: Checking APIGroup: apps
Dec 14 10:08:18.899: INFO: PreferredVersion.GroupVersion: apps/v1
Dec 14 10:08:18.899: INFO: Versions found [{apps/v1 v1}]
Dec 14 10:08:18.899: INFO: apps/v1 matches apps/v1
Dec 14 10:08:18.899: INFO: Checking APIGroup: events.k8s.io
Dec 14 10:08:18.905: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Dec 14 10:08:18.905: INFO: Versions found [{events.k8s.io/v1 v1}]
Dec 14 10:08:18.905: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Dec 14 10:08:18.905: INFO: Checking APIGroup: authentication.k8s.io
Dec 14 10:08:18.911: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Dec 14 10:08:18.911: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Dec 14 10:08:18.911: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Dec 14 10:08:18.911: INFO: Checking APIGroup: authorization.k8s.io
Dec 14 10:08:18.917: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Dec 14 10:08:18.917: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Dec 14 10:08:18.917: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Dec 14 10:08:18.917: INFO: Checking APIGroup: autoscaling
Dec 14 10:08:18.922: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Dec 14 10:08:18.922: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Dec 14 10:08:18.922: INFO: autoscaling/v2 matches autoscaling/v2
Dec 14 10:08:18.922: INFO: Checking APIGroup: batch
Dec 14 10:08:18.928: INFO: PreferredVersion.GroupVersion: batch/v1
Dec 14 10:08:18.928: INFO: Versions found [{batch/v1 v1}]
Dec 14 10:08:18.928: INFO: batch/v1 matches batch/v1
Dec 14 10:08:18.928: INFO: Checking APIGroup: certificates.k8s.io
Dec 14 10:08:18.934: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Dec 14 10:08:18.934: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Dec 14 10:08:18.934: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Dec 14 10:08:18.934: INFO: Checking APIGroup: networking.k8s.io
Dec 14 10:08:18.940: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Dec 14 10:08:18.940: INFO: Versions found [{networking.k8s.io/v1 v1}]
Dec 14 10:08:18.940: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Dec 14 10:08:18.940: INFO: Checking APIGroup: policy
Dec 14 10:08:18.946: INFO: PreferredVersion.GroupVersion: policy/v1
Dec 14 10:08:18.946: INFO: Versions found [{policy/v1 v1}]
Dec 14 10:08:18.946: INFO: policy/v1 matches policy/v1
Dec 14 10:08:18.946: INFO: Checking APIGroup: rbac.authorization.k8s.io
Dec 14 10:08:18.952: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Dec 14 10:08:18.952: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Dec 14 10:08:18.952: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Dec 14 10:08:18.952: INFO: Checking APIGroup: storage.k8s.io
Dec 14 10:08:18.958: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Dec 14 10:08:18.958: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Dec 14 10:08:18.958: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Dec 14 10:08:18.958: INFO: Checking APIGroup: admissionregistration.k8s.io
Dec 14 10:08:18.964: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Dec 14 10:08:18.964: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Dec 14 10:08:18.964: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Dec 14 10:08:18.964: INFO: Checking APIGroup: apiextensions.k8s.io
Dec 14 10:08:18.970: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Dec 14 10:08:18.970: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Dec 14 10:08:18.970: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Dec 14 10:08:18.970: INFO: Checking APIGroup: scheduling.k8s.io
Dec 14 10:08:18.976: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Dec 14 10:08:18.976: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Dec 14 10:08:18.976: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Dec 14 10:08:18.976: INFO: Checking APIGroup: coordination.k8s.io
Dec 14 10:08:18.982: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Dec 14 10:08:18.982: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Dec 14 10:08:18.982: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Dec 14 10:08:18.982: INFO: Checking APIGroup: node.k8s.io
Dec 14 10:08:18.988: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Dec 14 10:08:18.988: INFO: Versions found [{node.k8s.io/v1 v1}]
Dec 14 10:08:18.988: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Dec 14 10:08:18.988: INFO: Checking APIGroup: discovery.k8s.io
Dec 14 10:08:18.994: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Dec 14 10:08:18.994: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Dec 14 10:08:18.994: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Dec 14 10:08:18.994: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Dec 14 10:08:19.000: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Dec 14 10:08:19.000: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Dec 14 10:08:19.000: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Dec 14 10:08:19.000: INFO: Checking APIGroup: autoscaling.k8s.io
Dec 14 10:08:19.006: INFO: PreferredVersion.GroupVersion: autoscaling.k8s.io/v1
Dec 14 10:08:19.006: INFO: Versions found [{autoscaling.k8s.io/v1 v1} {autoscaling.k8s.io/v1beta2 v1beta2}]
Dec 14 10:08:19.006: INFO: autoscaling.k8s.io/v1 matches autoscaling.k8s.io/v1
Dec 14 10:08:19.006: INFO: Checking APIGroup: crd.projectcalico.org
Dec 14 10:08:19.012: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Dec 14 10:08:19.012: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Dec 14 10:08:19.012: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Dec 14 10:08:19.012: INFO: Checking APIGroup: snapshot.storage.k8s.io
Dec 14 10:08:19.019: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Dec 14 10:08:19.019: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
Dec 14 10:08:19.019: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Dec 14 10:08:19.019: INFO: Checking APIGroup: cert.gardener.cloud
Dec 14 10:08:19.026: INFO: PreferredVersion.GroupVersion: cert.gardener.cloud/v1alpha1
Dec 14 10:08:19.026: INFO: Versions found [{cert.gardener.cloud/v1alpha1 v1alpha1}]
Dec 14 10:08:19.026: INFO: cert.gardener.cloud/v1alpha1 matches cert.gardener.cloud/v1alpha1
Dec 14 10:08:19.026: INFO: Checking APIGroup: dns.gardener.cloud
Dec 14 10:08:19.032: INFO: PreferredVersion.GroupVersion: dns.gardener.cloud/v1alpha1
Dec 14 10:08:19.032: INFO: Versions found [{dns.gardener.cloud/v1alpha1 v1alpha1}]
Dec 14 10:08:19.032: INFO: dns.gardener.cloud/v1alpha1 matches dns.gardener.cloud/v1alpha1
Dec 14 10:08:19.032: INFO: Checking APIGroup: metrics.k8s.io
Dec 14 10:08:19.038: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Dec 14 10:08:19.038: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Dec 14 10:08:19.038: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Dec 14 10:08:19.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3059" for this suite. 12/14/22 10:08:19.051
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":341,"skipped":6205,"failed":0}
------------------------------
• [0.565 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:08:18.494
    Dec 14 10:08:18.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename discovery 12/14/22 10:08:18.496
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:18.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:18.531
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 12/14/22 10:08:18.549
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Dec 14 10:08:18.886: INFO: Checking APIGroup: apiregistration.k8s.io
    Dec 14 10:08:18.893: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Dec 14 10:08:18.893: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Dec 14 10:08:18.893: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Dec 14 10:08:18.893: INFO: Checking APIGroup: apps
    Dec 14 10:08:18.899: INFO: PreferredVersion.GroupVersion: apps/v1
    Dec 14 10:08:18.899: INFO: Versions found [{apps/v1 v1}]
    Dec 14 10:08:18.899: INFO: apps/v1 matches apps/v1
    Dec 14 10:08:18.899: INFO: Checking APIGroup: events.k8s.io
    Dec 14 10:08:18.905: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Dec 14 10:08:18.905: INFO: Versions found [{events.k8s.io/v1 v1}]
    Dec 14 10:08:18.905: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Dec 14 10:08:18.905: INFO: Checking APIGroup: authentication.k8s.io
    Dec 14 10:08:18.911: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Dec 14 10:08:18.911: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Dec 14 10:08:18.911: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Dec 14 10:08:18.911: INFO: Checking APIGroup: authorization.k8s.io
    Dec 14 10:08:18.917: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Dec 14 10:08:18.917: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Dec 14 10:08:18.917: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Dec 14 10:08:18.917: INFO: Checking APIGroup: autoscaling
    Dec 14 10:08:18.922: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Dec 14 10:08:18.922: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Dec 14 10:08:18.922: INFO: autoscaling/v2 matches autoscaling/v2
    Dec 14 10:08:18.922: INFO: Checking APIGroup: batch
    Dec 14 10:08:18.928: INFO: PreferredVersion.GroupVersion: batch/v1
    Dec 14 10:08:18.928: INFO: Versions found [{batch/v1 v1}]
    Dec 14 10:08:18.928: INFO: batch/v1 matches batch/v1
    Dec 14 10:08:18.928: INFO: Checking APIGroup: certificates.k8s.io
    Dec 14 10:08:18.934: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Dec 14 10:08:18.934: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Dec 14 10:08:18.934: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Dec 14 10:08:18.934: INFO: Checking APIGroup: networking.k8s.io
    Dec 14 10:08:18.940: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Dec 14 10:08:18.940: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Dec 14 10:08:18.940: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Dec 14 10:08:18.940: INFO: Checking APIGroup: policy
    Dec 14 10:08:18.946: INFO: PreferredVersion.GroupVersion: policy/v1
    Dec 14 10:08:18.946: INFO: Versions found [{policy/v1 v1}]
    Dec 14 10:08:18.946: INFO: policy/v1 matches policy/v1
    Dec 14 10:08:18.946: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Dec 14 10:08:18.952: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Dec 14 10:08:18.952: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Dec 14 10:08:18.952: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Dec 14 10:08:18.952: INFO: Checking APIGroup: storage.k8s.io
    Dec 14 10:08:18.958: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Dec 14 10:08:18.958: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Dec 14 10:08:18.958: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Dec 14 10:08:18.958: INFO: Checking APIGroup: admissionregistration.k8s.io
    Dec 14 10:08:18.964: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Dec 14 10:08:18.964: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Dec 14 10:08:18.964: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Dec 14 10:08:18.964: INFO: Checking APIGroup: apiextensions.k8s.io
    Dec 14 10:08:18.970: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Dec 14 10:08:18.970: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Dec 14 10:08:18.970: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Dec 14 10:08:18.970: INFO: Checking APIGroup: scheduling.k8s.io
    Dec 14 10:08:18.976: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Dec 14 10:08:18.976: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Dec 14 10:08:18.976: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Dec 14 10:08:18.976: INFO: Checking APIGroup: coordination.k8s.io
    Dec 14 10:08:18.982: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Dec 14 10:08:18.982: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Dec 14 10:08:18.982: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Dec 14 10:08:18.982: INFO: Checking APIGroup: node.k8s.io
    Dec 14 10:08:18.988: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Dec 14 10:08:18.988: INFO: Versions found [{node.k8s.io/v1 v1}]
    Dec 14 10:08:18.988: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Dec 14 10:08:18.988: INFO: Checking APIGroup: discovery.k8s.io
    Dec 14 10:08:18.994: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Dec 14 10:08:18.994: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Dec 14 10:08:18.994: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Dec 14 10:08:18.994: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Dec 14 10:08:19.000: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Dec 14 10:08:19.000: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Dec 14 10:08:19.000: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Dec 14 10:08:19.000: INFO: Checking APIGroup: autoscaling.k8s.io
    Dec 14 10:08:19.006: INFO: PreferredVersion.GroupVersion: autoscaling.k8s.io/v1
    Dec 14 10:08:19.006: INFO: Versions found [{autoscaling.k8s.io/v1 v1} {autoscaling.k8s.io/v1beta2 v1beta2}]
    Dec 14 10:08:19.006: INFO: autoscaling.k8s.io/v1 matches autoscaling.k8s.io/v1
    Dec 14 10:08:19.006: INFO: Checking APIGroup: crd.projectcalico.org
    Dec 14 10:08:19.012: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Dec 14 10:08:19.012: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Dec 14 10:08:19.012: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Dec 14 10:08:19.012: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Dec 14 10:08:19.019: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Dec 14 10:08:19.019: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1} {snapshot.storage.k8s.io/v1beta1 v1beta1}]
    Dec 14 10:08:19.019: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Dec 14 10:08:19.019: INFO: Checking APIGroup: cert.gardener.cloud
    Dec 14 10:08:19.026: INFO: PreferredVersion.GroupVersion: cert.gardener.cloud/v1alpha1
    Dec 14 10:08:19.026: INFO: Versions found [{cert.gardener.cloud/v1alpha1 v1alpha1}]
    Dec 14 10:08:19.026: INFO: cert.gardener.cloud/v1alpha1 matches cert.gardener.cloud/v1alpha1
    Dec 14 10:08:19.026: INFO: Checking APIGroup: dns.gardener.cloud
    Dec 14 10:08:19.032: INFO: PreferredVersion.GroupVersion: dns.gardener.cloud/v1alpha1
    Dec 14 10:08:19.032: INFO: Versions found [{dns.gardener.cloud/v1alpha1 v1alpha1}]
    Dec 14 10:08:19.032: INFO: dns.gardener.cloud/v1alpha1 matches dns.gardener.cloud/v1alpha1
    Dec 14 10:08:19.032: INFO: Checking APIGroup: metrics.k8s.io
    Dec 14 10:08:19.038: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Dec 14 10:08:19.038: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Dec 14 10:08:19.038: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Dec 14 10:08:19.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3059" for this suite. 12/14/22 10:08:19.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:08:19.06
Dec 14 10:08:19.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 10:08:19.061
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:19.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:19.096
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Dec 14 10:08:19.109: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 create -f -'
Dec 14 10:08:19.682: INFO: stderr: ""
Dec 14 10:08:19.682: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Dec 14 10:08:19.682: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 create -f -'
Dec 14 10:08:19.939: INFO: stderr: ""
Dec 14 10:08:19.939: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 10:08:19.939
Dec 14 10:08:20.947: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:08:20.947: INFO: Found 0 / 1
Dec 14 10:08:21.949: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:08:21.949: INFO: Found 1 / 1
Dec 14 10:08:21.949: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 14 10:08:21.957: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:08:21.957: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 10:08:21.957: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe pod agnhost-primary-hdlx2'
Dec 14 10:08:22.060: INFO: stderr: ""
Dec 14 10:08:22.060: INFO: stdout: "Name:             agnhost-primary-hdlx2\nNamespace:        kubectl-5113\nPriority:         0\nService Account:  default\nNode:             izgw8jfcr55yi09nr0a5xaz/10.250.18.72\nStart Time:       Wed, 14 Dec 2022 10:08:19 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: bf5f1b3cd870674a75f69c773d6cf9438cdc823b446624bb086d2bd0fd463317\n                  cni.projectcalico.org/podIP: 172.16.0.236/32\n                  cni.projectcalico.org/podIPs: 172.16.0.236/32\nStatus:           Running\nIP:               172.16.0.236\nIPs:\n  IP:           172.16.0.236\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://096c70072e7e4a7f9765b1a8ecdaadebef8117e44c5ed1fea49bbda3a0dab1eb\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Dec 2022 10:08:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2sbx4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-2sbx4:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5113/agnhost-primary-hdlx2 to izgw8jfcr55yi09nr0a5xaz\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
Dec 14 10:08:22.060: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe rc agnhost-primary'
Dec 14 10:08:22.200: INFO: stderr: ""
Dec 14 10:08:22.200: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5113\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-hdlx2\n"
Dec 14 10:08:22.200: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe service agnhost-primary'
Dec 14 10:08:22.301: INFO: stderr: ""
Dec 14 10:08:22.301: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5113\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.26.46.38\nIPs:               172.26.46.38\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.0.236:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 14 10:08:22.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe node izgw86e9lj0cm6u1hvldynz'
Dec 14 10:08:22.458: INFO: stderr: ""
Dec 14 10:08:22.458: INFO: stdout: "Name:               izgw86e9lj0cm6u1hvldynz\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.t6-c1m2.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=izgw86e9lj0cm6u1hvldynz\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=true\n                    node.kubernetes.io/instance-type=ecs.t6-c1m2.large\n                    node.kubernetes.io/role=node\n                    topology.diskplugin.csi.alibabacloud.com/zone=eu-central-1b\n                    topology.kubernetes.io/region=eu-central-1\n                    topology.kubernetes.io/zone=eu-central-1b\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.4\n                    worker.gardener.cloud/pool=worker-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: 19e3838790ad0cd4c024089cdbf70ddd38ad112688d2157f154613e7590deef1\n                    csi.volume.kubernetes.io/nodeid: {\"diskplugin.csi.alibabacloud.com\":\"i-gw86e9lj0cm6u1hvldyn\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"true\",\"no...\n                    projectcalico.org/IPv4Address: 10.250.18.71/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Dec 2022 08:02:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  izgw86e9lj0cm6u1hvldynz\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 14 Dec 2022 10:08:22 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ClusterNetworkProblem         False   Wed, 14 Dec 2022 10:07:01 +0000   Wed, 14 Dec 2022 08:04:56 +0000   NoNetworkProblems               no cluster network problems\n  FrequentContainerdRestart     False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentDockerRestart         docker is functioning properly\n  HostNetworkProblem            False   Wed, 14 Dec 2022 10:07:11 +0000   Wed, 14 Dec 2022 08:35:46 +0000   NoNetworkProblems               no host network problems\n  NetworkUnavailable            False   Wed, 14 Dec 2022 08:02:54 +0000   Wed, 14 Dec 2022 08:02:54 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:03:23 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.18.71\n  Hostname:    izgw86e9lj0cm6u1hvldynz\nCapacity:\n  cpu:                2\n  ephemeral-storage:  34160548Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3832848Ki\n  pods:               110\nAllocatable:\n  cpu:                1920m\n  ephemeral-storage:  33231381069\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2681872Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 5258134d5fab421a85cc93f8974d5139\n  System UUID:                5258134d-5fab-421a-85cc-93f8974d5139\n  Boot ID:                    a1805fbe-5301-4fea-9ff0-14d9a42f564e\n  Kernel Version:             5.15.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 934.1\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      172.16.1.0/24\nPodCIDRs:                     172.16.1.0/24\nProviderID:                   eu-central-1.i-gw86e9lj0cm6u1hvldyn\nNon-terminated Pods:          (21 in total)\n  Namespace                   Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits    Age\n  ---------                   ----                                                               ------------  ----------  ---------------  -------------    ---\n  kube-system                 addons-nginx-ingress-controller-66dcb55f8b-cqwc8                   100m (5%)     0 (0%)      163378051 (5%)   4Gi (156%)       16m\n  kube-system                 addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s    0 (0%)        0 (0%)      0 (0%)           0 (0%)           128m\n  kube-system                 apiserver-proxy-wcs5k                                              40m (2%)      0 (0%)      40Mi (1%)        1114Mi (42%)     125m\n  kube-system                 calico-node-79gdj                                                  250m (13%)    0 (0%)      100Mi (3%)       2800Mi (106%)    125m\n  kube-system                 calico-node-vertical-autoscaler-6597dd8998-tsbck                   10m (0%)      0 (0%)      50Mi (1%)        130Mi (4%)       127m\n  kube-system                 calico-typha-deploy-65c54d4db6-6mdx6                               320m (16%)    0 (0%)      262144k (9%)     4194304k (152%)  123m\n  kube-system                 calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm                10m (0%)      0 (0%)      50Mi (1%)        100Mi (3%)       127m\n  kube-system                 calico-typha-vertical-autoscaler-84df655c88-wlqx5                  10m (0%)      0 (0%)      50Mi (1%)        130Mi (4%)       127m\n  kube-system                 coredns-859d4f7b5b-724vk                                           50m (2%)      0 (0%)      15Mi (0%)        1500Mi (57%)     127m\n  kube-system                 coredns-859d4f7b5b-zxww6                                           50m (2%)      0 (0%)      15Mi (0%)        1500Mi (57%)     127m\n  kube-system                 csi-disk-plugin-alicloud-mz6gw                                     34m (1%)      0 (0%)      104Mi (3%)       1580Mi (60%)     125m\n  kube-system                 egress-filter-applier-n76g2                                        50m (2%)      0 (0%)      64Mi (2%)        256Mi (9%)       125m\n  kube-system                 kube-proxy-worker-1-v1.25.4-4k5xr                                  22m (1%)      0 (0%)      47753748 (1%)    2Gi (78%)        114m\n  kube-system                 network-problem-detector-host-zrqcc                                10m (0%)      50m (2%)    32Mi (1%)        64Mi (2%)        125m\n  kube-system                 network-problem-detector-pod-ms9lr                                 10m (0%)      50m (2%)    32Mi (1%)        64Mi (2%)        125m\n  kube-system                 node-exporter-9qtdl                                                50m (2%)      0 (0%)      50Mi (1%)        250Mi (9%)       125m\n  kube-system                 node-local-dns-bfkj9                                               11m (0%)      0 (0%)      36253748 (1%)    145014992 (5%)   110m\n  kube-system                 node-problem-detector-l92rw                                        11m (0%)      0 (0%)      36253748 (1%)    120Mi (4%)       74m\n  kube-system                 vpn-shoot-5b86586f48-fbfm5                                         100m (5%)     0 (0%)      100Mi (3%)       100Mi (3%)       128m\n  kubernetes-dashboard        dashboard-metrics-scraper-6d54964d4b-jh2jz                         0 (0%)        0 (0%)      0 (0%)           0 (0%)           128m\n  kubernetes-dashboard        kubernetes-dashboard-8494758d8f-lwknh                              50m (2%)      0 (0%)      50Mi (1%)        256Mi (9%)       128m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests          Limits\n  --------           --------          ------\n  cpu                1188m (61%)       100m (5%)\n  memory             1334312447 (48%)  21229781200 (773%)\n  ephemeral-storage  0 (0%)            0 (0%)\n  hugepages-1Gi      0 (0%)            0 (0%)\n  hugepages-2Mi      0 (0%)            0 (0%)\nEvents:              <none>\n"
Dec 14 10:08:22.459: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe namespace kubectl-5113'
Dec 14 10:08:22.605: INFO: stderr: ""
Dec 14 10:08:22.605: INFO: stdout: "Name:         kubectl-5113\nLabels:       e2e-framework=kubectl\n              e2e-run=d784b4f6-5b92-4d47-8c5f-aec0e1a12994\n              kubernetes.io/metadata.name=kubectl-5113\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 10:08:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5113" for this suite. 12/14/22 10:08:22.617
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":342,"skipped":6229,"failed":0}
------------------------------
• [3.565 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:08:19.06
    Dec 14 10:08:19.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 10:08:19.061
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:19.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:19.096
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Dec 14 10:08:19.109: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 create -f -'
    Dec 14 10:08:19.682: INFO: stderr: ""
    Dec 14 10:08:19.682: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Dec 14 10:08:19.682: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 create -f -'
    Dec 14 10:08:19.939: INFO: stderr: ""
    Dec 14 10:08:19.939: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 10:08:19.939
    Dec 14 10:08:20.947: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:08:20.947: INFO: Found 0 / 1
    Dec 14 10:08:21.949: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:08:21.949: INFO: Found 1 / 1
    Dec 14 10:08:21.949: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec 14 10:08:21.957: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:08:21.957: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 10:08:21.957: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe pod agnhost-primary-hdlx2'
    Dec 14 10:08:22.060: INFO: stderr: ""
    Dec 14 10:08:22.060: INFO: stdout: "Name:             agnhost-primary-hdlx2\nNamespace:        kubectl-5113\nPriority:         0\nService Account:  default\nNode:             izgw8jfcr55yi09nr0a5xaz/10.250.18.72\nStart Time:       Wed, 14 Dec 2022 10:08:19 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: bf5f1b3cd870674a75f69c773d6cf9438cdc823b446624bb086d2bd0fd463317\n                  cni.projectcalico.org/podIP: 172.16.0.236/32\n                  cni.projectcalico.org/podIPs: 172.16.0.236/32\nStatus:           Running\nIP:               172.16.0.236\nIPs:\n  IP:           172.16.0.236\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://096c70072e7e4a7f9765b1a8ecdaadebef8117e44c5ed1fea49bbda3a0dab1eb\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Dec 2022 10:08:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.tmp5j-n6c.it.internal.staging.k8s.ondemand.com\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2sbx4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-2sbx4:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5113/agnhost-primary-hdlx2 to izgw8jfcr55yi09nr0a5xaz\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
    Dec 14 10:08:22.060: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe rc agnhost-primary'
    Dec 14 10:08:22.200: INFO: stderr: ""
    Dec 14 10:08:22.200: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5113\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-hdlx2\n"
    Dec 14 10:08:22.200: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe service agnhost-primary'
    Dec 14 10:08:22.301: INFO: stderr: ""
    Dec 14 10:08:22.301: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5113\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.26.46.38\nIPs:               172.26.46.38\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.0.236:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Dec 14 10:08:22.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe node izgw86e9lj0cm6u1hvldynz'
    Dec 14 10:08:22.458: INFO: stderr: ""
    Dec 14 10:08:22.458: INFO: stdout: "Name:               izgw86e9lj0cm6u1hvldynz\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.t6-c1m2.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=izgw86e9lj0cm6u1hvldynz\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=true\n                    node.kubernetes.io/instance-type=ecs.t6-c1m2.large\n                    node.kubernetes.io/role=node\n                    topology.diskplugin.csi.alibabacloud.com/zone=eu-central-1b\n                    topology.kubernetes.io/region=eu-central-1\n                    topology.kubernetes.io/zone=eu-central-1b\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.4\n                    worker.gardener.cloud/pool=worker-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: 19e3838790ad0cd4c024089cdbf70ddd38ad112688d2157f154613e7590deef1\n                    csi.volume.kubernetes.io/nodeid: {\"diskplugin.csi.alibabacloud.com\":\"i-gw86e9lj0cm6u1hvldyn\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"true\",\"no...\n                    projectcalico.org/IPv4Address: 10.250.18.71/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Dec 2022 08:02:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  izgw86e9lj0cm6u1hvldynz\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 14 Dec 2022 10:08:22 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ClusterNetworkProblem         False   Wed, 14 Dec 2022 10:07:01 +0000   Wed, 14 Dec 2022 08:04:56 +0000   NoNetworkProblems               no cluster network problems\n  FrequentContainerdRestart     False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Wed, 14 Dec 2022 10:04:02 +0000   Wed, 14 Dec 2022 08:53:57 +0000   NoFrequentDockerRestart         docker is functioning properly\n  HostNetworkProblem            False   Wed, 14 Dec 2022 10:07:11 +0000   Wed, 14 Dec 2022 08:35:46 +0000   NoNetworkProblems               no host network problems\n  NetworkUnavailable            False   Wed, 14 Dec 2022 08:02:54 +0000   Wed, 14 Dec 2022 08:02:54 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:02:42 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Wed, 14 Dec 2022 10:08:19 +0000   Wed, 14 Dec 2022 08:03:23 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.18.71\n  Hostname:    izgw86e9lj0cm6u1hvldynz\nCapacity:\n  cpu:                2\n  ephemeral-storage:  34160548Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3832848Ki\n  pods:               110\nAllocatable:\n  cpu:                1920m\n  ephemeral-storage:  33231381069\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2681872Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 5258134d5fab421a85cc93f8974d5139\n  System UUID:                5258134d-5fab-421a-85cc-93f8974d5139\n  Boot ID:                    a1805fbe-5301-4fea-9ff0-14d9a42f564e\n  Kernel Version:             5.15.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 934.1\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.4\n  Kube-Proxy Version:         v1.25.4\nPodCIDR:                      172.16.1.0/24\nPodCIDRs:                     172.16.1.0/24\nProviderID:                   eu-central-1.i-gw86e9lj0cm6u1hvldyn\nNon-terminated Pods:          (21 in total)\n  Namespace                   Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits    Age\n  ---------                   ----                                                               ------------  ----------  ---------------  -------------    ---\n  kube-system                 addons-nginx-ingress-controller-66dcb55f8b-cqwc8                   100m (5%)     0 (0%)      163378051 (5%)   4Gi (156%)       16m\n  kube-system                 addons-nginx-ingress-nginx-ingress-k8s-backend-8668c9bb59-r5v5s    0 (0%)        0 (0%)      0 (0%)           0 (0%)           128m\n  kube-system                 apiserver-proxy-wcs5k                                              40m (2%)      0 (0%)      40Mi (1%)        1114Mi (42%)     125m\n  kube-system                 calico-node-79gdj                                                  250m (13%)    0 (0%)      100Mi (3%)       2800Mi (106%)    125m\n  kube-system                 calico-node-vertical-autoscaler-6597dd8998-tsbck                   10m (0%)      0 (0%)      50Mi (1%)        130Mi (4%)       127m\n  kube-system                 calico-typha-deploy-65c54d4db6-6mdx6                               320m (16%)    0 (0%)      262144k (9%)     4194304k (152%)  123m\n  kube-system                 calico-typha-horizontal-autoscaler-6bb4bc55bc-mg8gm                10m (0%)      0 (0%)      50Mi (1%)        100Mi (3%)       127m\n  kube-system                 calico-typha-vertical-autoscaler-84df655c88-wlqx5                  10m (0%)      0 (0%)      50Mi (1%)        130Mi (4%)       127m\n  kube-system                 coredns-859d4f7b5b-724vk                                           50m (2%)      0 (0%)      15Mi (0%)        1500Mi (57%)     127m\n  kube-system                 coredns-859d4f7b5b-zxww6                                           50m (2%)      0 (0%)      15Mi (0%)        1500Mi (57%)     127m\n  kube-system                 csi-disk-plugin-alicloud-mz6gw                                     34m (1%)      0 (0%)      104Mi (3%)       1580Mi (60%)     125m\n  kube-system                 egress-filter-applier-n76g2                                        50m (2%)      0 (0%)      64Mi (2%)        256Mi (9%)       125m\n  kube-system                 kube-proxy-worker-1-v1.25.4-4k5xr                                  22m (1%)      0 (0%)      47753748 (1%)    2Gi (78%)        114m\n  kube-system                 network-problem-detector-host-zrqcc                                10m (0%)      50m (2%)    32Mi (1%)        64Mi (2%)        125m\n  kube-system                 network-problem-detector-pod-ms9lr                                 10m (0%)      50m (2%)    32Mi (1%)        64Mi (2%)        125m\n  kube-system                 node-exporter-9qtdl                                                50m (2%)      0 (0%)      50Mi (1%)        250Mi (9%)       125m\n  kube-system                 node-local-dns-bfkj9                                               11m (0%)      0 (0%)      36253748 (1%)    145014992 (5%)   110m\n  kube-system                 node-problem-detector-l92rw                                        11m (0%)      0 (0%)      36253748 (1%)    120Mi (4%)       74m\n  kube-system                 vpn-shoot-5b86586f48-fbfm5                                         100m (5%)     0 (0%)      100Mi (3%)       100Mi (3%)       128m\n  kubernetes-dashboard        dashboard-metrics-scraper-6d54964d4b-jh2jz                         0 (0%)        0 (0%)      0 (0%)           0 (0%)           128m\n  kubernetes-dashboard        kubernetes-dashboard-8494758d8f-lwknh                              50m (2%)      0 (0%)      50Mi (1%)        256Mi (9%)       128m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests          Limits\n  --------           --------          ------\n  cpu                1188m (61%)       100m (5%)\n  memory             1334312447 (48%)  21229781200 (773%)\n  ephemeral-storage  0 (0%)            0 (0%)\n  hugepages-1Gi      0 (0%)            0 (0%)\n  hugepages-2Mi      0 (0%)            0 (0%)\nEvents:              <none>\n"
    Dec 14 10:08:22.459: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-5113 describe namespace kubectl-5113'
    Dec 14 10:08:22.605: INFO: stderr: ""
    Dec 14 10:08:22.605: INFO: stdout: "Name:         kubectl-5113\nLabels:       e2e-framework=kubectl\n              e2e-run=d784b4f6-5b92-4d47-8c5f-aec0e1a12994\n              kubernetes.io/metadata.name=kubectl-5113\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 10:08:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5113" for this suite. 12/14/22 10:08:22.617
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:08:22.626
Dec 14 10:08:22.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns 12/14/22 10:08:22.626
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:22.648
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:22.66
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/14/22 10:08:22.673
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 12/14/22 10:08:22.673
STEP: creating a pod to probe DNS 12/14/22 10:08:22.673
STEP: submitting the pod to kubernetes 12/14/22 10:08:22.673
Dec 14 10:08:22.688: INFO: Waiting up to 15m0s for pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d" in namespace "dns-9300" to be "running"
Dec 14 10:08:22.696: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.519018ms
Dec 14 10:08:24.705: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016377323s
Dec 14 10:08:24.705: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d" satisfied condition "running"
STEP: retrieving the pod 12/14/22 10:08:24.705
STEP: looking for the results for each expected name from probers 12/14/22 10:08:24.713
Dec 14 10:08:24.904: INFO: DNS probes using dns-9300/dns-test-11971162-2bfa-4d9f-9a62-84694510280d succeeded

STEP: deleting the pod 12/14/22 10:08:24.904
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Dec 14 10:08:24.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9300" for this suite. 12/14/22 10:08:24.93
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":343,"skipped":6229,"failed":0}
------------------------------
• [2.313 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:08:22.626
    Dec 14 10:08:22.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename dns 12/14/22 10:08:22.626
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:22.648
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:22.66
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/14/22 10:08:22.673
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     12/14/22 10:08:22.673
    STEP: creating a pod to probe DNS 12/14/22 10:08:22.673
    STEP: submitting the pod to kubernetes 12/14/22 10:08:22.673
    Dec 14 10:08:22.688: INFO: Waiting up to 15m0s for pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d" in namespace "dns-9300" to be "running"
    Dec 14 10:08:22.696: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.519018ms
    Dec 14 10:08:24.705: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016377323s
    Dec 14 10:08:24.705: INFO: Pod "dns-test-11971162-2bfa-4d9f-9a62-84694510280d" satisfied condition "running"
    STEP: retrieving the pod 12/14/22 10:08:24.705
    STEP: looking for the results for each expected name from probers 12/14/22 10:08:24.713
    Dec 14 10:08:24.904: INFO: DNS probes using dns-9300/dns-test-11971162-2bfa-4d9f-9a62-84694510280d succeeded

    STEP: deleting the pod 12/14/22 10:08:24.904
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Dec 14 10:08:24.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9300" for this suite. 12/14/22 10:08:24.93
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:08:24.942
Dec 14 10:08:24.942: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency 12/14/22 10:08:24.943
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:24.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:24.979
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Dec 14 10:08:24.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7506 12/14/22 10:08:24.992
I1214 10:08:25.001181    6248 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7506, replica count: 1
I1214 10:08:26.051894    6248 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1214 10:08:27.052498    6248 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 10:08:27.169: INFO: Created: latency-svc-gqpkw
Dec 14 10:08:27.172: INFO: Got endpoints: latency-svc-gqpkw [19.860875ms]
Dec 14 10:08:27.185: INFO: Created: latency-svc-dmqdd
Dec 14 10:08:27.189: INFO: Got endpoints: latency-svc-dmqdd [16.486566ms]
Dec 14 10:08:27.189: INFO: Created: latency-svc-w7mrf
Dec 14 10:08:27.193: INFO: Got endpoints: latency-svc-w7mrf [20.4942ms]
Dec 14 10:08:27.196: INFO: Created: latency-svc-k64wb
Dec 14 10:08:27.200: INFO: Created: latency-svc-ddpc6
Dec 14 10:08:27.201: INFO: Got endpoints: latency-svc-k64wb [28.186708ms]
Dec 14 10:08:27.204: INFO: Got endpoints: latency-svc-ddpc6 [31.027589ms]
Dec 14 10:08:27.204: INFO: Created: latency-svc-4gswm
Dec 14 10:08:27.208: INFO: Got endpoints: latency-svc-4gswm [35.298943ms]
Dec 14 10:08:27.211: INFO: Created: latency-svc-kmtjm
Dec 14 10:08:27.214: INFO: Created: latency-svc-pdgsn
Dec 14 10:08:27.216: INFO: Got endpoints: latency-svc-kmtjm [43.409137ms]
Dec 14 10:08:27.219: INFO: Got endpoints: latency-svc-pdgsn [46.18355ms]
Dec 14 10:08:27.219: INFO: Created: latency-svc-f7kr6
Dec 14 10:08:27.222: INFO: Got endpoints: latency-svc-f7kr6 [49.560616ms]
Dec 14 10:08:27.224: INFO: Created: latency-svc-x5824
Dec 14 10:08:27.226: INFO: Got endpoints: latency-svc-x5824 [53.928679ms]
Dec 14 10:08:27.228: INFO: Created: latency-svc-ztj6p
Dec 14 10:08:27.230: INFO: Got endpoints: latency-svc-ztj6p [57.73972ms]
Dec 14 10:08:27.231: INFO: Created: latency-svc-6r5cz
Dec 14 10:08:27.234: INFO: Got endpoints: latency-svc-6r5cz [61.815718ms]
Dec 14 10:08:27.235: INFO: Created: latency-svc-dxzvk
Dec 14 10:08:27.239: INFO: Got endpoints: latency-svc-dxzvk [65.907622ms]
Dec 14 10:08:27.239: INFO: Created: latency-svc-stjb6
Dec 14 10:08:27.243: INFO: Got endpoints: latency-svc-stjb6 [69.939701ms]
Dec 14 10:08:27.245: INFO: Created: latency-svc-r9gl8
Dec 14 10:08:27.248: INFO: Got endpoints: latency-svc-r9gl8 [76.021465ms]
Dec 14 10:08:27.252: INFO: Created: latency-svc-n52cj
Dec 14 10:08:27.255: INFO: Got endpoints: latency-svc-n52cj [82.658549ms]
Dec 14 10:08:27.257: INFO: Created: latency-svc-stb5v
Dec 14 10:08:27.261: INFO: Created: latency-svc-4vpl4
Dec 14 10:08:27.261: INFO: Got endpoints: latency-svc-stb5v [72.646624ms]
Dec 14 10:08:27.267: INFO: Got endpoints: latency-svc-4vpl4 [74.500389ms]
Dec 14 10:08:27.268: INFO: Created: latency-svc-2gk42
Dec 14 10:08:27.271: INFO: Got endpoints: latency-svc-2gk42 [70.791242ms]
Dec 14 10:08:27.283: INFO: Created: latency-svc-r652t
Dec 14 10:08:27.290: INFO: Created: latency-svc-fzflf
Dec 14 10:08:27.290: INFO: Got endpoints: latency-svc-r652t [86.501344ms]
Dec 14 10:08:27.291: INFO: Got endpoints: latency-svc-fzflf [83.244899ms]
Dec 14 10:08:27.291: INFO: Created: latency-svc-fckmz
Dec 14 10:08:27.295: INFO: Got endpoints: latency-svc-fckmz [78.74786ms]
Dec 14 10:08:27.299: INFO: Created: latency-svc-ltjkw
Dec 14 10:08:27.300: INFO: Got endpoints: latency-svc-ltjkw [81.234777ms]
Dec 14 10:08:27.303: INFO: Created: latency-svc-v5z5q
Dec 14 10:08:27.309: INFO: Created: latency-svc-9k55c
Dec 14 10:08:27.309: INFO: Got endpoints: latency-svc-9k55c [82.615717ms]
Dec 14 10:08:27.309: INFO: Got endpoints: latency-svc-v5z5q [87.124275ms]
Dec 14 10:08:27.311: INFO: Created: latency-svc-2rvfp
Dec 14 10:08:27.314: INFO: Got endpoints: latency-svc-2rvfp [83.787739ms]
Dec 14 10:08:27.316: INFO: Created: latency-svc-hg8zk
Dec 14 10:08:27.319: INFO: Created: latency-svc-t8zc2
Dec 14 10:08:27.320: INFO: Got endpoints: latency-svc-hg8zk [85.055508ms]
Dec 14 10:08:27.321: INFO: Got endpoints: latency-svc-t8zc2 [82.407239ms]
Dec 14 10:08:27.323: INFO: Created: latency-svc-t7qfl
Dec 14 10:08:27.326: INFO: Got endpoints: latency-svc-t7qfl [83.682933ms]
Dec 14 10:08:27.327: INFO: Created: latency-svc-hnpbf
Dec 14 10:08:27.330: INFO: Got endpoints: latency-svc-hnpbf [81.328652ms]
Dec 14 10:08:27.331: INFO: Created: latency-svc-klc56
Dec 14 10:08:27.333: INFO: Created: latency-svc-mt9rd
Dec 14 10:08:27.334: INFO: Got endpoints: latency-svc-klc56 [78.350438ms]
Dec 14 10:08:27.336: INFO: Got endpoints: latency-svc-mt9rd [74.811533ms]
Dec 14 10:08:27.338: INFO: Created: latency-svc-6c2n4
Dec 14 10:08:27.341: INFO: Got endpoints: latency-svc-6c2n4 [73.847434ms]
Dec 14 10:08:27.341: INFO: Created: latency-svc-vqwcn
Dec 14 10:08:27.346: INFO: Created: latency-svc-2r599
Dec 14 10:08:27.348: INFO: Created: latency-svc-sn2dq
Dec 14 10:08:27.353: INFO: Created: latency-svc-fxkbb
Dec 14 10:08:27.356: INFO: Created: latency-svc-2m7m6
Dec 14 10:08:27.361: INFO: Created: latency-svc-p9fc9
Dec 14 10:08:27.365: INFO: Created: latency-svc-bfkxl
Dec 14 10:08:27.373: INFO: Got endpoints: latency-svc-vqwcn [101.529943ms]
Dec 14 10:08:27.374: INFO: Created: latency-svc-4xtpx
Dec 14 10:08:27.378: INFO: Created: latency-svc-szrkw
Dec 14 10:08:27.390: INFO: Created: latency-svc-nsnmv
Dec 14 10:08:27.393: INFO: Created: latency-svc-bszns
Dec 14 10:08:27.397: INFO: Created: latency-svc-wc8fn
Dec 14 10:08:27.399: INFO: Created: latency-svc-6q6wb
Dec 14 10:08:27.404: INFO: Created: latency-svc-bbcs4
Dec 14 10:08:27.407: INFO: Created: latency-svc-228fm
Dec 14 10:08:27.414: INFO: Created: latency-svc-qnpkh
Dec 14 10:08:27.422: INFO: Got endpoints: latency-svc-2r599 [132.331913ms]
Dec 14 10:08:27.434: INFO: Created: latency-svc-8fbdc
Dec 14 10:08:27.473: INFO: Got endpoints: latency-svc-sn2dq [181.452753ms]
Dec 14 10:08:27.484: INFO: Created: latency-svc-lhsqm
Dec 14 10:08:27.524: INFO: Got endpoints: latency-svc-fxkbb [228.949311ms]
Dec 14 10:08:27.536: INFO: Created: latency-svc-cjw4b
Dec 14 10:08:27.573: INFO: Got endpoints: latency-svc-2m7m6 [272.799937ms]
Dec 14 10:08:27.585: INFO: Created: latency-svc-b28b9
Dec 14 10:08:27.623: INFO: Got endpoints: latency-svc-p9fc9 [314.126159ms]
Dec 14 10:08:27.637: INFO: Created: latency-svc-n4sm4
Dec 14 10:08:27.673: INFO: Got endpoints: latency-svc-bfkxl [363.913666ms]
Dec 14 10:08:27.694: INFO: Created: latency-svc-mgzzr
Dec 14 10:08:27.722: INFO: Got endpoints: latency-svc-4xtpx [407.39892ms]
Dec 14 10:08:27.733: INFO: Created: latency-svc-wws6z
Dec 14 10:08:27.773: INFO: Got endpoints: latency-svc-szrkw [452.910801ms]
Dec 14 10:08:27.784: INFO: Created: latency-svc-wfplm
Dec 14 10:08:27.828: INFO: Got endpoints: latency-svc-nsnmv [507.407398ms]
Dec 14 10:08:27.840: INFO: Created: latency-svc-hqrbp
Dec 14 10:08:27.874: INFO: Got endpoints: latency-svc-bszns [548.121756ms]
Dec 14 10:08:27.886: INFO: Created: latency-svc-4chff
Dec 14 10:08:27.923: INFO: Got endpoints: latency-svc-wc8fn [592.83607ms]
Dec 14 10:08:27.934: INFO: Created: latency-svc-ccrzg
Dec 14 10:08:27.973: INFO: Got endpoints: latency-svc-6q6wb [638.876065ms]
Dec 14 10:08:27.985: INFO: Created: latency-svc-2p8sj
Dec 14 10:08:28.023: INFO: Got endpoints: latency-svc-bbcs4 [686.50679ms]
Dec 14 10:08:28.035: INFO: Created: latency-svc-h2bbj
Dec 14 10:08:28.075: INFO: Got endpoints: latency-svc-228fm [734.129371ms]
Dec 14 10:08:28.088: INFO: Created: latency-svc-xdkfw
Dec 14 10:08:28.123: INFO: Got endpoints: latency-svc-qnpkh [749.574186ms]
Dec 14 10:08:28.135: INFO: Created: latency-svc-c4nww
Dec 14 10:08:28.173: INFO: Got endpoints: latency-svc-8fbdc [750.475093ms]
Dec 14 10:08:28.186: INFO: Created: latency-svc-54npz
Dec 14 10:08:28.223: INFO: Got endpoints: latency-svc-lhsqm [750.851596ms]
Dec 14 10:08:28.249: INFO: Created: latency-svc-krg6m
Dec 14 10:08:28.273: INFO: Got endpoints: latency-svc-cjw4b [748.680112ms]
Dec 14 10:08:28.284: INFO: Created: latency-svc-crn64
Dec 14 10:08:28.324: INFO: Got endpoints: latency-svc-b28b9 [750.748682ms]
Dec 14 10:08:28.338: INFO: Created: latency-svc-r9ck2
Dec 14 10:08:28.373: INFO: Got endpoints: latency-svc-n4sm4 [749.391466ms]
Dec 14 10:08:28.384: INFO: Created: latency-svc-vnl8x
Dec 14 10:08:28.423: INFO: Got endpoints: latency-svc-mgzzr [750.316872ms]
Dec 14 10:08:28.435: INFO: Created: latency-svc-2cmkz
Dec 14 10:08:28.524: INFO: Got endpoints: latency-svc-wws6z [802.496956ms]
Dec 14 10:08:28.536: INFO: Created: latency-svc-75ccq
Dec 14 10:08:28.573: INFO: Got endpoints: latency-svc-wfplm [799.909252ms]
Dec 14 10:08:28.584: INFO: Created: latency-svc-g947r
Dec 14 10:08:28.623: INFO: Got endpoints: latency-svc-hqrbp [794.424568ms]
Dec 14 10:08:28.635: INFO: Created: latency-svc-wtc6w
Dec 14 10:08:28.673: INFO: Got endpoints: latency-svc-4chff [798.91881ms]
Dec 14 10:08:28.685: INFO: Created: latency-svc-vxpwm
Dec 14 10:08:28.724: INFO: Got endpoints: latency-svc-ccrzg [801.365786ms]
Dec 14 10:08:28.736: INFO: Created: latency-svc-rgvzq
Dec 14 10:08:28.773: INFO: Got endpoints: latency-svc-2p8sj [800.260316ms]
Dec 14 10:08:28.784: INFO: Created: latency-svc-rdvmm
Dec 14 10:08:28.822: INFO: Got endpoints: latency-svc-h2bbj [799.322669ms]
Dec 14 10:08:28.834: INFO: Created: latency-svc-vxq5g
Dec 14 10:08:28.873: INFO: Got endpoints: latency-svc-xdkfw [797.447289ms]
Dec 14 10:08:28.884: INFO: Created: latency-svc-2zjmm
Dec 14 10:08:28.923: INFO: Got endpoints: latency-svc-c4nww [800.627788ms]
Dec 14 10:08:28.940: INFO: Created: latency-svc-phqnp
Dec 14 10:08:28.978: INFO: Got endpoints: latency-svc-54npz [804.876732ms]
Dec 14 10:08:28.990: INFO: Created: latency-svc-fhvf4
Dec 14 10:08:29.024: INFO: Got endpoints: latency-svc-krg6m [800.598128ms]
Dec 14 10:08:29.036: INFO: Created: latency-svc-4d854
Dec 14 10:08:29.072: INFO: Got endpoints: latency-svc-crn64 [799.762328ms]
Dec 14 10:08:29.083: INFO: Created: latency-svc-6dq5c
Dec 14 10:08:29.122: INFO: Got endpoints: latency-svc-r9ck2 [797.939569ms]
Dec 14 10:08:29.135: INFO: Created: latency-svc-54bbn
Dec 14 10:08:29.173: INFO: Got endpoints: latency-svc-vnl8x [800.33926ms]
Dec 14 10:08:29.185: INFO: Created: latency-svc-rcgbk
Dec 14 10:08:29.223: INFO: Got endpoints: latency-svc-2cmkz [799.518629ms]
Dec 14 10:08:29.237: INFO: Created: latency-svc-j74ql
Dec 14 10:08:29.272: INFO: Got endpoints: latency-svc-75ccq [748.156458ms]
Dec 14 10:08:29.283: INFO: Created: latency-svc-5swws
Dec 14 10:08:29.323: INFO: Got endpoints: latency-svc-g947r [750.203219ms]
Dec 14 10:08:29.334: INFO: Created: latency-svc-gbsvg
Dec 14 10:08:29.372: INFO: Got endpoints: latency-svc-wtc6w [749.347624ms]
Dec 14 10:08:29.384: INFO: Created: latency-svc-r7tpj
Dec 14 10:08:29.423: INFO: Got endpoints: latency-svc-vxpwm [749.300722ms]
Dec 14 10:08:29.435: INFO: Created: latency-svc-xr7l9
Dec 14 10:08:29.474: INFO: Got endpoints: latency-svc-rgvzq [750.371622ms]
Dec 14 10:08:29.486: INFO: Created: latency-svc-q42df
Dec 14 10:08:29.524: INFO: Got endpoints: latency-svc-rdvmm [751.107652ms]
Dec 14 10:08:29.536: INFO: Created: latency-svc-rzsrv
Dec 14 10:08:29.572: INFO: Got endpoints: latency-svc-vxq5g [749.752682ms]
Dec 14 10:08:29.584: INFO: Created: latency-svc-znmkl
Dec 14 10:08:29.623: INFO: Got endpoints: latency-svc-2zjmm [749.887305ms]
Dec 14 10:08:29.635: INFO: Created: latency-svc-fc9gg
Dec 14 10:08:29.673: INFO: Got endpoints: latency-svc-phqnp [749.220916ms]
Dec 14 10:08:29.684: INFO: Created: latency-svc-sgdj4
Dec 14 10:08:29.723: INFO: Got endpoints: latency-svc-fhvf4 [745.403277ms]
Dec 14 10:08:29.743: INFO: Created: latency-svc-7p44b
Dec 14 10:08:29.772: INFO: Got endpoints: latency-svc-4d854 [747.501586ms]
Dec 14 10:08:29.783: INFO: Created: latency-svc-w547s
Dec 14 10:08:29.823: INFO: Got endpoints: latency-svc-6dq5c [750.569584ms]
Dec 14 10:08:29.834: INFO: Created: latency-svc-8dksh
Dec 14 10:08:29.874: INFO: Got endpoints: latency-svc-54bbn [751.438845ms]
Dec 14 10:08:29.885: INFO: Created: latency-svc-hkd7c
Dec 14 10:08:29.923: INFO: Got endpoints: latency-svc-rcgbk [749.424085ms]
Dec 14 10:08:29.935: INFO: Created: latency-svc-9zqg6
Dec 14 10:08:29.972: INFO: Got endpoints: latency-svc-j74ql [749.154467ms]
Dec 14 10:08:29.983: INFO: Created: latency-svc-28wqz
Dec 14 10:08:30.023: INFO: Got endpoints: latency-svc-5swws [750.635279ms]
Dec 14 10:08:30.034: INFO: Created: latency-svc-b5669
Dec 14 10:08:30.072: INFO: Got endpoints: latency-svc-gbsvg [749.330402ms]
Dec 14 10:08:30.083: INFO: Created: latency-svc-flhnj
Dec 14 10:08:30.124: INFO: Got endpoints: latency-svc-r7tpj [751.633126ms]
Dec 14 10:08:30.135: INFO: Created: latency-svc-ncf8n
Dec 14 10:08:30.173: INFO: Got endpoints: latency-svc-xr7l9 [750.051654ms]
Dec 14 10:08:30.184: INFO: Created: latency-svc-nx72k
Dec 14 10:08:30.222: INFO: Got endpoints: latency-svc-q42df [747.764481ms]
Dec 14 10:08:30.234: INFO: Created: latency-svc-5ldvx
Dec 14 10:08:30.273: INFO: Got endpoints: latency-svc-rzsrv [749.177392ms]
Dec 14 10:08:30.285: INFO: Created: latency-svc-9rk59
Dec 14 10:08:30.323: INFO: Got endpoints: latency-svc-znmkl [750.804065ms]
Dec 14 10:08:30.334: INFO: Created: latency-svc-qr8ms
Dec 14 10:08:30.372: INFO: Got endpoints: latency-svc-fc9gg [749.123651ms]
Dec 14 10:08:30.383: INFO: Created: latency-svc-twrwh
Dec 14 10:08:30.423: INFO: Got endpoints: latency-svc-sgdj4 [749.764824ms]
Dec 14 10:08:30.434: INFO: Created: latency-svc-8pt5v
Dec 14 10:08:30.473: INFO: Got endpoints: latency-svc-7p44b [749.510199ms]
Dec 14 10:08:30.485: INFO: Created: latency-svc-n6v26
Dec 14 10:08:30.523: INFO: Got endpoints: latency-svc-w547s [750.823349ms]
Dec 14 10:08:30.534: INFO: Created: latency-svc-8sjqz
Dec 14 10:08:30.573: INFO: Got endpoints: latency-svc-8dksh [749.840887ms]
Dec 14 10:08:30.584: INFO: Created: latency-svc-jvqtx
Dec 14 10:08:30.622: INFO: Got endpoints: latency-svc-hkd7c [748.748288ms]
Dec 14 10:08:30.634: INFO: Created: latency-svc-g4955
Dec 14 10:08:30.676: INFO: Got endpoints: latency-svc-9zqg6 [753.580245ms]
Dec 14 10:08:30.687: INFO: Created: latency-svc-fgvfb
Dec 14 10:08:30.723: INFO: Got endpoints: latency-svc-28wqz [750.679729ms]
Dec 14 10:08:30.735: INFO: Created: latency-svc-p5z4h
Dec 14 10:08:30.774: INFO: Got endpoints: latency-svc-b5669 [751.110158ms]
Dec 14 10:08:30.792: INFO: Created: latency-svc-828pp
Dec 14 10:08:30.822: INFO: Got endpoints: latency-svc-flhnj [749.739288ms]
Dec 14 10:08:30.834: INFO: Created: latency-svc-487cf
Dec 14 10:08:30.878: INFO: Got endpoints: latency-svc-ncf8n [754.126048ms]
Dec 14 10:08:30.900: INFO: Created: latency-svc-92vm8
Dec 14 10:08:30.923: INFO: Got endpoints: latency-svc-nx72k [749.640035ms]
Dec 14 10:08:30.935: INFO: Created: latency-svc-5hwlh
Dec 14 10:08:30.974: INFO: Got endpoints: latency-svc-5ldvx [751.198041ms]
Dec 14 10:08:30.985: INFO: Created: latency-svc-8f6hq
Dec 14 10:08:31.022: INFO: Got endpoints: latency-svc-9rk59 [749.060316ms]
Dec 14 10:08:31.034: INFO: Created: latency-svc-jr2hz
Dec 14 10:08:31.072: INFO: Got endpoints: latency-svc-qr8ms [749.101729ms]
Dec 14 10:08:31.083: INFO: Created: latency-svc-sm9m6
Dec 14 10:08:31.125: INFO: Got endpoints: latency-svc-twrwh [752.323675ms]
Dec 14 10:08:31.137: INFO: Created: latency-svc-t8r6r
Dec 14 10:08:31.174: INFO: Got endpoints: latency-svc-8pt5v [751.607428ms]
Dec 14 10:08:31.186: INFO: Created: latency-svc-99ns4
Dec 14 10:08:31.223: INFO: Got endpoints: latency-svc-n6v26 [749.598386ms]
Dec 14 10:08:31.234: INFO: Created: latency-svc-njg54
Dec 14 10:08:31.273: INFO: Got endpoints: latency-svc-8sjqz [750.415426ms]
Dec 14 10:08:31.285: INFO: Created: latency-svc-qs7gl
Dec 14 10:08:31.323: INFO: Got endpoints: latency-svc-jvqtx [750.155278ms]
Dec 14 10:08:31.337: INFO: Created: latency-svc-f896j
Dec 14 10:08:31.373: INFO: Got endpoints: latency-svc-g4955 [750.63438ms]
Dec 14 10:08:31.386: INFO: Created: latency-svc-mtwqn
Dec 14 10:08:31.423: INFO: Got endpoints: latency-svc-fgvfb [746.806286ms]
Dec 14 10:08:31.435: INFO: Created: latency-svc-gb5vr
Dec 14 10:08:31.472: INFO: Got endpoints: latency-svc-p5z4h [749.107563ms]
Dec 14 10:08:31.484: INFO: Created: latency-svc-2w2sl
Dec 14 10:08:31.523: INFO: Got endpoints: latency-svc-828pp [748.472749ms]
Dec 14 10:08:31.535: INFO: Created: latency-svc-gfn9r
Dec 14 10:08:31.573: INFO: Got endpoints: latency-svc-487cf [751.313558ms]
Dec 14 10:08:31.585: INFO: Created: latency-svc-h68k5
Dec 14 10:08:31.632: INFO: Got endpoints: latency-svc-92vm8 [754.087914ms]
Dec 14 10:08:31.644: INFO: Created: latency-svc-7zzxw
Dec 14 10:08:31.673: INFO: Got endpoints: latency-svc-5hwlh [750.125311ms]
Dec 14 10:08:31.685: INFO: Created: latency-svc-kktn6
Dec 14 10:08:31.724: INFO: Got endpoints: latency-svc-8f6hq [750.388283ms]
Dec 14 10:08:31.737: INFO: Created: latency-svc-9wqdz
Dec 14 10:08:31.773: INFO: Got endpoints: latency-svc-jr2hz [750.029147ms]
Dec 14 10:08:31.784: INFO: Created: latency-svc-4q2kz
Dec 14 10:08:31.822: INFO: Got endpoints: latency-svc-sm9m6 [750.084829ms]
Dec 14 10:08:31.837: INFO: Created: latency-svc-5tgq2
Dec 14 10:08:31.873: INFO: Got endpoints: latency-svc-t8r6r [748.857359ms]
Dec 14 10:08:31.887: INFO: Created: latency-svc-fmw7l
Dec 14 10:08:31.922: INFO: Got endpoints: latency-svc-99ns4 [748.068866ms]
Dec 14 10:08:31.934: INFO: Created: latency-svc-r2g2d
Dec 14 10:08:31.972: INFO: Got endpoints: latency-svc-njg54 [749.351312ms]
Dec 14 10:08:31.984: INFO: Created: latency-svc-w46fv
Dec 14 10:08:32.023: INFO: Got endpoints: latency-svc-qs7gl [749.405445ms]
Dec 14 10:08:32.035: INFO: Created: latency-svc-btt5z
Dec 14 10:08:32.072: INFO: Got endpoints: latency-svc-f896j [748.763386ms]
Dec 14 10:08:32.084: INFO: Created: latency-svc-gbsc5
Dec 14 10:08:32.123: INFO: Got endpoints: latency-svc-mtwqn [749.816134ms]
Dec 14 10:08:32.135: INFO: Created: latency-svc-m5kvg
Dec 14 10:08:32.172: INFO: Got endpoints: latency-svc-gb5vr [749.224934ms]
Dec 14 10:08:32.185: INFO: Created: latency-svc-t7x6b
Dec 14 10:08:32.223: INFO: Got endpoints: latency-svc-2w2sl [750.525317ms]
Dec 14 10:08:32.235: INFO: Created: latency-svc-dkpvp
Dec 14 10:08:32.273: INFO: Got endpoints: latency-svc-gfn9r [750.10883ms]
Dec 14 10:08:32.284: INFO: Created: latency-svc-2pnjb
Dec 14 10:08:32.323: INFO: Got endpoints: latency-svc-h68k5 [749.590582ms]
Dec 14 10:08:32.335: INFO: Created: latency-svc-kqvfv
Dec 14 10:08:32.375: INFO: Got endpoints: latency-svc-7zzxw [742.124733ms]
Dec 14 10:08:32.387: INFO: Created: latency-svc-2pgk5
Dec 14 10:08:32.422: INFO: Got endpoints: latency-svc-kktn6 [749.507706ms]
Dec 14 10:08:32.434: INFO: Created: latency-svc-ltj6q
Dec 14 10:08:32.473: INFO: Got endpoints: latency-svc-9wqdz [749.026758ms]
Dec 14 10:08:32.486: INFO: Created: latency-svc-jqm8p
Dec 14 10:08:32.522: INFO: Got endpoints: latency-svc-4q2kz [749.74194ms]
Dec 14 10:08:32.534: INFO: Created: latency-svc-ppzfj
Dec 14 10:08:32.574: INFO: Got endpoints: latency-svc-5tgq2 [751.701864ms]
Dec 14 10:08:32.586: INFO: Created: latency-svc-4c5fb
Dec 14 10:08:32.622: INFO: Got endpoints: latency-svc-fmw7l [748.978892ms]
Dec 14 10:08:32.636: INFO: Created: latency-svc-pj8g7
Dec 14 10:08:32.672: INFO: Got endpoints: latency-svc-r2g2d [750.039271ms]
Dec 14 10:08:32.685: INFO: Created: latency-svc-wd8gc
Dec 14 10:08:32.723: INFO: Got endpoints: latency-svc-w46fv [750.518833ms]
Dec 14 10:08:32.734: INFO: Created: latency-svc-qrfts
Dec 14 10:08:32.772: INFO: Got endpoints: latency-svc-btt5z [749.522222ms]
Dec 14 10:08:32.784: INFO: Created: latency-svc-z9q6n
Dec 14 10:08:32.823: INFO: Got endpoints: latency-svc-gbsc5 [750.68754ms]
Dec 14 10:08:32.834: INFO: Created: latency-svc-njvfw
Dec 14 10:08:32.875: INFO: Got endpoints: latency-svc-m5kvg [751.473466ms]
Dec 14 10:08:32.893: INFO: Created: latency-svc-v6lsb
Dec 14 10:08:32.924: INFO: Got endpoints: latency-svc-t7x6b [751.596856ms]
Dec 14 10:08:32.935: INFO: Created: latency-svc-mtpr9
Dec 14 10:08:32.976: INFO: Got endpoints: latency-svc-dkpvp [752.752799ms]
Dec 14 10:08:32.987: INFO: Created: latency-svc-flx8l
Dec 14 10:08:33.022: INFO: Got endpoints: latency-svc-2pnjb [748.770261ms]
Dec 14 10:08:33.033: INFO: Created: latency-svc-rgpj4
Dec 14 10:08:33.072: INFO: Got endpoints: latency-svc-kqvfv [748.927303ms]
Dec 14 10:08:33.083: INFO: Created: latency-svc-lkwqg
Dec 14 10:08:33.123: INFO: Got endpoints: latency-svc-2pgk5 [747.883407ms]
Dec 14 10:08:33.134: INFO: Created: latency-svc-cv5rb
Dec 14 10:08:33.172: INFO: Got endpoints: latency-svc-ltj6q [749.948327ms]
Dec 14 10:08:33.184: INFO: Created: latency-svc-wdlz6
Dec 14 10:08:33.223: INFO: Got endpoints: latency-svc-jqm8p [749.965804ms]
Dec 14 10:08:33.235: INFO: Created: latency-svc-hhqvf
Dec 14 10:08:33.272: INFO: Got endpoints: latency-svc-ppzfj [749.439205ms]
Dec 14 10:08:33.286: INFO: Created: latency-svc-m9w5z
Dec 14 10:08:33.325: INFO: Got endpoints: latency-svc-4c5fb [750.992109ms]
Dec 14 10:08:33.337: INFO: Created: latency-svc-42cxc
Dec 14 10:08:33.372: INFO: Got endpoints: latency-svc-pj8g7 [749.350545ms]
Dec 14 10:08:33.383: INFO: Created: latency-svc-wjlgz
Dec 14 10:08:33.422: INFO: Got endpoints: latency-svc-wd8gc [749.935667ms]
Dec 14 10:08:33.435: INFO: Created: latency-svc-h5bd7
Dec 14 10:08:33.473: INFO: Got endpoints: latency-svc-qrfts [749.931541ms]
Dec 14 10:08:33.485: INFO: Created: latency-svc-t688l
Dec 14 10:08:33.523: INFO: Got endpoints: latency-svc-z9q6n [750.33839ms]
Dec 14 10:08:33.534: INFO: Created: latency-svc-9868c
Dec 14 10:08:33.573: INFO: Got endpoints: latency-svc-njvfw [749.786659ms]
Dec 14 10:08:33.585: INFO: Created: latency-svc-qjlr7
Dec 14 10:08:33.623: INFO: Got endpoints: latency-svc-v6lsb [748.230791ms]
Dec 14 10:08:33.635: INFO: Created: latency-svc-lgpqq
Dec 14 10:08:33.673: INFO: Got endpoints: latency-svc-mtpr9 [749.184714ms]
Dec 14 10:08:33.685: INFO: Created: latency-svc-hfx94
Dec 14 10:08:33.723: INFO: Got endpoints: latency-svc-flx8l [747.580279ms]
Dec 14 10:08:33.735: INFO: Created: latency-svc-zjhk7
Dec 14 10:08:33.773: INFO: Got endpoints: latency-svc-rgpj4 [750.819305ms]
Dec 14 10:08:33.785: INFO: Created: latency-svc-fgjmx
Dec 14 10:08:33.823: INFO: Got endpoints: latency-svc-lkwqg [750.611099ms]
Dec 14 10:08:33.835: INFO: Created: latency-svc-bqgvb
Dec 14 10:08:33.873: INFO: Got endpoints: latency-svc-cv5rb [750.324891ms]
Dec 14 10:08:33.885: INFO: Created: latency-svc-btn6p
Dec 14 10:08:33.924: INFO: Got endpoints: latency-svc-wdlz6 [751.025689ms]
Dec 14 10:08:33.935: INFO: Created: latency-svc-bp6ct
Dec 14 10:08:33.973: INFO: Got endpoints: latency-svc-hhqvf [749.63635ms]
Dec 14 10:08:33.984: INFO: Created: latency-svc-cbd89
Dec 14 10:08:34.023: INFO: Got endpoints: latency-svc-m9w5z [750.77335ms]
Dec 14 10:08:34.035: INFO: Created: latency-svc-sz7wz
Dec 14 10:08:34.073: INFO: Got endpoints: latency-svc-42cxc [747.636026ms]
Dec 14 10:08:34.085: INFO: Created: latency-svc-s4tkb
Dec 14 10:08:34.123: INFO: Got endpoints: latency-svc-wjlgz [751.086191ms]
Dec 14 10:08:34.134: INFO: Created: latency-svc-6t6v9
Dec 14 10:08:34.172: INFO: Got endpoints: latency-svc-h5bd7 [749.518145ms]
Dec 14 10:08:34.184: INFO: Created: latency-svc-j7p7f
Dec 14 10:08:34.223: INFO: Got endpoints: latency-svc-t688l [750.351761ms]
Dec 14 10:08:34.235: INFO: Created: latency-svc-dqwwt
Dec 14 10:08:34.273: INFO: Got endpoints: latency-svc-9868c [750.157653ms]
Dec 14 10:08:34.286: INFO: Created: latency-svc-xk6xb
Dec 14 10:08:34.328: INFO: Got endpoints: latency-svc-qjlr7 [754.941306ms]
Dec 14 10:08:34.340: INFO: Created: latency-svc-9lbtn
Dec 14 10:08:34.372: INFO: Got endpoints: latency-svc-lgpqq [749.457208ms]
Dec 14 10:08:34.384: INFO: Created: latency-svc-b86g5
Dec 14 10:08:34.425: INFO: Got endpoints: latency-svc-hfx94 [751.589661ms]
Dec 14 10:08:34.436: INFO: Created: latency-svc-lcn8q
Dec 14 10:08:34.472: INFO: Got endpoints: latency-svc-zjhk7 [748.985587ms]
Dec 14 10:08:34.483: INFO: Created: latency-svc-wwh9b
Dec 14 10:08:34.522: INFO: Got endpoints: latency-svc-fgjmx [749.181107ms]
Dec 14 10:08:34.533: INFO: Created: latency-svc-86vgm
Dec 14 10:08:34.573: INFO: Got endpoints: latency-svc-bqgvb [749.810268ms]
Dec 14 10:08:34.585: INFO: Created: latency-svc-75jkk
Dec 14 10:08:34.622: INFO: Got endpoints: latency-svc-btn6p [749.366515ms]
Dec 14 10:08:34.634: INFO: Created: latency-svc-k87ww
Dec 14 10:08:34.672: INFO: Got endpoints: latency-svc-bp6ct [748.754153ms]
Dec 14 10:08:34.684: INFO: Created: latency-svc-8mk64
Dec 14 10:08:34.723: INFO: Got endpoints: latency-svc-cbd89 [750.209463ms]
Dec 14 10:08:34.738: INFO: Created: latency-svc-pfj48
Dec 14 10:08:34.774: INFO: Got endpoints: latency-svc-sz7wz [751.282693ms]
Dec 14 10:08:34.785: INFO: Created: latency-svc-przr6
Dec 14 10:08:34.823: INFO: Got endpoints: latency-svc-s4tkb [750.371804ms]
Dec 14 10:08:34.838: INFO: Created: latency-svc-7xxjw
Dec 14 10:08:34.873: INFO: Got endpoints: latency-svc-6t6v9 [749.45763ms]
Dec 14 10:08:34.884: INFO: Created: latency-svc-kn9vf
Dec 14 10:08:34.923: INFO: Got endpoints: latency-svc-j7p7f [750.412232ms]
Dec 14 10:08:34.933: INFO: Created: latency-svc-db8nk
Dec 14 10:08:34.975: INFO: Got endpoints: latency-svc-dqwwt [751.382098ms]
Dec 14 10:08:34.986: INFO: Created: latency-svc-tbj4n
Dec 14 10:08:35.023: INFO: Got endpoints: latency-svc-xk6xb [749.701737ms]
Dec 14 10:08:35.034: INFO: Created: latency-svc-8tgnd
Dec 14 10:08:35.072: INFO: Got endpoints: latency-svc-9lbtn [744.442932ms]
Dec 14 10:08:35.123: INFO: Got endpoints: latency-svc-b86g5 [751.074414ms]
Dec 14 10:08:35.174: INFO: Got endpoints: latency-svc-lcn8q [748.799229ms]
Dec 14 10:08:35.223: INFO: Got endpoints: latency-svc-wwh9b [750.697713ms]
Dec 14 10:08:35.273: INFO: Got endpoints: latency-svc-86vgm [750.521298ms]
Dec 14 10:08:35.323: INFO: Got endpoints: latency-svc-75jkk [750.058068ms]
Dec 14 10:08:35.373: INFO: Got endpoints: latency-svc-k87ww [750.267996ms]
Dec 14 10:08:35.422: INFO: Got endpoints: latency-svc-8mk64 [749.853768ms]
Dec 14 10:08:35.473: INFO: Got endpoints: latency-svc-pfj48 [750.131311ms]
Dec 14 10:08:35.524: INFO: Got endpoints: latency-svc-przr6 [749.82688ms]
Dec 14 10:08:35.572: INFO: Got endpoints: latency-svc-7xxjw [749.180141ms]
Dec 14 10:08:35.623: INFO: Got endpoints: latency-svc-kn9vf [749.918936ms]
Dec 14 10:08:35.672: INFO: Got endpoints: latency-svc-db8nk [749.476351ms]
Dec 14 10:08:35.723: INFO: Got endpoints: latency-svc-tbj4n [748.035971ms]
Dec 14 10:08:35.773: INFO: Got endpoints: latency-svc-8tgnd [750.459492ms]
Dec 14 10:08:35.773: INFO: Latencies: [16.486566ms 20.4942ms 28.186708ms 31.027589ms 35.298943ms 43.409137ms 46.18355ms 49.560616ms 53.928679ms 57.73972ms 61.815718ms 65.907622ms 69.939701ms 70.791242ms 72.646624ms 73.847434ms 74.500389ms 74.811533ms 76.021465ms 78.350438ms 78.74786ms 81.234777ms 81.328652ms 82.407239ms 82.615717ms 82.658549ms 83.244899ms 83.682933ms 83.787739ms 85.055508ms 86.501344ms 87.124275ms 101.529943ms 132.331913ms 181.452753ms 228.949311ms 272.799937ms 314.126159ms 363.913666ms 407.39892ms 452.910801ms 507.407398ms 548.121756ms 592.83607ms 638.876065ms 686.50679ms 734.129371ms 742.124733ms 744.442932ms 745.403277ms 746.806286ms 747.501586ms 747.580279ms 747.636026ms 747.764481ms 747.883407ms 748.035971ms 748.068866ms 748.156458ms 748.230791ms 748.472749ms 748.680112ms 748.748288ms 748.754153ms 748.763386ms 748.770261ms 748.799229ms 748.857359ms 748.927303ms 748.978892ms 748.985587ms 749.026758ms 749.060316ms 749.101729ms 749.107563ms 749.123651ms 749.154467ms 749.177392ms 749.180141ms 749.181107ms 749.184714ms 749.220916ms 749.224934ms 749.300722ms 749.330402ms 749.347624ms 749.350545ms 749.351312ms 749.366515ms 749.391466ms 749.405445ms 749.424085ms 749.439205ms 749.457208ms 749.45763ms 749.476351ms 749.507706ms 749.510199ms 749.518145ms 749.522222ms 749.574186ms 749.590582ms 749.598386ms 749.63635ms 749.640035ms 749.701737ms 749.739288ms 749.74194ms 749.752682ms 749.764824ms 749.786659ms 749.810268ms 749.816134ms 749.82688ms 749.840887ms 749.853768ms 749.887305ms 749.918936ms 749.931541ms 749.935667ms 749.948327ms 749.965804ms 750.029147ms 750.039271ms 750.051654ms 750.058068ms 750.084829ms 750.10883ms 750.125311ms 750.131311ms 750.155278ms 750.157653ms 750.203219ms 750.209463ms 750.267996ms 750.316872ms 750.324891ms 750.33839ms 750.351761ms 750.371622ms 750.371804ms 750.388283ms 750.412232ms 750.415426ms 750.459492ms 750.475093ms 750.518833ms 750.521298ms 750.525317ms 750.569584ms 750.611099ms 750.63438ms 750.635279ms 750.679729ms 750.68754ms 750.697713ms 750.748682ms 750.77335ms 750.804065ms 750.819305ms 750.823349ms 750.851596ms 750.992109ms 751.025689ms 751.074414ms 751.086191ms 751.107652ms 751.110158ms 751.198041ms 751.282693ms 751.313558ms 751.382098ms 751.438845ms 751.473466ms 751.589661ms 751.596856ms 751.607428ms 751.633126ms 751.701864ms 752.323675ms 752.752799ms 753.580245ms 754.087914ms 754.126048ms 754.941306ms 794.424568ms 797.447289ms 797.939569ms 798.91881ms 799.322669ms 799.518629ms 799.762328ms 799.909252ms 800.260316ms 800.33926ms 800.598128ms 800.627788ms 801.365786ms 802.496956ms 804.876732ms]
Dec 14 10:08:35.773: INFO: 50 %ile: 749.574186ms
Dec 14 10:08:35.773: INFO: 90 %ile: 752.752799ms
Dec 14 10:08:35.773: INFO: 99 %ile: 802.496956ms
Dec 14 10:08:35.773: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Dec 14 10:08:35.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7506" for this suite. 12/14/22 10:08:35.788
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":344,"skipped":6292,"failed":0}
------------------------------
• [10.856 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:08:24.942
    Dec 14 10:08:24.942: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename svc-latency 12/14/22 10:08:24.943
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:24.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:24.979
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Dec 14 10:08:24.991: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-7506 12/14/22 10:08:24.992
    I1214 10:08:25.001181    6248 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7506, replica count: 1
    I1214 10:08:26.051894    6248 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1214 10:08:27.052498    6248 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 10:08:27.169: INFO: Created: latency-svc-gqpkw
    Dec 14 10:08:27.172: INFO: Got endpoints: latency-svc-gqpkw [19.860875ms]
    Dec 14 10:08:27.185: INFO: Created: latency-svc-dmqdd
    Dec 14 10:08:27.189: INFO: Got endpoints: latency-svc-dmqdd [16.486566ms]
    Dec 14 10:08:27.189: INFO: Created: latency-svc-w7mrf
    Dec 14 10:08:27.193: INFO: Got endpoints: latency-svc-w7mrf [20.4942ms]
    Dec 14 10:08:27.196: INFO: Created: latency-svc-k64wb
    Dec 14 10:08:27.200: INFO: Created: latency-svc-ddpc6
    Dec 14 10:08:27.201: INFO: Got endpoints: latency-svc-k64wb [28.186708ms]
    Dec 14 10:08:27.204: INFO: Got endpoints: latency-svc-ddpc6 [31.027589ms]
    Dec 14 10:08:27.204: INFO: Created: latency-svc-4gswm
    Dec 14 10:08:27.208: INFO: Got endpoints: latency-svc-4gswm [35.298943ms]
    Dec 14 10:08:27.211: INFO: Created: latency-svc-kmtjm
    Dec 14 10:08:27.214: INFO: Created: latency-svc-pdgsn
    Dec 14 10:08:27.216: INFO: Got endpoints: latency-svc-kmtjm [43.409137ms]
    Dec 14 10:08:27.219: INFO: Got endpoints: latency-svc-pdgsn [46.18355ms]
    Dec 14 10:08:27.219: INFO: Created: latency-svc-f7kr6
    Dec 14 10:08:27.222: INFO: Got endpoints: latency-svc-f7kr6 [49.560616ms]
    Dec 14 10:08:27.224: INFO: Created: latency-svc-x5824
    Dec 14 10:08:27.226: INFO: Got endpoints: latency-svc-x5824 [53.928679ms]
    Dec 14 10:08:27.228: INFO: Created: latency-svc-ztj6p
    Dec 14 10:08:27.230: INFO: Got endpoints: latency-svc-ztj6p [57.73972ms]
    Dec 14 10:08:27.231: INFO: Created: latency-svc-6r5cz
    Dec 14 10:08:27.234: INFO: Got endpoints: latency-svc-6r5cz [61.815718ms]
    Dec 14 10:08:27.235: INFO: Created: latency-svc-dxzvk
    Dec 14 10:08:27.239: INFO: Got endpoints: latency-svc-dxzvk [65.907622ms]
    Dec 14 10:08:27.239: INFO: Created: latency-svc-stjb6
    Dec 14 10:08:27.243: INFO: Got endpoints: latency-svc-stjb6 [69.939701ms]
    Dec 14 10:08:27.245: INFO: Created: latency-svc-r9gl8
    Dec 14 10:08:27.248: INFO: Got endpoints: latency-svc-r9gl8 [76.021465ms]
    Dec 14 10:08:27.252: INFO: Created: latency-svc-n52cj
    Dec 14 10:08:27.255: INFO: Got endpoints: latency-svc-n52cj [82.658549ms]
    Dec 14 10:08:27.257: INFO: Created: latency-svc-stb5v
    Dec 14 10:08:27.261: INFO: Created: latency-svc-4vpl4
    Dec 14 10:08:27.261: INFO: Got endpoints: latency-svc-stb5v [72.646624ms]
    Dec 14 10:08:27.267: INFO: Got endpoints: latency-svc-4vpl4 [74.500389ms]
    Dec 14 10:08:27.268: INFO: Created: latency-svc-2gk42
    Dec 14 10:08:27.271: INFO: Got endpoints: latency-svc-2gk42 [70.791242ms]
    Dec 14 10:08:27.283: INFO: Created: latency-svc-r652t
    Dec 14 10:08:27.290: INFO: Created: latency-svc-fzflf
    Dec 14 10:08:27.290: INFO: Got endpoints: latency-svc-r652t [86.501344ms]
    Dec 14 10:08:27.291: INFO: Got endpoints: latency-svc-fzflf [83.244899ms]
    Dec 14 10:08:27.291: INFO: Created: latency-svc-fckmz
    Dec 14 10:08:27.295: INFO: Got endpoints: latency-svc-fckmz [78.74786ms]
    Dec 14 10:08:27.299: INFO: Created: latency-svc-ltjkw
    Dec 14 10:08:27.300: INFO: Got endpoints: latency-svc-ltjkw [81.234777ms]
    Dec 14 10:08:27.303: INFO: Created: latency-svc-v5z5q
    Dec 14 10:08:27.309: INFO: Created: latency-svc-9k55c
    Dec 14 10:08:27.309: INFO: Got endpoints: latency-svc-9k55c [82.615717ms]
    Dec 14 10:08:27.309: INFO: Got endpoints: latency-svc-v5z5q [87.124275ms]
    Dec 14 10:08:27.311: INFO: Created: latency-svc-2rvfp
    Dec 14 10:08:27.314: INFO: Got endpoints: latency-svc-2rvfp [83.787739ms]
    Dec 14 10:08:27.316: INFO: Created: latency-svc-hg8zk
    Dec 14 10:08:27.319: INFO: Created: latency-svc-t8zc2
    Dec 14 10:08:27.320: INFO: Got endpoints: latency-svc-hg8zk [85.055508ms]
    Dec 14 10:08:27.321: INFO: Got endpoints: latency-svc-t8zc2 [82.407239ms]
    Dec 14 10:08:27.323: INFO: Created: latency-svc-t7qfl
    Dec 14 10:08:27.326: INFO: Got endpoints: latency-svc-t7qfl [83.682933ms]
    Dec 14 10:08:27.327: INFO: Created: latency-svc-hnpbf
    Dec 14 10:08:27.330: INFO: Got endpoints: latency-svc-hnpbf [81.328652ms]
    Dec 14 10:08:27.331: INFO: Created: latency-svc-klc56
    Dec 14 10:08:27.333: INFO: Created: latency-svc-mt9rd
    Dec 14 10:08:27.334: INFO: Got endpoints: latency-svc-klc56 [78.350438ms]
    Dec 14 10:08:27.336: INFO: Got endpoints: latency-svc-mt9rd [74.811533ms]
    Dec 14 10:08:27.338: INFO: Created: latency-svc-6c2n4
    Dec 14 10:08:27.341: INFO: Got endpoints: latency-svc-6c2n4 [73.847434ms]
    Dec 14 10:08:27.341: INFO: Created: latency-svc-vqwcn
    Dec 14 10:08:27.346: INFO: Created: latency-svc-2r599
    Dec 14 10:08:27.348: INFO: Created: latency-svc-sn2dq
    Dec 14 10:08:27.353: INFO: Created: latency-svc-fxkbb
    Dec 14 10:08:27.356: INFO: Created: latency-svc-2m7m6
    Dec 14 10:08:27.361: INFO: Created: latency-svc-p9fc9
    Dec 14 10:08:27.365: INFO: Created: latency-svc-bfkxl
    Dec 14 10:08:27.373: INFO: Got endpoints: latency-svc-vqwcn [101.529943ms]
    Dec 14 10:08:27.374: INFO: Created: latency-svc-4xtpx
    Dec 14 10:08:27.378: INFO: Created: latency-svc-szrkw
    Dec 14 10:08:27.390: INFO: Created: latency-svc-nsnmv
    Dec 14 10:08:27.393: INFO: Created: latency-svc-bszns
    Dec 14 10:08:27.397: INFO: Created: latency-svc-wc8fn
    Dec 14 10:08:27.399: INFO: Created: latency-svc-6q6wb
    Dec 14 10:08:27.404: INFO: Created: latency-svc-bbcs4
    Dec 14 10:08:27.407: INFO: Created: latency-svc-228fm
    Dec 14 10:08:27.414: INFO: Created: latency-svc-qnpkh
    Dec 14 10:08:27.422: INFO: Got endpoints: latency-svc-2r599 [132.331913ms]
    Dec 14 10:08:27.434: INFO: Created: latency-svc-8fbdc
    Dec 14 10:08:27.473: INFO: Got endpoints: latency-svc-sn2dq [181.452753ms]
    Dec 14 10:08:27.484: INFO: Created: latency-svc-lhsqm
    Dec 14 10:08:27.524: INFO: Got endpoints: latency-svc-fxkbb [228.949311ms]
    Dec 14 10:08:27.536: INFO: Created: latency-svc-cjw4b
    Dec 14 10:08:27.573: INFO: Got endpoints: latency-svc-2m7m6 [272.799937ms]
    Dec 14 10:08:27.585: INFO: Created: latency-svc-b28b9
    Dec 14 10:08:27.623: INFO: Got endpoints: latency-svc-p9fc9 [314.126159ms]
    Dec 14 10:08:27.637: INFO: Created: latency-svc-n4sm4
    Dec 14 10:08:27.673: INFO: Got endpoints: latency-svc-bfkxl [363.913666ms]
    Dec 14 10:08:27.694: INFO: Created: latency-svc-mgzzr
    Dec 14 10:08:27.722: INFO: Got endpoints: latency-svc-4xtpx [407.39892ms]
    Dec 14 10:08:27.733: INFO: Created: latency-svc-wws6z
    Dec 14 10:08:27.773: INFO: Got endpoints: latency-svc-szrkw [452.910801ms]
    Dec 14 10:08:27.784: INFO: Created: latency-svc-wfplm
    Dec 14 10:08:27.828: INFO: Got endpoints: latency-svc-nsnmv [507.407398ms]
    Dec 14 10:08:27.840: INFO: Created: latency-svc-hqrbp
    Dec 14 10:08:27.874: INFO: Got endpoints: latency-svc-bszns [548.121756ms]
    Dec 14 10:08:27.886: INFO: Created: latency-svc-4chff
    Dec 14 10:08:27.923: INFO: Got endpoints: latency-svc-wc8fn [592.83607ms]
    Dec 14 10:08:27.934: INFO: Created: latency-svc-ccrzg
    Dec 14 10:08:27.973: INFO: Got endpoints: latency-svc-6q6wb [638.876065ms]
    Dec 14 10:08:27.985: INFO: Created: latency-svc-2p8sj
    Dec 14 10:08:28.023: INFO: Got endpoints: latency-svc-bbcs4 [686.50679ms]
    Dec 14 10:08:28.035: INFO: Created: latency-svc-h2bbj
    Dec 14 10:08:28.075: INFO: Got endpoints: latency-svc-228fm [734.129371ms]
    Dec 14 10:08:28.088: INFO: Created: latency-svc-xdkfw
    Dec 14 10:08:28.123: INFO: Got endpoints: latency-svc-qnpkh [749.574186ms]
    Dec 14 10:08:28.135: INFO: Created: latency-svc-c4nww
    Dec 14 10:08:28.173: INFO: Got endpoints: latency-svc-8fbdc [750.475093ms]
    Dec 14 10:08:28.186: INFO: Created: latency-svc-54npz
    Dec 14 10:08:28.223: INFO: Got endpoints: latency-svc-lhsqm [750.851596ms]
    Dec 14 10:08:28.249: INFO: Created: latency-svc-krg6m
    Dec 14 10:08:28.273: INFO: Got endpoints: latency-svc-cjw4b [748.680112ms]
    Dec 14 10:08:28.284: INFO: Created: latency-svc-crn64
    Dec 14 10:08:28.324: INFO: Got endpoints: latency-svc-b28b9 [750.748682ms]
    Dec 14 10:08:28.338: INFO: Created: latency-svc-r9ck2
    Dec 14 10:08:28.373: INFO: Got endpoints: latency-svc-n4sm4 [749.391466ms]
    Dec 14 10:08:28.384: INFO: Created: latency-svc-vnl8x
    Dec 14 10:08:28.423: INFO: Got endpoints: latency-svc-mgzzr [750.316872ms]
    Dec 14 10:08:28.435: INFO: Created: latency-svc-2cmkz
    Dec 14 10:08:28.524: INFO: Got endpoints: latency-svc-wws6z [802.496956ms]
    Dec 14 10:08:28.536: INFO: Created: latency-svc-75ccq
    Dec 14 10:08:28.573: INFO: Got endpoints: latency-svc-wfplm [799.909252ms]
    Dec 14 10:08:28.584: INFO: Created: latency-svc-g947r
    Dec 14 10:08:28.623: INFO: Got endpoints: latency-svc-hqrbp [794.424568ms]
    Dec 14 10:08:28.635: INFO: Created: latency-svc-wtc6w
    Dec 14 10:08:28.673: INFO: Got endpoints: latency-svc-4chff [798.91881ms]
    Dec 14 10:08:28.685: INFO: Created: latency-svc-vxpwm
    Dec 14 10:08:28.724: INFO: Got endpoints: latency-svc-ccrzg [801.365786ms]
    Dec 14 10:08:28.736: INFO: Created: latency-svc-rgvzq
    Dec 14 10:08:28.773: INFO: Got endpoints: latency-svc-2p8sj [800.260316ms]
    Dec 14 10:08:28.784: INFO: Created: latency-svc-rdvmm
    Dec 14 10:08:28.822: INFO: Got endpoints: latency-svc-h2bbj [799.322669ms]
    Dec 14 10:08:28.834: INFO: Created: latency-svc-vxq5g
    Dec 14 10:08:28.873: INFO: Got endpoints: latency-svc-xdkfw [797.447289ms]
    Dec 14 10:08:28.884: INFO: Created: latency-svc-2zjmm
    Dec 14 10:08:28.923: INFO: Got endpoints: latency-svc-c4nww [800.627788ms]
    Dec 14 10:08:28.940: INFO: Created: latency-svc-phqnp
    Dec 14 10:08:28.978: INFO: Got endpoints: latency-svc-54npz [804.876732ms]
    Dec 14 10:08:28.990: INFO: Created: latency-svc-fhvf4
    Dec 14 10:08:29.024: INFO: Got endpoints: latency-svc-krg6m [800.598128ms]
    Dec 14 10:08:29.036: INFO: Created: latency-svc-4d854
    Dec 14 10:08:29.072: INFO: Got endpoints: latency-svc-crn64 [799.762328ms]
    Dec 14 10:08:29.083: INFO: Created: latency-svc-6dq5c
    Dec 14 10:08:29.122: INFO: Got endpoints: latency-svc-r9ck2 [797.939569ms]
    Dec 14 10:08:29.135: INFO: Created: latency-svc-54bbn
    Dec 14 10:08:29.173: INFO: Got endpoints: latency-svc-vnl8x [800.33926ms]
    Dec 14 10:08:29.185: INFO: Created: latency-svc-rcgbk
    Dec 14 10:08:29.223: INFO: Got endpoints: latency-svc-2cmkz [799.518629ms]
    Dec 14 10:08:29.237: INFO: Created: latency-svc-j74ql
    Dec 14 10:08:29.272: INFO: Got endpoints: latency-svc-75ccq [748.156458ms]
    Dec 14 10:08:29.283: INFO: Created: latency-svc-5swws
    Dec 14 10:08:29.323: INFO: Got endpoints: latency-svc-g947r [750.203219ms]
    Dec 14 10:08:29.334: INFO: Created: latency-svc-gbsvg
    Dec 14 10:08:29.372: INFO: Got endpoints: latency-svc-wtc6w [749.347624ms]
    Dec 14 10:08:29.384: INFO: Created: latency-svc-r7tpj
    Dec 14 10:08:29.423: INFO: Got endpoints: latency-svc-vxpwm [749.300722ms]
    Dec 14 10:08:29.435: INFO: Created: latency-svc-xr7l9
    Dec 14 10:08:29.474: INFO: Got endpoints: latency-svc-rgvzq [750.371622ms]
    Dec 14 10:08:29.486: INFO: Created: latency-svc-q42df
    Dec 14 10:08:29.524: INFO: Got endpoints: latency-svc-rdvmm [751.107652ms]
    Dec 14 10:08:29.536: INFO: Created: latency-svc-rzsrv
    Dec 14 10:08:29.572: INFO: Got endpoints: latency-svc-vxq5g [749.752682ms]
    Dec 14 10:08:29.584: INFO: Created: latency-svc-znmkl
    Dec 14 10:08:29.623: INFO: Got endpoints: latency-svc-2zjmm [749.887305ms]
    Dec 14 10:08:29.635: INFO: Created: latency-svc-fc9gg
    Dec 14 10:08:29.673: INFO: Got endpoints: latency-svc-phqnp [749.220916ms]
    Dec 14 10:08:29.684: INFO: Created: latency-svc-sgdj4
    Dec 14 10:08:29.723: INFO: Got endpoints: latency-svc-fhvf4 [745.403277ms]
    Dec 14 10:08:29.743: INFO: Created: latency-svc-7p44b
    Dec 14 10:08:29.772: INFO: Got endpoints: latency-svc-4d854 [747.501586ms]
    Dec 14 10:08:29.783: INFO: Created: latency-svc-w547s
    Dec 14 10:08:29.823: INFO: Got endpoints: latency-svc-6dq5c [750.569584ms]
    Dec 14 10:08:29.834: INFO: Created: latency-svc-8dksh
    Dec 14 10:08:29.874: INFO: Got endpoints: latency-svc-54bbn [751.438845ms]
    Dec 14 10:08:29.885: INFO: Created: latency-svc-hkd7c
    Dec 14 10:08:29.923: INFO: Got endpoints: latency-svc-rcgbk [749.424085ms]
    Dec 14 10:08:29.935: INFO: Created: latency-svc-9zqg6
    Dec 14 10:08:29.972: INFO: Got endpoints: latency-svc-j74ql [749.154467ms]
    Dec 14 10:08:29.983: INFO: Created: latency-svc-28wqz
    Dec 14 10:08:30.023: INFO: Got endpoints: latency-svc-5swws [750.635279ms]
    Dec 14 10:08:30.034: INFO: Created: latency-svc-b5669
    Dec 14 10:08:30.072: INFO: Got endpoints: latency-svc-gbsvg [749.330402ms]
    Dec 14 10:08:30.083: INFO: Created: latency-svc-flhnj
    Dec 14 10:08:30.124: INFO: Got endpoints: latency-svc-r7tpj [751.633126ms]
    Dec 14 10:08:30.135: INFO: Created: latency-svc-ncf8n
    Dec 14 10:08:30.173: INFO: Got endpoints: latency-svc-xr7l9 [750.051654ms]
    Dec 14 10:08:30.184: INFO: Created: latency-svc-nx72k
    Dec 14 10:08:30.222: INFO: Got endpoints: latency-svc-q42df [747.764481ms]
    Dec 14 10:08:30.234: INFO: Created: latency-svc-5ldvx
    Dec 14 10:08:30.273: INFO: Got endpoints: latency-svc-rzsrv [749.177392ms]
    Dec 14 10:08:30.285: INFO: Created: latency-svc-9rk59
    Dec 14 10:08:30.323: INFO: Got endpoints: latency-svc-znmkl [750.804065ms]
    Dec 14 10:08:30.334: INFO: Created: latency-svc-qr8ms
    Dec 14 10:08:30.372: INFO: Got endpoints: latency-svc-fc9gg [749.123651ms]
    Dec 14 10:08:30.383: INFO: Created: latency-svc-twrwh
    Dec 14 10:08:30.423: INFO: Got endpoints: latency-svc-sgdj4 [749.764824ms]
    Dec 14 10:08:30.434: INFO: Created: latency-svc-8pt5v
    Dec 14 10:08:30.473: INFO: Got endpoints: latency-svc-7p44b [749.510199ms]
    Dec 14 10:08:30.485: INFO: Created: latency-svc-n6v26
    Dec 14 10:08:30.523: INFO: Got endpoints: latency-svc-w547s [750.823349ms]
    Dec 14 10:08:30.534: INFO: Created: latency-svc-8sjqz
    Dec 14 10:08:30.573: INFO: Got endpoints: latency-svc-8dksh [749.840887ms]
    Dec 14 10:08:30.584: INFO: Created: latency-svc-jvqtx
    Dec 14 10:08:30.622: INFO: Got endpoints: latency-svc-hkd7c [748.748288ms]
    Dec 14 10:08:30.634: INFO: Created: latency-svc-g4955
    Dec 14 10:08:30.676: INFO: Got endpoints: latency-svc-9zqg6 [753.580245ms]
    Dec 14 10:08:30.687: INFO: Created: latency-svc-fgvfb
    Dec 14 10:08:30.723: INFO: Got endpoints: latency-svc-28wqz [750.679729ms]
    Dec 14 10:08:30.735: INFO: Created: latency-svc-p5z4h
    Dec 14 10:08:30.774: INFO: Got endpoints: latency-svc-b5669 [751.110158ms]
    Dec 14 10:08:30.792: INFO: Created: latency-svc-828pp
    Dec 14 10:08:30.822: INFO: Got endpoints: latency-svc-flhnj [749.739288ms]
    Dec 14 10:08:30.834: INFO: Created: latency-svc-487cf
    Dec 14 10:08:30.878: INFO: Got endpoints: latency-svc-ncf8n [754.126048ms]
    Dec 14 10:08:30.900: INFO: Created: latency-svc-92vm8
    Dec 14 10:08:30.923: INFO: Got endpoints: latency-svc-nx72k [749.640035ms]
    Dec 14 10:08:30.935: INFO: Created: latency-svc-5hwlh
    Dec 14 10:08:30.974: INFO: Got endpoints: latency-svc-5ldvx [751.198041ms]
    Dec 14 10:08:30.985: INFO: Created: latency-svc-8f6hq
    Dec 14 10:08:31.022: INFO: Got endpoints: latency-svc-9rk59 [749.060316ms]
    Dec 14 10:08:31.034: INFO: Created: latency-svc-jr2hz
    Dec 14 10:08:31.072: INFO: Got endpoints: latency-svc-qr8ms [749.101729ms]
    Dec 14 10:08:31.083: INFO: Created: latency-svc-sm9m6
    Dec 14 10:08:31.125: INFO: Got endpoints: latency-svc-twrwh [752.323675ms]
    Dec 14 10:08:31.137: INFO: Created: latency-svc-t8r6r
    Dec 14 10:08:31.174: INFO: Got endpoints: latency-svc-8pt5v [751.607428ms]
    Dec 14 10:08:31.186: INFO: Created: latency-svc-99ns4
    Dec 14 10:08:31.223: INFO: Got endpoints: latency-svc-n6v26 [749.598386ms]
    Dec 14 10:08:31.234: INFO: Created: latency-svc-njg54
    Dec 14 10:08:31.273: INFO: Got endpoints: latency-svc-8sjqz [750.415426ms]
    Dec 14 10:08:31.285: INFO: Created: latency-svc-qs7gl
    Dec 14 10:08:31.323: INFO: Got endpoints: latency-svc-jvqtx [750.155278ms]
    Dec 14 10:08:31.337: INFO: Created: latency-svc-f896j
    Dec 14 10:08:31.373: INFO: Got endpoints: latency-svc-g4955 [750.63438ms]
    Dec 14 10:08:31.386: INFO: Created: latency-svc-mtwqn
    Dec 14 10:08:31.423: INFO: Got endpoints: latency-svc-fgvfb [746.806286ms]
    Dec 14 10:08:31.435: INFO: Created: latency-svc-gb5vr
    Dec 14 10:08:31.472: INFO: Got endpoints: latency-svc-p5z4h [749.107563ms]
    Dec 14 10:08:31.484: INFO: Created: latency-svc-2w2sl
    Dec 14 10:08:31.523: INFO: Got endpoints: latency-svc-828pp [748.472749ms]
    Dec 14 10:08:31.535: INFO: Created: latency-svc-gfn9r
    Dec 14 10:08:31.573: INFO: Got endpoints: latency-svc-487cf [751.313558ms]
    Dec 14 10:08:31.585: INFO: Created: latency-svc-h68k5
    Dec 14 10:08:31.632: INFO: Got endpoints: latency-svc-92vm8 [754.087914ms]
    Dec 14 10:08:31.644: INFO: Created: latency-svc-7zzxw
    Dec 14 10:08:31.673: INFO: Got endpoints: latency-svc-5hwlh [750.125311ms]
    Dec 14 10:08:31.685: INFO: Created: latency-svc-kktn6
    Dec 14 10:08:31.724: INFO: Got endpoints: latency-svc-8f6hq [750.388283ms]
    Dec 14 10:08:31.737: INFO: Created: latency-svc-9wqdz
    Dec 14 10:08:31.773: INFO: Got endpoints: latency-svc-jr2hz [750.029147ms]
    Dec 14 10:08:31.784: INFO: Created: latency-svc-4q2kz
    Dec 14 10:08:31.822: INFO: Got endpoints: latency-svc-sm9m6 [750.084829ms]
    Dec 14 10:08:31.837: INFO: Created: latency-svc-5tgq2
    Dec 14 10:08:31.873: INFO: Got endpoints: latency-svc-t8r6r [748.857359ms]
    Dec 14 10:08:31.887: INFO: Created: latency-svc-fmw7l
    Dec 14 10:08:31.922: INFO: Got endpoints: latency-svc-99ns4 [748.068866ms]
    Dec 14 10:08:31.934: INFO: Created: latency-svc-r2g2d
    Dec 14 10:08:31.972: INFO: Got endpoints: latency-svc-njg54 [749.351312ms]
    Dec 14 10:08:31.984: INFO: Created: latency-svc-w46fv
    Dec 14 10:08:32.023: INFO: Got endpoints: latency-svc-qs7gl [749.405445ms]
    Dec 14 10:08:32.035: INFO: Created: latency-svc-btt5z
    Dec 14 10:08:32.072: INFO: Got endpoints: latency-svc-f896j [748.763386ms]
    Dec 14 10:08:32.084: INFO: Created: latency-svc-gbsc5
    Dec 14 10:08:32.123: INFO: Got endpoints: latency-svc-mtwqn [749.816134ms]
    Dec 14 10:08:32.135: INFO: Created: latency-svc-m5kvg
    Dec 14 10:08:32.172: INFO: Got endpoints: latency-svc-gb5vr [749.224934ms]
    Dec 14 10:08:32.185: INFO: Created: latency-svc-t7x6b
    Dec 14 10:08:32.223: INFO: Got endpoints: latency-svc-2w2sl [750.525317ms]
    Dec 14 10:08:32.235: INFO: Created: latency-svc-dkpvp
    Dec 14 10:08:32.273: INFO: Got endpoints: latency-svc-gfn9r [750.10883ms]
    Dec 14 10:08:32.284: INFO: Created: latency-svc-2pnjb
    Dec 14 10:08:32.323: INFO: Got endpoints: latency-svc-h68k5 [749.590582ms]
    Dec 14 10:08:32.335: INFO: Created: latency-svc-kqvfv
    Dec 14 10:08:32.375: INFO: Got endpoints: latency-svc-7zzxw [742.124733ms]
    Dec 14 10:08:32.387: INFO: Created: latency-svc-2pgk5
    Dec 14 10:08:32.422: INFO: Got endpoints: latency-svc-kktn6 [749.507706ms]
    Dec 14 10:08:32.434: INFO: Created: latency-svc-ltj6q
    Dec 14 10:08:32.473: INFO: Got endpoints: latency-svc-9wqdz [749.026758ms]
    Dec 14 10:08:32.486: INFO: Created: latency-svc-jqm8p
    Dec 14 10:08:32.522: INFO: Got endpoints: latency-svc-4q2kz [749.74194ms]
    Dec 14 10:08:32.534: INFO: Created: latency-svc-ppzfj
    Dec 14 10:08:32.574: INFO: Got endpoints: latency-svc-5tgq2 [751.701864ms]
    Dec 14 10:08:32.586: INFO: Created: latency-svc-4c5fb
    Dec 14 10:08:32.622: INFO: Got endpoints: latency-svc-fmw7l [748.978892ms]
    Dec 14 10:08:32.636: INFO: Created: latency-svc-pj8g7
    Dec 14 10:08:32.672: INFO: Got endpoints: latency-svc-r2g2d [750.039271ms]
    Dec 14 10:08:32.685: INFO: Created: latency-svc-wd8gc
    Dec 14 10:08:32.723: INFO: Got endpoints: latency-svc-w46fv [750.518833ms]
    Dec 14 10:08:32.734: INFO: Created: latency-svc-qrfts
    Dec 14 10:08:32.772: INFO: Got endpoints: latency-svc-btt5z [749.522222ms]
    Dec 14 10:08:32.784: INFO: Created: latency-svc-z9q6n
    Dec 14 10:08:32.823: INFO: Got endpoints: latency-svc-gbsc5 [750.68754ms]
    Dec 14 10:08:32.834: INFO: Created: latency-svc-njvfw
    Dec 14 10:08:32.875: INFO: Got endpoints: latency-svc-m5kvg [751.473466ms]
    Dec 14 10:08:32.893: INFO: Created: latency-svc-v6lsb
    Dec 14 10:08:32.924: INFO: Got endpoints: latency-svc-t7x6b [751.596856ms]
    Dec 14 10:08:32.935: INFO: Created: latency-svc-mtpr9
    Dec 14 10:08:32.976: INFO: Got endpoints: latency-svc-dkpvp [752.752799ms]
    Dec 14 10:08:32.987: INFO: Created: latency-svc-flx8l
    Dec 14 10:08:33.022: INFO: Got endpoints: latency-svc-2pnjb [748.770261ms]
    Dec 14 10:08:33.033: INFO: Created: latency-svc-rgpj4
    Dec 14 10:08:33.072: INFO: Got endpoints: latency-svc-kqvfv [748.927303ms]
    Dec 14 10:08:33.083: INFO: Created: latency-svc-lkwqg
    Dec 14 10:08:33.123: INFO: Got endpoints: latency-svc-2pgk5 [747.883407ms]
    Dec 14 10:08:33.134: INFO: Created: latency-svc-cv5rb
    Dec 14 10:08:33.172: INFO: Got endpoints: latency-svc-ltj6q [749.948327ms]
    Dec 14 10:08:33.184: INFO: Created: latency-svc-wdlz6
    Dec 14 10:08:33.223: INFO: Got endpoints: latency-svc-jqm8p [749.965804ms]
    Dec 14 10:08:33.235: INFO: Created: latency-svc-hhqvf
    Dec 14 10:08:33.272: INFO: Got endpoints: latency-svc-ppzfj [749.439205ms]
    Dec 14 10:08:33.286: INFO: Created: latency-svc-m9w5z
    Dec 14 10:08:33.325: INFO: Got endpoints: latency-svc-4c5fb [750.992109ms]
    Dec 14 10:08:33.337: INFO: Created: latency-svc-42cxc
    Dec 14 10:08:33.372: INFO: Got endpoints: latency-svc-pj8g7 [749.350545ms]
    Dec 14 10:08:33.383: INFO: Created: latency-svc-wjlgz
    Dec 14 10:08:33.422: INFO: Got endpoints: latency-svc-wd8gc [749.935667ms]
    Dec 14 10:08:33.435: INFO: Created: latency-svc-h5bd7
    Dec 14 10:08:33.473: INFO: Got endpoints: latency-svc-qrfts [749.931541ms]
    Dec 14 10:08:33.485: INFO: Created: latency-svc-t688l
    Dec 14 10:08:33.523: INFO: Got endpoints: latency-svc-z9q6n [750.33839ms]
    Dec 14 10:08:33.534: INFO: Created: latency-svc-9868c
    Dec 14 10:08:33.573: INFO: Got endpoints: latency-svc-njvfw [749.786659ms]
    Dec 14 10:08:33.585: INFO: Created: latency-svc-qjlr7
    Dec 14 10:08:33.623: INFO: Got endpoints: latency-svc-v6lsb [748.230791ms]
    Dec 14 10:08:33.635: INFO: Created: latency-svc-lgpqq
    Dec 14 10:08:33.673: INFO: Got endpoints: latency-svc-mtpr9 [749.184714ms]
    Dec 14 10:08:33.685: INFO: Created: latency-svc-hfx94
    Dec 14 10:08:33.723: INFO: Got endpoints: latency-svc-flx8l [747.580279ms]
    Dec 14 10:08:33.735: INFO: Created: latency-svc-zjhk7
    Dec 14 10:08:33.773: INFO: Got endpoints: latency-svc-rgpj4 [750.819305ms]
    Dec 14 10:08:33.785: INFO: Created: latency-svc-fgjmx
    Dec 14 10:08:33.823: INFO: Got endpoints: latency-svc-lkwqg [750.611099ms]
    Dec 14 10:08:33.835: INFO: Created: latency-svc-bqgvb
    Dec 14 10:08:33.873: INFO: Got endpoints: latency-svc-cv5rb [750.324891ms]
    Dec 14 10:08:33.885: INFO: Created: latency-svc-btn6p
    Dec 14 10:08:33.924: INFO: Got endpoints: latency-svc-wdlz6 [751.025689ms]
    Dec 14 10:08:33.935: INFO: Created: latency-svc-bp6ct
    Dec 14 10:08:33.973: INFO: Got endpoints: latency-svc-hhqvf [749.63635ms]
    Dec 14 10:08:33.984: INFO: Created: latency-svc-cbd89
    Dec 14 10:08:34.023: INFO: Got endpoints: latency-svc-m9w5z [750.77335ms]
    Dec 14 10:08:34.035: INFO: Created: latency-svc-sz7wz
    Dec 14 10:08:34.073: INFO: Got endpoints: latency-svc-42cxc [747.636026ms]
    Dec 14 10:08:34.085: INFO: Created: latency-svc-s4tkb
    Dec 14 10:08:34.123: INFO: Got endpoints: latency-svc-wjlgz [751.086191ms]
    Dec 14 10:08:34.134: INFO: Created: latency-svc-6t6v9
    Dec 14 10:08:34.172: INFO: Got endpoints: latency-svc-h5bd7 [749.518145ms]
    Dec 14 10:08:34.184: INFO: Created: latency-svc-j7p7f
    Dec 14 10:08:34.223: INFO: Got endpoints: latency-svc-t688l [750.351761ms]
    Dec 14 10:08:34.235: INFO: Created: latency-svc-dqwwt
    Dec 14 10:08:34.273: INFO: Got endpoints: latency-svc-9868c [750.157653ms]
    Dec 14 10:08:34.286: INFO: Created: latency-svc-xk6xb
    Dec 14 10:08:34.328: INFO: Got endpoints: latency-svc-qjlr7 [754.941306ms]
    Dec 14 10:08:34.340: INFO: Created: latency-svc-9lbtn
    Dec 14 10:08:34.372: INFO: Got endpoints: latency-svc-lgpqq [749.457208ms]
    Dec 14 10:08:34.384: INFO: Created: latency-svc-b86g5
    Dec 14 10:08:34.425: INFO: Got endpoints: latency-svc-hfx94 [751.589661ms]
    Dec 14 10:08:34.436: INFO: Created: latency-svc-lcn8q
    Dec 14 10:08:34.472: INFO: Got endpoints: latency-svc-zjhk7 [748.985587ms]
    Dec 14 10:08:34.483: INFO: Created: latency-svc-wwh9b
    Dec 14 10:08:34.522: INFO: Got endpoints: latency-svc-fgjmx [749.181107ms]
    Dec 14 10:08:34.533: INFO: Created: latency-svc-86vgm
    Dec 14 10:08:34.573: INFO: Got endpoints: latency-svc-bqgvb [749.810268ms]
    Dec 14 10:08:34.585: INFO: Created: latency-svc-75jkk
    Dec 14 10:08:34.622: INFO: Got endpoints: latency-svc-btn6p [749.366515ms]
    Dec 14 10:08:34.634: INFO: Created: latency-svc-k87ww
    Dec 14 10:08:34.672: INFO: Got endpoints: latency-svc-bp6ct [748.754153ms]
    Dec 14 10:08:34.684: INFO: Created: latency-svc-8mk64
    Dec 14 10:08:34.723: INFO: Got endpoints: latency-svc-cbd89 [750.209463ms]
    Dec 14 10:08:34.738: INFO: Created: latency-svc-pfj48
    Dec 14 10:08:34.774: INFO: Got endpoints: latency-svc-sz7wz [751.282693ms]
    Dec 14 10:08:34.785: INFO: Created: latency-svc-przr6
    Dec 14 10:08:34.823: INFO: Got endpoints: latency-svc-s4tkb [750.371804ms]
    Dec 14 10:08:34.838: INFO: Created: latency-svc-7xxjw
    Dec 14 10:08:34.873: INFO: Got endpoints: latency-svc-6t6v9 [749.45763ms]
    Dec 14 10:08:34.884: INFO: Created: latency-svc-kn9vf
    Dec 14 10:08:34.923: INFO: Got endpoints: latency-svc-j7p7f [750.412232ms]
    Dec 14 10:08:34.933: INFO: Created: latency-svc-db8nk
    Dec 14 10:08:34.975: INFO: Got endpoints: latency-svc-dqwwt [751.382098ms]
    Dec 14 10:08:34.986: INFO: Created: latency-svc-tbj4n
    Dec 14 10:08:35.023: INFO: Got endpoints: latency-svc-xk6xb [749.701737ms]
    Dec 14 10:08:35.034: INFO: Created: latency-svc-8tgnd
    Dec 14 10:08:35.072: INFO: Got endpoints: latency-svc-9lbtn [744.442932ms]
    Dec 14 10:08:35.123: INFO: Got endpoints: latency-svc-b86g5 [751.074414ms]
    Dec 14 10:08:35.174: INFO: Got endpoints: latency-svc-lcn8q [748.799229ms]
    Dec 14 10:08:35.223: INFO: Got endpoints: latency-svc-wwh9b [750.697713ms]
    Dec 14 10:08:35.273: INFO: Got endpoints: latency-svc-86vgm [750.521298ms]
    Dec 14 10:08:35.323: INFO: Got endpoints: latency-svc-75jkk [750.058068ms]
    Dec 14 10:08:35.373: INFO: Got endpoints: latency-svc-k87ww [750.267996ms]
    Dec 14 10:08:35.422: INFO: Got endpoints: latency-svc-8mk64 [749.853768ms]
    Dec 14 10:08:35.473: INFO: Got endpoints: latency-svc-pfj48 [750.131311ms]
    Dec 14 10:08:35.524: INFO: Got endpoints: latency-svc-przr6 [749.82688ms]
    Dec 14 10:08:35.572: INFO: Got endpoints: latency-svc-7xxjw [749.180141ms]
    Dec 14 10:08:35.623: INFO: Got endpoints: latency-svc-kn9vf [749.918936ms]
    Dec 14 10:08:35.672: INFO: Got endpoints: latency-svc-db8nk [749.476351ms]
    Dec 14 10:08:35.723: INFO: Got endpoints: latency-svc-tbj4n [748.035971ms]
    Dec 14 10:08:35.773: INFO: Got endpoints: latency-svc-8tgnd [750.459492ms]
    Dec 14 10:08:35.773: INFO: Latencies: [16.486566ms 20.4942ms 28.186708ms 31.027589ms 35.298943ms 43.409137ms 46.18355ms 49.560616ms 53.928679ms 57.73972ms 61.815718ms 65.907622ms 69.939701ms 70.791242ms 72.646624ms 73.847434ms 74.500389ms 74.811533ms 76.021465ms 78.350438ms 78.74786ms 81.234777ms 81.328652ms 82.407239ms 82.615717ms 82.658549ms 83.244899ms 83.682933ms 83.787739ms 85.055508ms 86.501344ms 87.124275ms 101.529943ms 132.331913ms 181.452753ms 228.949311ms 272.799937ms 314.126159ms 363.913666ms 407.39892ms 452.910801ms 507.407398ms 548.121756ms 592.83607ms 638.876065ms 686.50679ms 734.129371ms 742.124733ms 744.442932ms 745.403277ms 746.806286ms 747.501586ms 747.580279ms 747.636026ms 747.764481ms 747.883407ms 748.035971ms 748.068866ms 748.156458ms 748.230791ms 748.472749ms 748.680112ms 748.748288ms 748.754153ms 748.763386ms 748.770261ms 748.799229ms 748.857359ms 748.927303ms 748.978892ms 748.985587ms 749.026758ms 749.060316ms 749.101729ms 749.107563ms 749.123651ms 749.154467ms 749.177392ms 749.180141ms 749.181107ms 749.184714ms 749.220916ms 749.224934ms 749.300722ms 749.330402ms 749.347624ms 749.350545ms 749.351312ms 749.366515ms 749.391466ms 749.405445ms 749.424085ms 749.439205ms 749.457208ms 749.45763ms 749.476351ms 749.507706ms 749.510199ms 749.518145ms 749.522222ms 749.574186ms 749.590582ms 749.598386ms 749.63635ms 749.640035ms 749.701737ms 749.739288ms 749.74194ms 749.752682ms 749.764824ms 749.786659ms 749.810268ms 749.816134ms 749.82688ms 749.840887ms 749.853768ms 749.887305ms 749.918936ms 749.931541ms 749.935667ms 749.948327ms 749.965804ms 750.029147ms 750.039271ms 750.051654ms 750.058068ms 750.084829ms 750.10883ms 750.125311ms 750.131311ms 750.155278ms 750.157653ms 750.203219ms 750.209463ms 750.267996ms 750.316872ms 750.324891ms 750.33839ms 750.351761ms 750.371622ms 750.371804ms 750.388283ms 750.412232ms 750.415426ms 750.459492ms 750.475093ms 750.518833ms 750.521298ms 750.525317ms 750.569584ms 750.611099ms 750.63438ms 750.635279ms 750.679729ms 750.68754ms 750.697713ms 750.748682ms 750.77335ms 750.804065ms 750.819305ms 750.823349ms 750.851596ms 750.992109ms 751.025689ms 751.074414ms 751.086191ms 751.107652ms 751.110158ms 751.198041ms 751.282693ms 751.313558ms 751.382098ms 751.438845ms 751.473466ms 751.589661ms 751.596856ms 751.607428ms 751.633126ms 751.701864ms 752.323675ms 752.752799ms 753.580245ms 754.087914ms 754.126048ms 754.941306ms 794.424568ms 797.447289ms 797.939569ms 798.91881ms 799.322669ms 799.518629ms 799.762328ms 799.909252ms 800.260316ms 800.33926ms 800.598128ms 800.627788ms 801.365786ms 802.496956ms 804.876732ms]
    Dec 14 10:08:35.773: INFO: 50 %ile: 749.574186ms
    Dec 14 10:08:35.773: INFO: 90 %ile: 752.752799ms
    Dec 14 10:08:35.773: INFO: 99 %ile: 802.496956ms
    Dec 14 10:08:35.773: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Dec 14 10:08:35.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-7506" for this suite. 12/14/22 10:08:35.788
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:08:35.799
Dec 14 10:08:35.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset 12/14/22 10:08:35.8
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:35.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:35.836
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5693 12/14/22 10:08:35.849
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 12/14/22 10:08:35.858
Dec 14 10:08:35.873: INFO: Found 0 stateful pods, waiting for 3
Dec 14 10:08:45.883: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:08:45.883: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:08:45.883: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 10:08:45.905
Dec 14 10:08:45.932: INFO: Updating stateful set ss2
STEP: Creating a new revision 12/14/22 10:08:45.932
STEP: Not applying an update when the partition is greater than the number of replicas 12/14/22 10:08:55.963
STEP: Performing a canary update 12/14/22 10:08:55.963
Dec 14 10:08:55.989: INFO: Updating stateful set ss2
Dec 14 10:08:56.003: INFO: Waiting for Pod statefulset-5693/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 12/14/22 10:09:06.02
Dec 14 10:09:06.051: INFO: Found 2 stateful pods, waiting for 3
Dec 14 10:09:16.060: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:09:16.060: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 14 10:09:16.060: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 12/14/22 10:09:16.076
Dec 14 10:09:16.103: INFO: Updating stateful set ss2
Dec 14 10:09:16.119: INFO: Waiting for Pod statefulset-5693/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Dec 14 10:09:26.162: INFO: Updating stateful set ss2
Dec 14 10:09:26.177: INFO: Waiting for StatefulSet statefulset-5693/ss2 to complete update
Dec 14 10:09:26.177: INFO: Waiting for Pod statefulset-5693/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Dec 14 10:09:36.204: INFO: Deleting all statefulset in ns statefulset-5693
Dec 14 10:09:36.211: INFO: Scaling statefulset ss2 to 0
Dec 14 10:09:46.244: INFO: Waiting for statefulset status.replicas updated to 0
Dec 14 10:09:46.251: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Dec 14 10:09:46.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5693" for this suite. 12/14/22 10:09:46.287
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":345,"skipped":6323,"failed":0}
------------------------------
• [70.495 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:08:35.799
    Dec 14 10:08:35.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename statefulset 12/14/22 10:08:35.8
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:08:35.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:08:35.836
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5693 12/14/22 10:08:35.849
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 12/14/22 10:08:35.858
    Dec 14 10:08:35.873: INFO: Found 0 stateful pods, waiting for 3
    Dec 14 10:08:45.883: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:08:45.883: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:08:45.883: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 12/14/22 10:08:45.905
    Dec 14 10:08:45.932: INFO: Updating stateful set ss2
    STEP: Creating a new revision 12/14/22 10:08:45.932
    STEP: Not applying an update when the partition is greater than the number of replicas 12/14/22 10:08:55.963
    STEP: Performing a canary update 12/14/22 10:08:55.963
    Dec 14 10:08:55.989: INFO: Updating stateful set ss2
    Dec 14 10:08:56.003: INFO: Waiting for Pod statefulset-5693/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 12/14/22 10:09:06.02
    Dec 14 10:09:06.051: INFO: Found 2 stateful pods, waiting for 3
    Dec 14 10:09:16.060: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:09:16.060: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Dec 14 10:09:16.060: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 12/14/22 10:09:16.076
    Dec 14 10:09:16.103: INFO: Updating stateful set ss2
    Dec 14 10:09:16.119: INFO: Waiting for Pod statefulset-5693/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Dec 14 10:09:26.162: INFO: Updating stateful set ss2
    Dec 14 10:09:26.177: INFO: Waiting for StatefulSet statefulset-5693/ss2 to complete update
    Dec 14 10:09:26.177: INFO: Waiting for Pod statefulset-5693/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Dec 14 10:09:36.204: INFO: Deleting all statefulset in ns statefulset-5693
    Dec 14 10:09:36.211: INFO: Scaling statefulset ss2 to 0
    Dec 14 10:09:46.244: INFO: Waiting for statefulset status.replicas updated to 0
    Dec 14 10:09:46.251: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Dec 14 10:09:46.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5693" for this suite. 12/14/22 10:09:46.287
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:09:46.295
Dec 14 10:09:46.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services 12/14/22 10:09:46.296
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:46.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:46.329
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-6219 12/14/22 10:09:46.341
STEP: creating service affinity-clusterip in namespace services-6219 12/14/22 10:09:46.341
STEP: creating replication controller affinity-clusterip in namespace services-6219 12/14/22 10:09:46.352
I1214 10:09:46.360884    6248 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6219, replica count: 3
I1214 10:09:49.411215    6248 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 14 10:09:49.433: INFO: Creating new exec pod
Dec 14 10:09:49.444: INFO: Waiting up to 5m0s for pod "execpod-affinityxfd57" in namespace "services-6219" to be "running"
Dec 14 10:09:49.452: INFO: Pod "execpod-affinityxfd57": Phase="Pending", Reason="", readiness=false. Elapsed: 7.897146ms
Dec 14 10:09:51.460: INFO: Pod "execpod-affinityxfd57": Phase="Running", Reason="", readiness=true. Elapsed: 2.016196658s
Dec 14 10:09:51.460: INFO: Pod "execpod-affinityxfd57" satisfied condition "running"
Dec 14 10:09:52.460: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Dec 14 10:09:52.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Dec 14 10:09:52.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:09:52.871: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.25.255.87 80'
Dec 14 10:09:53.358: INFO: stderr: "+ nc -v -t -w 2 172.25.255.87 80\n+ echo hostName\nConnection to 172.25.255.87 80 port [tcp/http] succeeded!\n"
Dec 14 10:09:53.358: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Dec 14 10:09:53.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.25.255.87:80/ ; done'
Dec 14 10:09:53.863: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n"
Dec 14 10:09:53.863: INFO: stdout: "\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k"
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
Dec 14 10:09:53.863: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-6219, will wait for the garbage collector to delete the pods 12/14/22 10:09:53.88
Dec 14 10:09:53.947: INFO: Deleting ReplicationController affinity-clusterip took: 8.765494ms
Dec 14 10:09:54.048: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.05351ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Dec 14 10:09:56.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6219" for this suite. 12/14/22 10:09:56.174
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":346,"skipped":6323,"failed":0}
------------------------------
• [9.888 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:09:46.295
    Dec 14 10:09:46.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename services 12/14/22 10:09:46.296
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:46.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:46.329
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-6219 12/14/22 10:09:46.341
    STEP: creating service affinity-clusterip in namespace services-6219 12/14/22 10:09:46.341
    STEP: creating replication controller affinity-clusterip in namespace services-6219 12/14/22 10:09:46.352
    I1214 10:09:46.360884    6248 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-6219, replica count: 3
    I1214 10:09:49.411215    6248 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Dec 14 10:09:49.433: INFO: Creating new exec pod
    Dec 14 10:09:49.444: INFO: Waiting up to 5m0s for pod "execpod-affinityxfd57" in namespace "services-6219" to be "running"
    Dec 14 10:09:49.452: INFO: Pod "execpod-affinityxfd57": Phase="Pending", Reason="", readiness=false. Elapsed: 7.897146ms
    Dec 14 10:09:51.460: INFO: Pod "execpod-affinityxfd57": Phase="Running", Reason="", readiness=true. Elapsed: 2.016196658s
    Dec 14 10:09:51.460: INFO: Pod "execpod-affinityxfd57" satisfied condition "running"
    Dec 14 10:09:52.460: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Dec 14 10:09:52.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Dec 14 10:09:52.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:09:52.871: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.25.255.87 80'
    Dec 14 10:09:53.358: INFO: stderr: "+ nc -v -t -w 2 172.25.255.87 80\n+ echo hostName\nConnection to 172.25.255.87 80 port [tcp/http] succeeded!\n"
    Dec 14 10:09:53.358: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Dec 14 10:09:53.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=services-6219 exec execpod-affinityxfd57 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.25.255.87:80/ ; done'
    Dec 14 10:09:53.863: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.25.255.87:80/\n"
    Dec 14 10:09:53.863: INFO: stdout: "\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k\naffinity-clusterip-5r98k"
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Received response from host: affinity-clusterip-5r98k
    Dec 14 10:09:53.863: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-6219, will wait for the garbage collector to delete the pods 12/14/22 10:09:53.88
    Dec 14 10:09:53.947: INFO: Deleting ReplicationController affinity-clusterip took: 8.765494ms
    Dec 14 10:09:54.048: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.05351ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Dec 14 10:09:56.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6219" for this suite. 12/14/22 10:09:56.174
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:09:56.185
Dec 14 10:09:56.185: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context 12/14/22 10:09:56.186
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:56.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:56.22
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 10:09:56.231
Dec 14 10:09:56.245: INFO: Waiting up to 5m0s for pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d" in namespace "security-context-645" to be "Succeeded or Failed"
Dec 14 10:09:56.252: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.136901ms
Dec 14 10:09:58.260: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015662115s
Dec 14 10:10:00.261: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016035611s
STEP: Saw pod success 12/14/22 10:10:00.261
Dec 14 10:10:00.261: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d" satisfied condition "Succeeded or Failed"
Dec 14 10:10:00.268: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d container test-container: <nil>
STEP: delete the pod 12/14/22 10:10:00.287
Dec 14 10:10:00.301: INFO: Waiting for pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d to disappear
Dec 14 10:10:00.309: INFO: Pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Dec 14 10:10:00.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-645" for this suite. 12/14/22 10:10:00.322
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":347,"skipped":6367,"failed":0}
------------------------------
• [4.146 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:09:56.185
    Dec 14 10:09:56.185: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename security-context 12/14/22 10:09:56.186
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:09:56.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:09:56.22
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 12/14/22 10:09:56.231
    Dec 14 10:09:56.245: INFO: Waiting up to 5m0s for pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d" in namespace "security-context-645" to be "Succeeded or Failed"
    Dec 14 10:09:56.252: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.136901ms
    Dec 14 10:09:58.260: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015662115s
    Dec 14 10:10:00.261: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016035611s
    STEP: Saw pod success 12/14/22 10:10:00.261
    Dec 14 10:10:00.261: INFO: Pod "security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d" satisfied condition "Succeeded or Failed"
    Dec 14 10:10:00.268: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d container test-container: <nil>
    STEP: delete the pod 12/14/22 10:10:00.287
    Dec 14 10:10:00.301: INFO: Waiting for pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d to disappear
    Dec 14 10:10:00.309: INFO: Pod security-context-ea6970a4-583d-421f-8f53-ff6d80b9477d no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Dec 14 10:10:00.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-645" for this suite. 12/14/22 10:10:00.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:00.331
Dec 14 10:10:00.332: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion 12/14/22 10:10:00.332
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:00.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:00.367
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 12/14/22 10:10:00.38
Dec 14 10:10:00.394: INFO: Waiting up to 5m0s for pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694" in namespace "var-expansion-4366" to be "Succeeded or Failed"
Dec 14 10:10:00.401: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Pending", Reason="", readiness=false. Elapsed: 6.936865ms
Dec 14 10:10:02.409: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01554671s
Dec 14 10:10:04.410: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015890237s
STEP: Saw pod success 12/14/22 10:10:04.41
Dec 14 10:10:04.410: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694" satisfied condition "Succeeded or Failed"
Dec 14 10:10:04.417: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 container dapi-container: <nil>
STEP: delete the pod 12/14/22 10:10:04.437
Dec 14 10:10:04.448: INFO: Waiting for pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 to disappear
Dec 14 10:10:04.455: INFO: Pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Dec 14 10:10:04.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4366" for this suite. 12/14/22 10:10:04.468
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":348,"skipped":6385,"failed":0}
------------------------------
• [4.145 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:00.331
    Dec 14 10:10:00.332: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename var-expansion 12/14/22 10:10:00.332
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:00.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:00.367
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 12/14/22 10:10:00.38
    Dec 14 10:10:00.394: INFO: Waiting up to 5m0s for pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694" in namespace "var-expansion-4366" to be "Succeeded or Failed"
    Dec 14 10:10:00.401: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Pending", Reason="", readiness=false. Elapsed: 6.936865ms
    Dec 14 10:10:02.409: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01554671s
    Dec 14 10:10:04.410: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015890237s
    STEP: Saw pod success 12/14/22 10:10:04.41
    Dec 14 10:10:04.410: INFO: Pod "var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694" satisfied condition "Succeeded or Failed"
    Dec 14 10:10:04.417: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 container dapi-container: <nil>
    STEP: delete the pod 12/14/22 10:10:04.437
    Dec 14 10:10:04.448: INFO: Waiting for pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 to disappear
    Dec 14 10:10:04.455: INFO: Pod var-expansion-539c658d-bc89-41bf-ae75-e601f30e9694 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Dec 14 10:10:04.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4366" for this suite. 12/14/22 10:10:04.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:04.478
Dec 14 10:10:04.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename endpointslice 12/14/22 10:10:04.479
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:04.502
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:04.515
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Dec 14 10:10:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5043" for this suite. 12/14/22 10:10:06.603
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":349,"skipped":6409,"failed":0}
------------------------------
• [2.133 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:04.478
    Dec 14 10:10:04.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename endpointslice 12/14/22 10:10:04.479
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:04.502
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:04.515
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Dec 14 10:10:06.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5043" for this suite. 12/14/22 10:10:06.603
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:06.612
Dec 14 10:10:06.612: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 10:10:06.612
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:06.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:06.647
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 10:10:06.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8304" for this suite. 12/14/22 10:10:06.739
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":350,"skipped":6424,"failed":0}
------------------------------
• [0.136 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:06.612
    Dec 14 10:10:06.612: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 10:10:06.612
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:06.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:06.647
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 10:10:06.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8304" for this suite. 12/14/22 10:10:06.739
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:10:06.749
Dec 14 10:10:06.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets 12/14/22 10:10:06.749
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:06.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:06.785
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-00a9f7d9-116b-493b-a808-a98d4147af6f 12/14/22 10:10:06.805
STEP: Creating secret with name s-test-opt-upd-a1beb230-9e25-44b4-bb6b-00afc437067f 12/14/22 10:10:06.813
STEP: Creating the pod 12/14/22 10:10:06.822
Dec 14 10:10:06.838: INFO: Waiting up to 5m0s for pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334" in namespace "secrets-2327" to be "running and ready"
Dec 14 10:10:06.845: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334": Phase="Pending", Reason="", readiness=false. Elapsed: 7.001926ms
Dec 14 10:10:06.845: INFO: The phase of Pod pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:10:08.853: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334": Phase="Running", Reason="", readiness=true. Elapsed: 2.015124396s
Dec 14 10:10:08.853: INFO: The phase of Pod pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334 is Running (Ready = true)
Dec 14 10:10:08.853: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-00a9f7d9-116b-493b-a808-a98d4147af6f 12/14/22 10:10:09.07
STEP: Updating secret s-test-opt-upd-a1beb230-9e25-44b4-bb6b-00afc437067f 12/14/22 10:10:09.078
STEP: Creating secret with name s-test-opt-create-0f330410-774d-449b-8e26-d83f302fb0af 12/14/22 10:10:09.086
STEP: waiting to observe update in volume 12/14/22 10:10:09.093
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Dec 14 10:11:36.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2327" for this suite. 12/14/22 10:11:36.301
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":351,"skipped":6462,"failed":0}
------------------------------
• [89.562 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:10:06.749
    Dec 14 10:10:06.749: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename secrets 12/14/22 10:10:06.749
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:10:06.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:10:06.785
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-00a9f7d9-116b-493b-a808-a98d4147af6f 12/14/22 10:10:06.805
    STEP: Creating secret with name s-test-opt-upd-a1beb230-9e25-44b4-bb6b-00afc437067f 12/14/22 10:10:06.813
    STEP: Creating the pod 12/14/22 10:10:06.822
    Dec 14 10:10:06.838: INFO: Waiting up to 5m0s for pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334" in namespace "secrets-2327" to be "running and ready"
    Dec 14 10:10:06.845: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334": Phase="Pending", Reason="", readiness=false. Elapsed: 7.001926ms
    Dec 14 10:10:06.845: INFO: The phase of Pod pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:10:08.853: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334": Phase="Running", Reason="", readiness=true. Elapsed: 2.015124396s
    Dec 14 10:10:08.853: INFO: The phase of Pod pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334 is Running (Ready = true)
    Dec 14 10:10:08.853: INFO: Pod "pod-secrets-5c33b060-0beb-4d35-a03a-52eb1ecac334" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-00a9f7d9-116b-493b-a808-a98d4147af6f 12/14/22 10:10:09.07
    STEP: Updating secret s-test-opt-upd-a1beb230-9e25-44b4-bb6b-00afc437067f 12/14/22 10:10:09.078
    STEP: Creating secret with name s-test-opt-create-0f330410-774d-449b-8e26-d83f302fb0af 12/14/22 10:10:09.086
    STEP: waiting to observe update in volume 12/14/22 10:10:09.093
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Dec 14 10:11:36.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2327" for this suite. 12/14/22 10:11:36.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:36.312
Dec 14 10:11:36.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected 12/14/22 10:11:36.313
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:36.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:36.351
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-2c1d3aa5-bf68-462c-8070-d41446cc5452 12/14/22 10:11:36.367
STEP: Creating a pod to test consume secrets 12/14/22 10:11:36.375
Dec 14 10:11:36.390: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457" in namespace "projected-4460" to be "Succeeded or Failed"
Dec 14 10:11:36.397: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Pending", Reason="", readiness=false. Elapsed: 7.011095ms
Dec 14 10:11:38.405: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015154906s
Dec 14 10:11:40.406: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015432516s
STEP: Saw pod success 12/14/22 10:11:40.406
Dec 14 10:11:40.406: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457" satisfied condition "Succeeded or Failed"
Dec 14 10:11:40.413: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 container secret-volume-test: <nil>
STEP: delete the pod 12/14/22 10:11:40.431
Dec 14 10:11:40.443: INFO: Waiting for pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 to disappear
Dec 14 10:11:40.450: INFO: Pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Dec 14 10:11:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4460" for this suite. 12/14/22 10:11:40.462
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":352,"skipped":6510,"failed":0}
------------------------------
• [4.159 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:36.312
    Dec 14 10:11:36.312: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename projected 12/14/22 10:11:36.313
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:36.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:36.351
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-2c1d3aa5-bf68-462c-8070-d41446cc5452 12/14/22 10:11:36.367
    STEP: Creating a pod to test consume secrets 12/14/22 10:11:36.375
    Dec 14 10:11:36.390: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457" in namespace "projected-4460" to be "Succeeded or Failed"
    Dec 14 10:11:36.397: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Pending", Reason="", readiness=false. Elapsed: 7.011095ms
    Dec 14 10:11:38.405: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015154906s
    Dec 14 10:11:40.406: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015432516s
    STEP: Saw pod success 12/14/22 10:11:40.406
    Dec 14 10:11:40.406: INFO: Pod "pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457" satisfied condition "Succeeded or Failed"
    Dec 14 10:11:40.413: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 container secret-volume-test: <nil>
    STEP: delete the pod 12/14/22 10:11:40.431
    Dec 14 10:11:40.443: INFO: Waiting for pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 to disappear
    Dec 14 10:11:40.450: INFO: Pod pod-projected-secrets-4921884d-0bb1-45ac-b348-deec58f2e457 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Dec 14 10:11:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4460" for this suite. 12/14/22 10:11:40.462
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:40.471
Dec 14 10:11:40.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 10:11:40.472
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:40.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:40.507
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Dec 14 10:11:40.549: INFO: Waiting up to 5m0s for pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1" in namespace "emptydir-wrapper-4168" to be "running and ready"
Dec 14 10:11:40.556: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.957748ms
Dec 14 10:11:40.556: INFO: The phase of Pod pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:11:42.564: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015492773s
Dec 14 10:11:42.564: INFO: The phase of Pod pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1 is Running (Ready = true)
Dec 14 10:11:42.564: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1" satisfied condition "running and ready"
STEP: Cleaning up the secret 12/14/22 10:11:42.572
STEP: Cleaning up the configmap 12/14/22 10:11:42.58
STEP: Cleaning up the pod 12/14/22 10:11:42.588
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Dec 14 10:11:42.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4168" for this suite. 12/14/22 10:11:42.612
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":353,"skipped":6517,"failed":0}
------------------------------
• [2.150 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:40.471
    Dec 14 10:11:40.471: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir-wrapper 12/14/22 10:11:40.472
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:40.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:40.507
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Dec 14 10:11:40.549: INFO: Waiting up to 5m0s for pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1" in namespace "emptydir-wrapper-4168" to be "running and ready"
    Dec 14 10:11:40.556: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.957748ms
    Dec 14 10:11:40.556: INFO: The phase of Pod pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:11:42.564: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015492773s
    Dec 14 10:11:42.564: INFO: The phase of Pod pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1 is Running (Ready = true)
    Dec 14 10:11:42.564: INFO: Pod "pod-secrets-943b47b2-e77a-49d0-97a9-937babd964d1" satisfied condition "running and ready"
    STEP: Cleaning up the secret 12/14/22 10:11:42.572
    STEP: Cleaning up the configmap 12/14/22 10:11:42.58
    STEP: Cleaning up the pod 12/14/22 10:11:42.588
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:11:42.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-4168" for this suite. 12/14/22 10:11:42.612
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:42.622
Dec 14 10:11:42.622: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 10:11:42.623
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:42.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:42.658
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 12/14/22 10:11:42.671
Dec 14 10:11:42.671: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 create -f -'
Dec 14 10:11:43.014: INFO: stderr: ""
Dec 14 10:11:43.014: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 10:11:43.014
Dec 14 10:11:43.014: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 10:11:43.125: INFO: stderr: ""
Dec 14 10:11:43.125: INFO: stdout: "update-demo-nautilus-5jthf update-demo-nautilus-gtxhj "
Dec 14 10:11:43.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 10:11:43.251: INFO: stderr: ""
Dec 14 10:11:43.251: INFO: stdout: ""
Dec 14 10:11:43.251: INFO: update-demo-nautilus-5jthf is created but not running
Dec 14 10:11:48.252: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Dec 14 10:11:48.371: INFO: stderr: ""
Dec 14 10:11:48.371: INFO: stdout: "update-demo-nautilus-5jthf update-demo-nautilus-gtxhj "
Dec 14 10:11:48.371: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 10:11:48.479: INFO: stderr: ""
Dec 14 10:11:48.479: INFO: stdout: "true"
Dec 14 10:11:48.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 10:11:48.575: INFO: stderr: ""
Dec 14 10:11:48.575: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 10:11:48.575: INFO: validating pod update-demo-nautilus-5jthf
Dec 14 10:11:48.608: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 10:11:48.608: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 10:11:48.608: INFO: update-demo-nautilus-5jthf is verified up and running
Dec 14 10:11:48.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-gtxhj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Dec 14 10:11:48.755: INFO: stderr: ""
Dec 14 10:11:48.755: INFO: stdout: "true"
Dec 14 10:11:48.755: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-gtxhj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Dec 14 10:11:48.863: INFO: stderr: ""
Dec 14 10:11:48.863: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Dec 14 10:11:48.863: INFO: validating pod update-demo-nautilus-gtxhj
Dec 14 10:11:48.933: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 14 10:11:48.933: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 14 10:11:48.933: INFO: update-demo-nautilus-gtxhj is verified up and running
STEP: using delete to clean up resources 12/14/22 10:11:48.933
Dec 14 10:11:48.933: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 delete --grace-period=0 --force -f -'
Dec 14 10:11:49.062: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 14 10:11:49.062: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 14 10:11:49.062: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get rc,svc -l name=update-demo --no-headers'
Dec 14 10:11:49.169: INFO: stderr: "No resources found in kubectl-1044 namespace.\n"
Dec 14 10:11:49.169: INFO: stdout: ""
Dec 14 10:11:49.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 14 10:11:49.291: INFO: stderr: ""
Dec 14 10:11:49.291: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 10:11:49.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1044" for this suite. 12/14/22 10:11:49.304
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":354,"skipped":6534,"failed":0}
------------------------------
• [6.690 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:42.622
    Dec 14 10:11:42.622: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 10:11:42.623
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:42.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:42.658
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 12/14/22 10:11:42.671
    Dec 14 10:11:42.671: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 create -f -'
    Dec 14 10:11:43.014: INFO: stderr: ""
    Dec 14 10:11:43.014: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 12/14/22 10:11:43.014
    Dec 14 10:11:43.014: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 10:11:43.125: INFO: stderr: ""
    Dec 14 10:11:43.125: INFO: stdout: "update-demo-nautilus-5jthf update-demo-nautilus-gtxhj "
    Dec 14 10:11:43.125: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 10:11:43.251: INFO: stderr: ""
    Dec 14 10:11:43.251: INFO: stdout: ""
    Dec 14 10:11:43.251: INFO: update-demo-nautilus-5jthf is created but not running
    Dec 14 10:11:48.252: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Dec 14 10:11:48.371: INFO: stderr: ""
    Dec 14 10:11:48.371: INFO: stdout: "update-demo-nautilus-5jthf update-demo-nautilus-gtxhj "
    Dec 14 10:11:48.371: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 10:11:48.479: INFO: stderr: ""
    Dec 14 10:11:48.479: INFO: stdout: "true"
    Dec 14 10:11:48.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-5jthf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 10:11:48.575: INFO: stderr: ""
    Dec 14 10:11:48.575: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 10:11:48.575: INFO: validating pod update-demo-nautilus-5jthf
    Dec 14 10:11:48.608: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 10:11:48.608: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 10:11:48.608: INFO: update-demo-nautilus-5jthf is verified up and running
    Dec 14 10:11:48.608: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-gtxhj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Dec 14 10:11:48.755: INFO: stderr: ""
    Dec 14 10:11:48.755: INFO: stdout: "true"
    Dec 14 10:11:48.755: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods update-demo-nautilus-gtxhj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Dec 14 10:11:48.863: INFO: stderr: ""
    Dec 14 10:11:48.863: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Dec 14 10:11:48.863: INFO: validating pod update-demo-nautilus-gtxhj
    Dec 14 10:11:48.933: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Dec 14 10:11:48.933: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Dec 14 10:11:48.933: INFO: update-demo-nautilus-gtxhj is verified up and running
    STEP: using delete to clean up resources 12/14/22 10:11:48.933
    Dec 14 10:11:48.933: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 delete --grace-period=0 --force -f -'
    Dec 14 10:11:49.062: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Dec 14 10:11:49.062: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Dec 14 10:11:49.062: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get rc,svc -l name=update-demo --no-headers'
    Dec 14 10:11:49.169: INFO: stderr: "No resources found in kubectl-1044 namespace.\n"
    Dec 14 10:11:49.169: INFO: stdout: ""
    Dec 14 10:11:49.169: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-1044 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Dec 14 10:11:49.291: INFO: stderr: ""
    Dec 14 10:11:49.291: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 10:11:49.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1044" for this suite. 12/14/22 10:11:49.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:49.314
Dec 14 10:11:49.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset 12/14/22 10:11:49.315
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:49.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:49.35
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/14/22 10:11:49.363
Dec 14 10:11:49.378: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7177" to be "running and ready"
Dec 14 10:11:49.385: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.922165ms
Dec 14 10:11:49.385: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:11:51.393: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.015628064s
Dec 14 10:11:51.393: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Dec 14 10:11:51.393: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 12/14/22 10:11:51.401
STEP: Then the orphan pod is adopted 12/14/22 10:11:51.41
STEP: When the matched label of one of its pods change 12/14/22 10:11:52.425
Dec 14 10:11:52.433: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 12/14/22 10:11:52.451
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Dec 14 10:11:52.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7177" for this suite. 12/14/22 10:11:52.472
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":355,"skipped":6552,"failed":0}
------------------------------
• [3.167 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:49.314
    Dec 14 10:11:49.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename replicaset 12/14/22 10:11:49.315
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:49.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:49.35
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 12/14/22 10:11:49.363
    Dec 14 10:11:49.378: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-7177" to be "running and ready"
    Dec 14 10:11:49.385: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.922165ms
    Dec 14 10:11:49.385: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:11:51.393: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.015628064s
    Dec 14 10:11:51.393: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Dec 14 10:11:51.393: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 12/14/22 10:11:51.401
    STEP: Then the orphan pod is adopted 12/14/22 10:11:51.41
    STEP: When the matched label of one of its pods change 12/14/22 10:11:52.425
    Dec 14 10:11:52.433: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 12/14/22 10:11:52.451
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Dec 14 10:11:52.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7177" for this suite. 12/14/22 10:11:52.472
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:52.484
Dec 14 10:11:52.484: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap 12/14/22 10:11:52.485
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:52.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:52.519
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-a14d3ca7-3d6a-4716-8186-176fbf303a27 12/14/22 10:11:52.54
STEP: Creating the pod 12/14/22 10:11:52.547
Dec 14 10:11:52.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27" in namespace "configmap-9453" to be "running and ready"
Dec 14 10:11:52.569: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 7.037466ms
Dec 14 10:11:52.569: INFO: The phase of Pod pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27 is Pending, waiting for it to be Running (with Ready = true)
Dec 14 10:11:54.577: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27": Phase="Running", Reason="", readiness=true. Elapsed: 2.015392304s
Dec 14 10:11:54.577: INFO: The phase of Pod pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27 is Running (Ready = true)
Dec 14 10:11:54.577: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-a14d3ca7-3d6a-4716-8186-176fbf303a27 12/14/22 10:11:54.603
STEP: waiting to observe update in volume 12/14/22 10:11:54.611
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Dec 14 10:11:56.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9453" for this suite. 12/14/22 10:11:56.734
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":356,"skipped":6616,"failed":0}
------------------------------
• [4.260 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:52.484
    Dec 14 10:11:52.484: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename configmap 12/14/22 10:11:52.485
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:52.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:52.519
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-a14d3ca7-3d6a-4716-8186-176fbf303a27 12/14/22 10:11:52.54
    STEP: Creating the pod 12/14/22 10:11:52.547
    Dec 14 10:11:52.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27" in namespace "configmap-9453" to be "running and ready"
    Dec 14 10:11:52.569: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 7.037466ms
    Dec 14 10:11:52.569: INFO: The phase of Pod pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27 is Pending, waiting for it to be Running (with Ready = true)
    Dec 14 10:11:54.577: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27": Phase="Running", Reason="", readiness=true. Elapsed: 2.015392304s
    Dec 14 10:11:54.577: INFO: The phase of Pod pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27 is Running (Ready = true)
    Dec 14 10:11:54.577: INFO: Pod "pod-configmaps-ac181742-ab31-47a3-99ca-4936e3a6cc27" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-a14d3ca7-3d6a-4716-8186-176fbf303a27 12/14/22 10:11:54.603
    STEP: waiting to observe update in volume 12/14/22 10:11:54.611
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Dec 14 10:11:56.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9453" for this suite. 12/14/22 10:11:56.734
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:11:56.747
Dec 14 10:11:56.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook 12/14/22 10:11:56.748
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:56.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:56.782
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 12/14/22 10:11:56.818
STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 10:11:57.531
STEP: Deploying the webhook pod 12/14/22 10:11:57.542
STEP: Wait for the deployment to be ready 12/14/22 10:11:57.562
Dec 14 10:11:57.580: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 12/14/22 10:11:59.604
STEP: Verifying the service has paired with the endpoint 12/14/22 10:11:59.617
Dec 14 10:12:00.617: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 10:12:00.625
STEP: create a pod that should be denied by the webhook 12/14/22 10:12:00.768
STEP: create a pod that causes the webhook to hang 12/14/22 10:12:00.882
STEP: create a configmap that should be denied by the webhook 12/14/22 10:12:10.9
STEP: create a configmap that should be admitted by the webhook 12/14/22 10:12:10.949
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:12:11.024
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:12:11.093
STEP: create a namespace that bypass the webhook 12/14/22 10:12:11.153
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/14/22 10:12:11.163
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Dec 14 10:12:11.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2512" for this suite. 12/14/22 10:12:11.23
STEP: Destroying namespace "webhook-2512-markers" for this suite. 12/14/22 10:12:11.239
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":357,"skipped":6658,"failed":0}
------------------------------
• [14.540 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:11:56.747
    Dec 14 10:11:56.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename webhook 12/14/22 10:11:56.748
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:11:56.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:11:56.782
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 12/14/22 10:11:56.818
    STEP: Create role binding to let webhook read extension-apiserver-authentication 12/14/22 10:11:57.531
    STEP: Deploying the webhook pod 12/14/22 10:11:57.542
    STEP: Wait for the deployment to be ready 12/14/22 10:11:57.562
    Dec 14 10:11:57.580: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 12/14/22 10:11:59.604
    STEP: Verifying the service has paired with the endpoint 12/14/22 10:11:59.617
    Dec 14 10:12:00.617: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 12/14/22 10:12:00.625
    STEP: create a pod that should be denied by the webhook 12/14/22 10:12:00.768
    STEP: create a pod that causes the webhook to hang 12/14/22 10:12:00.882
    STEP: create a configmap that should be denied by the webhook 12/14/22 10:12:10.9
    STEP: create a configmap that should be admitted by the webhook 12/14/22 10:12:10.949
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:12:11.024
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 12/14/22 10:12:11.093
    STEP: create a namespace that bypass the webhook 12/14/22 10:12:11.153
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 12/14/22 10:12:11.163
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Dec 14 10:12:11.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2512" for this suite. 12/14/22 10:12:11.23
    STEP: Destroying namespace "webhook-2512-markers" for this suite. 12/14/22 10:12:11.239
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:12:11.288
Dec 14 10:12:11.288: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir 12/14/22 10:12:11.288
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:11.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:11.326
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 10:12:11.339
Dec 14 10:12:11.354: INFO: Waiting up to 5m0s for pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5" in namespace "emptydir-599" to be "Succeeded or Failed"
Dec 14 10:12:11.361: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.733934ms
Dec 14 10:12:13.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016417661s
Dec 14 10:12:15.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016206255s
STEP: Saw pod success 12/14/22 10:12:15.37
Dec 14 10:12:15.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5" satisfied condition "Succeeded or Failed"
Dec 14 10:12:15.377: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 container test-container: <nil>
STEP: delete the pod 12/14/22 10:12:15.404
Dec 14 10:12:15.416: INFO: Waiting for pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 to disappear
Dec 14 10:12:15.423: INFO: Pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Dec 14 10:12:15.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-599" for this suite. 12/14/22 10:12:15.435
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":358,"skipped":6659,"failed":0}
------------------------------
• [4.157 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:12:11.288
    Dec 14 10:12:11.288: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename emptydir 12/14/22 10:12:11.288
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:11.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:11.326
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 12/14/22 10:12:11.339
    Dec 14 10:12:11.354: INFO: Waiting up to 5m0s for pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5" in namespace "emptydir-599" to be "Succeeded or Failed"
    Dec 14 10:12:11.361: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.733934ms
    Dec 14 10:12:13.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016417661s
    Dec 14 10:12:15.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016206255s
    STEP: Saw pod success 12/14/22 10:12:15.37
    Dec 14 10:12:15.370: INFO: Pod "pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5" satisfied condition "Succeeded or Failed"
    Dec 14 10:12:15.377: INFO: Trying to get logs from node izgw8jfcr55yi09nr0a5xaz pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 container test-container: <nil>
    STEP: delete the pod 12/14/22 10:12:15.404
    Dec 14 10:12:15.416: INFO: Waiting for pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 to disappear
    Dec 14 10:12:15.423: INFO: Pod pod-5fe45855-3dc9-4b05-ba71-8a90f6324db5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Dec 14 10:12:15.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-599" for this suite. 12/14/22 10:12:15.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:12:15.446
Dec 14 10:12:15.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl 12/14/22 10:12:15.447
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:15.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:15.482
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 12/14/22 10:12:15.494
Dec 14 10:12:15.495: INFO: namespace kubectl-7899
Dec 14 10:12:15.495: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 create -f -'
Dec 14 10:12:15.787: INFO: stderr: ""
Dec 14 10:12:15.787: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 12/14/22 10:12:15.787
Dec 14 10:12:16.796: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:12:16.796: INFO: Found 0 / 1
Dec 14 10:12:17.796: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:12:17.796: INFO: Found 1 / 1
Dec 14 10:12:17.796: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 14 10:12:17.815: INFO: Selector matched 1 pods for map[app:agnhost]
Dec 14 10:12:17.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 14 10:12:17.815: INFO: wait on agnhost-primary startup in kubectl-7899 
Dec 14 10:12:17.816: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 logs agnhost-primary-nv4kp agnhost-primary'
Dec 14 10:12:17.973: INFO: stderr: ""
Dec 14 10:12:17.973: INFO: stdout: "Paused\n"
STEP: exposing RC 12/14/22 10:12:17.973
Dec 14 10:12:17.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Dec 14 10:12:18.085: INFO: stderr: ""
Dec 14 10:12:18.085: INFO: stdout: "service/rm2 exposed\n"
Dec 14 10:12:18.092: INFO: Service rm2 in namespace kubectl-7899 found.
STEP: exposing service 12/14/22 10:12:20.107
Dec 14 10:12:20.107: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Dec 14 10:12:20.256: INFO: stderr: ""
Dec 14 10:12:20.256: INFO: stdout: "service/rm3 exposed\n"
Dec 14 10:12:20.264: INFO: Service rm3 in namespace kubectl-7899 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Dec 14 10:12:22.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7899" for this suite. 12/14/22 10:12:22.292
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":359,"skipped":6677,"failed":0}
------------------------------
• [6.856 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:12:15.446
    Dec 14 10:12:15.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename kubectl 12/14/22 10:12:15.447
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:15.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:15.482
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 12/14/22 10:12:15.494
    Dec 14 10:12:15.495: INFO: namespace kubectl-7899
    Dec 14 10:12:15.495: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 create -f -'
    Dec 14 10:12:15.787: INFO: stderr: ""
    Dec 14 10:12:15.787: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 12/14/22 10:12:15.787
    Dec 14 10:12:16.796: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:12:16.796: INFO: Found 0 / 1
    Dec 14 10:12:17.796: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:12:17.796: INFO: Found 1 / 1
    Dec 14 10:12:17.796: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Dec 14 10:12:17.815: INFO: Selector matched 1 pods for map[app:agnhost]
    Dec 14 10:12:17.815: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Dec 14 10:12:17.815: INFO: wait on agnhost-primary startup in kubectl-7899 
    Dec 14 10:12:17.816: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 logs agnhost-primary-nv4kp agnhost-primary'
    Dec 14 10:12:17.973: INFO: stderr: ""
    Dec 14 10:12:17.973: INFO: stdout: "Paused\n"
    STEP: exposing RC 12/14/22 10:12:17.973
    Dec 14 10:12:17.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Dec 14 10:12:18.085: INFO: stderr: ""
    Dec 14 10:12:18.085: INFO: stdout: "service/rm2 exposed\n"
    Dec 14 10:12:18.092: INFO: Service rm2 in namespace kubectl-7899 found.
    STEP: exposing service 12/14/22 10:12:20.107
    Dec 14 10:12:20.107: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp5j-n6c.it.shoot.staging.k8s-hana.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-7899 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Dec 14 10:12:20.256: INFO: stderr: ""
    Dec 14 10:12:20.256: INFO: stdout: "service/rm3 exposed\n"
    Dec 14 10:12:20.264: INFO: Service rm3 in namespace kubectl-7899 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Dec 14 10:12:22.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7899" for this suite. 12/14/22 10:12:22.292
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:12:22.301
Dec 14 10:12:22.302: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 10:12:22.302
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:22.324
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:22.336
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 12/14/22 10:12:22.348
STEP: delete the rc 12/14/22 10:12:27.366
STEP: wait for all pods to be garbage collected 12/14/22 10:12:27.375
STEP: Gathering metrics 12/14/22 10:12:32.391
W1214 10:12:32.410230    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 10:12:32.410: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 10:12:32.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8001" for this suite. 12/14/22 10:12:32.418
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":360,"skipped":6677,"failed":0}
------------------------------
• [10.124 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:12:22.301
    Dec 14 10:12:22.302: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 10:12:22.302
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:22.324
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:22.336
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 12/14/22 10:12:22.348
    STEP: delete the rc 12/14/22 10:12:27.366
    STEP: wait for all pods to be garbage collected 12/14/22 10:12:27.375
    STEP: Gathering metrics 12/14/22 10:12:32.391
    W1214 10:12:32.410230    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 10:12:32.410: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 10:12:32.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8001" for this suite. 12/14/22 10:12:32.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:12:32.426
Dec 14 10:12:32.426: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename cronjob 12/14/22 10:12:32.427
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:32.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:32.461
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 12/14/22 10:12:32.474
STEP: Ensuring no jobs are scheduled 12/14/22 10:12:32.482
STEP: Ensuring no job exists by listing jobs explicitly 12/14/22 10:17:32.499
STEP: Removing cronjob 12/14/22 10:17:32.507
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Dec 14 10:17:32.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2945" for this suite. 12/14/22 10:17:32.529
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":361,"skipped":6684,"failed":0}
------------------------------
• [SLOW TEST] [300.111 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:12:32.426
    Dec 14 10:12:32.426: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename cronjob 12/14/22 10:12:32.427
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:12:32.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:12:32.461
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 12/14/22 10:12:32.474
    STEP: Ensuring no jobs are scheduled 12/14/22 10:12:32.482
    STEP: Ensuring no job exists by listing jobs explicitly 12/14/22 10:17:32.499
    STEP: Removing cronjob 12/14/22 10:17:32.507
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Dec 14 10:17:32.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2945" for this suite. 12/14/22 10:17:32.529
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 12/14/22 10:17:32.538
Dec 14 10:17:32.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc 12/14/22 10:17:32.538
STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:17:32.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:17:32.578
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 12/14/22 10:17:32.603
STEP: delete the rc 12/14/22 10:17:37.619
STEP: wait for the rc to be deleted 12/14/22 10:17:37.628
Dec 14 10:17:38.655: INFO: 94 pods remaining
Dec 14 10:17:38.655: INFO: 94 pods has nil DeletionTimestamp
Dec 14 10:17:38.655: INFO: 
Dec 14 10:17:39.716: INFO: 70 pods remaining
Dec 14 10:17:39.716: INFO: 70 pods has nil DeletionTimestamp
Dec 14 10:17:39.716: INFO: 
Dec 14 10:17:40.653: INFO: 70 pods remaining
Dec 14 10:17:40.654: INFO: 70 pods has nil DeletionTimestamp
Dec 14 10:17:40.654: INFO: 
Dec 14 10:17:41.664: INFO: 40 pods remaining
Dec 14 10:17:41.664: INFO: 40 pods has nil DeletionTimestamp
Dec 14 10:17:41.664: INFO: 
Dec 14 10:17:42.662: INFO: 40 pods remaining
Dec 14 10:17:42.662: INFO: 40 pods has nil DeletionTimestamp
Dec 14 10:17:42.662: INFO: 
Dec 14 10:17:43.655: INFO: 14 pods remaining
Dec 14 10:17:43.655: INFO: 13 pods has nil DeletionTimestamp
Dec 14 10:17:43.655: INFO: 
STEP: Gathering metrics 12/14/22 10:17:44.645
W1214 10:17:44.665618    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Dec 14 10:17:44.665: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Dec 14 10:17:44.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7523" for this suite. 12/14/22 10:17:44.673
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":362,"skipped":6697,"failed":0}
------------------------------
• [12.144 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 12/14/22 10:17:32.538
    Dec 14 10:17:32.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
    STEP: Building a namespace api object, basename gc 12/14/22 10:17:32.538
    STEP: Waiting for a default service account to be provisioned in namespace 12/14/22 10:17:32.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 12/14/22 10:17:32.578
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 12/14/22 10:17:32.603
    STEP: delete the rc 12/14/22 10:17:37.619
    STEP: wait for the rc to be deleted 12/14/22 10:17:37.628
    Dec 14 10:17:38.655: INFO: 94 pods remaining
    Dec 14 10:17:38.655: INFO: 94 pods has nil DeletionTimestamp
    Dec 14 10:17:38.655: INFO: 
    Dec 14 10:17:39.716: INFO: 70 pods remaining
    Dec 14 10:17:39.716: INFO: 70 pods has nil DeletionTimestamp
    Dec 14 10:17:39.716: INFO: 
    Dec 14 10:17:40.653: INFO: 70 pods remaining
    Dec 14 10:17:40.654: INFO: 70 pods has nil DeletionTimestamp
    Dec 14 10:17:40.654: INFO: 
    Dec 14 10:17:41.664: INFO: 40 pods remaining
    Dec 14 10:17:41.664: INFO: 40 pods has nil DeletionTimestamp
    Dec 14 10:17:41.664: INFO: 
    Dec 14 10:17:42.662: INFO: 40 pods remaining
    Dec 14 10:17:42.662: INFO: 40 pods has nil DeletionTimestamp
    Dec 14 10:17:42.662: INFO: 
    Dec 14 10:17:43.655: INFO: 14 pods remaining
    Dec 14 10:17:43.655: INFO: 13 pods has nil DeletionTimestamp
    Dec 14 10:17:43.655: INFO: 
    STEP: Gathering metrics 12/14/22 10:17:44.645
    W1214 10:17:44.665618    6248 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Dec 14 10:17:44.665: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Dec 14 10:17:44.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7523" for this suite. 12/14/22 10:17:44.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Dec 14 10:17:44.682: INFO: Running AfterSuite actions on all nodes
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Dec 14 10:17:44.683: INFO: Running AfterSuite actions on node 1
Dec 14 10:17:44.683: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec 14 10:17:44.682: INFO: Running AfterSuite actions on all nodes
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Dec 14 10:17:44.682: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Dec 14 10:17:44.683: INFO: Running AfterSuite actions on node 1
    Dec 14 10:17:44.683: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.075 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5849.330 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--ginkgo.dryRun is deprecated, use --ginkgo.dry-run instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m
  [38;5;11m--ginkgo.flakeAttempts is deprecated, use --ginkgo.flake-attempts instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m


Ginkgo ran 1 suite in 1h37m29.62473817s
Test Suite Passed
