I1111 23:08:57.877792      21 e2e.go:116] Starting e2e run "0cbcaf67-ec2b-40e5-9cf1-f211c8b02420" on Ginkgo node 1
Nov 11 23:08:57.896: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1668208137 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Nov 11 23:08:58.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:08:58.189: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E1111 23:08:58.190912      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
E1111 23:08:58.190912      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Nov 11 23:08:58.269: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 11 23:08:58.390: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 11 23:08:58.390: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
Nov 11 23:08:58.390: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
Nov 11 23:08:58.415: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Nov 11 23:08:58.416: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Nov 11 23:08:58.416: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Nov 11 23:08:58.416: INFO: e2e test version: v1.25.4
Nov 11 23:08:58.422: INFO: kube-apiserver version: v1.25.4+IKS
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Nov 11 23:08:58.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:08:58.439: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.253 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 11 23:08:58.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:08:58.189: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    E1111 23:08:58.190912      21 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Nov 11 23:08:58.269: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Nov 11 23:08:58.390: INFO: 36 / 36 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Nov 11 23:08:58.390: INFO: expected 21 pod replicas in namespace 'kube-system', 21 are Running and Ready.
    Nov 11 23:08:58.390: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
    Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibmcloud-block-storage-driver' (0 seconds elapsed)
    Nov 11 23:08:58.415: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'konnectivity-agent' (0 seconds elapsed)
    Nov 11 23:08:58.415: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
    Nov 11 23:08:58.416: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
    Nov 11 23:08:58.416: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
    Nov 11 23:08:58.416: INFO: e2e test version: v1.25.4
    Nov 11 23:08:58.422: INFO: kube-apiserver version: v1.25.4+IKS
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 11 23:08:58.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:08:58.439: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:08:58.469
Nov 11 23:08:58.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:08:58.47
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:08:58.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:08:58.622
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 11/11/22 23:08:58.671
Nov 11 23:08:58.703: INFO: Waiting up to 5m0s for pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a" in namespace "emptydir-9650" to be "Succeeded or Failed"
Nov 11 23:08:58.718: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.49484ms
Nov 11 23:09:00.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030415058s
Nov 11 23:09:02.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028947598s
Nov 11 23:09:04.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028655214s
Nov 11 23:09:06.749: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=true. Elapsed: 8.045997696s
Nov 11 23:09:08.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=false. Elapsed: 10.030463511s
Nov 11 23:09:10.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=false. Elapsed: 12.029430672s
Nov 11 23:09:12.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.030398376s
STEP: Saw pod success 11/11/22 23:09:12.734
Nov 11 23:09:12.735: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a" satisfied condition "Succeeded or Failed"
Nov 11 23:09:12.749: INFO: Trying to get logs from node 10.184.98.55 pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a container test-container: <nil>
STEP: delete the pod 11/11/22 23:09:12.829
Nov 11 23:09:12.871: INFO: Waiting for pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a to disappear
Nov 11 23:09:12.885: INFO: Pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:09:12.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9650" for this suite. 11/11/22 23:09:12.904
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":1,"skipped":16,"failed":0}
------------------------------
• [SLOW TEST] [14.484 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:08:58.469
    Nov 11 23:08:58.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:08:58.47
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:08:58.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:08:58.622
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 11/11/22 23:08:58.671
    Nov 11 23:08:58.703: INFO: Waiting up to 5m0s for pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a" in namespace "emptydir-9650" to be "Succeeded or Failed"
    Nov 11 23:08:58.718: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.49484ms
    Nov 11 23:09:00.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030415058s
    Nov 11 23:09:02.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028947598s
    Nov 11 23:09:04.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028655214s
    Nov 11 23:09:06.749: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=true. Elapsed: 8.045997696s
    Nov 11 23:09:08.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=false. Elapsed: 10.030463511s
    Nov 11 23:09:10.732: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Running", Reason="", readiness=false. Elapsed: 12.029430672s
    Nov 11 23:09:12.733: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.030398376s
    STEP: Saw pod success 11/11/22 23:09:12.734
    Nov 11 23:09:12.735: INFO: Pod "pod-0ddadcbb-5f4d-497d-a01b-f248faad585a" satisfied condition "Succeeded or Failed"
    Nov 11 23:09:12.749: INFO: Trying to get logs from node 10.184.98.55 pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a container test-container: <nil>
    STEP: delete the pod 11/11/22 23:09:12.829
    Nov 11 23:09:12.871: INFO: Waiting for pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a to disappear
    Nov 11 23:09:12.885: INFO: Pod pod-0ddadcbb-5f4d-497d-a01b-f248faad585a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:09:12.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9650" for this suite. 11/11/22 23:09:12.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:09:12.971
Nov 11 23:09:12.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/11/22 23:09:12.973
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:13.02
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:13.034
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 11/11/22 23:09:13.069
STEP: delete the rc 11/11/22 23:09:18.103
STEP: wait for the rc to be deleted 11/11/22 23:09:18.127
STEP: Gathering metrics 11/11/22 23:09:19.159
W1111 23:09:19.212188      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 11 23:09:19.212: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 11 23:09:19.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4346" for this suite. 11/11/22 23:09:19.234
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":2,"skipped":50,"failed":0}
------------------------------
• [SLOW TEST] [6.300 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:09:12.971
    Nov 11 23:09:12.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/11/22 23:09:12.973
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:13.02
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:13.034
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 11/11/22 23:09:13.069
    STEP: delete the rc 11/11/22 23:09:18.103
    STEP: wait for the rc to be deleted 11/11/22 23:09:18.127
    STEP: Gathering metrics 11/11/22 23:09:19.159
    W1111 23:09:19.212188      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 11 23:09:19.212: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 11 23:09:19.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4346" for this suite. 11/11/22 23:09:19.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:09:19.296
Nov 11 23:09:19.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:09:19.305
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:19.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:19.413
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:09:19.435
Nov 11 23:09:19.474: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11" in namespace "downward-api-4000" to be "Succeeded or Failed"
Nov 11 23:09:19.488: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 13.825911ms
Nov 11 23:09:21.505: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030783204s
Nov 11 23:09:23.503: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028635231s
Nov 11 23:09:25.529: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055373796s
Nov 11 23:09:27.504: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Running", Reason="", readiness=false. Elapsed: 8.029596077s
Nov 11 23:09:29.518: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Running", Reason="", readiness=false. Elapsed: 10.043893505s
Nov 11 23:09:31.505: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.031019568s
STEP: Saw pod success 11/11/22 23:09:31.505
Nov 11 23:09:31.506: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11" satisfied condition "Succeeded or Failed"
Nov 11 23:09:31.519: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 container client-container: <nil>
STEP: delete the pod 11/11/22 23:09:31.548
Nov 11 23:09:31.586: INFO: Waiting for pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 to disappear
Nov 11 23:09:31.614: INFO: Pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 11 23:09:31.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4000" for this suite. 11/11/22 23:09:31.634
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":3,"skipped":72,"failed":0}
------------------------------
• [SLOW TEST] [12.364 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:09:19.296
    Nov 11 23:09:19.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:09:19.305
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:19.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:19.413
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:09:19.435
    Nov 11 23:09:19.474: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11" in namespace "downward-api-4000" to be "Succeeded or Failed"
    Nov 11 23:09:19.488: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 13.825911ms
    Nov 11 23:09:21.505: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030783204s
    Nov 11 23:09:23.503: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028635231s
    Nov 11 23:09:25.529: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055373796s
    Nov 11 23:09:27.504: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Running", Reason="", readiness=false. Elapsed: 8.029596077s
    Nov 11 23:09:29.518: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Running", Reason="", readiness=false. Elapsed: 10.043893505s
    Nov 11 23:09:31.505: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.031019568s
    STEP: Saw pod success 11/11/22 23:09:31.505
    Nov 11 23:09:31.506: INFO: Pod "downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11" satisfied condition "Succeeded or Failed"
    Nov 11 23:09:31.519: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:09:31.548
    Nov 11 23:09:31.586: INFO: Waiting for pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 to disappear
    Nov 11 23:09:31.614: INFO: Pod downwardapi-volume-5039df9d-c6cd-4b5d-a8c0-ee4a86489a11 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 11 23:09:31.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4000" for this suite. 11/11/22 23:09:31.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:09:31.661
Nov 11 23:09:31.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:09:31.664
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:31.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:31.755
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8993 11/11/22 23:09:31.77
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-8993 11/11/22 23:09:31.792
Nov 11 23:09:31.878: INFO: Found 0 stateful pods, waiting for 1
Nov 11 23:09:41.899: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 11/11/22 23:09:41.927
STEP: updating a scale subresource 11/11/22 23:09:41.968
STEP: verifying the statefulset Spec.Replicas was modified 11/11/22 23:09:41.99
STEP: Patch a scale subresource 11/11/22 23:09:42.007
STEP: verifying the statefulset Spec.Replicas was modified 11/11/22 23:09:42.065
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 11 23:09:42.083: INFO: Deleting all statefulset in ns statefulset-8993
Nov 11 23:09:42.098: INFO: Scaling statefulset ss to 0
Nov 11 23:10:02.161: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:10:02.175: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 11 23:10:02.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8993" for this suite. 11/11/22 23:10:02.26
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":4,"skipped":78,"failed":0}
------------------------------
• [SLOW TEST] [30.633 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:09:31.661
    Nov 11 23:09:31.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:09:31.664
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:09:31.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:09:31.755
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8993 11/11/22 23:09:31.77
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-8993 11/11/22 23:09:31.792
    Nov 11 23:09:31.878: INFO: Found 0 stateful pods, waiting for 1
    Nov 11 23:09:41.899: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 11/11/22 23:09:41.927
    STEP: updating a scale subresource 11/11/22 23:09:41.968
    STEP: verifying the statefulset Spec.Replicas was modified 11/11/22 23:09:41.99
    STEP: Patch a scale subresource 11/11/22 23:09:42.007
    STEP: verifying the statefulset Spec.Replicas was modified 11/11/22 23:09:42.065
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 11 23:09:42.083: INFO: Deleting all statefulset in ns statefulset-8993
    Nov 11 23:09:42.098: INFO: Scaling statefulset ss to 0
    Nov 11 23:10:02.161: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:10:02.175: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 11 23:10:02.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8993" for this suite. 11/11/22 23:10:02.26
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:10:02.3
Nov 11 23:10:02.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:10:02.304
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:02.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:02.403
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:10:02.421
Nov 11 23:10:02.463: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9" in namespace "downward-api-4690" to be "Succeeded or Failed"
Nov 11 23:10:02.480: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.196794ms
Nov 11 23:10:04.496: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033121911s
Nov 11 23:10:06.493: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030775582s
Nov 11 23:10:08.495: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032261203s
STEP: Saw pod success 11/11/22 23:10:08.495
Nov 11 23:10:08.495: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9" satisfied condition "Succeeded or Failed"
Nov 11 23:10:08.509: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 container client-container: <nil>
STEP: delete the pod 11/11/22 23:10:08.59
Nov 11 23:10:08.632: INFO: Waiting for pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 to disappear
Nov 11 23:10:08.646: INFO: Pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 11 23:10:08.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4690" for this suite. 11/11/22 23:10:08.692
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":5,"skipped":78,"failed":0}
------------------------------
• [SLOW TEST] [6.423 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:10:02.3
    Nov 11 23:10:02.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:10:02.304
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:02.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:02.403
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:10:02.421
    Nov 11 23:10:02.463: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9" in namespace "downward-api-4690" to be "Succeeded or Failed"
    Nov 11 23:10:02.480: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.196794ms
    Nov 11 23:10:04.496: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033121911s
    Nov 11 23:10:06.493: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030775582s
    Nov 11 23:10:08.495: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032261203s
    STEP: Saw pod success 11/11/22 23:10:08.495
    Nov 11 23:10:08.495: INFO: Pod "downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9" satisfied condition "Succeeded or Failed"
    Nov 11 23:10:08.509: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:10:08.59
    Nov 11 23:10:08.632: INFO: Waiting for pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 to disappear
    Nov 11 23:10:08.646: INFO: Pod downwardapi-volume-5d3b2841-b96b-4259-88d4-f50c03bd5ff9 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 11 23:10:08.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4690" for this suite. 11/11/22 23:10:08.692
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:10:08.725
Nov 11 23:10:08.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replication-controller 11/11/22 23:10:08.728
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:08.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:08.859
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 11/11/22 23:10:08.876
Nov 11 23:10:08.940: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-587" to be "running and ready"
Nov 11 23:10:08.979: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 39.714518ms
Nov 11 23:10:08.979: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:10:10.995: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05535016s
Nov 11 23:10:10.995: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:10:12.994: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.054690751s
Nov 11 23:10:12.994: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Nov 11 23:10:12.995: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 11/11/22 23:10:13.009
STEP: Then the orphan pod is adopted 11/11/22 23:10:13.025
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 11 23:10:14.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-587" for this suite. 11/11/22 23:10:14.101
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":6,"skipped":96,"failed":0}
------------------------------
• [SLOW TEST] [5.463 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:10:08.725
    Nov 11 23:10:08.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replication-controller 11/11/22 23:10:08.728
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:08.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:08.859
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 11/11/22 23:10:08.876
    Nov 11 23:10:08.940: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-587" to be "running and ready"
    Nov 11 23:10:08.979: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 39.714518ms
    Nov 11 23:10:08.979: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:10:10.995: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05535016s
    Nov 11 23:10:10.995: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:10:12.994: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.054690751s
    Nov 11 23:10:12.994: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Nov 11 23:10:12.995: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 11/11/22 23:10:13.009
    STEP: Then the orphan pod is adopted 11/11/22 23:10:13.025
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 11 23:10:14.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-587" for this suite. 11/11/22 23:10:14.101
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:10:14.189
Nov 11 23:10:14.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename subpath 11/11/22 23:10:14.191
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:14.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:14.258
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/11/22 23:10:14.275
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-28pv 11/11/22 23:10:14.317
STEP: Creating a pod to test atomic-volume-subpath 11/11/22 23:10:14.317
Nov 11 23:10:14.351: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-28pv" in namespace "subpath-3030" to be "Succeeded or Failed"
Nov 11 23:10:14.366: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.554562ms
Nov 11 23:10:16.396: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044704556s
Nov 11 23:10:18.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 4.029717856s
Nov 11 23:10:20.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 6.029418843s
Nov 11 23:10:22.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 8.030451712s
Nov 11 23:10:24.408: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 10.056385068s
Nov 11 23:10:26.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 12.029378516s
Nov 11 23:10:28.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 14.029978786s
Nov 11 23:10:30.380: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 16.028408019s
Nov 11 23:10:32.401: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 18.049840914s
Nov 11 23:10:34.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 20.03034038s
Nov 11 23:10:36.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 22.030947857s
Nov 11 23:10:38.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=false. Elapsed: 24.030242271s
Nov 11 23:10:40.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.030719558s
STEP: Saw pod success 11/11/22 23:10:40.382
Nov 11 23:10:40.383: INFO: Pod "pod-subpath-test-configmap-28pv" satisfied condition "Succeeded or Failed"
Nov 11 23:10:40.397: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-configmap-28pv container test-container-subpath-configmap-28pv: <nil>
STEP: delete the pod 11/11/22 23:10:40.428
Nov 11 23:10:40.467: INFO: Waiting for pod pod-subpath-test-configmap-28pv to disappear
Nov 11 23:10:40.479: INFO: Pod pod-subpath-test-configmap-28pv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-28pv 11/11/22 23:10:40.479
Nov 11 23:10:40.480: INFO: Deleting pod "pod-subpath-test-configmap-28pv" in namespace "subpath-3030"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 11 23:10:40.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3030" for this suite. 11/11/22 23:10:40.52
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":7,"skipped":96,"failed":0}
------------------------------
• [SLOW TEST] [26.358 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:10:14.189
    Nov 11 23:10:14.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename subpath 11/11/22 23:10:14.191
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:14.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:14.258
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/11/22 23:10:14.275
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-28pv 11/11/22 23:10:14.317
    STEP: Creating a pod to test atomic-volume-subpath 11/11/22 23:10:14.317
    Nov 11 23:10:14.351: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-28pv" in namespace "subpath-3030" to be "Succeeded or Failed"
    Nov 11 23:10:14.366: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Pending", Reason="", readiness=false. Elapsed: 14.554562ms
    Nov 11 23:10:16.396: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044704556s
    Nov 11 23:10:18.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 4.029717856s
    Nov 11 23:10:20.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 6.029418843s
    Nov 11 23:10:22.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 8.030451712s
    Nov 11 23:10:24.408: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 10.056385068s
    Nov 11 23:10:26.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 12.029378516s
    Nov 11 23:10:28.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 14.029978786s
    Nov 11 23:10:30.380: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 16.028408019s
    Nov 11 23:10:32.401: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 18.049840914s
    Nov 11 23:10:34.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 20.03034038s
    Nov 11 23:10:36.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=true. Elapsed: 22.030947857s
    Nov 11 23:10:38.381: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Running", Reason="", readiness=false. Elapsed: 24.030242271s
    Nov 11 23:10:40.382: INFO: Pod "pod-subpath-test-configmap-28pv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.030719558s
    STEP: Saw pod success 11/11/22 23:10:40.382
    Nov 11 23:10:40.383: INFO: Pod "pod-subpath-test-configmap-28pv" satisfied condition "Succeeded or Failed"
    Nov 11 23:10:40.397: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-configmap-28pv container test-container-subpath-configmap-28pv: <nil>
    STEP: delete the pod 11/11/22 23:10:40.428
    Nov 11 23:10:40.467: INFO: Waiting for pod pod-subpath-test-configmap-28pv to disappear
    Nov 11 23:10:40.479: INFO: Pod pod-subpath-test-configmap-28pv no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-28pv 11/11/22 23:10:40.479
    Nov 11 23:10:40.480: INFO: Deleting pod "pod-subpath-test-configmap-28pv" in namespace "subpath-3030"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 11 23:10:40.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3030" for this suite. 11/11/22 23:10:40.52
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:10:40.551
Nov 11 23:10:40.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename namespaces 11/11/22 23:10:40.554
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:40.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:40.66
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 11/11/22 23:10:40.699
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:40.749
STEP: Creating a pod in the namespace 11/11/22 23:10:40.765
STEP: Waiting for the pod to have running status 11/11/22 23:10:40.831
Nov 11 23:10:40.831: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-9528" to be "running"
Nov 11 23:10:40.845: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.300091ms
Nov 11 23:10:42.859: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028208876s
Nov 11 23:10:44.862: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03142733s
Nov 11 23:10:44.862: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 11/11/22 23:10:44.862
STEP: Waiting for the namespace to be removed. 11/11/22 23:10:44.897
STEP: Recreating the namespace 11/11/22 23:10:56.913
STEP: Verifying there are no pods in the namespace 11/11/22 23:10:56.972
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:10:56.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9505" for this suite. 11/11/22 23:10:57.022
STEP: Destroying namespace "nsdeletetest-9528" for this suite. 11/11/22 23:10:57.05
Nov 11 23:10:57.067: INFO: Namespace nsdeletetest-9528 was already deleted
STEP: Destroying namespace "nsdeletetest-3417" for this suite. 11/11/22 23:10:57.067
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":8,"skipped":116,"failed":0}
------------------------------
• [SLOW TEST] [16.544 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:10:40.551
    Nov 11 23:10:40.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename namespaces 11/11/22 23:10:40.554
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:40.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:40.66
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 11/11/22 23:10:40.699
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:40.749
    STEP: Creating a pod in the namespace 11/11/22 23:10:40.765
    STEP: Waiting for the pod to have running status 11/11/22 23:10:40.831
    Nov 11 23:10:40.831: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-9528" to be "running"
    Nov 11 23:10:40.845: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.300091ms
    Nov 11 23:10:42.859: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028208876s
    Nov 11 23:10:44.862: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03142733s
    Nov 11 23:10:44.862: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 11/11/22 23:10:44.862
    STEP: Waiting for the namespace to be removed. 11/11/22 23:10:44.897
    STEP: Recreating the namespace 11/11/22 23:10:56.913
    STEP: Verifying there are no pods in the namespace 11/11/22 23:10:56.972
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:10:56.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9505" for this suite. 11/11/22 23:10:57.022
    STEP: Destroying namespace "nsdeletetest-9528" for this suite. 11/11/22 23:10:57.05
    Nov 11 23:10:57.067: INFO: Namespace nsdeletetest-9528 was already deleted
    STEP: Destroying namespace "nsdeletetest-3417" for this suite. 11/11/22 23:10:57.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:10:57.097
Nov 11 23:10:57.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:10:57.099
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:57.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:57.165
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/11/22 23:10:57.182
Nov 11 23:10:57.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/11/22 23:11:20.835
Nov 11 23:11:20.838: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:11:27.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:11:55.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6293" for this suite. 11/11/22 23:11:55.981
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":9,"skipped":121,"failed":0}
------------------------------
• [SLOW TEST] [58.908 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:10:57.097
    Nov 11 23:10:57.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:10:57.099
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:10:57.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:10:57.165
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/11/22 23:10:57.182
    Nov 11 23:10:57.185: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/11/22 23:11:20.835
    Nov 11 23:11:20.838: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:11:27.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:11:55.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6293" for this suite. 11/11/22 23:11:55.981
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:11:56.01
Nov 11 23:11:56.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:11:56.013
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:11:56.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:11:56.083
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 11/11/22 23:11:56.103
Nov 11 23:11:56.143: INFO: Waiting up to 5m0s for pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f" in namespace "emptydir-9740" to be "Succeeded or Failed"
Nov 11 23:11:56.173: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.003051ms
Nov 11 23:11:58.195: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05163457s
Nov 11 23:12:00.194: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050332209s
Nov 11 23:12:02.194: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050677727s
STEP: Saw pod success 11/11/22 23:12:02.194
Nov 11 23:12:02.195: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f" satisfied condition "Succeeded or Failed"
Nov 11 23:12:02.213: INFO: Trying to get logs from node 10.184.98.55 pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f container test-container: <nil>
STEP: delete the pod 11/11/22 23:12:02.333
Nov 11 23:12:02.392: INFO: Waiting for pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f to disappear
Nov 11 23:12:02.409: INFO: Pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:12:02.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9740" for this suite. 11/11/22 23:12:02.426
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":10,"skipped":122,"failed":0}
------------------------------
• [SLOW TEST] [6.439 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:11:56.01
    Nov 11 23:11:56.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:11:56.013
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:11:56.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:11:56.083
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/11/22 23:11:56.103
    Nov 11 23:11:56.143: INFO: Waiting up to 5m0s for pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f" in namespace "emptydir-9740" to be "Succeeded or Failed"
    Nov 11 23:11:56.173: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.003051ms
    Nov 11 23:11:58.195: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05163457s
    Nov 11 23:12:00.194: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050332209s
    Nov 11 23:12:02.194: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050677727s
    STEP: Saw pod success 11/11/22 23:12:02.194
    Nov 11 23:12:02.195: INFO: Pod "pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f" satisfied condition "Succeeded or Failed"
    Nov 11 23:12:02.213: INFO: Trying to get logs from node 10.184.98.55 pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f container test-container: <nil>
    STEP: delete the pod 11/11/22 23:12:02.333
    Nov 11 23:12:02.392: INFO: Waiting for pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f to disappear
    Nov 11 23:12:02.409: INFO: Pod pod-3937e5a9-3e2f-4a09-bd1e-d235dd88660f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:12:02.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9740" for this suite. 11/11/22 23:12:02.426
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:12:02.454
Nov 11 23:12:02.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:12:02.458
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:12:02.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:12:02.527
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 11/11/22 23:12:02.544
Nov 11 23:12:02.582: INFO: Waiting up to 5m0s for pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d" in namespace "downward-api-5722" to be "Succeeded or Failed"
Nov 11 23:12:02.602: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.684346ms
Nov 11 23:12:04.623: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041302802s
Nov 11 23:12:06.626: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044024813s
Nov 11 23:12:08.625: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043430007s
STEP: Saw pod success 11/11/22 23:12:08.625
Nov 11 23:12:08.626: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d" satisfied condition "Succeeded or Failed"
Nov 11 23:12:08.644: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d container dapi-container: <nil>
STEP: delete the pod 11/11/22 23:12:08.686
Nov 11 23:12:08.743: INFO: Waiting for pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d to disappear
Nov 11 23:12:08.763: INFO: Pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 11 23:12:08.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5722" for this suite. 11/11/22 23:12:08.783
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":11,"skipped":142,"failed":0}
------------------------------
• [SLOW TEST] [6.350 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:12:02.454
    Nov 11 23:12:02.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:12:02.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:12:02.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:12:02.527
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 11/11/22 23:12:02.544
    Nov 11 23:12:02.582: INFO: Waiting up to 5m0s for pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d" in namespace "downward-api-5722" to be "Succeeded or Failed"
    Nov 11 23:12:02.602: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.684346ms
    Nov 11 23:12:04.623: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041302802s
    Nov 11 23:12:06.626: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044024813s
    Nov 11 23:12:08.625: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043430007s
    STEP: Saw pod success 11/11/22 23:12:08.625
    Nov 11 23:12:08.626: INFO: Pod "downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d" satisfied condition "Succeeded or Failed"
    Nov 11 23:12:08.644: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d container dapi-container: <nil>
    STEP: delete the pod 11/11/22 23:12:08.686
    Nov 11 23:12:08.743: INFO: Waiting for pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d to disappear
    Nov 11 23:12:08.763: INFO: Pod downward-api-ffb91a42-d827-4b66-bb46-b2e2e2d7b89d no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 11 23:12:08.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5722" for this suite. 11/11/22 23:12:08.783
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:12:08.807
Nov 11 23:12:08.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:12:08.808
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:12:08.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:12:08.891
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4261 11/11/22 23:12:08.908
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-4261 11/11/22 23:12:08.933
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4261 11/11/22 23:12:08.958
Nov 11 23:12:08.980: INFO: Found 0 stateful pods, waiting for 1
Nov 11 23:12:19.000: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/11/22 23:12:19.001
Nov 11 23:12:19.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:12:19.552: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:12:19.552: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:12:19.552: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:12:19.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 11 23:12:29.594: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:12:29.594: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:12:29.674: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Nov 11 23:12:29.674: INFO: ss-0  10.184.98.55  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
Nov 11 23:12:29.674: INFO: ss-1                Pending         []
Nov 11 23:12:29.674: INFO: 
Nov 11 23:12:29.674: INFO: StatefulSet ss has not reached scale 3, at 2
Nov 11 23:12:30.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979054349s
Nov 11 23:12:31.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.922878892s
Nov 11 23:12:32.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.901276654s
Nov 11 23:12:33.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.878626219s
Nov 11 23:12:34.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.855758836s
Nov 11 23:12:35.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.818038267s
Nov 11 23:12:36.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.79872045s
Nov 11 23:12:37.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.776387697s
Nov 11 23:12:38.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 754.714037ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4261 11/11/22 23:12:39.921
Nov 11 23:12:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:12:40.463: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:12:40.463: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:12:40.463: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:12:40.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:12:40.875: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 11 23:12:40.875: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:12:40.875: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:12:40.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:12:41.296: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 11 23:12:41.297: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:12:41.297: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:12:41.320: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov 11 23:12:51.357: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:12:51.357: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:12:51.357: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 11/11/22 23:12:51.357
Nov 11 23:12:51.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:12:51.769: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:12:51.769: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:12:51.769: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:12:51.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:12:52.203: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:12:52.203: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:12:52.203: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:12:52.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:12:52.651: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:12:52.651: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:12:52.651: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:12:52.651: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:12:52.670: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 11 23:13:02.730: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:13:02.730: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:13:02.730: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:13:02.798: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 11 23:13:02.798: INFO: ss-0  10.184.98.55    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
Nov 11 23:13:02.798: INFO: ss-1  10.241.148.26   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
Nov 11 23:13:02.798: INFO: ss-2  10.241.148.113  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
Nov 11 23:13:02.798: INFO: 
Nov 11 23:13:02.798: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 23:13:03.839: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 11 23:13:03.839: INFO: ss-0  10.184.98.55    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
Nov 11 23:13:03.840: INFO: ss-1  10.241.148.26   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
Nov 11 23:13:03.840: INFO: ss-2  10.241.148.113  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
Nov 11 23:13:03.840: INFO: 
Nov 11 23:13:03.840: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 11 23:13:04.868: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.932066226s
Nov 11 23:13:05.888: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.904660287s
Nov 11 23:13:06.940: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.884213127s
Nov 11 23:13:07.976: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.832099844s
Nov 11 23:13:08.998: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.796049899s
Nov 11 23:13:10.021: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.770857546s
Nov 11 23:13:11.041: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.751604329s
Nov 11 23:13:12.064: INFO: Verifying statefulset ss doesn't scale past 0 for another 731.10627ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4261 11/11/22 23:13:13.065
Nov 11 23:13:13.090: INFO: Scaling statefulset ss to 0
Nov 11 23:13:13.153: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 11 23:13:13.171: INFO: Deleting all statefulset in ns statefulset-4261
Nov 11 23:13:13.187: INFO: Scaling statefulset ss to 0
Nov 11 23:13:13.265: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:13:13.284: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 11 23:13:13.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4261" for this suite. 11/11/22 23:13:13.369
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":12,"skipped":150,"failed":0}
------------------------------
• [SLOW TEST] [64.587 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:12:08.807
    Nov 11 23:12:08.807: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:12:08.808
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:12:08.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:12:08.891
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4261 11/11/22 23:12:08.908
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-4261 11/11/22 23:12:08.933
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4261 11/11/22 23:12:08.958
    Nov 11 23:12:08.980: INFO: Found 0 stateful pods, waiting for 1
    Nov 11 23:12:19.000: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/11/22 23:12:19.001
    Nov 11 23:12:19.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:12:19.552: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:12:19.552: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:12:19.552: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:12:19.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 11 23:12:29.594: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:12:29.594: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:12:29.674: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
    Nov 11 23:12:29.674: INFO: ss-0  10.184.98.55  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
    Nov 11 23:12:29.674: INFO: ss-1                Pending         []
    Nov 11 23:12:29.674: INFO: 
    Nov 11 23:12:29.674: INFO: StatefulSet ss has not reached scale 3, at 2
    Nov 11 23:12:30.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979054349s
    Nov 11 23:12:31.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.922878892s
    Nov 11 23:12:32.775: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.901276654s
    Nov 11 23:12:33.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.878626219s
    Nov 11 23:12:34.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.855758836s
    Nov 11 23:12:35.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.818038267s
    Nov 11 23:12:36.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.79872045s
    Nov 11 23:12:37.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.776387697s
    Nov 11 23:12:38.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 754.714037ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4261 11/11/22 23:12:39.921
    Nov 11 23:12:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:12:40.463: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:12:40.463: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:12:40.463: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:12:40.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:12:40.875: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 11 23:12:40.875: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:12:40.875: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:12:40.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:12:41.296: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 11 23:12:41.297: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:12:41.297: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:12:41.320: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Nov 11 23:12:51.357: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:12:51.357: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:12:51.357: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 11/11/22 23:12:51.357
    Nov 11 23:12:51.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:12:51.769: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:12:51.769: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:12:51.769: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:12:51.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:12:52.203: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:12:52.203: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:12:52.203: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:12:52.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-4261 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:12:52.651: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:12:52.651: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:12:52.651: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:12:52.651: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:12:52.670: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Nov 11 23:13:02.730: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:13:02.730: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:13:02.730: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:13:02.798: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Nov 11 23:13:02.798: INFO: ss-0  10.184.98.55    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
    Nov 11 23:13:02.798: INFO: ss-1  10.241.148.26   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
    Nov 11 23:13:02.798: INFO: ss-2  10.241.148.113  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
    Nov 11 23:13:02.798: INFO: 
    Nov 11 23:13:02.798: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov 11 23:13:03.839: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
    Nov 11 23:13:03.839: INFO: ss-0  10.184.98.55    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:08 +0000 UTC  }]
    Nov 11 23:13:03.840: INFO: ss-1  10.241.148.26   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
    Nov 11 23:13:03.840: INFO: ss-2  10.241.148.113  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:12:29 +0000 UTC  }]
    Nov 11 23:13:03.840: INFO: 
    Nov 11 23:13:03.840: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov 11 23:13:04.868: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.932066226s
    Nov 11 23:13:05.888: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.904660287s
    Nov 11 23:13:06.940: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.884213127s
    Nov 11 23:13:07.976: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.832099844s
    Nov 11 23:13:08.998: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.796049899s
    Nov 11 23:13:10.021: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.770857546s
    Nov 11 23:13:11.041: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.751604329s
    Nov 11 23:13:12.064: INFO: Verifying statefulset ss doesn't scale past 0 for another 731.10627ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4261 11/11/22 23:13:13.065
    Nov 11 23:13:13.090: INFO: Scaling statefulset ss to 0
    Nov 11 23:13:13.153: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 11 23:13:13.171: INFO: Deleting all statefulset in ns statefulset-4261
    Nov 11 23:13:13.187: INFO: Scaling statefulset ss to 0
    Nov 11 23:13:13.265: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:13:13.284: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 11 23:13:13.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4261" for this suite. 11/11/22 23:13:13.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:13.403
Nov 11 23:13:13.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:13:13.406
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:13.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:13.48
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:13:13.497
Nov 11 23:13:13.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8" in namespace "projected-676" to be "Succeeded or Failed"
Nov 11 23:13:13.565: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.260244ms
Nov 11 23:13:15.589: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045636646s
Nov 11 23:13:17.588: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044790313s
Nov 11 23:13:19.583: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039853377s
STEP: Saw pod success 11/11/22 23:13:19.583
Nov 11 23:13:19.584: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8" satisfied condition "Succeeded or Failed"
Nov 11 23:13:19.624: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 container client-container: <nil>
STEP: delete the pod 11/11/22 23:13:19.67
Nov 11 23:13:19.752: INFO: Waiting for pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 to disappear
Nov 11 23:13:19.773: INFO: Pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 11 23:13:19.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-676" for this suite. 11/11/22 23:13:19.811
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":13,"skipped":159,"failed":0}
------------------------------
• [SLOW TEST] [6.431 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:13.403
    Nov 11 23:13:13.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:13:13.406
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:13.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:13.48
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:13:13.497
    Nov 11 23:13:13.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8" in namespace "projected-676" to be "Succeeded or Failed"
    Nov 11 23:13:13.565: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.260244ms
    Nov 11 23:13:15.589: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045636646s
    Nov 11 23:13:17.588: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044790313s
    Nov 11 23:13:19.583: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039853377s
    STEP: Saw pod success 11/11/22 23:13:19.583
    Nov 11 23:13:19.584: INFO: Pod "downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8" satisfied condition "Succeeded or Failed"
    Nov 11 23:13:19.624: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:13:19.67
    Nov 11 23:13:19.752: INFO: Waiting for pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 to disappear
    Nov 11 23:13:19.773: INFO: Pod downwardapi-volume-0f1bab4f-74ee-4e93-a07f-361ad722a2b8 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 11 23:13:19.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-676" for this suite. 11/11/22 23:13:19.811
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:19.835
Nov 11 23:13:19.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-lifecycle-hook 11/11/22 23:13:19.84
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:19.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:19.978
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/11/22 23:13:20.02
Nov 11 23:13:20.061: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9466" to be "running and ready"
Nov 11 23:13:20.080: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 18.886366ms
Nov 11 23:13:20.080: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:13:22.101: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039763531s
Nov 11 23:13:22.101: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:13:24.103: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041745784s
Nov 11 23:13:24.103: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:13:26.103: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 6.041469521s
Nov 11 23:13:26.103: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 11 23:13:26.103: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 11/11/22 23:13:26.124
Nov 11 23:13:26.149: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9466" to be "running and ready"
Nov 11 23:13:26.198: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 48.623988ms
Nov 11 23:13:26.198: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:13:28.234: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084546655s
Nov 11 23:13:28.234: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:13:30.220: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.070571349s
Nov 11 23:13:30.220: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Nov 11 23:13:30.220: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/11/22 23:13:30.241
Nov 11 23:13:30.287: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 23:13:30.310: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 23:13:32.310: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 23:13:32.331: INFO: Pod pod-with-prestop-http-hook still exists
Nov 11 23:13:34.311: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 11 23:13:34.344: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 11/11/22 23:13:34.344
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 11 23:13:34.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9466" for this suite. 11/11/22 23:13:34.483
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":14,"skipped":166,"failed":0}
------------------------------
• [SLOW TEST] [14.673 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:19.835
    Nov 11 23:13:19.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/11/22 23:13:19.84
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:19.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:19.978
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/11/22 23:13:20.02
    Nov 11 23:13:20.061: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9466" to be "running and ready"
    Nov 11 23:13:20.080: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 18.886366ms
    Nov 11 23:13:20.080: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:13:22.101: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039763531s
    Nov 11 23:13:22.101: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:13:24.103: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041745784s
    Nov 11 23:13:24.103: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:13:26.103: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 6.041469521s
    Nov 11 23:13:26.103: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 11 23:13:26.103: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 11/11/22 23:13:26.124
    Nov 11 23:13:26.149: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-9466" to be "running and ready"
    Nov 11 23:13:26.198: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 48.623988ms
    Nov 11 23:13:26.198: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:13:28.234: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084546655s
    Nov 11 23:13:28.234: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:13:30.220: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.070571349s
    Nov 11 23:13:30.220: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Nov 11 23:13:30.220: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/11/22 23:13:30.241
    Nov 11 23:13:30.287: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 11 23:13:30.310: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 11 23:13:32.310: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 11 23:13:32.331: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 11 23:13:34.311: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 11 23:13:34.344: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 11/11/22 23:13:34.344
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 11 23:13:34.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9466" for this suite. 11/11/22 23:13:34.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:34.511
Nov 11 23:13:34.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/11/22 23:13:34.515
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:34.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:34.588
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 11/11/22 23:13:34.607
STEP: Getting a ResourceQuota 11/11/22 23:13:34.627
STEP: Listing all ResourceQuotas with LabelSelector 11/11/22 23:13:34.642
STEP: Patching the ResourceQuota 11/11/22 23:13:34.66
STEP: Deleting a Collection of ResourceQuotas 11/11/22 23:13:34.687
STEP: Verifying the deleted ResourceQuota 11/11/22 23:13:34.748
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 11 23:13:34.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7559" for this suite. 11/11/22 23:13:34.793
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":15,"skipped":183,"failed":0}
------------------------------
• [0.303 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:34.511
    Nov 11 23:13:34.511: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/11/22 23:13:34.515
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:34.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:34.588
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 11/11/22 23:13:34.607
    STEP: Getting a ResourceQuota 11/11/22 23:13:34.627
    STEP: Listing all ResourceQuotas with LabelSelector 11/11/22 23:13:34.642
    STEP: Patching the ResourceQuota 11/11/22 23:13:34.66
    STEP: Deleting a Collection of ResourceQuotas 11/11/22 23:13:34.687
    STEP: Verifying the deleted ResourceQuota 11/11/22 23:13:34.748
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 11 23:13:34.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7559" for this suite. 11/11/22 23:13:34.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:34.828
Nov 11 23:13:34.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/11/22 23:13:34.831
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:34.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:34.893
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 11/11/22 23:13:34.911
STEP: Ensuring ResourceQuota status is calculated 11/11/22 23:13:34.935
STEP: Creating a ResourceQuota with not best effort scope 11/11/22 23:13:36.973
STEP: Ensuring ResourceQuota status is calculated 11/11/22 23:13:36.995
STEP: Creating a best-effort pod 11/11/22 23:13:39.014
STEP: Ensuring resource quota with best effort scope captures the pod usage 11/11/22 23:13:39.073
STEP: Ensuring resource quota with not best effort ignored the pod usage 11/11/22 23:13:41.094
STEP: Deleting the pod 11/11/22 23:13:43.114
STEP: Ensuring resource quota status released the pod usage 11/11/22 23:13:43.17
STEP: Creating a not best-effort pod 11/11/22 23:13:45.189
STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/11/22 23:13:45.227
STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/11/22 23:13:47.246
STEP: Deleting the pod 11/11/22 23:13:49.268
STEP: Ensuring resource quota status released the pod usage 11/11/22 23:13:49.315
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 11 23:13:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2156" for this suite. 11/11/22 23:13:51.357
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":16,"skipped":196,"failed":0}
------------------------------
• [SLOW TEST] [16.605 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:34.828
    Nov 11 23:13:34.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/11/22 23:13:34.831
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:34.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:34.893
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 11/11/22 23:13:34.911
    STEP: Ensuring ResourceQuota status is calculated 11/11/22 23:13:34.935
    STEP: Creating a ResourceQuota with not best effort scope 11/11/22 23:13:36.973
    STEP: Ensuring ResourceQuota status is calculated 11/11/22 23:13:36.995
    STEP: Creating a best-effort pod 11/11/22 23:13:39.014
    STEP: Ensuring resource quota with best effort scope captures the pod usage 11/11/22 23:13:39.073
    STEP: Ensuring resource quota with not best effort ignored the pod usage 11/11/22 23:13:41.094
    STEP: Deleting the pod 11/11/22 23:13:43.114
    STEP: Ensuring resource quota status released the pod usage 11/11/22 23:13:43.17
    STEP: Creating a not best-effort pod 11/11/22 23:13:45.189
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/11/22 23:13:45.227
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/11/22 23:13:47.246
    STEP: Deleting the pod 11/11/22 23:13:49.268
    STEP: Ensuring resource quota status released the pod usage 11/11/22 23:13:49.315
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 11 23:13:51.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2156" for this suite. 11/11/22 23:13:51.357
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:51.436
Nov 11 23:13:51.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:13:51.438
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:51.491
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:51.511
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-f96a2618-6431-403d-9aeb-acbf72ee69e4 11/11/22 23:13:51.532
STEP: Creating a pod to test consume configMaps 11/11/22 23:13:51.55
Nov 11 23:13:51.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d" in namespace "configmap-4580" to be "Succeeded or Failed"
Nov 11 23:13:51.606: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.700484ms
Nov 11 23:13:53.628: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04226443s
Nov 11 23:13:55.629: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043906162s
Nov 11 23:13:57.628: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04256501s
STEP: Saw pod success 11/11/22 23:13:57.628
Nov 11 23:13:57.629: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d" satisfied condition "Succeeded or Failed"
Nov 11 23:13:57.649: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d container configmap-volume-test: <nil>
STEP: delete the pod 11/11/22 23:13:57.689
Nov 11 23:13:57.747: INFO: Waiting for pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d to disappear
Nov 11 23:13:57.767: INFO: Pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:13:57.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4580" for this suite. 11/11/22 23:13:57.794
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":17,"skipped":204,"failed":0}
------------------------------
• [SLOW TEST] [6.382 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:51.436
    Nov 11 23:13:51.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:13:51.438
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:51.491
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:51.511
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-f96a2618-6431-403d-9aeb-acbf72ee69e4 11/11/22 23:13:51.532
    STEP: Creating a pod to test consume configMaps 11/11/22 23:13:51.55
    Nov 11 23:13:51.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d" in namespace "configmap-4580" to be "Succeeded or Failed"
    Nov 11 23:13:51.606: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.700484ms
    Nov 11 23:13:53.628: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04226443s
    Nov 11 23:13:55.629: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043906162s
    Nov 11 23:13:57.628: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04256501s
    STEP: Saw pod success 11/11/22 23:13:57.628
    Nov 11 23:13:57.629: INFO: Pod "pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d" satisfied condition "Succeeded or Failed"
    Nov 11 23:13:57.649: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d container configmap-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:13:57.689
    Nov 11 23:13:57.747: INFO: Waiting for pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d to disappear
    Nov 11 23:13:57.767: INFO: Pod pod-configmaps-4dc39cc0-9e49-4768-bfe1-32ce2f7c749d no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:13:57.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4580" for this suite. 11/11/22 23:13:57.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:57.821
Nov 11 23:13:57.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/11/22 23:13:57.825
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:57.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:57.902
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 11/11/22 23:13:57.927
STEP: submitting the pod to kubernetes 11/11/22 23:13:57.928
STEP: verifying QOS class is set on the pod 11/11/22 23:13:57.966
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Nov 11 23:13:57.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8487" for this suite. 11/11/22 23:13:58.008
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":18,"skipped":212,"failed":0}
------------------------------
• [0.212 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:57.821
    Nov 11 23:13:57.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/11/22 23:13:57.825
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:57.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:57.902
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 11/11/22 23:13:57.927
    STEP: submitting the pod to kubernetes 11/11/22 23:13:57.928
    STEP: verifying QOS class is set on the pod 11/11/22 23:13:57.966
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Nov 11 23:13:57.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8487" for this suite. 11/11/22 23:13:58.008
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:58.035
Nov 11 23:13:58.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename namespaces 11/11/22 23:13:58.036
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:58.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:58.099
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 11/11/22 23:13:58.114
Nov 11 23:13:58.132: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 11/11/22 23:13:58.132
Nov 11 23:13:58.152: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 11/11/22 23:13:58.152
Nov 11 23:13:58.206: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:13:58.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5213" for this suite. 11/11/22 23:13:58.229
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":19,"skipped":224,"failed":0}
------------------------------
• [0.221 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:58.035
    Nov 11 23:13:58.035: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename namespaces 11/11/22 23:13:58.036
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:58.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:58.099
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 11/11/22 23:13:58.114
    Nov 11 23:13:58.132: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 11/11/22 23:13:58.132
    Nov 11 23:13:58.152: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 11/11/22 23:13:58.152
    Nov 11 23:13:58.206: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:13:58.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-5213" for this suite. 11/11/22 23:13:58.229
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:13:58.26
Nov 11 23:13:58.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/11/22 23:13:58.262
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:58.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:58.33
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 11/11/22 23:13:58.351
STEP: Verify that the required pods have come up 11/11/22 23:13:58.376
Nov 11 23:13:58.396: INFO: Pod name sample-pod: Found 0 pods out of 3
Nov 11 23:14:03.422: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 11/11/22 23:14:03.422
Nov 11 23:14:03.442: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 11/11/22 23:14:03.442
STEP: DeleteCollection of the ReplicaSets 11/11/22 23:14:03.472
STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/11/22 23:14:03.517
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 11 23:14:03.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-46" for this suite. 11/11/22 23:14:03.574
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":20,"skipped":241,"failed":0}
------------------------------
• [SLOW TEST] [5.345 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:13:58.26
    Nov 11 23:13:58.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/11/22 23:13:58.262
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:13:58.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:13:58.33
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 11/11/22 23:13:58.351
    STEP: Verify that the required pods have come up 11/11/22 23:13:58.376
    Nov 11 23:13:58.396: INFO: Pod name sample-pod: Found 0 pods out of 3
    Nov 11 23:14:03.422: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 11/11/22 23:14:03.422
    Nov 11 23:14:03.442: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 11/11/22 23:14:03.442
    STEP: DeleteCollection of the ReplicaSets 11/11/22 23:14:03.472
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/11/22 23:14:03.517
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 11 23:14:03.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-46" for this suite. 11/11/22 23:14:03.574
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:03.619
Nov 11 23:14:03.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replication-controller 11/11/22 23:14:03.625
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:03.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:03.702
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a 11/11/22 23:14:03.719
Nov 11 23:14:03.765: INFO: Pod name my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Found 0 pods out of 1
Nov 11 23:14:08.789: INFO: Pod name my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Found 1 pods out of 1
Nov 11 23:14:08.789: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a" are running
Nov 11 23:14:08.789: INFO: Waiting up to 5m0s for pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" in namespace "replication-controller-636" to be "running"
Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9": Phase="Running", Reason="", readiness=true. Elapsed: 20.606769ms
Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" satisfied condition "running"
Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:03 +0000 UTC Reason: Message:}])
Nov 11 23:14:08.810: INFO: Trying to dial the pod
Nov 11 23:14:13.926: INFO: Controller my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Got expected result from replica 1 [my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9]: "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 11 23:14:13.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-636" for this suite. 11/11/22 23:14:13.952
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":21,"skipped":257,"failed":0}
------------------------------
• [SLOW TEST] [10.359 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:03.619
    Nov 11 23:14:03.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replication-controller 11/11/22 23:14:03.625
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:03.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:03.702
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a 11/11/22 23:14:03.719
    Nov 11 23:14:03.765: INFO: Pod name my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Found 0 pods out of 1
    Nov 11 23:14:08.789: INFO: Pod name my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Found 1 pods out of 1
    Nov 11 23:14:08.789: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a" are running
    Nov 11 23:14:08.789: INFO: Waiting up to 5m0s for pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" in namespace "replication-controller-636" to be "running"
    Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9": Phase="Running", Reason="", readiness=true. Elapsed: 20.606769ms
    Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" satisfied condition "running"
    Nov 11 23:14:08.809: INFO: Pod "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:14:03 +0000 UTC Reason: Message:}])
    Nov 11 23:14:08.810: INFO: Trying to dial the pod
    Nov 11 23:14:13.926: INFO: Controller my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a: Got expected result from replica 1 [my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9]: "my-hostname-basic-7785d642-48d1-4d3d-8728-689784cd659a-94vl9", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 11 23:14:13.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-636" for this suite. 11/11/22 23:14:13.952
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:13.979
Nov 11 23:14:13.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename podtemplate 11/11/22 23:14:13.981
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.056
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 11/11/22 23:14:14.075
Nov 11 23:14:14.098: INFO: created test-podtemplate-1
Nov 11 23:14:14.122: INFO: created test-podtemplate-2
Nov 11 23:14:14.140: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 11/11/22 23:14:14.14
STEP: delete collection of pod templates 11/11/22 23:14:14.16
Nov 11 23:14:14.160: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 11/11/22 23:14:14.231
Nov 11 23:14:14.232: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 11 23:14:14.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3614" for this suite. 11/11/22 23:14:14.273
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":22,"skipped":257,"failed":0}
------------------------------
• [0.317 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:13.979
    Nov 11 23:14:13.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename podtemplate 11/11/22 23:14:13.981
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.056
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 11/11/22 23:14:14.075
    Nov 11 23:14:14.098: INFO: created test-podtemplate-1
    Nov 11 23:14:14.122: INFO: created test-podtemplate-2
    Nov 11 23:14:14.140: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 11/11/22 23:14:14.14
    STEP: delete collection of pod templates 11/11/22 23:14:14.16
    Nov 11 23:14:14.160: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 11/11/22 23:14:14.231
    Nov 11 23:14:14.232: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 11 23:14:14.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-3614" for this suite. 11/11/22 23:14:14.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:14.299
Nov 11 23:14:14.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename cronjob 11/11/22 23:14:14.301
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.378
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 11/11/22 23:14:14.396
STEP: creating 11/11/22 23:14:14.396
STEP: getting 11/11/22 23:14:14.42
STEP: listing 11/11/22 23:14:14.435
STEP: watching 11/11/22 23:14:14.452
Nov 11 23:14:14.452: INFO: starting watch
STEP: cluster-wide listing 11/11/22 23:14:14.461
STEP: cluster-wide watching 11/11/22 23:14:14.477
Nov 11 23:14:14.478: INFO: starting watch
STEP: patching 11/11/22 23:14:14.487
STEP: updating 11/11/22 23:14:14.512
Nov 11 23:14:14.549: INFO: waiting for watch events with expected annotations
Nov 11 23:14:14.549: INFO: saw patched and updated annotations
STEP: patching /status 11/11/22 23:14:14.549
STEP: updating /status 11/11/22 23:14:14.572
STEP: get /status 11/11/22 23:14:14.608
STEP: deleting 11/11/22 23:14:14.624
STEP: deleting a collection 11/11/22 23:14:14.688
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 11 23:14:14.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2904" for this suite. 11/11/22 23:14:14.758
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":23,"skipped":267,"failed":0}
------------------------------
• [0.484 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:14.299
    Nov 11 23:14:14.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename cronjob 11/11/22 23:14:14.301
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.378
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 11/11/22 23:14:14.396
    STEP: creating 11/11/22 23:14:14.396
    STEP: getting 11/11/22 23:14:14.42
    STEP: listing 11/11/22 23:14:14.435
    STEP: watching 11/11/22 23:14:14.452
    Nov 11 23:14:14.452: INFO: starting watch
    STEP: cluster-wide listing 11/11/22 23:14:14.461
    STEP: cluster-wide watching 11/11/22 23:14:14.477
    Nov 11 23:14:14.478: INFO: starting watch
    STEP: patching 11/11/22 23:14:14.487
    STEP: updating 11/11/22 23:14:14.512
    Nov 11 23:14:14.549: INFO: waiting for watch events with expected annotations
    Nov 11 23:14:14.549: INFO: saw patched and updated annotations
    STEP: patching /status 11/11/22 23:14:14.549
    STEP: updating /status 11/11/22 23:14:14.572
    STEP: get /status 11/11/22 23:14:14.608
    STEP: deleting 11/11/22 23:14:14.624
    STEP: deleting a collection 11/11/22 23:14:14.688
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 11 23:14:14.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2904" for this suite. 11/11/22 23:14:14.758
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:14.784
Nov 11 23:14:14.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/11/22 23:14:14.785
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.855
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Nov 11 23:14:14.983: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5baa4c3e-29ea-4ed4-b695-67b05de26a2e", Controller:(*bool)(0xc005125826), BlockOwnerDeletion:(*bool)(0xc005125827)}}
Nov 11 23:14:15.012: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dad75a99-780e-4ec1-a7e6-519a392a51a6", Controller:(*bool)(0xc005125ad6), BlockOwnerDeletion:(*bool)(0xc005125ad7)}}
Nov 11 23:14:15.040: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b196bbce-c03e-4541-b2cc-85b4d5f8a4a1", Controller:(*bool)(0xc005125dae), BlockOwnerDeletion:(*bool)(0xc005125daf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 11 23:14:20.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7484" for this suite. 11/11/22 23:14:20.122
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":24,"skipped":268,"failed":0}
------------------------------
• [SLOW TEST] [5.366 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:14.784
    Nov 11 23:14:14.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/11/22 23:14:14.785
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:14.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:14.855
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Nov 11 23:14:14.983: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5baa4c3e-29ea-4ed4-b695-67b05de26a2e", Controller:(*bool)(0xc005125826), BlockOwnerDeletion:(*bool)(0xc005125827)}}
    Nov 11 23:14:15.012: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dad75a99-780e-4ec1-a7e6-519a392a51a6", Controller:(*bool)(0xc005125ad6), BlockOwnerDeletion:(*bool)(0xc005125ad7)}}
    Nov 11 23:14:15.040: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b196bbce-c03e-4541-b2cc-85b4d5f8a4a1", Controller:(*bool)(0xc005125dae), BlockOwnerDeletion:(*bool)(0xc005125daf)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 11 23:14:20.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7484" for this suite. 11/11/22 23:14:20.122
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:20.153
Nov 11 23:14:20.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename watch 11/11/22 23:14:20.158
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:20.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:20.232
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 11/11/22 23:14:20.25
STEP: creating a watch on configmaps with label B 11/11/22 23:14:20.26
STEP: creating a watch on configmaps with label A or B 11/11/22 23:14:20.268
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.277
Nov 11 23:14:20.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19732 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:20.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19732 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.297
Nov 11 23:14:20.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19733 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:20.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19733 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/11/22 23:14:20.334
Nov 11 23:14:20.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19734 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:20.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19734 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.374
Nov 11 23:14:20.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19735 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:20.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19735 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/11/22 23:14:20.401
Nov 11 23:14:20.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19736 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:20.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19736 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/11/22 23:14:30.426
Nov 11 23:14:30.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19759 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:14:30.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19759 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 11 23:14:40.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3974" for this suite. 11/11/22 23:14:40.498
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":25,"skipped":271,"failed":0}
------------------------------
• [SLOW TEST] [20.370 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:20.153
    Nov 11 23:14:20.154: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename watch 11/11/22 23:14:20.158
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:20.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:20.232
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 11/11/22 23:14:20.25
    STEP: creating a watch on configmaps with label B 11/11/22 23:14:20.26
    STEP: creating a watch on configmaps with label A or B 11/11/22 23:14:20.268
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.277
    Nov 11 23:14:20.296: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19732 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:20.297: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19732 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.297
    Nov 11 23:14:20.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19733 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:20.333: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19733 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/11/22 23:14:20.334
    Nov 11 23:14:20.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19734 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:20.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19734 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/11/22 23:14:20.374
    Nov 11 23:14:20.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19735 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:20.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3974  254e95f6-f3e5-4a9c-942e-437b1dbc8a87 19735 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/11/22 23:14:20.401
    Nov 11 23:14:20.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19736 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:20.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19736 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/11/22 23:14:30.426
    Nov 11 23:14:30.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19759 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:14:30.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3974  5c6e3213-3e82-4c21-a921-916393fc2d82 19759 0 2022-11-11 23:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-11 23:14:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 11 23:14:40.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3974" for this suite. 11/11/22 23:14:40.498
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:40.534
Nov 11 23:14:40.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/11/22 23:14:40.537
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:40.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:40.606
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 11/11/22 23:14:40.623
Nov 11 23:14:40.662: INFO: Waiting up to 5m0s for pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6" in namespace "var-expansion-4119" to be "Succeeded or Failed"
Nov 11 23:14:40.682: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.95052ms
Nov 11 23:14:42.703: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040293736s
Nov 11 23:14:44.701: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038566082s
STEP: Saw pod success 11/11/22 23:14:44.701
Nov 11 23:14:44.701: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6" satisfied condition "Succeeded or Failed"
Nov 11 23:14:44.720: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 container dapi-container: <nil>
STEP: delete the pod 11/11/22 23:14:44.759
Nov 11 23:14:44.804: INFO: Waiting for pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 to disappear
Nov 11 23:14:44.823: INFO: Pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 11 23:14:44.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4119" for this suite. 11/11/22 23:14:44.844
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":26,"skipped":283,"failed":0}
------------------------------
• [4.334 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:40.534
    Nov 11 23:14:40.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/11/22 23:14:40.537
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:40.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:40.606
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 11/11/22 23:14:40.623
    Nov 11 23:14:40.662: INFO: Waiting up to 5m0s for pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6" in namespace "var-expansion-4119" to be "Succeeded or Failed"
    Nov 11 23:14:40.682: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.95052ms
    Nov 11 23:14:42.703: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040293736s
    Nov 11 23:14:44.701: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038566082s
    STEP: Saw pod success 11/11/22 23:14:44.701
    Nov 11 23:14:44.701: INFO: Pod "var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6" satisfied condition "Succeeded or Failed"
    Nov 11 23:14:44.720: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 container dapi-container: <nil>
    STEP: delete the pod 11/11/22 23:14:44.759
    Nov 11 23:14:44.804: INFO: Waiting for pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 to disappear
    Nov 11 23:14:44.823: INFO: Pod var-expansion-f08be1a5-b943-4eaf-b2de-5c5a7ef79bb6 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 11 23:14:44.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4119" for this suite. 11/11/22 23:14:44.844
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:44.868
Nov 11 23:14:44.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:14:44.87
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:44.922
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:44.94
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:14:44.956
Nov 11 23:14:44.995: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb" in namespace "projected-2524" to be "Succeeded or Failed"
Nov 11 23:14:45.016: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.859173ms
Nov 11 23:14:47.037: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042018673s
Nov 11 23:14:49.039: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043839731s
Nov 11 23:14:51.040: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044134633s
STEP: Saw pod success 11/11/22 23:14:51.04
Nov 11 23:14:51.041: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb" satisfied condition "Succeeded or Failed"
Nov 11 23:14:51.060: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb container client-container: <nil>
STEP: delete the pod 11/11/22 23:14:51.107
Nov 11 23:14:51.170: INFO: Waiting for pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb to disappear
Nov 11 23:14:51.194: INFO: Pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 11 23:14:51.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2524" for this suite. 11/11/22 23:14:51.218
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":27,"skipped":283,"failed":0}
------------------------------
• [SLOW TEST] [6.375 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:44.868
    Nov 11 23:14:44.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:14:44.87
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:44.922
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:44.94
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:14:44.956
    Nov 11 23:14:44.995: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb" in namespace "projected-2524" to be "Succeeded or Failed"
    Nov 11 23:14:45.016: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.859173ms
    Nov 11 23:14:47.037: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042018673s
    Nov 11 23:14:49.039: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043839731s
    Nov 11 23:14:51.040: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044134633s
    STEP: Saw pod success 11/11/22 23:14:51.04
    Nov 11 23:14:51.041: INFO: Pod "downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb" satisfied condition "Succeeded or Failed"
    Nov 11 23:14:51.060: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb container client-container: <nil>
    STEP: delete the pod 11/11/22 23:14:51.107
    Nov 11 23:14:51.170: INFO: Waiting for pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb to disappear
    Nov 11 23:14:51.194: INFO: Pod downwardapi-volume-08d25706-f641-4a77-acfd-b8e0f29153bb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 11 23:14:51.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2524" for this suite. 11/11/22 23:14:51.218
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:51.245
Nov 11 23:14:51.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:14:51.247
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:51.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:51.32
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:14:51.391
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:14:52.411
STEP: Deploying the webhook pod 11/11/22 23:14:52.447
STEP: Wait for the deployment to be ready 11/11/22 23:14:52.494
Nov 11 23:14:52.539: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:14:54.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:14:56.618
STEP: Verifying the service has paired with the endpoint 11/11/22 23:14:56.653
Nov 11 23:14:57.654: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/11/22 23:14:57.669
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/11/22 23:14:57.812
STEP: Creating a dummy validating-webhook-configuration object 11/11/22 23:14:57.904
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/11/22 23:14:57.945
STEP: Creating a dummy mutating-webhook-configuration object 11/11/22 23:14:57.976
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/11/22 23:14:58.03
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:14:58.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-689" for this suite. 11/11/22 23:14:58.144
STEP: Destroying namespace "webhook-689-markers" for this suite. 11/11/22 23:14:58.17
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":28,"skipped":284,"failed":0}
------------------------------
• [SLOW TEST] [7.103 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:51.245
    Nov 11 23:14:51.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:14:51.247
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:51.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:51.32
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:14:51.391
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:14:52.411
    STEP: Deploying the webhook pod 11/11/22 23:14:52.447
    STEP: Wait for the deployment to be ready 11/11/22 23:14:52.494
    Nov 11 23:14:52.539: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:14:54.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 14, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:14:56.618
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:14:56.653
    Nov 11 23:14:57.654: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/11/22 23:14:57.669
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/11/22 23:14:57.812
    STEP: Creating a dummy validating-webhook-configuration object 11/11/22 23:14:57.904
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/11/22 23:14:57.945
    STEP: Creating a dummy mutating-webhook-configuration object 11/11/22 23:14:57.976
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/11/22 23:14:58.03
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:14:58.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-689" for this suite. 11/11/22 23:14:58.144
    STEP: Destroying namespace "webhook-689-markers" for this suite. 11/11/22 23:14:58.17
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:14:58.359
Nov 11 23:14:58.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:14:58.362
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:58.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:58.443
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-076add7e-11bb-4e86-ada0-2b9c1f37a50d 11/11/22 23:14:58.46
STEP: Creating a pod to test consume secrets 11/11/22 23:14:58.491
Nov 11 23:14:58.532: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b" in namespace "projected-9122" to be "Succeeded or Failed"
Nov 11 23:14:58.551: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.409026ms
Nov 11 23:15:00.572: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038691348s
Nov 11 23:15:02.574: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040847264s
Nov 11 23:15:04.569: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036428115s
STEP: Saw pod success 11/11/22 23:15:04.569
Nov 11 23:15:04.570: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b" satisfied condition "Succeeded or Failed"
Nov 11 23:15:04.589: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b container projected-secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:15:04.628
Nov 11 23:15:04.690: INFO: Waiting for pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b to disappear
Nov 11 23:15:04.709: INFO: Pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 11 23:15:04.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9122" for this suite. 11/11/22 23:15:04.732
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":29,"skipped":291,"failed":0}
------------------------------
• [SLOW TEST] [6.397 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:14:58.359
    Nov 11 23:14:58.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:14:58.362
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:14:58.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:14:58.443
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-076add7e-11bb-4e86-ada0-2b9c1f37a50d 11/11/22 23:14:58.46
    STEP: Creating a pod to test consume secrets 11/11/22 23:14:58.491
    Nov 11 23:14:58.532: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b" in namespace "projected-9122" to be "Succeeded or Failed"
    Nov 11 23:14:58.551: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.409026ms
    Nov 11 23:15:00.572: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038691348s
    Nov 11 23:15:02.574: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040847264s
    Nov 11 23:15:04.569: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036428115s
    STEP: Saw pod success 11/11/22 23:15:04.569
    Nov 11 23:15:04.570: INFO: Pod "pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b" satisfied condition "Succeeded or Failed"
    Nov 11 23:15:04.589: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:15:04.628
    Nov 11 23:15:04.690: INFO: Waiting for pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b to disappear
    Nov 11 23:15:04.709: INFO: Pod pod-projected-secrets-2a9844d9-75d2-438c-ab45-c31b99f4584b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 11 23:15:04.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9122" for this suite. 11/11/22 23:15:04.732
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:15:04.76
Nov 11 23:15:04.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:15:04.764
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:15:04.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:15:04.851
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-7105 11/11/22 23:15:04.866
STEP: creating service affinity-nodeport-transition in namespace services-7105 11/11/22 23:15:04.867
STEP: creating replication controller affinity-nodeport-transition in namespace services-7105 11/11/22 23:15:04.923
I1111 23:15:04.948651      21 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-7105, replica count: 3
I1111 23:15:08.000263      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 23:15:11.000952      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:15:11.066: INFO: Creating new exec pod
Nov 11 23:15:11.106: INFO: Waiting up to 5m0s for pod "execpod-affinitykzpcs" in namespace "services-7105" to be "running"
Nov 11 23:15:11.127: INFO: Pod "execpod-affinitykzpcs": Phase="Pending", Reason="", readiness=false. Elapsed: 20.685396ms
Nov 11 23:15:13.149: INFO: Pod "execpod-affinitykzpcs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0420581s
Nov 11 23:15:15.148: INFO: Pod "execpod-affinitykzpcs": Phase="Running", Reason="", readiness=true. Elapsed: 4.04130528s
Nov 11 23:15:15.148: INFO: Pod "execpod-affinitykzpcs" satisfied condition "running"
Nov 11 23:15:16.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Nov 11 23:15:16.611: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Nov 11 23:15:16.611: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:15:16.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.122.188 80'
Nov 11 23:15:17.120: INFO: stderr: "+ nc -v -t -w 2 172.21.122.188 80\n+ echo hostName\nConnection to 172.21.122.188 80 port [tcp/http] succeeded!\n"
Nov 11 23:15:17.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:15:17.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32274'
Nov 11 23:15:17.523: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32274\nConnection to 10.241.148.26 32274 port [tcp/*] succeeded!\n"
Nov 11 23:15:17.523: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:15:17.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32274'
Nov 11 23:15:17.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 32274\nConnection to 10.241.148.113 32274 port [tcp/*] succeeded!\n"
Nov 11 23:15:17.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:15:18.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
Nov 11 23:15:18.672: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
Nov 11 23:15:18.672: INFO: stdout: "\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64"
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:18.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
Nov 11 23:15:19.422: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
Nov 11 23:15:19.423: INFO: stdout: "\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64"
Nov 11 23:15:19.423: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:19.423: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.427: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-69qjg
Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-cxw64
Nov 11 23:15:49.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
Nov 11 23:15:50.060: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
Nov 11 23:15:50.060: INFO: stdout: "\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt"
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
Nov 11 23:15:50.060: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7105, will wait for the garbage collector to delete the pods 11/11/22 23:15:50.144
Nov 11 23:15:50.244: INFO: Deleting ReplicationController affinity-nodeport-transition took: 29.891382ms
Nov 11 23:15:50.445: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 200.432798ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:15:53.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7105" for this suite. 11/11/22 23:15:53.351
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":30,"skipped":292,"failed":0}
------------------------------
• [SLOW TEST] [48.619 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:15:04.76
    Nov 11 23:15:04.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:15:04.764
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:15:04.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:15:04.851
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-7105 11/11/22 23:15:04.866
    STEP: creating service affinity-nodeport-transition in namespace services-7105 11/11/22 23:15:04.867
    STEP: creating replication controller affinity-nodeport-transition in namespace services-7105 11/11/22 23:15:04.923
    I1111 23:15:04.948651      21 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-7105, replica count: 3
    I1111 23:15:08.000263      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1111 23:15:11.000952      21 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:15:11.066: INFO: Creating new exec pod
    Nov 11 23:15:11.106: INFO: Waiting up to 5m0s for pod "execpod-affinitykzpcs" in namespace "services-7105" to be "running"
    Nov 11 23:15:11.127: INFO: Pod "execpod-affinitykzpcs": Phase="Pending", Reason="", readiness=false. Elapsed: 20.685396ms
    Nov 11 23:15:13.149: INFO: Pod "execpod-affinitykzpcs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0420581s
    Nov 11 23:15:15.148: INFO: Pod "execpod-affinitykzpcs": Phase="Running", Reason="", readiness=true. Elapsed: 4.04130528s
    Nov 11 23:15:15.148: INFO: Pod "execpod-affinitykzpcs" satisfied condition "running"
    Nov 11 23:15:16.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Nov 11 23:15:16.611: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Nov 11 23:15:16.611: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:15:16.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.122.188 80'
    Nov 11 23:15:17.120: INFO: stderr: "+ nc -v -t -w 2 172.21.122.188 80\n+ echo hostName\nConnection to 172.21.122.188 80 port [tcp/http] succeeded!\n"
    Nov 11 23:15:17.120: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:15:17.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32274'
    Nov 11 23:15:17.523: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32274\nConnection to 10.241.148.26 32274 port [tcp/*] succeeded!\n"
    Nov 11 23:15:17.523: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:15:17.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32274'
    Nov 11 23:15:17.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 32274\nConnection to 10.241.148.113 32274 port [tcp/*] succeeded!\n"
    Nov 11 23:15:17.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:15:18.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
    Nov 11 23:15:18.672: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
    Nov 11 23:15:18.672: INFO: stdout: "\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64"
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:18.672: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:18.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
    Nov 11 23:15:19.422: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
    Nov 11 23:15:19.423: INFO: stdout: "\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-cxw64\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-69qjg\naffinity-nodeport-transition-cxw64"
    Nov 11 23:15:19.423: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:19.423: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.424: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:19.426: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.427: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-69qjg
    Nov 11 23:15:19.428: INFO: Received response from host: affinity-nodeport-transition-cxw64
    Nov 11 23:15:49.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-7105 exec execpod-affinitykzpcs -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32274/ ; done'
    Nov 11 23:15:50.060: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32274/\n"
    Nov 11 23:15:50.060: INFO: stdout: "\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt\naffinity-nodeport-transition-5rpdt"
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Received response from host: affinity-nodeport-transition-5rpdt
    Nov 11 23:15:50.060: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-7105, will wait for the garbage collector to delete the pods 11/11/22 23:15:50.144
    Nov 11 23:15:50.244: INFO: Deleting ReplicationController affinity-nodeport-transition took: 29.891382ms
    Nov 11 23:15:50.445: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 200.432798ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:15:53.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7105" for this suite. 11/11/22 23:15:53.351
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:15:53.387
Nov 11 23:15:53.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/11/22 23:15:53.391
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:15:53.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:15:53.466
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 11/11/22 23:15:53.577
STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:15:53.609
Nov 11 23:15:53.651: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:15:53.651: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:15:54.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:15:54.691: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:15:55.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 11 23:15:55.695: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:15:56.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:15:56.696: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 11/11/22 23:15:56.712
Nov 11 23:15:56.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:15:56.815: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:15:57.870: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:15:57.871: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:15:58.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:15:58.872: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:15:59.862: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:15:59.862: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:16:00.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:16:00.855: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:16:00.869
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8745, will wait for the garbage collector to delete the pods 11/11/22 23:16:00.869
Nov 11 23:16:00.965: INFO: Deleting DaemonSet.extensions daemon-set took: 30.635549ms
Nov 11 23:16:01.066: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.95276ms
Nov 11 23:16:03.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:16:03.885: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 11 23:16:03.932: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20288"},"items":null}

Nov 11 23:16:03.951: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20288"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:16:04.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8745" for this suite. 11/11/22 23:16:04.046
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":31,"skipped":333,"failed":0}
------------------------------
• [SLOW TEST] [10.699 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:15:53.387
    Nov 11 23:15:53.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/11/22 23:15:53.391
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:15:53.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:15:53.466
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 11/11/22 23:15:53.577
    STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:15:53.609
    Nov 11 23:15:53.651: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:15:53.651: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:15:54.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:15:54.691: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:15:55.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 11 23:15:55.695: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:15:56.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:15:56.696: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 11/11/22 23:15:56.712
    Nov 11 23:15:56.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:15:56.815: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:15:57.870: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:15:57.871: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:15:58.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:15:58.872: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:15:59.862: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:15:59.862: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:16:00.855: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:16:00.855: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:16:00.869
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8745, will wait for the garbage collector to delete the pods 11/11/22 23:16:00.869
    Nov 11 23:16:00.965: INFO: Deleting DaemonSet.extensions daemon-set took: 30.635549ms
    Nov 11 23:16:01.066: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.95276ms
    Nov 11 23:16:03.885: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:16:03.885: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 11 23:16:03.932: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20288"},"items":null}

    Nov 11 23:16:03.951: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20288"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:16:04.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8745" for this suite. 11/11/22 23:16:04.046
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:04.1
Nov 11 23:16:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:16:04.102
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:04.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:04.19
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Nov 11 23:16:04.292: INFO: created pod pod-service-account-defaultsa
Nov 11 23:16:04.292: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 11 23:16:04.315: INFO: created pod pod-service-account-mountsa
Nov 11 23:16:04.315: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 11 23:16:04.337: INFO: created pod pod-service-account-nomountsa
Nov 11 23:16:04.337: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 11 23:16:04.367: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 11 23:16:04.367: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 11 23:16:04.392: INFO: created pod pod-service-account-mountsa-mountspec
Nov 11 23:16:04.392: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 11 23:16:04.431: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 11 23:16:04.431: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 11 23:16:04.456: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 11 23:16:04.456: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 11 23:16:04.481: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 11 23:16:04.481: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 11 23:16:04.505: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 11 23:16:04.505: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:16:04.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4543" for this suite. 11/11/22 23:16:04.532
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":32,"skipped":417,"failed":0}
------------------------------
• [0.458 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:04.1
    Nov 11 23:16:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:16:04.102
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:04.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:04.19
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Nov 11 23:16:04.292: INFO: created pod pod-service-account-defaultsa
    Nov 11 23:16:04.292: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Nov 11 23:16:04.315: INFO: created pod pod-service-account-mountsa
    Nov 11 23:16:04.315: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Nov 11 23:16:04.337: INFO: created pod pod-service-account-nomountsa
    Nov 11 23:16:04.337: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Nov 11 23:16:04.367: INFO: created pod pod-service-account-defaultsa-mountspec
    Nov 11 23:16:04.367: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Nov 11 23:16:04.392: INFO: created pod pod-service-account-mountsa-mountspec
    Nov 11 23:16:04.392: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Nov 11 23:16:04.431: INFO: created pod pod-service-account-nomountsa-mountspec
    Nov 11 23:16:04.431: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Nov 11 23:16:04.456: INFO: created pod pod-service-account-defaultsa-nomountspec
    Nov 11 23:16:04.456: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Nov 11 23:16:04.481: INFO: created pod pod-service-account-mountsa-nomountspec
    Nov 11 23:16:04.481: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Nov 11 23:16:04.505: INFO: created pod pod-service-account-nomountsa-nomountspec
    Nov 11 23:16:04.505: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:16:04.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4543" for this suite. 11/11/22 23:16:04.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:04.56
Nov 11 23:16:04.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:16:04.565
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:04.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:04.641
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Nov 11 23:16:04.731: INFO: Waiting up to 5m0s for pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed" in namespace "svcaccounts-1984" to be "running"
Nov 11 23:16:04.749: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Pending", Reason="", readiness=false. Elapsed: 17.503869ms
Nov 11 23:16:06.771: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039309482s
Nov 11 23:16:08.773: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.041367125s
Nov 11 23:16:08.773: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed" satisfied condition "running"
STEP: reading a file in the container 11/11/22 23:16:08.773
Nov 11 23:16:08.774: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 11/11/22 23:16:09.225
Nov 11 23:16:09.225: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 11/11/22 23:16:09.645
Nov 11 23:16:09.645: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Nov 11 23:16:10.078: INFO: Got root ca configmap in namespace "svcaccounts-1984"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:16:10.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1984" for this suite. 11/11/22 23:16:10.123
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":33,"skipped":426,"failed":0}
------------------------------
• [SLOW TEST] [5.588 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:04.56
    Nov 11 23:16:04.560: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:16:04.565
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:04.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:04.641
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Nov 11 23:16:04.731: INFO: Waiting up to 5m0s for pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed" in namespace "svcaccounts-1984" to be "running"
    Nov 11 23:16:04.749: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Pending", Reason="", readiness=false. Elapsed: 17.503869ms
    Nov 11 23:16:06.771: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039309482s
    Nov 11 23:16:08.773: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed": Phase="Running", Reason="", readiness=true. Elapsed: 4.041367125s
    Nov 11 23:16:08.773: INFO: Pod "pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed" satisfied condition "running"
    STEP: reading a file in the container 11/11/22 23:16:08.773
    Nov 11 23:16:08.774: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 11/11/22 23:16:09.225
    Nov 11 23:16:09.225: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 11/11/22 23:16:09.645
    Nov 11 23:16:09.645: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1984 pod-service-account-023a33e7-207f-4ae0-8def-32ce7fc826ed -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Nov 11 23:16:10.078: INFO: Got root ca configmap in namespace "svcaccounts-1984"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:16:10.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1984" for this suite. 11/11/22 23:16:10.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:10.156
Nov 11 23:16:10.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/11/22 23:16:10.157
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:10.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:10.239
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 11/11/22 23:16:10.353
STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:16:10.376
Nov 11 23:16:10.432: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:16:10.432: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:16:11.504: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:16:11.504: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:16:12.490: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:16:12.490: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:16:13.512: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:16:13.512: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
Nov 11 23:16:14.507: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:16:14.507: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/11/22 23:16:14.524
Nov 11 23:16:14.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:16:14.640: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:16:15.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:16:15.688: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:16:16.702: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:16:16.702: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
Nov 11 23:16:17.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:16:17.692: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 11/11/22 23:16:17.692
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:16:17.73
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6531, will wait for the garbage collector to delete the pods 11/11/22 23:16:17.73
Nov 11 23:16:17.847: INFO: Deleting DaemonSet.extensions daemon-set took: 26.699205ms
Nov 11 23:16:17.948: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.951957ms
Nov 11 23:16:19.968: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:16:19.969: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 11 23:16:19.985: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20593"},"items":null}

Nov 11 23:16:20.005: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20593"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:16:20.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6531" for this suite. 11/11/22 23:16:20.102
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":34,"skipped":451,"failed":0}
------------------------------
• [SLOW TEST] [9.970 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:10.156
    Nov 11 23:16:10.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/11/22 23:16:10.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:10.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:10.239
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 11/11/22 23:16:10.353
    STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:16:10.376
    Nov 11 23:16:10.432: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:16:10.432: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:16:11.504: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:16:11.504: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:16:12.490: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:16:12.490: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:16:13.512: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:16:13.512: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
    Nov 11 23:16:14.507: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:16:14.507: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/11/22 23:16:14.524
    Nov 11 23:16:14.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:16:14.640: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:16:15.688: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:16:15.688: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:16:16.702: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:16:16.702: INFO: Node 10.241.148.113 is running 0 daemon pod, expected 1
    Nov 11 23:16:17.691: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:16:17.692: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 11/11/22 23:16:17.692
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:16:17.73
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6531, will wait for the garbage collector to delete the pods 11/11/22 23:16:17.73
    Nov 11 23:16:17.847: INFO: Deleting DaemonSet.extensions daemon-set took: 26.699205ms
    Nov 11 23:16:17.948: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.951957ms
    Nov 11 23:16:19.968: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:16:19.969: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 11 23:16:19.985: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20593"},"items":null}

    Nov 11 23:16:20.005: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20593"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:16:20.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6531" for this suite. 11/11/22 23:16:20.102
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:20.138
Nov 11 23:16:20.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:16:20.14
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:20.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:20.213
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 11/11/22 23:16:20.253
STEP: listing secrets in all namespaces to ensure that there are more than zero 11/11/22 23:16:20.276
STEP: patching the secret 11/11/22 23:16:20.296
STEP: deleting the secret using a LabelSelector 11/11/22 23:16:20.338
STEP: listing secrets in all namespaces, searching for label name and value in patch 11/11/22 23:16:20.375
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:16:20.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1706" for this suite. 11/11/22 23:16:20.424
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":35,"skipped":483,"failed":0}
------------------------------
• [0.319 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:20.138
    Nov 11 23:16:20.139: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:16:20.14
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:20.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:20.213
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 11/11/22 23:16:20.253
    STEP: listing secrets in all namespaces to ensure that there are more than zero 11/11/22 23:16:20.276
    STEP: patching the secret 11/11/22 23:16:20.296
    STEP: deleting the secret using a LabelSelector 11/11/22 23:16:20.338
    STEP: listing secrets in all namespaces, searching for label name and value in patch 11/11/22 23:16:20.375
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:16:20.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1706" for this suite. 11/11/22 23:16:20.424
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:20.459
Nov 11 23:16:20.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:16:20.463
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:20.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:20.536
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 11/11/22 23:16:20.553
Nov 11 23:16:20.592: INFO: Waiting up to 5m0s for pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e" in namespace "downward-api-7083" to be "Succeeded or Failed"
Nov 11 23:16:20.612: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.424519ms
Nov 11 23:16:22.656: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063825781s
Nov 11 23:16:24.631: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038891537s
Nov 11 23:16:26.633: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040526978s
STEP: Saw pod success 11/11/22 23:16:26.633
Nov 11 23:16:26.633: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e" satisfied condition "Succeeded or Failed"
Nov 11 23:16:26.663: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e container dapi-container: <nil>
STEP: delete the pod 11/11/22 23:16:26.706
Nov 11 23:16:26.783: INFO: Waiting for pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e to disappear
Nov 11 23:16:26.800: INFO: Pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 11 23:16:26.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7083" for this suite. 11/11/22 23:16:26.828
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":36,"skipped":484,"failed":0}
------------------------------
• [SLOW TEST] [6.395 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:20.459
    Nov 11 23:16:20.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:16:20.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:20.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:20.536
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 11/11/22 23:16:20.553
    Nov 11 23:16:20.592: INFO: Waiting up to 5m0s for pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e" in namespace "downward-api-7083" to be "Succeeded or Failed"
    Nov 11 23:16:20.612: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.424519ms
    Nov 11 23:16:22.656: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063825781s
    Nov 11 23:16:24.631: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038891537s
    Nov 11 23:16:26.633: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040526978s
    STEP: Saw pod success 11/11/22 23:16:26.633
    Nov 11 23:16:26.633: INFO: Pod "downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e" satisfied condition "Succeeded or Failed"
    Nov 11 23:16:26.663: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e container dapi-container: <nil>
    STEP: delete the pod 11/11/22 23:16:26.706
    Nov 11 23:16:26.783: INFO: Waiting for pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e to disappear
    Nov 11 23:16:26.800: INFO: Pod downward-api-1841983d-b207-42ed-81dd-bee36ac6a13e no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 11 23:16:26.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7083" for this suite. 11/11/22 23:16:26.828
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:26.857
Nov 11 23:16:26.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:16:26.858
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:26.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:26.932
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-3762 11/11/22 23:16:26.95
STEP: creating service affinity-clusterip in namespace services-3762 11/11/22 23:16:26.951
STEP: creating replication controller affinity-clusterip in namespace services-3762 11/11/22 23:16:26.997
I1111 23:16:27.027087      21 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3762, replica count: 3
I1111 23:16:30.079280      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 23:16:33.079644      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:16:33.114: INFO: Creating new exec pod
Nov 11 23:16:33.154: INFO: Waiting up to 5m0s for pod "execpod-affinitybgd7f" in namespace "services-3762" to be "running"
Nov 11 23:16:33.174: INFO: Pod "execpod-affinitybgd7f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.748005ms
Nov 11 23:16:35.193: INFO: Pod "execpod-affinitybgd7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038994303s
Nov 11 23:16:37.194: INFO: Pod "execpod-affinitybgd7f": Phase="Running", Reason="", readiness=true. Elapsed: 4.039507313s
Nov 11 23:16:37.194: INFO: Pod "execpod-affinitybgd7f" satisfied condition "running"
Nov 11 23:16:38.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 11 23:16:38.710: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Nov 11 23:16:38.710: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:16:38.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.195.167 80'
Nov 11 23:16:39.168: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.195.167 80\nConnection to 172.21.195.167 80 port [tcp/http] succeeded!\n"
Nov 11 23:16:39.169: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:16:39.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.195.167:80/ ; done'
Nov 11 23:16:39.716: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n"
Nov 11 23:16:39.716: INFO: stdout: "\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp"
Nov 11 23:16:39.716: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
Nov 11 23:16:39.717: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-3762, will wait for the garbage collector to delete the pods 11/11/22 23:16:39.775
Nov 11 23:16:39.902: INFO: Deleting ReplicationController affinity-clusterip took: 57.711294ms
Nov 11 23:16:40.005: INFO: Terminating ReplicationController affinity-clusterip pods took: 103.051666ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:16:42.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3762" for this suite. 11/11/22 23:16:42.753
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":37,"skipped":487,"failed":0}
------------------------------
• [SLOW TEST] [15.927 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:26.857
    Nov 11 23:16:26.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:16:26.858
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:26.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:26.932
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-3762 11/11/22 23:16:26.95
    STEP: creating service affinity-clusterip in namespace services-3762 11/11/22 23:16:26.951
    STEP: creating replication controller affinity-clusterip in namespace services-3762 11/11/22 23:16:26.997
    I1111 23:16:27.027087      21 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3762, replica count: 3
    I1111 23:16:30.079280      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1111 23:16:33.079644      21 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:16:33.114: INFO: Creating new exec pod
    Nov 11 23:16:33.154: INFO: Waiting up to 5m0s for pod "execpod-affinitybgd7f" in namespace "services-3762" to be "running"
    Nov 11 23:16:33.174: INFO: Pod "execpod-affinitybgd7f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.748005ms
    Nov 11 23:16:35.193: INFO: Pod "execpod-affinitybgd7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038994303s
    Nov 11 23:16:37.194: INFO: Pod "execpod-affinitybgd7f": Phase="Running", Reason="", readiness=true. Elapsed: 4.039507313s
    Nov 11 23:16:37.194: INFO: Pod "execpod-affinitybgd7f" satisfied condition "running"
    Nov 11 23:16:38.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 11 23:16:38.710: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Nov 11 23:16:38.710: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:16:38.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.195.167 80'
    Nov 11 23:16:39.168: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.195.167 80\nConnection to 172.21.195.167 80 port [tcp/http] succeeded!\n"
    Nov 11 23:16:39.169: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:16:39.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3762 exec execpod-affinitybgd7f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.195.167:80/ ; done'
    Nov 11 23:16:39.716: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.195.167:80/\n"
    Nov 11 23:16:39.716: INFO: stdout: "\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp\naffinity-clusterip-88scp"
    Nov 11 23:16:39.716: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Received response from host: affinity-clusterip-88scp
    Nov 11 23:16:39.717: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-3762, will wait for the garbage collector to delete the pods 11/11/22 23:16:39.775
    Nov 11 23:16:39.902: INFO: Deleting ReplicationController affinity-clusterip took: 57.711294ms
    Nov 11 23:16:40.005: INFO: Terminating ReplicationController affinity-clusterip pods took: 103.051666ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:16:42.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3762" for this suite. 11/11/22 23:16:42.753
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:42.792
Nov 11 23:16:42.792: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/11/22 23:16:42.795
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:42.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:42.867
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 11/11/22 23:16:42.962
STEP: Ensuring job reaches completions 11/11/22 23:16:43.001
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 11 23:16:57.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2547" for this suite. 11/11/22 23:16:57.05
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":38,"skipped":493,"failed":0}
------------------------------
• [SLOW TEST] [14.283 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:42.792
    Nov 11 23:16:42.792: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/11/22 23:16:42.795
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:42.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:42.867
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 11/11/22 23:16:42.962
    STEP: Ensuring job reaches completions 11/11/22 23:16:43.001
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 11 23:16:57.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2547" for this suite. 11/11/22 23:16:57.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:16:57.102
Nov 11 23:16:57.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:16:57.104
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:57.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:57.174
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:16:57.245
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:16:57.854
STEP: Deploying the webhook pod 11/11/22 23:16:57.889
STEP: Wait for the deployment to be ready 11/11/22 23:16:57.951
Nov 11 23:16:57.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:17:00.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 16, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:17:02.108
STEP: Verifying the service has paired with the endpoint 11/11/22 23:17:02.157
Nov 11 23:17:03.159: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 11/11/22 23:17:03.174
STEP: Creating a custom resource definition that should be denied by the webhook 11/11/22 23:17:03.274
Nov 11 23:17:03.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:17:03.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5659" for this suite. 11/11/22 23:17:03.415
STEP: Destroying namespace "webhook-5659-markers" for this suite. 11/11/22 23:17:03.439
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":39,"skipped":550,"failed":0}
------------------------------
• [SLOW TEST] [6.522 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:16:57.102
    Nov 11 23:16:57.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:16:57.104
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:16:57.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:16:57.174
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:16:57.245
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:16:57.854
    STEP: Deploying the webhook pod 11/11/22 23:16:57.889
    STEP: Wait for the deployment to be ready 11/11/22 23:16:57.951
    Nov 11 23:16:57.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:17:00.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 16, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 16, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:17:02.108
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:17:02.157
    Nov 11 23:17:03.159: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 11/11/22 23:17:03.174
    STEP: Creating a custom resource definition that should be denied by the webhook 11/11/22 23:17:03.274
    Nov 11 23:17:03.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:17:03.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5659" for this suite. 11/11/22 23:17:03.415
    STEP: Destroying namespace "webhook-5659-markers" for this suite. 11/11/22 23:17:03.439
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:17:03.645
Nov 11 23:17:03.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename cronjob 11/11/22 23:17:03.653
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:17:03.722
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:17:03.766
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 11/11/22 23:17:03.787
STEP: Ensuring a job is scheduled 11/11/22 23:17:03.807
STEP: Ensuring exactly one is scheduled 11/11/22 23:18:01.827
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/11/22 23:18:01.85
STEP: Ensuring no more jobs are scheduled 11/11/22 23:18:01.875
STEP: Removing cronjob 11/11/22 23:23:01.914
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 11 23:23:01.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9308" for this suite. 11/11/22 23:23:02.011
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":40,"skipped":630,"failed":0}
------------------------------
• [SLOW TEST] [358.395 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:17:03.645
    Nov 11 23:17:03.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename cronjob 11/11/22 23:17:03.653
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:17:03.722
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:17:03.766
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 11/11/22 23:17:03.787
    STEP: Ensuring a job is scheduled 11/11/22 23:17:03.807
    STEP: Ensuring exactly one is scheduled 11/11/22 23:18:01.827
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/11/22 23:18:01.85
    STEP: Ensuring no more jobs are scheduled 11/11/22 23:18:01.875
    STEP: Removing cronjob 11/11/22 23:23:01.914
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 11 23:23:01.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9308" for this suite. 11/11/22 23:23:02.011
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:02.042
Nov 11 23:23:02.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir-wrapper 11/11/22 23:23:02.044
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:02.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:02.135
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Nov 11 23:23:02.303: INFO: Waiting up to 5m0s for pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003" in namespace "emptydir-wrapper-8651" to be "running and ready"
Nov 11 23:23:02.321: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Pending", Reason="", readiness=false. Elapsed: 18.758411ms
Nov 11 23:23:02.321: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:23:04.342: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039592786s
Nov 11 23:23:04.342: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:23:06.343: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Running", Reason="", readiness=true. Elapsed: 4.04010959s
Nov 11 23:23:06.343: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Running (Ready = true)
Nov 11 23:23:06.343: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003" satisfied condition "running and ready"
STEP: Cleaning up the secret 11/11/22 23:23:06.363
STEP: Cleaning up the configmap 11/11/22 23:23:06.391
STEP: Cleaning up the pod 11/11/22 23:23:06.414
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 11 23:23:06.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8651" for this suite. 11/11/22 23:23:06.498
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":41,"skipped":654,"failed":0}
------------------------------
• [4.495 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:02.042
    Nov 11 23:23:02.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir-wrapper 11/11/22 23:23:02.044
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:02.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:02.135
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Nov 11 23:23:02.303: INFO: Waiting up to 5m0s for pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003" in namespace "emptydir-wrapper-8651" to be "running and ready"
    Nov 11 23:23:02.321: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Pending", Reason="", readiness=false. Elapsed: 18.758411ms
    Nov 11 23:23:02.321: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:23:04.342: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039592786s
    Nov 11 23:23:04.342: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:23:06.343: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003": Phase="Running", Reason="", readiness=true. Elapsed: 4.04010959s
    Nov 11 23:23:06.343: INFO: The phase of Pod pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003 is Running (Ready = true)
    Nov 11 23:23:06.343: INFO: Pod "pod-secrets-d66d47e7-acd4-4ee4-a145-4a0b190c4003" satisfied condition "running and ready"
    STEP: Cleaning up the secret 11/11/22 23:23:06.363
    STEP: Cleaning up the configmap 11/11/22 23:23:06.391
    STEP: Cleaning up the pod 11/11/22 23:23:06.414
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:23:06.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-8651" for this suite. 11/11/22 23:23:06.498
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:06.538
Nov 11 23:23:06.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/11/22 23:23:06.54
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:06.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:06.611
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 11/11/22 23:23:06.63
STEP: waiting for pod running 11/11/22 23:23:06.685
Nov 11 23:23:06.685: INFO: Waiting up to 2m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319" to be "running"
Nov 11 23:23:06.705: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Pending", Reason="", readiness=false. Elapsed: 20.246333ms
Nov 11 23:23:08.726: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040601958s
Nov 11 23:23:10.744: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Running", Reason="", readiness=true. Elapsed: 4.058767152s
Nov 11 23:23:10.744: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" satisfied condition "running"
STEP: creating a file in subpath 11/11/22 23:23:10.744
Nov 11 23:23:10.763: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3319 PodName:var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:23:10.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:23:10.765: INFO: ExecWithOptions: Clientset creation
Nov 11 23:23:10.765: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3319/pods/var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 11/11/22 23:23:11.026
Nov 11 23:23:11.045: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3319 PodName:var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:23:11.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:23:11.046: INFO: ExecWithOptions: Clientset creation
Nov 11 23:23:11.046: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3319/pods/var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 11/11/22 23:23:11.302
Nov 11 23:23:11.871: INFO: Successfully updated pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833"
STEP: waiting for annotated pod running 11/11/22 23:23:11.871
Nov 11 23:23:11.871: INFO: Waiting up to 2m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319" to be "running"
Nov 11 23:23:11.889: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Running", Reason="", readiness=true. Elapsed: 17.763935ms
Nov 11 23:23:11.889: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" satisfied condition "running"
STEP: deleting the pod gracefully 11/11/22 23:23:11.889
Nov 11 23:23:11.890: INFO: Deleting pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319"
Nov 11 23:23:11.922: INFO: Wait up to 5m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 11 23:23:43.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3319" for this suite. 11/11/22 23:23:44.004
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":42,"skipped":655,"failed":0}
------------------------------
• [SLOW TEST] [37.489 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:06.538
    Nov 11 23:23:06.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/11/22 23:23:06.54
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:06.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:06.611
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 11/11/22 23:23:06.63
    STEP: waiting for pod running 11/11/22 23:23:06.685
    Nov 11 23:23:06.685: INFO: Waiting up to 2m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319" to be "running"
    Nov 11 23:23:06.705: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Pending", Reason="", readiness=false. Elapsed: 20.246333ms
    Nov 11 23:23:08.726: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040601958s
    Nov 11 23:23:10.744: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Running", Reason="", readiness=true. Elapsed: 4.058767152s
    Nov 11 23:23:10.744: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" satisfied condition "running"
    STEP: creating a file in subpath 11/11/22 23:23:10.744
    Nov 11 23:23:10.763: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3319 PodName:var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:23:10.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:23:10.765: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:23:10.765: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3319/pods/var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 11/11/22 23:23:11.026
    Nov 11 23:23:11.045: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3319 PodName:var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:23:11.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:23:11.046: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:23:11.046: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/var-expansion-3319/pods/var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 11/11/22 23:23:11.302
    Nov 11 23:23:11.871: INFO: Successfully updated pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833"
    STEP: waiting for annotated pod running 11/11/22 23:23:11.871
    Nov 11 23:23:11.871: INFO: Waiting up to 2m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319" to be "running"
    Nov 11 23:23:11.889: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833": Phase="Running", Reason="", readiness=true. Elapsed: 17.763935ms
    Nov 11 23:23:11.889: INFO: Pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" satisfied condition "running"
    STEP: deleting the pod gracefully 11/11/22 23:23:11.889
    Nov 11 23:23:11.890: INFO: Deleting pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" in namespace "var-expansion-3319"
    Nov 11 23:23:11.922: INFO: Wait up to 5m0s for pod "var-expansion-6f70d0d9-9cb6-49d1-914e-73a4bdc6c833" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 11 23:23:43.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3319" for this suite. 11/11/22 23:23:44.004
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:44.033
Nov 11 23:23:44.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/11/22 23:23:44.036
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:44.104
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:44.12
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 11/11/22 23:23:44.141
STEP: Getting a ResourceQuota 11/11/22 23:23:44.161
STEP: Updating a ResourceQuota 11/11/22 23:23:44.182
STEP: Verifying a ResourceQuota was modified 11/11/22 23:23:44.204
STEP: Deleting a ResourceQuota 11/11/22 23:23:44.222
STEP: Verifying the deleted ResourceQuota 11/11/22 23:23:44.251
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 11 23:23:44.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5909" for this suite. 11/11/22 23:23:44.307
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":43,"skipped":658,"failed":0}
------------------------------
• [0.300 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:44.033
    Nov 11 23:23:44.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/11/22 23:23:44.036
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:44.104
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:44.12
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 11/11/22 23:23:44.141
    STEP: Getting a ResourceQuota 11/11/22 23:23:44.161
    STEP: Updating a ResourceQuota 11/11/22 23:23:44.182
    STEP: Verifying a ResourceQuota was modified 11/11/22 23:23:44.204
    STEP: Deleting a ResourceQuota 11/11/22 23:23:44.222
    STEP: Verifying the deleted ResourceQuota 11/11/22 23:23:44.251
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 11 23:23:44.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5909" for this suite. 11/11/22 23:23:44.307
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:44.344
Nov 11 23:23:44.344: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:23:44.347
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:44.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:44.422
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-7f571992-0f45-4d21-b130-4fc869282770 11/11/22 23:23:44.442
STEP: Creating a pod to test consume configMaps 11/11/22 23:23:44.462
Nov 11 23:23:44.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b" in namespace "configmap-298" to be "Succeeded or Failed"
Nov 11 23:23:44.521: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.179049ms
Nov 11 23:23:46.573: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Running", Reason="", readiness=true. Elapsed: 2.072294844s
Nov 11 23:23:48.543: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Running", Reason="", readiness=false. Elapsed: 4.042313476s
Nov 11 23:23:50.545: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043867925s
STEP: Saw pod success 11/11/22 23:23:50.545
Nov 11 23:23:50.545: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b" satisfied condition "Succeeded or Failed"
Nov 11 23:23:50.564: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:23:50.671
Nov 11 23:23:50.718: INFO: Waiting for pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b to disappear
Nov 11 23:23:50.739: INFO: Pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:23:50.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-298" for this suite. 11/11/22 23:23:50.772
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":44,"skipped":667,"failed":0}
------------------------------
• [SLOW TEST] [6.452 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:44.344
    Nov 11 23:23:44.344: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:23:44.347
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:44.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:44.422
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-7f571992-0f45-4d21-b130-4fc869282770 11/11/22 23:23:44.442
    STEP: Creating a pod to test consume configMaps 11/11/22 23:23:44.462
    Nov 11 23:23:44.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b" in namespace "configmap-298" to be "Succeeded or Failed"
    Nov 11 23:23:44.521: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.179049ms
    Nov 11 23:23:46.573: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Running", Reason="", readiness=true. Elapsed: 2.072294844s
    Nov 11 23:23:48.543: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Running", Reason="", readiness=false. Elapsed: 4.042313476s
    Nov 11 23:23:50.545: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043867925s
    STEP: Saw pod success 11/11/22 23:23:50.545
    Nov 11 23:23:50.545: INFO: Pod "pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b" satisfied condition "Succeeded or Failed"
    Nov 11 23:23:50.564: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:23:50.671
    Nov 11 23:23:50.718: INFO: Waiting for pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b to disappear
    Nov 11 23:23:50.739: INFO: Pod pod-configmaps-3c7bebfc-83d8-407f-9f1e-2ae30723c86b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:23:50.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-298" for this suite. 11/11/22 23:23:50.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:50.807
Nov 11 23:23:50.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:23:50.809
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:50.86
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:50.877
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 11/11/22 23:23:50.893
Nov 11 23:23:50.893: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-5236 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 11/11/22 23:23:51.001
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:23:51.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5236" for this suite. 11/11/22 23:23:51.058
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":45,"skipped":710,"failed":0}
------------------------------
• [0.274 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:50.807
    Nov 11 23:23:50.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:23:50.809
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:50.86
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:50.877
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 11/11/22 23:23:50.893
    Nov 11 23:23:50.893: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-5236 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 11/11/22 23:23:51.001
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:23:51.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5236" for this suite. 11/11/22 23:23:51.058
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:51.082
Nov 11 23:23:51.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-pred 11/11/22 23:23:51.084
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:51.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:51.153
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 11 23:23:51.172: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 23:23:51.222: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 23:23:51.261: INFO: 
Logging pods the apiserver thinks is on node 10.184.98.55 before test
Nov 11 23:23:51.355: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.355: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:23:51.356: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:23:51.356: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:23:51.356: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:23:51.356: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:23:51.356: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:23:51.356: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:23:51.356: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Nov 11 23:23:51.356: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:23:51.356: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:23:51.356: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:23:51.356: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:23:51.356: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:23:51.356: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 11 23:23:51.356: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:23:51.356: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:23:51.356: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.113 before test
Nov 11 23:23:51.436: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 11 23:23:51.436: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:23:51.436: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:23:51.436: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container autoscaler ready: true, restart count 0
Nov 11 23:23:51.436: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:23:51.436: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:23:51.436: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:23:51.436: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:23:51.436: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Nov 11 23:23:51.436: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:23:51.436: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 11 23:23:51.436: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:23:51.436: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:23:51.436: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:23:51.436: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.436: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:23:51.437: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.437: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:23:51.437: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.437: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:23:51.437: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:23:51.437: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:23:51.437: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.26 before test
Nov 11 23:23:51.506: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov 11 23:23:51.506: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:23:51.506: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:23:51.506: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:23:51.506: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:23:51.506: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:23:51.506: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:23:51.506: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:23:51.506: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:23:51.506: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.506: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:23:51.506: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:23:51.507: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:23:51.507: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.507: INFO: 	Container e2e ready: true, restart count 0
Nov 11 23:23:51.507: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:23:51.507: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:23:51.507: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:23:51.507: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node 10.184.98.55 11/11/22 23:23:51.619
STEP: verifying the node has the label node 10.241.148.113 11/11/22 23:23:51.668
STEP: verifying the node has the label node 10.241.148.26 11/11/22 23:23:51.724
Nov 11 23:23:51.814: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln requesting resource cpu=5m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc requesting resource cpu=5m on Node 10.184.98.55
Nov 11 23:23:51.814: INFO: Pod calico-kube-controllers-69d96775d-x5dzw requesting resource cpu=10m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod calico-node-4pllg requesting resource cpu=250m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod calico-node-j9dvb requesting resource cpu=250m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod calico-node-jr9ch requesting resource cpu=250m on Node 10.184.98.55
Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-6hz97 requesting resource cpu=250m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-c44sg requesting resource cpu=250m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-mwlr2 requesting resource cpu=250m on Node 10.184.98.55
Nov 11 23:23:51.814: INFO: Pod coredns-autoscaler-78b44f5654-q5xkl requesting resource cpu=1m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-7d4gj requesting resource cpu=100m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-vrmsd requesting resource cpu=100m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-ww5mz requesting resource cpu=100m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod dashboard-metrics-scraper-98b99ddbd-qs8t7 requesting resource cpu=1m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod ibm-file-plugin-766c57449-rm8fx requesting resource cpu=50m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-8s5vg requesting resource cpu=5m on Node 10.184.98.55
Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-rvvrm requesting resource cpu=5m on Node 10.241.148.26
Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-xsshm requesting resource cpu=5m on Node 10.241.148.113
Nov 11 23:23:51.814: INFO: Pod ibm-master-proxy-static-10.184.98.55 requesting resource cpu=25m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod ibm-master-proxy-static-10.241.148.113 requesting resource cpu=25m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod ibm-master-proxy-static-10.241.148.26 requesting resource cpu=25m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod ibm-storage-watcher-56b46bbdcf-hnrzg requesting resource cpu=50m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-c2stl requesting resource cpu=50m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-ks5rd requesting resource cpu=50m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-ljthd requesting resource cpu=50m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd requesting resource cpu=50m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod ingress-cluster-healthcheck-5fc9658887-j96dq requesting resource cpu=10m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-58g6r requesting resource cpu=10m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-kvttr requesting resource cpu=10m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-wrcmz requesting resource cpu=10m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod kubernetes-dashboard-65969f7576-7w24f requesting resource cpu=50m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod metrics-server-6f6df44444-686d8 requesting resource cpu=126m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod metrics-server-6f6df44444-8tc95 requesting resource cpu=126m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc requesting resource cpu=20m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h requesting resource cpu=20m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-hcrtw requesting resource cpu=10m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-k7jgh requesting resource cpu=10m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-th9dx requesting resource cpu=10m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.184.98.55
Nov 11 23:23:51.815: INFO: Pod sonobuoy-e2e-job-2a0ed9b558a64b7e requesting resource cpu=0m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk requesting resource cpu=0m on Node 10.241.148.26
Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch requesting resource cpu=0m on Node 10.241.148.113
Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 requesting resource cpu=0m on Node 10.184.98.55
STEP: Starting Pods to consume most of the cluster CPU. 11/11/22 23:23:51.815
Nov 11 23:23:51.815: INFO: Creating a pod which consumes cpu=2211m on Node 10.184.98.55
Nov 11 23:23:51.853: INFO: Creating a pod which consumes cpu=1926m on Node 10.241.148.113
Nov 11 23:23:51.880: INFO: Creating a pod which consumes cpu=2236m on Node 10.241.148.26
Nov 11 23:23:51.915: INFO: Waiting up to 5m0s for pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730" in namespace "sched-pred-8679" to be "running"
Nov 11 23:23:51.936: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Pending", Reason="", readiness=false. Elapsed: 20.973155ms
Nov 11 23:23:53.957: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041520857s
Nov 11 23:23:55.956: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Running", Reason="", readiness=true. Elapsed: 4.040734395s
Nov 11 23:23:55.956: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730" satisfied condition "running"
Nov 11 23:23:55.956: INFO: Waiting up to 5m0s for pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3" in namespace "sched-pred-8679" to be "running"
Nov 11 23:23:55.975: INFO: Pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3": Phase="Running", Reason="", readiness=true. Elapsed: 19.319078ms
Nov 11 23:23:55.976: INFO: Pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3" satisfied condition "running"
Nov 11 23:23:55.976: INFO: Waiting up to 5m0s for pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd" in namespace "sched-pred-8679" to be "running"
Nov 11 23:23:55.998: INFO: Pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd": Phase="Running", Reason="", readiness=true. Elapsed: 22.772621ms
Nov 11 23:23:55.998: INFO: Pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 11/11/22 23:23:55.998
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab46a3217ee8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-181e9758-6967-4443-9969-d62095f3f730 to 10.184.98.55] 11/11/22 23:23:56.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab470bb9c3cc], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/11/22 23:23:56.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab4710075f29], Reason = [Created], Message = [Created container filler-pod-181e9758-6967-4443-9969-d62095f3f730] 11/11/22 23:23:56.02
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab471d02de2b], Reason = [Started], Message = [Started container filler-pod-181e9758-6967-4443-9969-d62095f3f730] 11/11/22 23:23:56.021
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46a4c93b1c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3 to 10.241.148.113] 11/11/22 23:23:56.021
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46f43eecec], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/11/22 23:23:56.021
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46f7c8ddcf], Reason = [Created], Message = [Created container filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3] 11/11/22 23:23:56.021
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab47077c8abc], Reason = [Started], Message = [Started container filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3] 11/11/22 23:23:56.021
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab46a6fa58b6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd to 10.241.148.26] 11/11/22 23:23:56.022
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab46fbfbe8e1], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 11/11/22 23:23:56.022
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab47142b44a2], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 405.705695ms] 11/11/22 23:23:56.023
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab471797a9ed], Reason = [Created], Message = [Created container filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd] 11/11/22 23:23:56.023
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab472863748b], Reason = [Started], Message = [Started container filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd] 11/11/22 23:23:56.023
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1726ab479ccbed11], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 11/11/22 23:23:56.069
STEP: removing the label node off the node 10.184.98.55 11/11/22 23:23:57.085
STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.137
STEP: removing the label node off the node 10.241.148.113 11/11/22 23:23:57.153
STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.198
STEP: removing the label node off the node 10.241.148.26 11/11/22 23:23:57.215
STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.261
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:23:57.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8679" for this suite. 11/11/22 23:23:57.311
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":46,"skipped":712,"failed":0}
------------------------------
• [SLOW TEST] [6.255 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:51.082
    Nov 11 23:23:51.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-pred 11/11/22 23:23:51.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:51.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:51.153
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 11 23:23:51.172: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 11 23:23:51.222: INFO: Waiting for terminating namespaces to be deleted...
    Nov 11 23:23:51.261: INFO: 
    Logging pods the apiserver thinks is on node 10.184.98.55 before test
    Nov 11 23:23:51.355: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.355: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:23:51.356: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.113 before test
    Nov 11 23:23:51.436: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:23:51.436: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.436: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:23:51.437: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.437: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:23:51.437: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.437: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:23:51.437: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.437: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:23:51.437: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:23:51.437: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.26 before test
    Nov 11 23:23:51.506: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.506: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:23:51.506: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:23:51.507: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:23:51.507: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.507: INFO: 	Container e2e ready: true, restart count 0
    Nov 11 23:23:51.507: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:23:51.507: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:23:51.507: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:23:51.507: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node 10.184.98.55 11/11/22 23:23:51.619
    STEP: verifying the node has the label node 10.241.148.113 11/11/22 23:23:51.668
    STEP: verifying the node has the label node 10.241.148.26 11/11/22 23:23:51.724
    Nov 11 23:23:51.814: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln requesting resource cpu=5m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc requesting resource cpu=5m on Node 10.184.98.55
    Nov 11 23:23:51.814: INFO: Pod calico-kube-controllers-69d96775d-x5dzw requesting resource cpu=10m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod calico-node-4pllg requesting resource cpu=250m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod calico-node-j9dvb requesting resource cpu=250m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod calico-node-jr9ch requesting resource cpu=250m on Node 10.184.98.55
    Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-6hz97 requesting resource cpu=250m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-c44sg requesting resource cpu=250m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod calico-typha-69875cbbb9-mwlr2 requesting resource cpu=250m on Node 10.184.98.55
    Nov 11 23:23:51.814: INFO: Pod coredns-autoscaler-78b44f5654-q5xkl requesting resource cpu=1m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-7d4gj requesting resource cpu=100m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-vrmsd requesting resource cpu=100m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod coredns-f7664d677-ww5mz requesting resource cpu=100m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod dashboard-metrics-scraper-98b99ddbd-qs8t7 requesting resource cpu=1m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod ibm-file-plugin-766c57449-rm8fx requesting resource cpu=50m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-8s5vg requesting resource cpu=5m on Node 10.184.98.55
    Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-rvvrm requesting resource cpu=5m on Node 10.241.148.26
    Nov 11 23:23:51.814: INFO: Pod ibm-keepalived-watcher-xsshm requesting resource cpu=5m on Node 10.241.148.113
    Nov 11 23:23:51.814: INFO: Pod ibm-master-proxy-static-10.184.98.55 requesting resource cpu=25m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod ibm-master-proxy-static-10.241.148.113 requesting resource cpu=25m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod ibm-master-proxy-static-10.241.148.26 requesting resource cpu=25m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod ibm-storage-watcher-56b46bbdcf-hnrzg requesting resource cpu=50m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-c2stl requesting resource cpu=50m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-ks5rd requesting resource cpu=50m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-driver-ljthd requesting resource cpu=50m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd requesting resource cpu=50m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod ingress-cluster-healthcheck-5fc9658887-j96dq requesting resource cpu=10m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-58g6r requesting resource cpu=10m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-kvttr requesting resource cpu=10m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod konnectivity-agent-wrcmz requesting resource cpu=10m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod kubernetes-dashboard-65969f7576-7w24f requesting resource cpu=50m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod metrics-server-6f6df44444-686d8 requesting resource cpu=126m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod metrics-server-6f6df44444-8tc95 requesting resource cpu=126m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc requesting resource cpu=20m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h requesting resource cpu=20m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-hcrtw requesting resource cpu=10m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-k7jgh requesting resource cpu=10m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod snapshot-controller-66bd5d44d9-th9dx requesting resource cpu=10m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.184.98.55
    Nov 11 23:23:51.815: INFO: Pod sonobuoy-e2e-job-2a0ed9b558a64b7e requesting resource cpu=0m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk requesting resource cpu=0m on Node 10.241.148.26
    Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch requesting resource cpu=0m on Node 10.241.148.113
    Nov 11 23:23:51.815: INFO: Pod sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 requesting resource cpu=0m on Node 10.184.98.55
    STEP: Starting Pods to consume most of the cluster CPU. 11/11/22 23:23:51.815
    Nov 11 23:23:51.815: INFO: Creating a pod which consumes cpu=2211m on Node 10.184.98.55
    Nov 11 23:23:51.853: INFO: Creating a pod which consumes cpu=1926m on Node 10.241.148.113
    Nov 11 23:23:51.880: INFO: Creating a pod which consumes cpu=2236m on Node 10.241.148.26
    Nov 11 23:23:51.915: INFO: Waiting up to 5m0s for pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730" in namespace "sched-pred-8679" to be "running"
    Nov 11 23:23:51.936: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Pending", Reason="", readiness=false. Elapsed: 20.973155ms
    Nov 11 23:23:53.957: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041520857s
    Nov 11 23:23:55.956: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730": Phase="Running", Reason="", readiness=true. Elapsed: 4.040734395s
    Nov 11 23:23:55.956: INFO: Pod "filler-pod-181e9758-6967-4443-9969-d62095f3f730" satisfied condition "running"
    Nov 11 23:23:55.956: INFO: Waiting up to 5m0s for pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3" in namespace "sched-pred-8679" to be "running"
    Nov 11 23:23:55.975: INFO: Pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3": Phase="Running", Reason="", readiness=true. Elapsed: 19.319078ms
    Nov 11 23:23:55.976: INFO: Pod "filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3" satisfied condition "running"
    Nov 11 23:23:55.976: INFO: Waiting up to 5m0s for pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd" in namespace "sched-pred-8679" to be "running"
    Nov 11 23:23:55.998: INFO: Pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd": Phase="Running", Reason="", readiness=true. Elapsed: 22.772621ms
    Nov 11 23:23:55.998: INFO: Pod "filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 11/11/22 23:23:55.998
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab46a3217ee8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-181e9758-6967-4443-9969-d62095f3f730 to 10.184.98.55] 11/11/22 23:23:56.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab470bb9c3cc], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/11/22 23:23:56.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab4710075f29], Reason = [Created], Message = [Created container filler-pod-181e9758-6967-4443-9969-d62095f3f730] 11/11/22 23:23:56.02
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-181e9758-6967-4443-9969-d62095f3f730.1726ab471d02de2b], Reason = [Started], Message = [Started container filler-pod-181e9758-6967-4443-9969-d62095f3f730] 11/11/22 23:23:56.021
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46a4c93b1c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3 to 10.241.148.113] 11/11/22 23:23:56.021
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46f43eecec], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/11/22 23:23:56.021
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab46f7c8ddcf], Reason = [Created], Message = [Created container filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3] 11/11/22 23:23:56.021
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3.1726ab47077c8abc], Reason = [Started], Message = [Started container filler-pod-7c09d83e-f73e-4daf-9506-5c4cf81dabd3] 11/11/22 23:23:56.021
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab46a6fa58b6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8679/filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd to 10.241.148.26] 11/11/22 23:23:56.022
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab46fbfbe8e1], Reason = [Pulling], Message = [Pulling image "registry.k8s.io/pause:3.8"] 11/11/22 23:23:56.022
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab47142b44a2], Reason = [Pulled], Message = [Successfully pulled image "registry.k8s.io/pause:3.8" in 405.705695ms] 11/11/22 23:23:56.023
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab471797a9ed], Reason = [Created], Message = [Created container filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd] 11/11/22 23:23:56.023
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd.1726ab472863748b], Reason = [Started], Message = [Started container filler-pod-f2f9bace-6291-4103-80d4-bfad140697dd] 11/11/22 23:23:56.023
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1726ab479ccbed11], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 11/11/22 23:23:56.069
    STEP: removing the label node off the node 10.184.98.55 11/11/22 23:23:57.085
    STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.137
    STEP: removing the label node off the node 10.241.148.113 11/11/22 23:23:57.153
    STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.198
    STEP: removing the label node off the node 10.241.148.26 11/11/22 23:23:57.215
    STEP: verifying the node doesn't have the label node 11/11/22 23:23:57.261
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:23:57.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8679" for this suite. 11/11/22 23:23:57.311
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:23:57.342
Nov 11 23:23:57.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/11/22 23:23:57.344
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:57.418
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:57.435
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 in namespace container-probe-3186 11/11/22 23:23:57.452
Nov 11 23:23:57.494: INFO: Waiting up to 5m0s for pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06" in namespace "container-probe-3186" to be "not pending"
Nov 11 23:23:57.515: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Pending", Reason="", readiness=false. Elapsed: 20.119716ms
Nov 11 23:23:59.535: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040728073s
Nov 11 23:24:01.536: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Running", Reason="", readiness=true. Elapsed: 4.041237802s
Nov 11 23:24:01.536: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06" satisfied condition "not pending"
Nov 11 23:24:01.536: INFO: Started pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 in namespace container-probe-3186
STEP: checking the pod's current state and verifying that restartCount is present 11/11/22 23:24:01.536
Nov 11 23:24:01.555: INFO: Initial restart count of pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is 0
Nov 11 23:24:19.769: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 1 (18.213579027s elapsed)
Nov 11 23:24:39.992: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 2 (38.436309295s elapsed)
Nov 11 23:25:00.199: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 3 (58.643710226s elapsed)
Nov 11 23:25:20.403: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 4 (1m18.847958932s elapsed)
Nov 11 23:26:19.007: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 5 (2m17.452127129s elapsed)
STEP: deleting the pod 11/11/22 23:26:19.007
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 11 23:26:19.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3186" for this suite. 11/11/22 23:26:19.094
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":47,"skipped":742,"failed":0}
------------------------------
• [SLOW TEST] [141.777 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:23:57.342
    Nov 11 23:23:57.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/11/22 23:23:57.344
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:23:57.418
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:23:57.435
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 in namespace container-probe-3186 11/11/22 23:23:57.452
    Nov 11 23:23:57.494: INFO: Waiting up to 5m0s for pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06" in namespace "container-probe-3186" to be "not pending"
    Nov 11 23:23:57.515: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Pending", Reason="", readiness=false. Elapsed: 20.119716ms
    Nov 11 23:23:59.535: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040728073s
    Nov 11 23:24:01.536: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06": Phase="Running", Reason="", readiness=true. Elapsed: 4.041237802s
    Nov 11 23:24:01.536: INFO: Pod "liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06" satisfied condition "not pending"
    Nov 11 23:24:01.536: INFO: Started pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 in namespace container-probe-3186
    STEP: checking the pod's current state and verifying that restartCount is present 11/11/22 23:24:01.536
    Nov 11 23:24:01.555: INFO: Initial restart count of pod liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is 0
    Nov 11 23:24:19.769: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 1 (18.213579027s elapsed)
    Nov 11 23:24:39.992: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 2 (38.436309295s elapsed)
    Nov 11 23:25:00.199: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 3 (58.643710226s elapsed)
    Nov 11 23:25:20.403: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 4 (1m18.847958932s elapsed)
    Nov 11 23:26:19.007: INFO: Restart count of pod container-probe-3186/liveness-b40c6d67-45f4-4c07-979d-1c6ef2543c06 is now 5 (2m17.452127129s elapsed)
    STEP: deleting the pod 11/11/22 23:26:19.007
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 11 23:26:19.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3186" for this suite. 11/11/22 23:26:19.094
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:26:19.122
Nov 11 23:26:19.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:26:19.125
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:19.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:19.197
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-d1aedf1a-098b-4862-94d5-90af2a39584b 11/11/22 23:26:19.251
STEP: Creating configMap with name cm-test-opt-upd-3f3848a2-45cc-46a4-a5fd-00e0ac8deeef 11/11/22 23:26:19.27
STEP: Creating the pod 11/11/22 23:26:19.293
Nov 11 23:26:19.332: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f" in namespace "projected-8542" to be "running and ready"
Nov 11 23:26:19.357: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.627852ms
Nov 11 23:26:19.357: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:26:21.379: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046557524s
Nov 11 23:26:21.379: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:26:23.385: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Running", Reason="", readiness=true. Elapsed: 4.052607948s
Nov 11 23:26:23.385: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Running (Ready = true)
Nov 11 23:26:23.385: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-d1aedf1a-098b-4862-94d5-90af2a39584b 11/11/22 23:26:23.588
STEP: Updating configmap cm-test-opt-upd-3f3848a2-45cc-46a4-a5fd-00e0ac8deeef 11/11/22 23:26:23.616
STEP: Creating configMap with name cm-test-opt-create-dff3a619-3704-4b96-b25e-9a92c623162a 11/11/22 23:26:23.635
STEP: waiting to observe update in volume 11/11/22 23:26:23.652
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 11 23:26:27.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8542" for this suite. 11/11/22 23:26:27.868
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":48,"skipped":742,"failed":0}
------------------------------
• [SLOW TEST] [8.769 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:26:19.122
    Nov 11 23:26:19.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:26:19.125
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:19.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:19.197
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-d1aedf1a-098b-4862-94d5-90af2a39584b 11/11/22 23:26:19.251
    STEP: Creating configMap with name cm-test-opt-upd-3f3848a2-45cc-46a4-a5fd-00e0ac8deeef 11/11/22 23:26:19.27
    STEP: Creating the pod 11/11/22 23:26:19.293
    Nov 11 23:26:19.332: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f" in namespace "projected-8542" to be "running and ready"
    Nov 11 23:26:19.357: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.627852ms
    Nov 11 23:26:19.357: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:26:21.379: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046557524s
    Nov 11 23:26:21.379: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:26:23.385: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f": Phase="Running", Reason="", readiness=true. Elapsed: 4.052607948s
    Nov 11 23:26:23.385: INFO: The phase of Pod pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f is Running (Ready = true)
    Nov 11 23:26:23.385: INFO: Pod "pod-projected-configmaps-1dd74d88-577d-4467-ac55-a60f0cbf895f" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-d1aedf1a-098b-4862-94d5-90af2a39584b 11/11/22 23:26:23.588
    STEP: Updating configmap cm-test-opt-upd-3f3848a2-45cc-46a4-a5fd-00e0ac8deeef 11/11/22 23:26:23.616
    STEP: Creating configMap with name cm-test-opt-create-dff3a619-3704-4b96-b25e-9a92c623162a 11/11/22 23:26:23.635
    STEP: waiting to observe update in volume 11/11/22 23:26:23.652
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 11 23:26:27.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8542" for this suite. 11/11/22 23:26:27.868
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:26:27.893
Nov 11 23:26:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/11/22 23:26:27.895
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:27.946
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:27.964
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Nov 11 23:26:27.985: INFO: Creating ReplicaSet my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1
Nov 11 23:26:28.030: INFO: Pod name my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Found 0 pods out of 1
Nov 11 23:26:33.051: INFO: Pod name my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Found 1 pods out of 1
Nov 11 23:26:33.051: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1" is running
Nov 11 23:26:33.051: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" in namespace "replicaset-6206" to be "running"
Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc": Phase="Running", Reason="", readiness=true. Elapsed: 22.113661ms
Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" satisfied condition "running"
Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:28 +0000 UTC Reason: Message:}])
Nov 11 23:26:33.074: INFO: Trying to dial the pod
Nov 11 23:26:38.185: INFO: Controller my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Got expected result from replica 1 [my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc]: "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 11 23:26:38.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6206" for this suite. 11/11/22 23:26:38.213
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":49,"skipped":743,"failed":0}
------------------------------
• [SLOW TEST] [10.347 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:26:27.893
    Nov 11 23:26:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/11/22 23:26:27.895
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:27.946
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:27.964
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Nov 11 23:26:27.985: INFO: Creating ReplicaSet my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1
    Nov 11 23:26:28.030: INFO: Pod name my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Found 0 pods out of 1
    Nov 11 23:26:33.051: INFO: Pod name my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Found 1 pods out of 1
    Nov 11 23:26:33.051: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1" is running
    Nov 11 23:26:33.051: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" in namespace "replicaset-6206" to be "running"
    Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc": Phase="Running", Reason="", readiness=true. Elapsed: 22.113661ms
    Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" satisfied condition "running"
    Nov 11 23:26:33.073: INFO: Pod "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-11 23:26:28 +0000 UTC Reason: Message:}])
    Nov 11 23:26:33.074: INFO: Trying to dial the pod
    Nov 11 23:26:38.185: INFO: Controller my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1: Got expected result from replica 1 [my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc]: "my-hostname-basic-2f999715-c6a5-40d1-8d74-5af11a6be4c1-sxbnc", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 11 23:26:38.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6206" for this suite. 11/11/22 23:26:38.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:26:38.251
Nov 11 23:26:38.251: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:26:38.253
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:38.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:38.353
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 11/11/22 23:26:38.373
Nov 11 23:26:38.413: INFO: Waiting up to 5m0s for pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d" in namespace "downward-api-4765" to be "running and ready"
Nov 11 23:26:38.432: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.338508ms
Nov 11 23:26:38.432: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:26:40.451: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037443068s
Nov 11 23:26:40.451: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:26:42.451: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Running", Reason="", readiness=true. Elapsed: 4.037835602s
Nov 11 23:26:42.452: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Running (Ready = true)
Nov 11 23:26:42.452: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d" satisfied condition "running and ready"
Nov 11 23:26:43.059: INFO: Successfully updated pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 11 23:26:45.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4765" for this suite. 11/11/22 23:26:45.168
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":50,"skipped":778,"failed":0}
------------------------------
• [SLOW TEST] [6.942 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:26:38.251
    Nov 11 23:26:38.251: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:26:38.253
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:38.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:38.353
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 11/11/22 23:26:38.373
    Nov 11 23:26:38.413: INFO: Waiting up to 5m0s for pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d" in namespace "downward-api-4765" to be "running and ready"
    Nov 11 23:26:38.432: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.338508ms
    Nov 11 23:26:38.432: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:26:40.451: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037443068s
    Nov 11 23:26:40.451: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:26:42.451: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d": Phase="Running", Reason="", readiness=true. Elapsed: 4.037835602s
    Nov 11 23:26:42.452: INFO: The phase of Pod labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d is Running (Ready = true)
    Nov 11 23:26:42.452: INFO: Pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d" satisfied condition "running and ready"
    Nov 11 23:26:43.059: INFO: Successfully updated pod "labelsupdatebef63e6a-4b67-4534-ab05-2d04de3ca86d"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 11 23:26:45.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4765" for this suite. 11/11/22 23:26:45.168
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:26:45.194
Nov 11 23:26:45.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:26:45.197
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:45.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:45.273
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:26:45.37
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:26:46.607
STEP: Deploying the webhook pod 11/11/22 23:26:46.638
STEP: Wait for the deployment to be ready 11/11/22 23:26:46.679
Nov 11 23:26:46.725: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 11 23:26:48.783: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:26:50.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:26:52.806
STEP: Verifying the service has paired with the endpoint 11/11/22 23:26:52.848
Nov 11 23:26:53.849: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/11/22 23:26:53.867
STEP: create a namespace for the webhook 11/11/22 23:26:53.995
STEP: create a configmap should be unconditionally rejected by the webhook 11/11/22 23:26:54.028
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:26:54.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8" for this suite. 11/11/22 23:26:54.188
STEP: Destroying namespace "webhook-8-markers" for this suite. 11/11/22 23:26:54.213
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":51,"skipped":778,"failed":0}
------------------------------
• [SLOW TEST] [9.187 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:26:45.194
    Nov 11 23:26:45.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:26:45.197
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:45.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:45.273
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:26:45.37
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:26:46.607
    STEP: Deploying the webhook pod 11/11/22 23:26:46.638
    STEP: Wait for the deployment to be ready 11/11/22 23:26:46.679
    Nov 11 23:26:46.725: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Nov 11 23:26:48.783: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:26:50.802: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 26, 46, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:26:52.806
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:26:52.848
    Nov 11 23:26:53.849: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/11/22 23:26:53.867
    STEP: create a namespace for the webhook 11/11/22 23:26:53.995
    STEP: create a configmap should be unconditionally rejected by the webhook 11/11/22 23:26:54.028
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:26:54.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8" for this suite. 11/11/22 23:26:54.188
    STEP: Destroying namespace "webhook-8-markers" for this suite. 11/11/22 23:26:54.213
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:26:54.388
Nov 11 23:26:54.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:26:54.391
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:54.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:54.457
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-19 11/11/22 23:26:54.487
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 11/11/22 23:26:54.51
STEP: Creating pod with conflicting port in namespace statefulset-19 11/11/22 23:26:54.532
STEP: Waiting until pod test-pod will start running in namespace statefulset-19 11/11/22 23:26:54.57
Nov 11 23:26:54.571: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-19" to be "running"
Nov 11 23:26:54.590: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.112952ms
Nov 11 23:26:56.607: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036391674s
Nov 11 23:26:58.612: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.041621054s
Nov 11 23:26:58.612: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-19 11/11/22 23:26:58.612
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-19 11/11/22 23:26:58.637
Nov 11 23:26:58.674: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Pending. Waiting for statefulset controller to delete.
Nov 11 23:26:58.717: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Failed. Waiting for statefulset controller to delete.
Nov 11 23:26:58.747: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Failed. Waiting for statefulset controller to delete.
Nov 11 23:26:58.760: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-19
STEP: Removing pod with conflicting port in namespace statefulset-19 11/11/22 23:26:58.76
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-19 and will be in running state 11/11/22 23:26:58.82
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 11 23:27:02.899: INFO: Deleting all statefulset in ns statefulset-19
Nov 11 23:27:02.919: INFO: Scaling statefulset ss to 0
Nov 11 23:27:13.002: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:27:13.020: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 11 23:27:13.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-19" for this suite. 11/11/22 23:27:13.108
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":52,"skipped":794,"failed":0}
------------------------------
• [SLOW TEST] [18.745 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:26:54.388
    Nov 11 23:26:54.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:26:54.391
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:26:54.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:26:54.457
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-19 11/11/22 23:26:54.487
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 11/11/22 23:26:54.51
    STEP: Creating pod with conflicting port in namespace statefulset-19 11/11/22 23:26:54.532
    STEP: Waiting until pod test-pod will start running in namespace statefulset-19 11/11/22 23:26:54.57
    Nov 11 23:26:54.571: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-19" to be "running"
    Nov 11 23:26:54.590: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.112952ms
    Nov 11 23:26:56.607: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036391674s
    Nov 11 23:26:58.612: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.041621054s
    Nov 11 23:26:58.612: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-19 11/11/22 23:26:58.612
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-19 11/11/22 23:26:58.637
    Nov 11 23:26:58.674: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Pending. Waiting for statefulset controller to delete.
    Nov 11 23:26:58.717: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 11 23:26:58.747: INFO: Observed stateful pod in namespace: statefulset-19, name: ss-0, uid: 2b898e37-7c16-46b0-b7d2-346882dc10e5, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 11 23:26:58.760: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-19
    STEP: Removing pod with conflicting port in namespace statefulset-19 11/11/22 23:26:58.76
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-19 and will be in running state 11/11/22 23:26:58.82
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 11 23:27:02.899: INFO: Deleting all statefulset in ns statefulset-19
    Nov 11 23:27:02.919: INFO: Scaling statefulset ss to 0
    Nov 11 23:27:13.002: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:27:13.020: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 11 23:27:13.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-19" for this suite. 11/11/22 23:27:13.108
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:13.134
Nov 11 23:27:13.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename ingressclass 11/11/22 23:27:13.136
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:13.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:13.202
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 11/11/22 23:27:13.218
STEP: getting /apis/networking.k8s.io 11/11/22 23:27:13.232
STEP: getting /apis/networking.k8s.iov1 11/11/22 23:27:13.241
STEP: creating 11/11/22 23:27:13.248
STEP: getting 11/11/22 23:27:13.327
STEP: listing 11/11/22 23:27:13.345
STEP: watching 11/11/22 23:27:13.364
Nov 11 23:27:13.364: INFO: starting watch
STEP: patching 11/11/22 23:27:13.371
STEP: updating 11/11/22 23:27:13.391
Nov 11 23:27:13.416: INFO: waiting for watch events with expected annotations
Nov 11 23:27:13.416: INFO: saw patched and updated annotations
STEP: deleting 11/11/22 23:27:13.416
STEP: deleting a collection 11/11/22 23:27:13.498
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Nov 11 23:27:13.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5517" for this suite. 11/11/22 23:27:13.631
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":53,"skipped":795,"failed":0}
------------------------------
• [0.521 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:13.134
    Nov 11 23:27:13.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename ingressclass 11/11/22 23:27:13.136
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:13.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:13.202
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 11/11/22 23:27:13.218
    STEP: getting /apis/networking.k8s.io 11/11/22 23:27:13.232
    STEP: getting /apis/networking.k8s.iov1 11/11/22 23:27:13.241
    STEP: creating 11/11/22 23:27:13.248
    STEP: getting 11/11/22 23:27:13.327
    STEP: listing 11/11/22 23:27:13.345
    STEP: watching 11/11/22 23:27:13.364
    Nov 11 23:27:13.364: INFO: starting watch
    STEP: patching 11/11/22 23:27:13.371
    STEP: updating 11/11/22 23:27:13.391
    Nov 11 23:27:13.416: INFO: waiting for watch events with expected annotations
    Nov 11 23:27:13.416: INFO: saw patched and updated annotations
    STEP: deleting 11/11/22 23:27:13.416
    STEP: deleting a collection 11/11/22 23:27:13.498
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Nov 11 23:27:13.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-5517" for this suite. 11/11/22 23:27:13.631
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:13.661
Nov 11 23:27:13.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename custom-resource-definition 11/11/22 23:27:13.664
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:13.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:13.738
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Nov 11 23:27:13.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:27:14.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2011" for this suite. 11/11/22 23:27:14.875
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":54,"skipped":809,"failed":0}
------------------------------
• [1.239 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:13.661
    Nov 11 23:27:13.661: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename custom-resource-definition 11/11/22 23:27:13.664
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:13.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:13.738
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Nov 11 23:27:13.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:27:14.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2011" for this suite. 11/11/22 23:27:14.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:14.921
Nov 11 23:27:14.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-runtime 11/11/22 23:27:14.923
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:14.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:14.995
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 11/11/22 23:27:15.014
STEP: wait for the container to reach Failed 11/11/22 23:27:15.059
STEP: get the container status 11/11/22 23:27:21.223
STEP: the container should be terminated 11/11/22 23:27:21.243
STEP: the termination message should be set 11/11/22 23:27:21.243
Nov 11 23:27:21.243: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/11/22 23:27:21.243
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 11 23:27:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1143" for this suite. 11/11/22 23:27:21.327
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":55,"skipped":854,"failed":0}
------------------------------
• [SLOW TEST] [6.443 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:14.921
    Nov 11 23:27:14.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-runtime 11/11/22 23:27:14.923
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:14.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:14.995
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 11/11/22 23:27:15.014
    STEP: wait for the container to reach Failed 11/11/22 23:27:15.059
    STEP: get the container status 11/11/22 23:27:21.223
    STEP: the container should be terminated 11/11/22 23:27:21.243
    STEP: the termination message should be set 11/11/22 23:27:21.243
    Nov 11 23:27:21.243: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/11/22 23:27:21.243
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 11 23:27:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1143" for this suite. 11/11/22 23:27:21.327
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:21.366
Nov 11 23:27:21.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:27:21.368
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.442
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 11/11/22 23:27:21.459
Nov 11 23:27:21.460: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-9273 proxy --unix-socket=/tmp/kubectl-proxy-unix560909493/test'
STEP: retrieving proxy /api/ output 11/11/22 23:27:21.572
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:27:21.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9273" for this suite. 11/11/22 23:27:21.6
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":56,"skipped":857,"failed":0}
------------------------------
• [0.260 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:21.366
    Nov 11 23:27:21.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:27:21.368
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.442
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 11/11/22 23:27:21.459
    Nov 11 23:27:21.460: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-9273 proxy --unix-socket=/tmp/kubectl-proxy-unix560909493/test'
    STEP: retrieving proxy /api/ output 11/11/22 23:27:21.572
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:27:21.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9273" for this suite. 11/11/22 23:27:21.6
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:21.628
Nov 11 23:27:21.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:27:21.63
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.693
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:27:21.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4804" for this suite. 11/11/22 23:27:21.746
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":57,"skipped":859,"failed":0}
------------------------------
• [0.142 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:21.628
    Nov 11 23:27:21.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:27:21.63
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.693
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:27:21.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4804" for this suite. 11/11/22 23:27:21.746
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:21.77
Nov 11 23:27:21.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename hostport 11/11/22 23:27:21.771
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.856
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/11/22 23:27:21.902
Nov 11 23:27:21.947: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-3977" to be "running and ready"
Nov 11 23:27:21.970: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.997595ms
Nov 11 23:27:21.970: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:23.991: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04412674s
Nov 11 23:27:23.991: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:25.991: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.044430544s
Nov 11 23:27:25.991: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 11 23:27:25.991: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.241.148.26 on the node which pod1 resides and expect scheduled 11/11/22 23:27:25.991
Nov 11 23:27:26.016: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-3977" to be "running and ready"
Nov 11 23:27:26.034: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.496922ms
Nov 11 23:27:26.034: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:28.052: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035566485s
Nov 11 23:27:28.053: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:30.055: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.038528618s
Nov 11 23:27:30.055: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 11 23:27:30.055: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.241.148.26 but use UDP protocol on the node which pod2 resides 11/11/22 23:27:30.055
Nov 11 23:27:30.080: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-3977" to be "running and ready"
Nov 11 23:27:30.099: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.910926ms
Nov 11 23:27:30.099: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:32.144: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064154188s
Nov 11 23:27:32.144: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:34.122: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.041574561s
Nov 11 23:27:34.122: INFO: The phase of Pod pod3 is Running (Ready = true)
Nov 11 23:27:34.123: INFO: Pod "pod3" satisfied condition "running and ready"
Nov 11 23:27:34.150: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-3977" to be "running and ready"
Nov 11 23:27:34.169: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 18.741115ms
Nov 11 23:27:34.170: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:36.190: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.039730302s
Nov 11 23:27:36.190: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Nov 11 23:27:36.190: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/11/22 23:27:36.214
Nov 11 23:27:36.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.241.148.26 http://127.0.0.1:54323/hostname] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:27:36.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:27:36.216: INFO: ExecWithOptions: Clientset creation
Nov 11 23:27:36.216: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.241.148.26+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.241.148.26, port: 54323 11/11/22 23:27:36.563
Nov 11 23:27:36.563: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.241.148.26:54323/hostname] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:27:36.563: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:27:36.563: INFO: ExecWithOptions: Clientset creation
Nov 11 23:27:36.563: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.241.148.26%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.241.148.26, port: 54323 UDP 11/11/22 23:27:36.833
Nov 11 23:27:36.833: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.241.148.26 54323] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:27:36.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:27:36.834: INFO: ExecWithOptions: Clientset creation
Nov 11 23:27:36.835: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.241.148.26+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Nov 11 23:27:42.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-3977" for this suite. 11/11/22 23:27:42.092
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":58,"skipped":861,"failed":0}
------------------------------
• [SLOW TEST] [20.347 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:21.77
    Nov 11 23:27:21.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename hostport 11/11/22 23:27:21.771
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:21.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:21.856
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/11/22 23:27:21.902
    Nov 11 23:27:21.947: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-3977" to be "running and ready"
    Nov 11 23:27:21.970: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.997595ms
    Nov 11 23:27:21.970: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:23.991: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04412674s
    Nov 11 23:27:23.991: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:25.991: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.044430544s
    Nov 11 23:27:25.991: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 11 23:27:25.991: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.241.148.26 on the node which pod1 resides and expect scheduled 11/11/22 23:27:25.991
    Nov 11 23:27:26.016: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-3977" to be "running and ready"
    Nov 11 23:27:26.034: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.496922ms
    Nov 11 23:27:26.034: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:28.052: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035566485s
    Nov 11 23:27:28.053: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:30.055: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.038528618s
    Nov 11 23:27:30.055: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 11 23:27:30.055: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.241.148.26 but use UDP protocol on the node which pod2 resides 11/11/22 23:27:30.055
    Nov 11 23:27:30.080: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-3977" to be "running and ready"
    Nov 11 23:27:30.099: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.910926ms
    Nov 11 23:27:30.099: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:32.144: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064154188s
    Nov 11 23:27:32.144: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:34.122: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.041574561s
    Nov 11 23:27:34.122: INFO: The phase of Pod pod3 is Running (Ready = true)
    Nov 11 23:27:34.123: INFO: Pod "pod3" satisfied condition "running and ready"
    Nov 11 23:27:34.150: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-3977" to be "running and ready"
    Nov 11 23:27:34.169: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 18.741115ms
    Nov 11 23:27:34.170: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:36.190: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.039730302s
    Nov 11 23:27:36.190: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Nov 11 23:27:36.190: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/11/22 23:27:36.214
    Nov 11 23:27:36.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.241.148.26 http://127.0.0.1:54323/hostname] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:27:36.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:27:36.216: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:27:36.216: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.241.148.26+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.241.148.26, port: 54323 11/11/22 23:27:36.563
    Nov 11 23:27:36.563: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.241.148.26:54323/hostname] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:27:36.563: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:27:36.563: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:27:36.563: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.241.148.26%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.241.148.26, port: 54323 UDP 11/11/22 23:27:36.833
    Nov 11 23:27:36.833: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.241.148.26 54323] Namespace:hostport-3977 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:27:36.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:27:36.834: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:27:36.835: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/hostport-3977/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.241.148.26+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Nov 11 23:27:42.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-3977" for this suite. 11/11/22 23:27:42.092
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:42.12
Nov 11 23:27:42.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sysctl 11/11/22 23:27:42.122
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.202
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 11/11/22 23:27:42.226
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 11 23:27:42.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-2615" for this suite. 11/11/22 23:27:42.284
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":59,"skipped":873,"failed":0}
------------------------------
• [0.188 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:42.12
    Nov 11 23:27:42.120: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sysctl 11/11/22 23:27:42.122
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.202
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 11/11/22 23:27:42.226
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 11 23:27:42.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-2615" for this suite. 11/11/22 23:27:42.284
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:42.315
Nov 11 23:27:42.315: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:27:42.316
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.386
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 11/11/22 23:27:42.408
Nov 11 23:27:42.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-4112 cluster-info'
Nov 11 23:27:42.585: INFO: stderr: ""
Nov 11 23:27:42.585: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:27:42.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4112" for this suite. 11/11/22 23:27:42.608
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":60,"skipped":879,"failed":0}
------------------------------
• [0.327 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:42.315
    Nov 11 23:27:42.315: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:27:42.316
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.386
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 11/11/22 23:27:42.408
    Nov 11 23:27:42.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-4112 cluster-info'
    Nov 11 23:27:42.585: INFO: stderr: ""
    Nov 11 23:27:42.585: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:27:42.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4112" for this suite. 11/11/22 23:27:42.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:42.644
Nov 11 23:27:42.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:27:42.646
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.709
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-3e4bfbdd-d688-43f7-bb18-2069a82d0e3e 11/11/22 23:27:42.772
STEP: Creating secret with name s-test-opt-upd-e576e590-1056-4e8e-9a7a-0915163741ae 11/11/22 23:27:42.802
STEP: Creating the pod 11/11/22 23:27:42.822
Nov 11 23:27:42.860: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171" in namespace "projected-934" to be "running and ready"
Nov 11 23:27:42.896: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Pending", Reason="", readiness=false. Elapsed: 36.257774ms
Nov 11 23:27:42.896: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:44.917: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057001761s
Nov 11 23:27:44.917: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:27:46.919: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Running", Reason="", readiness=true. Elapsed: 4.058673682s
Nov 11 23:27:46.919: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Running (Ready = true)
Nov 11 23:27:46.919: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-3e4bfbdd-d688-43f7-bb18-2069a82d0e3e 11/11/22 23:27:47.067
STEP: Updating secret s-test-opt-upd-e576e590-1056-4e8e-9a7a-0915163741ae 11/11/22 23:27:47.098
STEP: Creating secret with name s-test-opt-create-30f76b31-919a-4c6e-b28a-7a7d9f0caa1f 11/11/22 23:27:47.121
STEP: waiting to observe update in volume 11/11/22 23:27:47.144
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 11 23:27:51.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-934" for this suite. 11/11/22 23:27:51.362
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":61,"skipped":895,"failed":0}
------------------------------
• [SLOW TEST] [8.743 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:42.644
    Nov 11 23:27:42.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:27:42.646
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:42.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:42.709
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-3e4bfbdd-d688-43f7-bb18-2069a82d0e3e 11/11/22 23:27:42.772
    STEP: Creating secret with name s-test-opt-upd-e576e590-1056-4e8e-9a7a-0915163741ae 11/11/22 23:27:42.802
    STEP: Creating the pod 11/11/22 23:27:42.822
    Nov 11 23:27:42.860: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171" in namespace "projected-934" to be "running and ready"
    Nov 11 23:27:42.896: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Pending", Reason="", readiness=false. Elapsed: 36.257774ms
    Nov 11 23:27:42.896: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:44.917: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057001761s
    Nov 11 23:27:44.917: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:27:46.919: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171": Phase="Running", Reason="", readiness=true. Elapsed: 4.058673682s
    Nov 11 23:27:46.919: INFO: The phase of Pod pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171 is Running (Ready = true)
    Nov 11 23:27:46.919: INFO: Pod "pod-projected-secrets-ebb4a149-aeed-46b7-ac51-f6756f828171" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-3e4bfbdd-d688-43f7-bb18-2069a82d0e3e 11/11/22 23:27:47.067
    STEP: Updating secret s-test-opt-upd-e576e590-1056-4e8e-9a7a-0915163741ae 11/11/22 23:27:47.098
    STEP: Creating secret with name s-test-opt-create-30f76b31-919a-4c6e-b28a-7a7d9f0caa1f 11/11/22 23:27:47.121
    STEP: waiting to observe update in volume 11/11/22 23:27:47.144
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 11 23:27:51.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-934" for this suite. 11/11/22 23:27:51.362
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:51.394
Nov 11 23:27:51.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:27:51.397
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:51.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:51.527
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:27:51.603
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:27:53.633
STEP: Deploying the webhook pod 11/11/22 23:27:53.664
STEP: Wait for the deployment to be ready 11/11/22 23:27:53.705
Nov 11 23:27:53.749: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:27:55.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:27:57.837
STEP: Verifying the service has paired with the endpoint 11/11/22 23:27:57.878
Nov 11 23:27:58.880: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/11/22 23:27:58.894
STEP: create a pod that should be updated by the webhook 11/11/22 23:27:59.016
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:27:59.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3714" for this suite. 11/11/22 23:27:59.245
STEP: Destroying namespace "webhook-3714-markers" for this suite. 11/11/22 23:27:59.27
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":62,"skipped":920,"failed":0}
------------------------------
• [SLOW TEST] [8.047 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:51.394
    Nov 11 23:27:51.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:27:51.397
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:51.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:51.527
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:27:51.603
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:27:53.633
    STEP: Deploying the webhook pod 11/11/22 23:27:53.664
    STEP: Wait for the deployment to be ready 11/11/22 23:27:53.705
    Nov 11 23:27:53.749: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:27:55.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 27, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:27:57.837
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:27:57.878
    Nov 11 23:27:58.880: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/11/22 23:27:58.894
    STEP: create a pod that should be updated by the webhook 11/11/22 23:27:59.016
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:27:59.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3714" for this suite. 11/11/22 23:27:59.245
    STEP: Destroying namespace "webhook-3714-markers" for this suite. 11/11/22 23:27:59.27
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:27:59.453
Nov 11 23:27:59.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/11/22 23:27:59.455
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:59.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:59.548
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 11/11/22 23:27:59.568
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:27:59.59
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:27:59.591
STEP: creating a pod to probe DNS 11/11/22 23:27:59.591
STEP: submitting the pod to kubernetes 11/11/22 23:27:59.591
Nov 11 23:27:59.633: INFO: Waiting up to 15m0s for pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf" in namespace "dns-1797" to be "running"
Nov 11 23:27:59.655: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.406182ms
Nov 11 23:28:01.696: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062957553s
Nov 11 23:28:03.677: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044223503s
Nov 11 23:28:05.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043462461s
Nov 11 23:28:07.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042883471s
Nov 11 23:28:09.675: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041613644s
Nov 11 23:28:11.700: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.067475248s
Nov 11 23:28:13.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Running", Reason="", readiness=true. Elapsed: 14.042568053s
Nov 11 23:28:13.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf" satisfied condition "running"
STEP: retrieving the pod 11/11/22 23:28:13.676
STEP: looking for the results for each expected name from probers 11/11/22 23:28:13.697
Nov 11 23:28:13.789: INFO: DNS probes using dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf succeeded

STEP: deleting the pod 11/11/22 23:28:13.789
STEP: changing the externalName to bar.example.com 11/11/22 23:28:13.847
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:28:13.881
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:28:13.881
STEP: creating a second pod to probe DNS 11/11/22 23:28:13.881
STEP: submitting the pod to kubernetes 11/11/22 23:28:13.882
Nov 11 23:28:13.906: INFO: Waiting up to 15m0s for pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb" in namespace "dns-1797" to be "running"
Nov 11 23:28:13.926: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 19.219375ms
Nov 11 23:28:15.957: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050306997s
Nov 11 23:28:17.948: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Running", Reason="", readiness=true. Elapsed: 4.041698871s
Nov 11 23:28:17.948: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb" satisfied condition "running"
STEP: retrieving the pod 11/11/22 23:28:17.948
STEP: looking for the results for each expected name from probers 11/11/22 23:28:17.968
Nov 11 23:28:18.033: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:18.059: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:18.059: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

Nov 11 23:28:23.087: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:23.115: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:23.115: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

Nov 11 23:28:28.090: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:28.118: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:28.118: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

Nov 11 23:28:33.087: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:33.114: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 11 23:28:33.114: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

Nov 11 23:28:38.116: INFO: DNS probes using dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb succeeded

STEP: deleting the pod 11/11/22 23:28:38.116
STEP: changing the service to type=ClusterIP 11/11/22 23:28:38.166
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:28:38.235
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
 11/11/22 23:28:38.235
STEP: creating a third pod to probe DNS 11/11/22 23:28:38.235
STEP: submitting the pod to kubernetes 11/11/22 23:28:38.252
Nov 11 23:28:38.305: INFO: Waiting up to 15m0s for pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d" in namespace "dns-1797" to be "running"
Nov 11 23:28:38.325: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.076975ms
Nov 11 23:28:40.346: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041447483s
Nov 11 23:28:42.356: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Running", Reason="", readiness=true. Elapsed: 4.051629203s
Nov 11 23:28:42.357: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d" satisfied condition "running"
STEP: retrieving the pod 11/11/22 23:28:42.357
STEP: looking for the results for each expected name from probers 11/11/22 23:28:42.379
Nov 11 23:28:42.480: INFO: DNS probes using dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d succeeded

STEP: deleting the pod 11/11/22 23:28:42.48
STEP: deleting the test externalName service 11/11/22 23:28:42.558
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 11 23:28:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1797" for this suite. 11/11/22 23:28:42.632
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":63,"skipped":932,"failed":0}
------------------------------
• [SLOW TEST] [43.206 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:27:59.453
    Nov 11 23:27:59.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/11/22 23:27:59.455
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:27:59.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:27:59.548
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 11/11/22 23:27:59.568
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:27:59.59
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:27:59.591
    STEP: creating a pod to probe DNS 11/11/22 23:27:59.591
    STEP: submitting the pod to kubernetes 11/11/22 23:27:59.591
    Nov 11 23:27:59.633: INFO: Waiting up to 15m0s for pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf" in namespace "dns-1797" to be "running"
    Nov 11 23:27:59.655: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.406182ms
    Nov 11 23:28:01.696: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062957553s
    Nov 11 23:28:03.677: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044223503s
    Nov 11 23:28:05.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043462461s
    Nov 11 23:28:07.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042883471s
    Nov 11 23:28:09.675: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041613644s
    Nov 11 23:28:11.700: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.067475248s
    Nov 11 23:28:13.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf": Phase="Running", Reason="", readiness=true. Elapsed: 14.042568053s
    Nov 11 23:28:13.676: INFO: Pod "dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf" satisfied condition "running"
    STEP: retrieving the pod 11/11/22 23:28:13.676
    STEP: looking for the results for each expected name from probers 11/11/22 23:28:13.697
    Nov 11 23:28:13.789: INFO: DNS probes using dns-test-706b5724-dab2-4e60-bad0-c59d170edfcf succeeded

    STEP: deleting the pod 11/11/22 23:28:13.789
    STEP: changing the externalName to bar.example.com 11/11/22 23:28:13.847
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:28:13.881
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:28:13.881
    STEP: creating a second pod to probe DNS 11/11/22 23:28:13.881
    STEP: submitting the pod to kubernetes 11/11/22 23:28:13.882
    Nov 11 23:28:13.906: INFO: Waiting up to 15m0s for pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb" in namespace "dns-1797" to be "running"
    Nov 11 23:28:13.926: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 19.219375ms
    Nov 11 23:28:15.957: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050306997s
    Nov 11 23:28:17.948: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb": Phase="Running", Reason="", readiness=true. Elapsed: 4.041698871s
    Nov 11 23:28:17.948: INFO: Pod "dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb" satisfied condition "running"
    STEP: retrieving the pod 11/11/22 23:28:17.948
    STEP: looking for the results for each expected name from probers 11/11/22 23:28:17.968
    Nov 11 23:28:18.033: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:18.059: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:18.059: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

    Nov 11 23:28:23.087: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:23.115: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:23.115: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

    Nov 11 23:28:28.090: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:28.118: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:28.118: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

    Nov 11 23:28:33.087: INFO: File wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:33.114: INFO: File jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local from pod  dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 11 23:28:33.114: INFO: Lookups using dns-1797/dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb failed for: [wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local]

    Nov 11 23:28:38.116: INFO: DNS probes using dns-test-24730a38-077a-4c11-8a9b-13dac4e4cbdb succeeded

    STEP: deleting the pod 11/11/22 23:28:38.116
    STEP: changing the service to type=ClusterIP 11/11/22 23:28:38.166
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:28:38.235
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1797.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1797.svc.cluster.local; sleep 1; done
     11/11/22 23:28:38.235
    STEP: creating a third pod to probe DNS 11/11/22 23:28:38.235
    STEP: submitting the pod to kubernetes 11/11/22 23:28:38.252
    Nov 11 23:28:38.305: INFO: Waiting up to 15m0s for pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d" in namespace "dns-1797" to be "running"
    Nov 11 23:28:38.325: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.076975ms
    Nov 11 23:28:40.346: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041447483s
    Nov 11 23:28:42.356: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d": Phase="Running", Reason="", readiness=true. Elapsed: 4.051629203s
    Nov 11 23:28:42.357: INFO: Pod "dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d" satisfied condition "running"
    STEP: retrieving the pod 11/11/22 23:28:42.357
    STEP: looking for the results for each expected name from probers 11/11/22 23:28:42.379
    Nov 11 23:28:42.480: INFO: DNS probes using dns-test-d9490ed0-d7be-4b07-8efd-b6a1b56f423d succeeded

    STEP: deleting the pod 11/11/22 23:28:42.48
    STEP: deleting the test externalName service 11/11/22 23:28:42.558
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 11 23:28:42.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1797" for this suite. 11/11/22 23:28:42.632
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:28:42.671
Nov 11 23:28:42.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:28:42.673
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:28:42.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:28:42.754
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:28:42.772
Nov 11 23:28:42.823: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06" in namespace "downward-api-4025" to be "Succeeded or Failed"
Nov 11 23:28:42.845: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 21.870765ms
Nov 11 23:28:44.869: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046756938s
Nov 11 23:28:46.866: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043089731s
Nov 11 23:28:48.865: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04278653s
STEP: Saw pod success 11/11/22 23:28:48.866
Nov 11 23:28:48.866: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06" satisfied condition "Succeeded or Failed"
Nov 11 23:28:48.887: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 container client-container: <nil>
STEP: delete the pod 11/11/22 23:28:48.966
Nov 11 23:28:49.048: INFO: Waiting for pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 to disappear
Nov 11 23:28:49.076: INFO: Pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 11 23:28:49.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4025" for this suite. 11/11/22 23:28:49.123
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":64,"skipped":962,"failed":0}
------------------------------
• [SLOW TEST] [6.477 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:28:42.671
    Nov 11 23:28:42.671: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:28:42.673
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:28:42.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:28:42.754
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:28:42.772
    Nov 11 23:28:42.823: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06" in namespace "downward-api-4025" to be "Succeeded or Failed"
    Nov 11 23:28:42.845: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 21.870765ms
    Nov 11 23:28:44.869: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046756938s
    Nov 11 23:28:46.866: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043089731s
    Nov 11 23:28:48.865: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04278653s
    STEP: Saw pod success 11/11/22 23:28:48.866
    Nov 11 23:28:48.866: INFO: Pod "downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06" satisfied condition "Succeeded or Failed"
    Nov 11 23:28:48.887: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:28:48.966
    Nov 11 23:28:49.048: INFO: Waiting for pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 to disappear
    Nov 11 23:28:49.076: INFO: Pod downwardapi-volume-e696f60b-f477-4b35-ba08-4c2fb3272a06 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 11 23:28:49.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4025" for this suite. 11/11/22 23:28:49.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:28:49.158
Nov 11 23:28:49.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:28:49.16
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:28:49.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:28:49.242
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 11/11/22 23:28:49.259
Nov 11 23:28:49.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: rename a version 11/11/22 23:29:06.86
STEP: check the new version name is served 11/11/22 23:29:06.908
STEP: check the old version name is removed 11/11/22 23:29:14.093
STEP: check the other version is not changed 11/11/22 23:29:17.207
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:29:27.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4985" for this suite. 11/11/22 23:29:27.549
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":65,"skipped":997,"failed":0}
------------------------------
• [SLOW TEST] [38.421 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:28:49.158
    Nov 11 23:28:49.158: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:28:49.16
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:28:49.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:28:49.242
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 11/11/22 23:28:49.259
    Nov 11 23:28:49.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: rename a version 11/11/22 23:29:06.86
    STEP: check the new version name is served 11/11/22 23:29:06.908
    STEP: check the old version name is removed 11/11/22 23:29:14.093
    STEP: check the other version is not changed 11/11/22 23:29:17.207
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:29:27.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4985" for this suite. 11/11/22 23:29:27.549
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:29:27.581
Nov 11 23:29:27.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename containers 11/11/22 23:29:27.586
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:27.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:27.648
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 11/11/22 23:29:27.659
Nov 11 23:29:27.689: INFO: Waiting up to 5m0s for pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b" in namespace "containers-7844" to be "Succeeded or Failed"
Nov 11 23:29:27.703: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.976235ms
Nov 11 23:29:29.721: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031802857s
Nov 11 23:29:31.720: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030566971s
Nov 11 23:29:33.762: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.072693386s
STEP: Saw pod success 11/11/22 23:29:33.762
Nov 11 23:29:33.763: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b" satisfied condition "Succeeded or Failed"
Nov 11 23:29:33.778: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:29:33.874
Nov 11 23:29:33.940: INFO: Waiting for pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b to disappear
Nov 11 23:29:33.956: INFO: Pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 11 23:29:33.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7844" for this suite. 11/11/22 23:29:33.99
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":66,"skipped":1000,"failed":0}
------------------------------
• [SLOW TEST] [6.453 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:29:27.581
    Nov 11 23:29:27.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename containers 11/11/22 23:29:27.586
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:27.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:27.648
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 11/11/22 23:29:27.659
    Nov 11 23:29:27.689: INFO: Waiting up to 5m0s for pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b" in namespace "containers-7844" to be "Succeeded or Failed"
    Nov 11 23:29:27.703: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.976235ms
    Nov 11 23:29:29.721: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031802857s
    Nov 11 23:29:31.720: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030566971s
    Nov 11 23:29:33.762: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.072693386s
    STEP: Saw pod success 11/11/22 23:29:33.762
    Nov 11 23:29:33.763: INFO: Pod "client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b" satisfied condition "Succeeded or Failed"
    Nov 11 23:29:33.778: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:29:33.874
    Nov 11 23:29:33.940: INFO: Waiting for pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b to disappear
    Nov 11 23:29:33.956: INFO: Pod client-containers-12804d2b-1909-4d18-b2cc-4dbb34a7752b no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 11 23:29:33.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7844" for this suite. 11/11/22 23:29:33.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:29:34.038
Nov 11 23:29:34.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:29:34.04
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:34.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:34.112
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:29:34.192
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:29:35.666
STEP: Deploying the webhook pod 11/11/22 23:29:35.691
STEP: Wait for the deployment to be ready 11/11/22 23:29:35.72
Nov 11 23:29:35.754: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:29:37.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:29:39.816
STEP: Verifying the service has paired with the endpoint 11/11/22 23:29:39.861
Nov 11 23:29:40.864: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Nov 11 23:29:40.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1650-crds.webhook.example.com via the AdmissionRegistration API 11/11/22 23:29:41.401
STEP: Creating a custom resource that should be mutated by the webhook 11/11/22 23:29:41.475
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:29:44.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5943" for this suite. 11/11/22 23:29:44.163
STEP: Destroying namespace "webhook-5943-markers" for this suite. 11/11/22 23:29:44.192
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":67,"skipped":1018,"failed":0}
------------------------------
• [SLOW TEST] [10.304 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:29:34.038
    Nov 11 23:29:34.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:29:34.04
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:34.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:34.112
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:29:34.192
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:29:35.666
    STEP: Deploying the webhook pod 11/11/22 23:29:35.691
    STEP: Wait for the deployment to be ready 11/11/22 23:29:35.72
    Nov 11 23:29:35.754: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:29:37.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 29, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:29:39.816
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:29:39.861
    Nov 11 23:29:40.864: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Nov 11 23:29:40.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1650-crds.webhook.example.com via the AdmissionRegistration API 11/11/22 23:29:41.401
    STEP: Creating a custom resource that should be mutated by the webhook 11/11/22 23:29:41.475
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:29:44.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5943" for this suite. 11/11/22 23:29:44.163
    STEP: Destroying namespace "webhook-5943-markers" for this suite. 11/11/22 23:29:44.192
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:29:44.344
Nov 11 23:29:44.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:29:44.346
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:44.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:44.395
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3746 11/11/22 23:29:44.405
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 11/11/22 23:29:44.415
Nov 11 23:29:44.447: INFO: Found 0 stateful pods, waiting for 3
Nov 11 23:29:54.465: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:29:54.465: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:29:54.465: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:29:54.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:29:55.002: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:29:55.002: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:29:55.002: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/11/22 23:30:05.065
Nov 11 23:30:05.095: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/11/22 23:30:05.095
STEP: Updating Pods in reverse ordinal order 11/11/22 23:30:15.144
Nov 11 23:30:15.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:30:15.644: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:30:15.644: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:30:15.644: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:30:35.726: INFO: Waiting for StatefulSet statefulset-3746/ss2 to complete update
Nov 11 23:30:35.727: INFO: Waiting for Pod statefulset-3746/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Rolling back to a previous revision 11/11/22 23:30:45.756
Nov 11 23:30:45.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:30:46.134: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:30:46.134: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:30:46.134: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:30:56.215: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 11/11/22 23:31:06.268
Nov 11 23:31:06.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:31:06.757: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:31:06.758: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:31:06.758: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:31:16.829: INFO: Waiting for StatefulSet statefulset-3746/ss2 to complete update
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 11 23:31:26.854: INFO: Deleting all statefulset in ns statefulset-3746
Nov 11 23:31:26.863: INFO: Scaling statefulset ss2 to 0
Nov 11 23:31:36.939: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:31:36.948: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 11 23:31:36.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3746" for this suite. 11/11/22 23:31:36.996
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":68,"skipped":1037,"failed":0}
------------------------------
• [SLOW TEST] [112.678 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:29:44.344
    Nov 11 23:29:44.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:29:44.346
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:29:44.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:29:44.395
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3746 11/11/22 23:29:44.405
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 11/11/22 23:29:44.415
    Nov 11 23:29:44.447: INFO: Found 0 stateful pods, waiting for 3
    Nov 11 23:29:54.465: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:29:54.465: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:29:54.465: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:29:54.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:29:55.002: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:29:55.002: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:29:55.002: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/11/22 23:30:05.065
    Nov 11 23:30:05.095: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/11/22 23:30:05.095
    STEP: Updating Pods in reverse ordinal order 11/11/22 23:30:15.144
    Nov 11 23:30:15.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:30:15.644: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:30:15.644: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:30:15.644: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:30:35.726: INFO: Waiting for StatefulSet statefulset-3746/ss2 to complete update
    Nov 11 23:30:35.727: INFO: Waiting for Pod statefulset-3746/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Rolling back to a previous revision 11/11/22 23:30:45.756
    Nov 11 23:30:45.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:30:46.134: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:30:46.134: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:30:46.134: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:30:56.215: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 11/11/22 23:31:06.268
    Nov 11 23:31:06.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-3746 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:31:06.757: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:31:06.758: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:31:06.758: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:31:16.829: INFO: Waiting for StatefulSet statefulset-3746/ss2 to complete update
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 11 23:31:26.854: INFO: Deleting all statefulset in ns statefulset-3746
    Nov 11 23:31:26.863: INFO: Scaling statefulset ss2 to 0
    Nov 11 23:31:36.939: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:31:36.948: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 11 23:31:36.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3746" for this suite. 11/11/22 23:31:36.996
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:31:37.033
Nov 11 23:31:37.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename limitrange 11/11/22 23:31:37.036
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:37.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:37.11
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 11/11/22 23:31:37.122
STEP: Setting up watch 11/11/22 23:31:37.122
STEP: Submitting a LimitRange 11/11/22 23:31:37.237
STEP: Verifying LimitRange creation was observed 11/11/22 23:31:37.26
STEP: Fetching the LimitRange to ensure it has proper values 11/11/22 23:31:37.261
Nov 11 23:31:37.273: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 11 23:31:37.273: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 11/11/22 23:31:37.273
STEP: Ensuring Pod has resource requirements applied from LimitRange 11/11/22 23:31:37.29
Nov 11 23:31:37.307: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 11 23:31:37.307: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 11/11/22 23:31:37.307
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/11/22 23:31:37.324
Nov 11 23:31:37.341: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov 11 23:31:37.341: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 11/11/22 23:31:37.341
STEP: Failing to create a Pod with more than max resources 11/11/22 23:31:37.348
STEP: Updating a LimitRange 11/11/22 23:31:37.353
STEP: Verifying LimitRange updating is effective 11/11/22 23:31:37.386
STEP: Creating a Pod with less than former min resources 11/11/22 23:31:39.402
STEP: Failing to create a Pod with more than max resources 11/11/22 23:31:39.42
STEP: Deleting a LimitRange 11/11/22 23:31:39.425
STEP: Verifying the LimitRange was deleted 11/11/22 23:31:39.455
Nov 11 23:31:44.469: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 11/11/22 23:31:44.469
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Nov 11 23:31:44.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2085" for this suite. 11/11/22 23:31:44.512
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":69,"skipped":1041,"failed":0}
------------------------------
• [SLOW TEST] [7.507 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:31:37.033
    Nov 11 23:31:37.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename limitrange 11/11/22 23:31:37.036
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:37.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:37.11
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 11/11/22 23:31:37.122
    STEP: Setting up watch 11/11/22 23:31:37.122
    STEP: Submitting a LimitRange 11/11/22 23:31:37.237
    STEP: Verifying LimitRange creation was observed 11/11/22 23:31:37.26
    STEP: Fetching the LimitRange to ensure it has proper values 11/11/22 23:31:37.261
    Nov 11 23:31:37.273: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 11 23:31:37.273: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 11/11/22 23:31:37.273
    STEP: Ensuring Pod has resource requirements applied from LimitRange 11/11/22 23:31:37.29
    Nov 11 23:31:37.307: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 11 23:31:37.307: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 11/11/22 23:31:37.307
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/11/22 23:31:37.324
    Nov 11 23:31:37.341: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Nov 11 23:31:37.341: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 11/11/22 23:31:37.341
    STEP: Failing to create a Pod with more than max resources 11/11/22 23:31:37.348
    STEP: Updating a LimitRange 11/11/22 23:31:37.353
    STEP: Verifying LimitRange updating is effective 11/11/22 23:31:37.386
    STEP: Creating a Pod with less than former min resources 11/11/22 23:31:39.402
    STEP: Failing to create a Pod with more than max resources 11/11/22 23:31:39.42
    STEP: Deleting a LimitRange 11/11/22 23:31:39.425
    STEP: Verifying the LimitRange was deleted 11/11/22 23:31:39.455
    Nov 11 23:31:44.469: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 11/11/22 23:31:44.469
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Nov 11 23:31:44.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-2085" for this suite. 11/11/22 23:31:44.512
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:31:44.542
Nov 11 23:31:44.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:31:44.544
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:44.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:44.616
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 11/11/22 23:31:44.628
Nov 11 23:31:44.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 create -f -'
Nov 11 23:31:45.930: INFO: stderr: ""
Nov 11 23:31:45.930: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:31:45.93
Nov 11 23:31:45.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:31:46.146: INFO: stderr: ""
Nov 11 23:31:46.146: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
Nov 11 23:31:46.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:31:46.311: INFO: stderr: ""
Nov 11 23:31:46.311: INFO: stdout: ""
Nov 11 23:31:46.311: INFO: update-demo-nautilus-c7r2f is created but not running
Nov 11 23:31:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:31:51.716: INFO: stderr: ""
Nov 11 23:31:51.716: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
Nov 11 23:31:51.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:31:51.918: INFO: stderr: ""
Nov 11 23:31:51.918: INFO: stdout: ""
Nov 11 23:31:51.918: INFO: update-demo-nautilus-c7r2f is created but not running
Nov 11 23:31:56.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:31:57.059: INFO: stderr: ""
Nov 11 23:31:57.059: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
Nov 11 23:31:57.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:31:57.217: INFO: stderr: ""
Nov 11 23:31:57.217: INFO: stdout: "true"
Nov 11 23:31:57.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:31:57.347: INFO: stderr: ""
Nov 11 23:31:57.347: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:31:57.347: INFO: validating pod update-demo-nautilus-c7r2f
Nov 11 23:31:57.426: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:31:57.426: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:31:57.426: INFO: update-demo-nautilus-c7r2f is verified up and running
Nov 11 23:31:57.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-p9q9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:31:57.552: INFO: stderr: ""
Nov 11 23:31:57.552: INFO: stdout: "true"
Nov 11 23:31:57.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-p9q9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:31:57.711: INFO: stderr: ""
Nov 11 23:31:57.711: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:31:57.711: INFO: validating pod update-demo-nautilus-p9q9n
Nov 11 23:31:57.761: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:31:57.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:31:57.762: INFO: update-demo-nautilus-p9q9n is verified up and running
STEP: using delete to clean up resources 11/11/22 23:31:57.762
Nov 11 23:31:57.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 delete --grace-period=0 --force -f -'
Nov 11 23:31:57.944: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:31:57.944: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 11 23:31:57.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get rc,svc -l name=update-demo --no-headers'
Nov 11 23:31:58.208: INFO: stderr: "No resources found in kubectl-6609 namespace.\n"
Nov 11 23:31:58.208: INFO: stdout: ""
Nov 11 23:31:58.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 23:31:58.487: INFO: stderr: ""
Nov 11 23:31:58.487: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:31:58.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6609" for this suite. 11/11/22 23:31:58.506
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":70,"skipped":1041,"failed":0}
------------------------------
• [SLOW TEST] [13.993 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:31:44.542
    Nov 11 23:31:44.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:31:44.544
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:44.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:44.616
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 11/11/22 23:31:44.628
    Nov 11 23:31:44.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 create -f -'
    Nov 11 23:31:45.930: INFO: stderr: ""
    Nov 11 23:31:45.930: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:31:45.93
    Nov 11 23:31:45.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:31:46.146: INFO: stderr: ""
    Nov 11 23:31:46.146: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
    Nov 11 23:31:46.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:31:46.311: INFO: stderr: ""
    Nov 11 23:31:46.311: INFO: stdout: ""
    Nov 11 23:31:46.311: INFO: update-demo-nautilus-c7r2f is created but not running
    Nov 11 23:31:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:31:51.716: INFO: stderr: ""
    Nov 11 23:31:51.716: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
    Nov 11 23:31:51.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:31:51.918: INFO: stderr: ""
    Nov 11 23:31:51.918: INFO: stdout: ""
    Nov 11 23:31:51.918: INFO: update-demo-nautilus-c7r2f is created but not running
    Nov 11 23:31:56.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:31:57.059: INFO: stderr: ""
    Nov 11 23:31:57.059: INFO: stdout: "update-demo-nautilus-c7r2f update-demo-nautilus-p9q9n "
    Nov 11 23:31:57.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:31:57.217: INFO: stderr: ""
    Nov 11 23:31:57.217: INFO: stdout: "true"
    Nov 11 23:31:57.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-c7r2f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:31:57.347: INFO: stderr: ""
    Nov 11 23:31:57.347: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:31:57.347: INFO: validating pod update-demo-nautilus-c7r2f
    Nov 11 23:31:57.426: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:31:57.426: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:31:57.426: INFO: update-demo-nautilus-c7r2f is verified up and running
    Nov 11 23:31:57.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-p9q9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:31:57.552: INFO: stderr: ""
    Nov 11 23:31:57.552: INFO: stdout: "true"
    Nov 11 23:31:57.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods update-demo-nautilus-p9q9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:31:57.711: INFO: stderr: ""
    Nov 11 23:31:57.711: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:31:57.711: INFO: validating pod update-demo-nautilus-p9q9n
    Nov 11 23:31:57.761: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:31:57.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:31:57.762: INFO: update-demo-nautilus-p9q9n is verified up and running
    STEP: using delete to clean up resources 11/11/22 23:31:57.762
    Nov 11 23:31:57.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 delete --grace-period=0 --force -f -'
    Nov 11 23:31:57.944: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:31:57.944: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 11 23:31:57.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get rc,svc -l name=update-demo --no-headers'
    Nov 11 23:31:58.208: INFO: stderr: "No resources found in kubectl-6609 namespace.\n"
    Nov 11 23:31:58.208: INFO: stdout: ""
    Nov 11 23:31:58.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-6609 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 11 23:31:58.487: INFO: stderr: ""
    Nov 11 23:31:58.487: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:31:58.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6609" for this suite. 11/11/22 23:31:58.506
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:31:58.54
Nov 11 23:31:58.540: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context 11/11/22 23:31:58.543
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:58.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:58.619
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/11/22 23:31:58.629
Nov 11 23:31:58.656: INFO: Waiting up to 5m0s for pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938" in namespace "security-context-5669" to be "Succeeded or Failed"
Nov 11 23:31:58.672: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 15.681413ms
Nov 11 23:32:00.689: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032784909s
Nov 11 23:32:02.703: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04699263s
Nov 11 23:32:04.688: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03182838s
STEP: Saw pod success 11/11/22 23:32:04.688
Nov 11 23:32:04.688: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938" satisfied condition "Succeeded or Failed"
Nov 11 23:32:04.703: INFO: Trying to get logs from node 10.184.98.55 pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 container test-container: <nil>
STEP: delete the pod 11/11/22 23:32:04.768
Nov 11 23:32:04.827: INFO: Waiting for pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 to disappear
Nov 11 23:32:04.842: INFO: Pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 11 23:32:04.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5669" for this suite. 11/11/22 23:32:04.855
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":71,"skipped":1052,"failed":0}
------------------------------
• [SLOW TEST] [6.347 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:31:58.54
    Nov 11 23:31:58.540: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context 11/11/22 23:31:58.543
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:31:58.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:31:58.619
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/11/22 23:31:58.629
    Nov 11 23:31:58.656: INFO: Waiting up to 5m0s for pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938" in namespace "security-context-5669" to be "Succeeded or Failed"
    Nov 11 23:31:58.672: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 15.681413ms
    Nov 11 23:32:00.689: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032784909s
    Nov 11 23:32:02.703: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04699263s
    Nov 11 23:32:04.688: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03182838s
    STEP: Saw pod success 11/11/22 23:32:04.688
    Nov 11 23:32:04.688: INFO: Pod "security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938" satisfied condition "Succeeded or Failed"
    Nov 11 23:32:04.703: INFO: Trying to get logs from node 10.184.98.55 pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 container test-container: <nil>
    STEP: delete the pod 11/11/22 23:32:04.768
    Nov 11 23:32:04.827: INFO: Waiting for pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 to disappear
    Nov 11 23:32:04.842: INFO: Pod security-context-f77d5a96-5d1b-43e6-91fe-3c2a5de0a938 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 11 23:32:04.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5669" for this suite. 11/11/22 23:32:04.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:04.894
Nov 11 23:32:04.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:32:04.895
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:04.928
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:04.938
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:32:04.947
Nov 11 23:32:04.976: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404" in namespace "downward-api-2331" to be "Succeeded or Failed"
Nov 11 23:32:04.991: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Pending", Reason="", readiness=false. Elapsed: 15.029418ms
Nov 11 23:32:07.009: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Running", Reason="", readiness=true. Elapsed: 2.032562473s
Nov 11 23:32:09.010: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Running", Reason="", readiness=false. Elapsed: 4.033090465s
Nov 11 23:32:11.007: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030489706s
STEP: Saw pod success 11/11/22 23:32:11.007
Nov 11 23:32:11.008: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404" satisfied condition "Succeeded or Failed"
Nov 11 23:32:11.023: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 container client-container: <nil>
STEP: delete the pod 11/11/22 23:32:11.054
Nov 11 23:32:11.108: INFO: Waiting for pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 to disappear
Nov 11 23:32:11.123: INFO: Pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 11 23:32:11.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2331" for this suite. 11/11/22 23:32:11.137
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":72,"skipped":1075,"failed":0}
------------------------------
• [SLOW TEST] [6.270 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:04.894
    Nov 11 23:32:04.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:32:04.895
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:04.928
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:04.938
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:32:04.947
    Nov 11 23:32:04.976: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404" in namespace "downward-api-2331" to be "Succeeded or Failed"
    Nov 11 23:32:04.991: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Pending", Reason="", readiness=false. Elapsed: 15.029418ms
    Nov 11 23:32:07.009: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Running", Reason="", readiness=true. Elapsed: 2.032562473s
    Nov 11 23:32:09.010: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Running", Reason="", readiness=false. Elapsed: 4.033090465s
    Nov 11 23:32:11.007: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030489706s
    STEP: Saw pod success 11/11/22 23:32:11.007
    Nov 11 23:32:11.008: INFO: Pod "downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404" satisfied condition "Succeeded or Failed"
    Nov 11 23:32:11.023: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:32:11.054
    Nov 11 23:32:11.108: INFO: Waiting for pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 to disappear
    Nov 11 23:32:11.123: INFO: Pod downwardapi-volume-c5385702-ce40-4e01-9a5a-96526ed7d404 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 11 23:32:11.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2331" for this suite. 11/11/22 23:32:11.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:11.184
Nov 11 23:32:11.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:32:11.186
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:11.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:11.232
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-f778c2b8-b366-4cd9-9166-54c6a160257e 11/11/22 23:32:11.242
STEP: Creating a pod to test consume configMaps 11/11/22 23:32:11.261
Nov 11 23:32:11.290: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5" in namespace "projected-8782" to be "Succeeded or Failed"
Nov 11 23:32:11.305: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.674539ms
Nov 11 23:32:13.324: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033767345s
Nov 11 23:32:15.322: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031762147s
Nov 11 23:32:17.323: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033154648s
STEP: Saw pod success 11/11/22 23:32:17.323
Nov 11 23:32:17.324: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5" satisfied condition "Succeeded or Failed"
Nov 11 23:32:17.340: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:32:17.37
Nov 11 23:32:17.423: INFO: Waiting for pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 to disappear
Nov 11 23:32:17.439: INFO: Pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 11 23:32:17.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8782" for this suite. 11/11/22 23:32:17.452
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":73,"skipped":1122,"failed":0}
------------------------------
• [SLOW TEST] [6.296 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:11.184
    Nov 11 23:32:11.184: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:32:11.186
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:11.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:11.232
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-f778c2b8-b366-4cd9-9166-54c6a160257e 11/11/22 23:32:11.242
    STEP: Creating a pod to test consume configMaps 11/11/22 23:32:11.261
    Nov 11 23:32:11.290: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5" in namespace "projected-8782" to be "Succeeded or Failed"
    Nov 11 23:32:11.305: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.674539ms
    Nov 11 23:32:13.324: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033767345s
    Nov 11 23:32:15.322: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031762147s
    Nov 11 23:32:17.323: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033154648s
    STEP: Saw pod success 11/11/22 23:32:17.323
    Nov 11 23:32:17.324: INFO: Pod "pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5" satisfied condition "Succeeded or Failed"
    Nov 11 23:32:17.340: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:32:17.37
    Nov 11 23:32:17.423: INFO: Waiting for pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 to disappear
    Nov 11 23:32:17.439: INFO: Pod pod-projected-configmaps-f0c61459-7532-4de8-b2f2-4cf7c947ccc5 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 11 23:32:17.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8782" for this suite. 11/11/22 23:32:17.452
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:17.487
Nov 11 23:32:17.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:32:17.488
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:17.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:17.542
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/11/22 23:32:17.552
Nov 11 23:32:17.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 11 23:32:17.725: INFO: stderr: ""
Nov 11 23:32:17.725: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 11/11/22 23:32:17.725
Nov 11 23:32:17.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Nov 11 23:32:18.273: INFO: stderr: ""
Nov 11 23:32:18.273: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/11/22 23:32:18.273
Nov 11 23:32:18.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 delete pods e2e-test-httpd-pod'
Nov 11 23:32:21.442: INFO: stderr: ""
Nov 11 23:32:21.442: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:32:21.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-102" for this suite. 11/11/22 23:32:21.459
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":74,"skipped":1156,"failed":0}
------------------------------
• [4.003 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:17.487
    Nov 11 23:32:17.487: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:32:17.488
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:17.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:17.542
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/11/22 23:32:17.552
    Nov 11 23:32:17.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 11 23:32:17.725: INFO: stderr: ""
    Nov 11 23:32:17.725: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 11/11/22 23:32:17.725
    Nov 11 23:32:17.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Nov 11 23:32:18.273: INFO: stderr: ""
    Nov 11 23:32:18.273: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/11/22 23:32:18.273
    Nov 11 23:32:18.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-102 delete pods e2e-test-httpd-pod'
    Nov 11 23:32:21.442: INFO: stderr: ""
    Nov 11 23:32:21.442: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:32:21.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-102" for this suite. 11/11/22 23:32:21.459
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:21.49
Nov 11 23:32:21.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:32:21.493
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:21.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:21.554
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-5a5058c9-927e-4ca0-a498-c6c35209ceff 11/11/22 23:32:21.565
STEP: Creating a pod to test consume secrets 11/11/22 23:32:21.575
Nov 11 23:32:21.616: INFO: Waiting up to 5m0s for pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3" in namespace "secrets-4054" to be "Succeeded or Failed"
Nov 11 23:32:21.631: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.804029ms
Nov 11 23:32:23.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033037675s
Nov 11 23:32:25.674: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057415654s
Nov 11 23:32:27.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032233397s
STEP: Saw pod success 11/11/22 23:32:27.649
Nov 11 23:32:27.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3" satisfied condition "Succeeded or Failed"
Nov 11 23:32:27.666: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 container secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:32:27.707
Nov 11 23:32:27.754: INFO: Waiting for pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 to disappear
Nov 11 23:32:27.800: INFO: Pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:32:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4054" for this suite. 11/11/22 23:32:27.844
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":75,"skipped":1160,"failed":0}
------------------------------
• [SLOW TEST] [6.398 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:21.49
    Nov 11 23:32:21.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:32:21.493
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:21.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:21.554
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-5a5058c9-927e-4ca0-a498-c6c35209ceff 11/11/22 23:32:21.565
    STEP: Creating a pod to test consume secrets 11/11/22 23:32:21.575
    Nov 11 23:32:21.616: INFO: Waiting up to 5m0s for pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3" in namespace "secrets-4054" to be "Succeeded or Failed"
    Nov 11 23:32:21.631: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.804029ms
    Nov 11 23:32:23.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033037675s
    Nov 11 23:32:25.674: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057415654s
    Nov 11 23:32:27.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032233397s
    STEP: Saw pod success 11/11/22 23:32:27.649
    Nov 11 23:32:27.649: INFO: Pod "pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3" satisfied condition "Succeeded or Failed"
    Nov 11 23:32:27.666: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 container secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:32:27.707
    Nov 11 23:32:27.754: INFO: Waiting for pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 to disappear
    Nov 11 23:32:27.800: INFO: Pod pod-secrets-7d7f0623-506a-40ee-b9bf-cfa1281336b3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:32:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4054" for this suite. 11/11/22 23:32:27.844
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:27.891
Nov 11 23:32:27.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:32:27.892
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:27.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:27.972
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-3784/secret-test-ae32ec1d-0e58-4738-929a-0326589957f1 11/11/22 23:32:27.991
STEP: Creating a pod to test consume secrets 11/11/22 23:32:28.002
Nov 11 23:32:28.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04" in namespace "secrets-3784" to be "Succeeded or Failed"
Nov 11 23:32:28.052: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 15.278273ms
Nov 11 23:32:30.068: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031322045s
Nov 11 23:32:32.078: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041382502s
Nov 11 23:32:34.067: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030572356s
STEP: Saw pod success 11/11/22 23:32:34.067
Nov 11 23:32:34.068: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04" satisfied condition "Succeeded or Failed"
Nov 11 23:32:34.083: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 container env-test: <nil>
STEP: delete the pod 11/11/22 23:32:34.12
Nov 11 23:32:34.184: INFO: Waiting for pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 to disappear
Nov 11 23:32:34.198: INFO: Pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:32:34.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3784" for this suite. 11/11/22 23:32:34.21
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":76,"skipped":1191,"failed":0}
------------------------------
• [SLOW TEST] [6.349 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:27.891
    Nov 11 23:32:27.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:32:27.892
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:27.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:27.972
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-3784/secret-test-ae32ec1d-0e58-4738-929a-0326589957f1 11/11/22 23:32:27.991
    STEP: Creating a pod to test consume secrets 11/11/22 23:32:28.002
    Nov 11 23:32:28.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04" in namespace "secrets-3784" to be "Succeeded or Failed"
    Nov 11 23:32:28.052: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 15.278273ms
    Nov 11 23:32:30.068: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031322045s
    Nov 11 23:32:32.078: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041382502s
    Nov 11 23:32:34.067: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030572356s
    STEP: Saw pod success 11/11/22 23:32:34.067
    Nov 11 23:32:34.068: INFO: Pod "pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04" satisfied condition "Succeeded or Failed"
    Nov 11 23:32:34.083: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 container env-test: <nil>
    STEP: delete the pod 11/11/22 23:32:34.12
    Nov 11 23:32:34.184: INFO: Waiting for pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 to disappear
    Nov 11 23:32:34.198: INFO: Pod pod-configmaps-e154b197-4bb6-4278-951b-ac485785ce04 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:32:34.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3784" for this suite. 11/11/22 23:32:34.21
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:34.243
Nov 11 23:32:34.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:32:34.245
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:34.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:34.294
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:32:34.343
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:32:35.496
STEP: Deploying the webhook pod 11/11/22 23:32:35.518
STEP: Wait for the deployment to be ready 11/11/22 23:32:35.589
Nov 11 23:32:35.625: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:32:37.690: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:32:39.704
STEP: Verifying the service has paired with the endpoint 11/11/22 23:32:39.75
Nov 11 23:32:40.751: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Nov 11 23:32:40.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8993-crds.webhook.example.com via the AdmissionRegistration API 11/11/22 23:32:41.281
STEP: Creating a custom resource that should be mutated by the webhook 11/11/22 23:32:41.392
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:32:44.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4805" for this suite. 11/11/22 23:32:44.106
STEP: Destroying namespace "webhook-4805-markers" for this suite. 11/11/22 23:32:44.138
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":77,"skipped":1200,"failed":0}
------------------------------
• [SLOW TEST] [10.040 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:34.243
    Nov 11 23:32:34.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:32:34.245
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:34.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:34.294
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:32:34.343
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:32:35.496
    STEP: Deploying the webhook pod 11/11/22 23:32:35.518
    STEP: Wait for the deployment to be ready 11/11/22 23:32:35.589
    Nov 11 23:32:35.625: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:32:37.690: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 32, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:32:39.704
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:32:39.75
    Nov 11 23:32:40.751: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Nov 11 23:32:40.760: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8993-crds.webhook.example.com via the AdmissionRegistration API 11/11/22 23:32:41.281
    STEP: Creating a custom resource that should be mutated by the webhook 11/11/22 23:32:41.392
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:32:44.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4805" for this suite. 11/11/22 23:32:44.106
    STEP: Destroying namespace "webhook-4805-markers" for this suite. 11/11/22 23:32:44.138
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:44.299
Nov 11 23:32:44.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:32:44.3
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:44.334
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:44.344
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 11/11/22 23:32:44.355
Nov 11 23:32:44.390: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc" in namespace "emptydir-7194" to be "running"
Nov 11 23:32:44.406: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Pending", Reason="", readiness=false. Elapsed: 15.833214ms
Nov 11 23:32:46.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032524815s
Nov 11 23:32:48.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Running", Reason="", readiness=false. Elapsed: 4.032274967s
Nov 11 23:32:48.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc" satisfied condition "running"
STEP: Reading file content from the nginx-container 11/11/22 23:32:48.423
Nov 11 23:32:48.424: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7194 PodName:pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:32:48.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:32:48.425: INFO: ExecWithOptions: Clientset creation
Nov 11 23:32:48.425: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-7194/pods/pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Nov 11 23:32:48.656: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:32:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7194" for this suite. 11/11/22 23:32:48.671
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":78,"skipped":1246,"failed":0}
------------------------------
• [4.400 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:44.299
    Nov 11 23:32:44.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:32:44.3
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:44.334
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:44.344
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 11/11/22 23:32:44.355
    Nov 11 23:32:44.390: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc" in namespace "emptydir-7194" to be "running"
    Nov 11 23:32:44.406: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Pending", Reason="", readiness=false. Elapsed: 15.833214ms
    Nov 11 23:32:46.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032524815s
    Nov 11 23:32:48.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc": Phase="Running", Reason="", readiness=false. Elapsed: 4.032274967s
    Nov 11 23:32:48.423: INFO: Pod "pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc" satisfied condition "running"
    STEP: Reading file content from the nginx-container 11/11/22 23:32:48.423
    Nov 11 23:32:48.424: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7194 PodName:pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:32:48.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:32:48.425: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:32:48.425: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/emptydir-7194/pods/pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Nov 11 23:32:48.656: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:32:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7194" for this suite. 11/11/22 23:32:48.671
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:48.703
Nov 11 23:32:48.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-pred 11/11/22 23:32:48.703
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:48.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:48.749
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 11 23:32:48.758: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 23:32:48.781: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 23:32:48.799: INFO: 
Logging pods the apiserver thinks is on node 10.184.98.55 before test
Nov 11 23:32:48.863: INFO: pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc from emptydir-7194 started at 2022-11-11 23:32:44 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container busybox-main-container ready: true, restart count 0
Nov 11 23:32:48.864: INFO: 	Container busybox-sub-container ready: false, restart count 0
Nov 11 23:32:48.864: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:32:48.864: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:32:48.864: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:32:48.864: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:32:48.864: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.864: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:32:48.864: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:32:48.865: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:32:48.865: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Nov 11 23:32:48.865: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:32:48.865: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:32:48.865: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:32:48.865: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:32:48.865: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:32:48.865: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 11 23:32:48.865: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.865: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:32:48.865: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:32:48.865: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.113 before test
Nov 11 23:32:48.920: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 11 23:32:48.920: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:32:48.920: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:32:48.920: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container autoscaler ready: true, restart count 0
Nov 11 23:32:48.920: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:32:48.920: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:32:48.920: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:32:48.920: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:32:48.920: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Nov 11 23:32:48.920: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:32:48.920: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 11 23:32:48.920: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:32:48.920: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:32:48.920: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:32:48.920: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:32:48.920: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:32:48.921: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:32:48.921: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:32:48.921: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.921: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:32:48.921: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:32:48.921: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.26 before test
Nov 11 23:32:48.969: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.970: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov 11 23:32:48.970: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.970: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:32:48.971: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.971: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:32:48.971: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.971: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:32:48.971: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.971: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:32:48.971: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.971: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:32:48.971: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:32:48.972: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:32:48.972: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:32:48.972: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:32:48.972: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:32:48.972: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container e2e ready: true, restart count 0
Nov 11 23:32:48.972: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:32:48.972: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:32:48.972: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:32:48.973: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/11/22 23:32:48.973
Nov 11 23:32:49.008: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4597" to be "running"
Nov 11 23:32:49.025: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 16.676072ms
Nov 11 23:32:51.052: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043767944s
Nov 11 23:32:53.041: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.032529569s
Nov 11 23:32:53.041: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/11/22 23:32:53.058
STEP: Trying to apply a random label on the found node. 11/11/22 23:32:53.102
STEP: verifying the node has the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f 42 11/11/22 23:32:53.141
STEP: Trying to relaunch the pod, now with labels. 11/11/22 23:32:53.155
Nov 11 23:32:53.177: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-4597" to be "not pending"
Nov 11 23:32:53.192: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 14.879712ms
Nov 11 23:32:55.210: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033036255s
Nov 11 23:32:57.209: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.03232011s
Nov 11 23:32:57.209: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f off the node 10.241.148.26 11/11/22 23:32:57.225
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f 11/11/22 23:32:57.256
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:32:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4597" for this suite. 11/11/22 23:32:57.283
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":79,"skipped":1268,"failed":0}
------------------------------
• [SLOW TEST] [8.613 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:48.703
    Nov 11 23:32:48.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-pred 11/11/22 23:32:48.703
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:48.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:48.749
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 11 23:32:48.758: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 11 23:32:48.781: INFO: Waiting for terminating namespaces to be deleted...
    Nov 11 23:32:48.799: INFO: 
    Logging pods the apiserver thinks is on node 10.184.98.55 before test
    Nov 11 23:32:48.863: INFO: pod-sharedvolume-18d8f5b9-fb5a-40ed-b6ad-41faa27f79cc from emptydir-7194 started at 2022-11-11 23:32:44 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container busybox-main-container ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: 	Container busybox-sub-container ready: false, restart count 0
    Nov 11 23:32:48.864: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.864: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:32:48.864: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.865: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:32:48.865: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.113 before test
    Nov 11 23:32:48.920: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:32:48.920: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:32:48.920: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:32:48.921: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:32:48.921: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.921: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:32:48.921: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.921: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:32:48.921: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:32:48.921: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.26 before test
    Nov 11 23:32:48.969: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.970: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    Nov 11 23:32:48.970: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.970: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:32:48.971: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.971: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:32:48.971: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.971: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:32:48.971: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.971: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:32:48.971: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.971: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:32:48.971: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container e2e ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:32:48.972: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:32:48.972: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:32:48.973: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/11/22 23:32:48.973
    Nov 11 23:32:49.008: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4597" to be "running"
    Nov 11 23:32:49.025: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 16.676072ms
    Nov 11 23:32:51.052: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043767944s
    Nov 11 23:32:53.041: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.032529569s
    Nov 11 23:32:53.041: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/11/22 23:32:53.058
    STEP: Trying to apply a random label on the found node. 11/11/22 23:32:53.102
    STEP: verifying the node has the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f 42 11/11/22 23:32:53.141
    STEP: Trying to relaunch the pod, now with labels. 11/11/22 23:32:53.155
    Nov 11 23:32:53.177: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-4597" to be "not pending"
    Nov 11 23:32:53.192: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 14.879712ms
    Nov 11 23:32:55.210: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033036255s
    Nov 11 23:32:57.209: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.03232011s
    Nov 11 23:32:57.209: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f off the node 10.241.148.26 11/11/22 23:32:57.225
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-8bf8ca02-1542-43f7-91c3-02b521c1d99f 11/11/22 23:32:57.256
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:32:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4597" for this suite. 11/11/22 23:32:57.283
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:32:57.336
Nov 11 23:32:57.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/11/22 23:32:57.339
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:57.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:57.416
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 11/11/22 23:32:57.436
STEP: Ensure pods equal to paralellism count is attached to the job 11/11/22 23:32:57.454
STEP: patching /status 11/11/22 23:33:01.471
STEP: updating /status 11/11/22 23:33:01.492
STEP: get /status 11/11/22 23:33:01.526
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 11 23:33:01.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9751" for this suite. 11/11/22 23:33:01.553
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":80,"skipped":1318,"failed":0}
------------------------------
• [4.243 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:32:57.336
    Nov 11 23:32:57.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/11/22 23:32:57.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:32:57.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:32:57.416
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 11/11/22 23:32:57.436
    STEP: Ensure pods equal to paralellism count is attached to the job 11/11/22 23:32:57.454
    STEP: patching /status 11/11/22 23:33:01.471
    STEP: updating /status 11/11/22 23:33:01.492
    STEP: get /status 11/11/22 23:33:01.526
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 11 23:33:01.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9751" for this suite. 11/11/22 23:33:01.553
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:01.583
Nov 11 23:33:01.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:33:01.584
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:01.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:01.64
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:33:01.692
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:33:02.534
STEP: Deploying the webhook pod 11/11/22 23:33:02.55
STEP: Wait for the deployment to be ready 11/11/22 23:33:02.601
Nov 11 23:33:02.636: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:33:04.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:33:06.697
STEP: Verifying the service has paired with the endpoint 11/11/22 23:33:06.735
Nov 11 23:33:07.736: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/11/22 23:33:07.747
STEP: create a configmap that should be updated by the webhook 11/11/22 23:33:07.819
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:33:07.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2307" for this suite. 11/11/22 23:33:07.961
STEP: Destroying namespace "webhook-2307-markers" for this suite. 11/11/22 23:33:07.99
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":81,"skipped":1365,"failed":0}
------------------------------
• [SLOW TEST] [6.557 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:01.583
    Nov 11 23:33:01.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:33:01.584
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:01.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:01.64
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:33:01.692
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:33:02.534
    STEP: Deploying the webhook pod 11/11/22 23:33:02.55
    STEP: Wait for the deployment to be ready 11/11/22 23:33:02.601
    Nov 11 23:33:02.636: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:33:04.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 33, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:33:06.697
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:33:06.735
    Nov 11 23:33:07.736: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/11/22 23:33:07.747
    STEP: create a configmap that should be updated by the webhook 11/11/22 23:33:07.819
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:33:07.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2307" for this suite. 11/11/22 23:33:07.961
    STEP: Destroying namespace "webhook-2307-markers" for this suite. 11/11/22 23:33:07.99
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:08.147
Nov 11 23:33:08.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pod-network-test 11/11/22 23:33:08.149
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:08.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:08.195
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-5535 11/11/22 23:33:08.205
STEP: creating a selector 11/11/22 23:33:08.205
STEP: Creating the service pods in kubernetes 11/11/22 23:33:08.205
Nov 11 23:33:08.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 11 23:33:08.303: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5535" to be "running and ready"
Nov 11 23:33:08.318: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.779894ms
Nov 11 23:33:08.318: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:10.337: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033367942s
Nov 11 23:33:10.337: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:12.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033647114s
Nov 11 23:33:12.337: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:14.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032837674s
Nov 11 23:33:14.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:16.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.033000478s
Nov 11 23:33:16.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:18.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.032186991s
Nov 11 23:33:18.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:20.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.031947657s
Nov 11 23:33:20.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:22.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.031684922s
Nov 11 23:33:22.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:24.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.030527598s
Nov 11 23:33:24.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:26.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.032779822s
Nov 11 23:33:26.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:28.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.033596419s
Nov 11 23:33:28.337: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 11 23:33:30.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.033398034s
Nov 11 23:33:30.337: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 11 23:33:30.337: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 11 23:33:30.352: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5535" to be "running and ready"
Nov 11 23:33:30.367: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 15.173209ms
Nov 11 23:33:30.367: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 11 23:33:30.367: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 11 23:33:30.383: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5535" to be "running and ready"
Nov 11 23:33:30.399: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.826326ms
Nov 11 23:33:30.399: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 11 23:33:30.399: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/11/22 23:33:30.413
Nov 11 23:33:30.430: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5535" to be "running"
Nov 11 23:33:30.454: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.384674ms
Nov 11 23:33:32.470: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040450165s
Nov 11 23:33:34.471: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.040733808s
Nov 11 23:33:34.471: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 11 23:33:34.489: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 11 23:33:34.489: INFO: Breadth first check of 172.30.146.33 on host 10.184.98.55...
Nov 11 23:33:34.508: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.146.33&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:33:34.509: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:33:34.510: INFO: ExecWithOptions: Clientset creation
Nov 11 23:33:34.510: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.146.33%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 11 23:33:34.733: INFO: Waiting for responses: map[]
Nov 11 23:33:34.733: INFO: reached 172.30.146.33 after 0/1 tries
Nov 11 23:33:34.733: INFO: Breadth first check of 172.30.188.219 on host 10.241.148.113...
Nov 11 23:33:34.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.188.219&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:33:34.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:33:34.749: INFO: ExecWithOptions: Clientset creation
Nov 11 23:33:34.749: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.188.219%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 11 23:33:34.974: INFO: Waiting for responses: map[]
Nov 11 23:33:34.974: INFO: reached 172.30.188.219 after 0/1 tries
Nov 11 23:33:34.974: INFO: Breadth first check of 172.30.194.99 on host 10.241.148.26...
Nov 11 23:33:34.990: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.194.99&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 11 23:33:34.990: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:33:34.992: INFO: ExecWithOptions: Clientset creation
Nov 11 23:33:34.992: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.194.99%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 11 23:33:35.255: INFO: Waiting for responses: map[]
Nov 11 23:33:35.255: INFO: reached 172.30.194.99 after 0/1 tries
Nov 11 23:33:35.255: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 11 23:33:35.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5535" for this suite. 11/11/22 23:33:35.271
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":82,"skipped":1377,"failed":0}
------------------------------
• [SLOW TEST] [27.151 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:08.147
    Nov 11 23:33:08.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pod-network-test 11/11/22 23:33:08.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:08.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:08.195
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-5535 11/11/22 23:33:08.205
    STEP: creating a selector 11/11/22 23:33:08.205
    STEP: Creating the service pods in kubernetes 11/11/22 23:33:08.205
    Nov 11 23:33:08.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 11 23:33:08.303: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5535" to be "running and ready"
    Nov 11 23:33:08.318: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.779894ms
    Nov 11 23:33:08.318: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:10.337: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033367942s
    Nov 11 23:33:10.337: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:12.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.033647114s
    Nov 11 23:33:12.337: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:14.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.032837674s
    Nov 11 23:33:14.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:16.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.033000478s
    Nov 11 23:33:16.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:18.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.032186991s
    Nov 11 23:33:18.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:20.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.031947657s
    Nov 11 23:33:20.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:22.335: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.031684922s
    Nov 11 23:33:22.335: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:24.334: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.030527598s
    Nov 11 23:33:24.334: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:26.336: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.032779822s
    Nov 11 23:33:26.336: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:28.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.033596419s
    Nov 11 23:33:28.337: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 11 23:33:30.337: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.033398034s
    Nov 11 23:33:30.337: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 11 23:33:30.337: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 11 23:33:30.352: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5535" to be "running and ready"
    Nov 11 23:33:30.367: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 15.173209ms
    Nov 11 23:33:30.367: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 11 23:33:30.367: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 11 23:33:30.383: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-5535" to be "running and ready"
    Nov 11 23:33:30.399: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.826326ms
    Nov 11 23:33:30.399: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 11 23:33:30.399: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/11/22 23:33:30.413
    Nov 11 23:33:30.430: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5535" to be "running"
    Nov 11 23:33:30.454: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 24.384674ms
    Nov 11 23:33:32.470: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040450165s
    Nov 11 23:33:34.471: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.040733808s
    Nov 11 23:33:34.471: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 11 23:33:34.489: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 11 23:33:34.489: INFO: Breadth first check of 172.30.146.33 on host 10.184.98.55...
    Nov 11 23:33:34.508: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.146.33&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:33:34.509: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:33:34.510: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:33:34.510: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.146.33%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 11 23:33:34.733: INFO: Waiting for responses: map[]
    Nov 11 23:33:34.733: INFO: reached 172.30.146.33 after 0/1 tries
    Nov 11 23:33:34.733: INFO: Breadth first check of 172.30.188.219 on host 10.241.148.113...
    Nov 11 23:33:34.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.188.219&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:33:34.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:33:34.749: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:33:34.749: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.188.219%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 11 23:33:34.974: INFO: Waiting for responses: map[]
    Nov 11 23:33:34.974: INFO: reached 172.30.188.219 after 0/1 tries
    Nov 11 23:33:34.974: INFO: Breadth first check of 172.30.194.99 on host 10.241.148.26...
    Nov 11 23:33:34.990: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.194.100:9080/dial?request=hostname&protocol=udp&host=172.30.194.99&port=8081&tries=1'] Namespace:pod-network-test-5535 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 11 23:33:34.990: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:33:34.992: INFO: ExecWithOptions: Clientset creation
    Nov 11 23:33:34.992: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-5535/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.194.100%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.30.194.99%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 11 23:33:35.255: INFO: Waiting for responses: map[]
    Nov 11 23:33:35.255: INFO: reached 172.30.194.99 after 0/1 tries
    Nov 11 23:33:35.255: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 11 23:33:35.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5535" for this suite. 11/11/22 23:33:35.271
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:35.305
Nov 11 23:33:35.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:33:35.306
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:35.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:35.369
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-0d654813-a06a-4682-8430-55d3bd1d60e0 11/11/22 23:33:35.393
STEP: Creating the pod 11/11/22 23:33:35.41
Nov 11 23:33:35.439: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db" in namespace "configmap-6945" to be "running"
Nov 11 23:33:35.454: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Pending", Reason="", readiness=false. Elapsed: 14.961862ms
Nov 11 23:33:37.470: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030805731s
Nov 11 23:33:39.473: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Running", Reason="", readiness=false. Elapsed: 4.033962362s
Nov 11 23:33:39.473: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db" satisfied condition "running"
STEP: Waiting for pod with text data 11/11/22 23:33:39.473
STEP: Waiting for pod with binary data 11/11/22 23:33:39.503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:33:39.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6945" for this suite. 11/11/22 23:33:39.552
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":83,"skipped":1417,"failed":0}
------------------------------
• [4.276 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:35.305
    Nov 11 23:33:35.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:33:35.306
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:35.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:35.369
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-0d654813-a06a-4682-8430-55d3bd1d60e0 11/11/22 23:33:35.393
    STEP: Creating the pod 11/11/22 23:33:35.41
    Nov 11 23:33:35.439: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db" in namespace "configmap-6945" to be "running"
    Nov 11 23:33:35.454: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Pending", Reason="", readiness=false. Elapsed: 14.961862ms
    Nov 11 23:33:37.470: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030805731s
    Nov 11 23:33:39.473: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db": Phase="Running", Reason="", readiness=false. Elapsed: 4.033962362s
    Nov 11 23:33:39.473: INFO: Pod "pod-configmaps-5e435421-5846-467f-9f34-b23899c287db" satisfied condition "running"
    STEP: Waiting for pod with text data 11/11/22 23:33:39.473
    STEP: Waiting for pod with binary data 11/11/22 23:33:39.503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:33:39.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6945" for this suite. 11/11/22 23:33:39.552
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:39.609
Nov 11 23:33:39.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-lifecycle-hook 11/11/22 23:33:39.612
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:39.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:39.741
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/11/22 23:33:39.795
Nov 11 23:33:39.825: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6920" to be "running and ready"
Nov 11 23:33:39.841: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 16.115612ms
Nov 11 23:33:39.841: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:41.861: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036178143s
Nov 11 23:33:41.861: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:43.857: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.031964928s
Nov 11 23:33:43.857: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 11 23:33:43.857: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 11/11/22 23:33:43.872
Nov 11 23:33:43.889: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-6920" to be "running and ready"
Nov 11 23:33:43.905: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.847498ms
Nov 11 23:33:43.905: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:45.922: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033024789s
Nov 11 23:33:45.922: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:47.921: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.032400321s
Nov 11 23:33:47.922: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Nov 11 23:33:47.922: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/11/22 23:33:47.938
Nov 11 23:33:47.967: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 23:33:47.984: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 11 23:33:49.985: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 23:33:50.001: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 11 23:33:51.985: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 11 23:33:52.007: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 11/11/22 23:33:52.007
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 11 23:33:52.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6920" for this suite. 11/11/22 23:33:52.052
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":84,"skipped":1464,"failed":0}
------------------------------
• [SLOW TEST] [12.473 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:39.609
    Nov 11 23:33:39.609: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/11/22 23:33:39.612
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:39.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:39.741
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/11/22 23:33:39.795
    Nov 11 23:33:39.825: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6920" to be "running and ready"
    Nov 11 23:33:39.841: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 16.115612ms
    Nov 11 23:33:39.841: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:41.861: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036178143s
    Nov 11 23:33:41.861: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:43.857: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.031964928s
    Nov 11 23:33:43.857: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 11 23:33:43.857: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 11/11/22 23:33:43.872
    Nov 11 23:33:43.889: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-6920" to be "running and ready"
    Nov 11 23:33:43.905: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.847498ms
    Nov 11 23:33:43.905: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:45.922: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033024789s
    Nov 11 23:33:45.922: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:47.921: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.032400321s
    Nov 11 23:33:47.922: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Nov 11 23:33:47.922: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/11/22 23:33:47.938
    Nov 11 23:33:47.967: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 11 23:33:47.984: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 11 23:33:49.985: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 11 23:33:50.001: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 11 23:33:51.985: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 11 23:33:52.007: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 11/11/22 23:33:52.007
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 11 23:33:52.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6920" for this suite. 11/11/22 23:33:52.052
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:52.083
Nov 11 23:33:52.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/11/22 23:33:52.084
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:52.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:52.129
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 11/11/22 23:33:52.14
Nov 11 23:33:52.169: INFO: Waiting up to 5m0s for pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7" in namespace "pods-7086" to be "running and ready"
Nov 11 23:33:52.184: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.888477ms
Nov 11 23:33:52.184: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:54.200: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030967408s
Nov 11 23:33:54.200: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:33:56.201: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Running", Reason="", readiness=true. Elapsed: 4.032052347s
Nov 11 23:33:56.201: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Running (Ready = true)
Nov 11 23:33:56.201: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7" satisfied condition "running and ready"
Nov 11 23:33:56.232: INFO: Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 has hostIP: 10.184.98.55
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 11 23:33:56.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7086" for this suite. 11/11/22 23:33:56.244
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":85,"skipped":1475,"failed":0}
------------------------------
• [4.192 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:52.083
    Nov 11 23:33:52.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/11/22 23:33:52.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:52.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:52.129
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 11/11/22 23:33:52.14
    Nov 11 23:33:52.169: INFO: Waiting up to 5m0s for pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7" in namespace "pods-7086" to be "running and ready"
    Nov 11 23:33:52.184: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.888477ms
    Nov 11 23:33:52.184: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:54.200: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030967408s
    Nov 11 23:33:54.200: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:33:56.201: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7": Phase="Running", Reason="", readiness=true. Elapsed: 4.032052347s
    Nov 11 23:33:56.201: INFO: The phase of Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 is Running (Ready = true)
    Nov 11 23:33:56.201: INFO: Pod "pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7" satisfied condition "running and ready"
    Nov 11 23:33:56.232: INFO: Pod pod-hostip-225fd502-10f9-4420-a4e8-af4fc55de9f7 has hostIP: 10.184.98.55
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 11 23:33:56.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7086" for this suite. 11/11/22 23:33:56.244
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:33:56.278
Nov 11 23:33:56.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:33:56.28
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:56.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:56.323
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Nov 11 23:33:56.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/11/22 23:34:00.96
Nov 11 23:34:00.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 create -f -'
Nov 11 23:34:02.353: INFO: stderr: ""
Nov 11 23:34:02.353: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 11 23:34:02.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 delete e2e-test-crd-publish-openapi-6921-crds test-cr'
Nov 11 23:34:02.554: INFO: stderr: ""
Nov 11 23:34:02.554: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 11 23:34:02.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 apply -f -'
Nov 11 23:34:03.429: INFO: stderr: ""
Nov 11 23:34:03.429: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 11 23:34:03.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 delete e2e-test-crd-publish-openapi-6921-crds test-cr'
Nov 11 23:34:03.612: INFO: stderr: ""
Nov 11 23:34:03.613: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 11/11/22 23:34:03.613
Nov 11 23:34:03.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 explain e2e-test-crd-publish-openapi-6921-crds'
Nov 11 23:34:04.127: INFO: stderr: ""
Nov 11 23:34:04.127: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6921-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:34:08.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8112" for this suite. 11/11/22 23:34:08.644
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":86,"skipped":1505,"failed":0}
------------------------------
• [SLOW TEST] [12.391 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:33:56.278
    Nov 11 23:33:56.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:33:56.28
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:33:56.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:33:56.323
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Nov 11 23:33:56.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/11/22 23:34:00.96
    Nov 11 23:34:00.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 create -f -'
    Nov 11 23:34:02.353: INFO: stderr: ""
    Nov 11 23:34:02.353: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 11 23:34:02.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 delete e2e-test-crd-publish-openapi-6921-crds test-cr'
    Nov 11 23:34:02.554: INFO: stderr: ""
    Nov 11 23:34:02.554: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Nov 11 23:34:02.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 apply -f -'
    Nov 11 23:34:03.429: INFO: stderr: ""
    Nov 11 23:34:03.429: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 11 23:34:03.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 --namespace=crd-publish-openapi-8112 delete e2e-test-crd-publish-openapi-6921-crds test-cr'
    Nov 11 23:34:03.612: INFO: stderr: ""
    Nov 11 23:34:03.613: INFO: stdout: "e2e-test-crd-publish-openapi-6921-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 11/11/22 23:34:03.613
    Nov 11 23:34:03.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-8112 explain e2e-test-crd-publish-openapi-6921-crds'
    Nov 11 23:34:04.127: INFO: stderr: ""
    Nov 11 23:34:04.127: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6921-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:34:08.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8112" for this suite. 11/11/22 23:34:08.644
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:34:08.67
Nov 11 23:34:08.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/11/22 23:34:08.673
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:08.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:08.745
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Nov 11 23:34:08.765: INFO: Creating simple deployment test-new-deployment
Nov 11 23:34:08.835: INFO: deployment "test-new-deployment" doesn't have the required revision set
Nov 11 23:34:10.889: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 11/11/22 23:34:12.928
STEP: updating a scale subresource 11/11/22 23:34:12.946
STEP: verifying the deployment Spec.Replicas was modified 11/11/22 23:34:12.975
STEP: Patch a scale subresource 11/11/22 23:34:12.995
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 11 23:34:13.135: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-3145  1f615c5a-f0f0-4fb3-8444-d1cc87ea8118 24783 3 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-11 23:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046fcbf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:2,UpdatedReplicas:2,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-11 23:34:10 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-11 23:34:12 +0000 UTC,LastTransitionTime:2022-11-11 23:34:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 11 23:34:13.157: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3145  369764d3-c9ba-4973-bc61-5856054072b0 24787 3 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 1f615c5a-f0f0-4fb3-8444-d1cc87ea8118 0xc0046fd067 0xc0046fd068}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f615c5a-f0f0-4fb3-8444-d1cc87ea8118\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046fd0f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 11 23:34:13.179: INFO: Pod "test-new-deployment-845c8977d9-n2mlx" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-n2mlx test-new-deployment-845c8977d9- deployment-3145  162456a1-1edb-4afd-9319-f0fe8d9ea35d 24786 0 2022-11-11 23:34:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c30ec7 0xc002c30ec8}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qwcd4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qwcd4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 23:34:13.180: INFO: Pod "test-new-deployment-845c8977d9-vfxtv" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-vfxtv test-new-deployment-845c8977d9- deployment-3145  329c2336-ae6a-4dd1-99cb-1cd659df347f 24790 0 2022-11-11 23:34:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c31030 0xc002c31031}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n2h54,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n2h54,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-11 23:34:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 23:34:13.180: INFO: Pod "test-new-deployment-845c8977d9-xq7kf" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-xq7kf test-new-deployment-845c8977d9- deployment-3145  ede50b26-db0d-43b2-8210-e1609c6b61fd 24791 0 2022-11-11 23:34:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c31207 0xc002c31208}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gkzx6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gkzx6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-11 23:34:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 11 23:34:13.181: INFO: Pod "test-new-deployment-845c8977d9-xzlpm" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-xzlpm test-new-deployment-845c8977d9- deployment-3145  ac6f6693-254d-452c-9bd2-9483ca8c2346 24760 0 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:52e97e1158e54940c0ee5f9f15e7c2f7cd03ed99ddbb2819f5b780c9603ae33c cni.projectcalico.org/podIP:172.30.146.39/32 cni.projectcalico.org/podIPs:172.30.146.39/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c313f7 0xc002c313f8}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:34:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:34:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-64lsq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-64lsq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.39,StartTime:2022-11-11 23:34:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:34:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://eb597b867640e21d2ffb67089ac9447944ad2c7e29d60c478cd0928357e2ce7d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 11 23:34:13.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3145" for this suite. 11/11/22 23:34:13.208
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":87,"skipped":1508,"failed":0}
------------------------------
• [4.561 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:34:08.67
    Nov 11 23:34:08.670: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/11/22 23:34:08.673
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:08.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:08.745
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Nov 11 23:34:08.765: INFO: Creating simple deployment test-new-deployment
    Nov 11 23:34:08.835: INFO: deployment "test-new-deployment" doesn't have the required revision set
    Nov 11 23:34:10.889: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 11/11/22 23:34:12.928
    STEP: updating a scale subresource 11/11/22 23:34:12.946
    STEP: verifying the deployment Spec.Replicas was modified 11/11/22 23:34:12.975
    STEP: Patch a scale subresource 11/11/22 23:34:12.995
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 11 23:34:13.135: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-3145  1f615c5a-f0f0-4fb3-8444-d1cc87ea8118 24783 3 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-11 23:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046fcbf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:2,UpdatedReplicas:2,AvailableReplicas:1,UnavailableReplicas:3,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-11 23:34:10 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-11 23:34:12 +0000 UTC,LastTransitionTime:2022-11-11 23:34:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 11 23:34:13.157: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3145  369764d3-c9ba-4973-bc61-5856054072b0 24787 3 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 1f615c5a-f0f0-4fb3-8444-d1cc87ea8118 0xc0046fd067 0xc0046fd068}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1f615c5a-f0f0-4fb3-8444-d1cc87ea8118\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046fd0f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:3,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 11 23:34:13.179: INFO: Pod "test-new-deployment-845c8977d9-n2mlx" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-n2mlx test-new-deployment-845c8977d9- deployment-3145  162456a1-1edb-4afd-9319-f0fe8d9ea35d 24786 0 2022-11-11 23:34:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c30ec7 0xc002c30ec8}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qwcd4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qwcd4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 11 23:34:13.180: INFO: Pod "test-new-deployment-845c8977d9-vfxtv" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-vfxtv test-new-deployment-845c8977d9- deployment-3145  329c2336-ae6a-4dd1-99cb-1cd659df347f 24790 0 2022-11-11 23:34:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c31030 0xc002c31031}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n2h54,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n2h54,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-11 23:34:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 11 23:34:13.180: INFO: Pod "test-new-deployment-845c8977d9-xq7kf" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-xq7kf test-new-deployment-845c8977d9- deployment-3145  ede50b26-db0d-43b2-8210-e1609c6b61fd 24791 0 2022-11-11 23:34:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c31207 0xc002c31208}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-11 23:34:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gkzx6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gkzx6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-11 23:34:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 11 23:34:13.181: INFO: Pod "test-new-deployment-845c8977d9-xzlpm" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-xzlpm test-new-deployment-845c8977d9- deployment-3145  ac6f6693-254d-452c-9bd2-9483ca8c2346 24760 0 2022-11-11 23:34:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:52e97e1158e54940c0ee5f9f15e7c2f7cd03ed99ddbb2819f5b780c9603ae33c cni.projectcalico.org/podIP:172.30.146.39/32 cni.projectcalico.org/podIPs:172.30.146.39/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 369764d3-c9ba-4973-bc61-5856054072b0 0xc002c313f7 0xc002c313f8}] [] [{kube-controller-manager Update v1 2022-11-11 23:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"369764d3-c9ba-4973-bc61-5856054072b0\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:34:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:34:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.39\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-64lsq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-64lsq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:34:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.39,StartTime:2022-11-11 23:34:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:34:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://eb597b867640e21d2ffb67089ac9447944ad2c7e29d60c478cd0928357e2ce7d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 11 23:34:13.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3145" for this suite. 11/11/22 23:34:13.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:34:13.233
Nov 11 23:34:13.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:34:13.236
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:13.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:13.307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:34:13.379
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:34:14.021
STEP: Deploying the webhook pod 11/11/22 23:34:14.056
STEP: Wait for the deployment to be ready 11/11/22 23:34:14.112
Nov 11 23:34:14.167: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:34:16.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:34:18.259
STEP: Verifying the service has paired with the endpoint 11/11/22 23:34:18.3
Nov 11 23:34:19.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 11/11/22 23:34:19.317
STEP: create a pod that should be denied by the webhook 11/11/22 23:34:19.459
STEP: create a pod that causes the webhook to hang 11/11/22 23:34:19.559
STEP: create a configmap that should be denied by the webhook 11/11/22 23:34:29.597
STEP: create a configmap that should be admitted by the webhook 11/11/22 23:34:29.687
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/11/22 23:34:29.75
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/11/22 23:34:29.795
STEP: create a namespace that bypass the webhook 11/11/22 23:34:29.826
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/11/22 23:34:29.858
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:34:29.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7796" for this suite. 11/11/22 23:34:30.032
STEP: Destroying namespace "webhook-7796-markers" for this suite. 11/11/22 23:34:30.059
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":88,"skipped":1514,"failed":0}
------------------------------
• [SLOW TEST] [17.024 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:34:13.233
    Nov 11 23:34:13.234: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:34:13.236
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:13.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:13.307
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:34:13.379
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:34:14.021
    STEP: Deploying the webhook pod 11/11/22 23:34:14.056
    STEP: Wait for the deployment to be ready 11/11/22 23:34:14.112
    Nov 11 23:34:14.167: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:34:16.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 34, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:34:18.259
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:34:18.3
    Nov 11 23:34:19.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 11/11/22 23:34:19.317
    STEP: create a pod that should be denied by the webhook 11/11/22 23:34:19.459
    STEP: create a pod that causes the webhook to hang 11/11/22 23:34:19.559
    STEP: create a configmap that should be denied by the webhook 11/11/22 23:34:29.597
    STEP: create a configmap that should be admitted by the webhook 11/11/22 23:34:29.687
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/11/22 23:34:29.75
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/11/22 23:34:29.795
    STEP: create a namespace that bypass the webhook 11/11/22 23:34:29.826
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/11/22 23:34:29.858
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:34:29.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7796" for this suite. 11/11/22 23:34:30.032
    STEP: Destroying namespace "webhook-7796-markers" for this suite. 11/11/22 23:34:30.059
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:34:30.262
Nov 11 23:34:30.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/11/22 23:34:30.265
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:30.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:30.339
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 11/11/22 23:34:30.358
STEP: Ensuring active pods == parallelism 11/11/22 23:34:30.388
STEP: delete a job 11/11/22 23:34:34.411
STEP: deleting Job.batch foo in namespace job-9514, will wait for the garbage collector to delete the pods 11/11/22 23:34:34.412
Nov 11 23:34:34.516: INFO: Deleting Job.batch foo took: 32.187713ms
Nov 11 23:34:34.616: INFO: Terminating Job.batch foo pods took: 100.57683ms
STEP: Ensuring job was deleted 11/11/22 23:35:07.317
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 11 23:35:07.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9514" for this suite. 11/11/22 23:35:07.371
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":89,"skipped":1522,"failed":0}
------------------------------
• [SLOW TEST] [37.136 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:34:30.262
    Nov 11 23:34:30.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/11/22 23:34:30.265
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:34:30.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:34:30.339
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 11/11/22 23:34:30.358
    STEP: Ensuring active pods == parallelism 11/11/22 23:34:30.388
    STEP: delete a job 11/11/22 23:34:34.411
    STEP: deleting Job.batch foo in namespace job-9514, will wait for the garbage collector to delete the pods 11/11/22 23:34:34.412
    Nov 11 23:34:34.516: INFO: Deleting Job.batch foo took: 32.187713ms
    Nov 11 23:34:34.616: INFO: Terminating Job.batch foo pods took: 100.57683ms
    STEP: Ensuring job was deleted 11/11/22 23:35:07.317
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 11 23:35:07.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9514" for this suite. 11/11/22 23:35:07.371
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:35:07.405
Nov 11 23:35:07.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename aggregator 11/11/22 23:35:07.407
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:07.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:07.508
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Nov 11 23:35:07.530: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 11/11/22 23:35:07.532
Nov 11 23:35:08.852: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 11 23:35:11.045: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:13.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:15.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:17.068: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:19.066: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:21.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:23.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:25.090: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:27.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:29.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:31.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 11 23:35:33.335: INFO: Waited 238.802146ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 11/11/22 23:35:33.639
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/11/22 23:35:33.659
STEP: List APIServices 11/11/22 23:35:33.684
Nov 11 23:35:33.714: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Nov 11 23:35:34.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6520" for this suite. 11/11/22 23:35:34.348
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":90,"skipped":1562,"failed":0}
------------------------------
• [SLOW TEST] [26.971 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:35:07.405
    Nov 11 23:35:07.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename aggregator 11/11/22 23:35:07.407
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:07.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:07.508
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Nov 11 23:35:07.530: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 11/11/22 23:35:07.532
    Nov 11 23:35:08.852: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Nov 11 23:35:11.045: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:13.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:15.081: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:17.068: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:19.066: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:21.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:23.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:25.090: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:27.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:29.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:31.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 35, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 11 23:35:33.335: INFO: Waited 238.802146ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 11/11/22 23:35:33.639
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/11/22 23:35:33.659
    STEP: List APIServices 11/11/22 23:35:33.684
    Nov 11 23:35:33.714: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Nov 11 23:35:34.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-6520" for this suite. 11/11/22 23:35:34.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:35:34.383
Nov 11 23:35:34.383: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:35:34.385
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:34.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:34.461
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-5743 11/11/22 23:35:34.48
STEP: creating service affinity-nodeport in namespace services-5743 11/11/22 23:35:34.48
STEP: creating replication controller affinity-nodeport in namespace services-5743 11/11/22 23:35:34.539
I1111 23:35:34.574347      21 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5743, replica count: 3
I1111 23:35:37.625937      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 23:35:40.626240      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:35:40.683: INFO: Creating new exec pod
Nov 11 23:35:40.745: INFO: Waiting up to 5m0s for pod "execpod-affinitybz26m" in namespace "services-5743" to be "running"
Nov 11 23:35:40.764: INFO: Pod "execpod-affinitybz26m": Phase="Pending", Reason="", readiness=false. Elapsed: 19.525105ms
Nov 11 23:35:42.789: INFO: Pod "execpod-affinitybz26m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044170056s
Nov 11 23:35:44.786: INFO: Pod "execpod-affinitybz26m": Phase="Running", Reason="", readiness=true. Elapsed: 4.040901941s
Nov 11 23:35:44.786: INFO: Pod "execpod-affinitybz26m" satisfied condition "running"
Nov 11 23:35:45.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 11 23:35:46.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Nov 11 23:35:46.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:35:46.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.162 80'
Nov 11 23:35:46.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.162 80\nConnection to 172.21.200.162 80 port [tcp/http] succeeded!\n"
Nov 11 23:35:46.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:35:46.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 32098'
Nov 11 23:35:47.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 32098\nConnection to 10.184.98.55 32098 port [tcp/*] succeeded!\n"
Nov 11 23:35:47.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:35:47.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32098'
Nov 11 23:35:47.565: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32098\nConnection to 10.241.148.26 32098 port [tcp/*] succeeded!\n"
Nov 11 23:35:47.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:35:47.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32098/ ; done'
Nov 11 23:35:48.191: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n"
Nov 11 23:35:48.191: INFO: stdout: "\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4"
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
Nov 11 23:35:48.191: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-5743, will wait for the garbage collector to delete the pods 11/11/22 23:35:48.244
Nov 11 23:35:48.350: INFO: Deleting ReplicationController affinity-nodeport took: 34.714115ms
Nov 11 23:35:48.451: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.884738ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:35:51.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5743" for this suite. 11/11/22 23:35:51.683
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":91,"skipped":1582,"failed":0}
------------------------------
• [SLOW TEST] [17.327 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:35:34.383
    Nov 11 23:35:34.383: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:35:34.385
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:34.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:34.461
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-5743 11/11/22 23:35:34.48
    STEP: creating service affinity-nodeport in namespace services-5743 11/11/22 23:35:34.48
    STEP: creating replication controller affinity-nodeport in namespace services-5743 11/11/22 23:35:34.539
    I1111 23:35:34.574347      21 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-5743, replica count: 3
    I1111 23:35:37.625937      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1111 23:35:40.626240      21 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:35:40.683: INFO: Creating new exec pod
    Nov 11 23:35:40.745: INFO: Waiting up to 5m0s for pod "execpod-affinitybz26m" in namespace "services-5743" to be "running"
    Nov 11 23:35:40.764: INFO: Pod "execpod-affinitybz26m": Phase="Pending", Reason="", readiness=false. Elapsed: 19.525105ms
    Nov 11 23:35:42.789: INFO: Pod "execpod-affinitybz26m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044170056s
    Nov 11 23:35:44.786: INFO: Pod "execpod-affinitybz26m": Phase="Running", Reason="", readiness=true. Elapsed: 4.040901941s
    Nov 11 23:35:44.786: INFO: Pod "execpod-affinitybz26m" satisfied condition "running"
    Nov 11 23:35:45.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 11 23:35:46.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Nov 11 23:35:46.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:35:46.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.162 80'
    Nov 11 23:35:46.823: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.162 80\nConnection to 172.21.200.162 80 port [tcp/http] succeeded!\n"
    Nov 11 23:35:46.823: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:35:46.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 32098'
    Nov 11 23:35:47.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 32098\nConnection to 10.184.98.55 32098 port [tcp/*] succeeded!\n"
    Nov 11 23:35:47.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:35:47.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32098'
    Nov 11 23:35:47.565: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32098\nConnection to 10.241.148.26 32098 port [tcp/*] succeeded!\n"
    Nov 11 23:35:47.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:35:47.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5743 exec execpod-affinitybz26m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:32098/ ; done'
    Nov 11 23:35:48.191: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:32098/\n"
    Nov 11 23:35:48.191: INFO: stdout: "\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4\naffinity-nodeport-7njn4"
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Received response from host: affinity-nodeport-7njn4
    Nov 11 23:35:48.191: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-5743, will wait for the garbage collector to delete the pods 11/11/22 23:35:48.244
    Nov 11 23:35:48.350: INFO: Deleting ReplicationController affinity-nodeport took: 34.714115ms
    Nov 11 23:35:48.451: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.884738ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:35:51.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5743" for this suite. 11/11/22 23:35:51.683
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:35:51.711
Nov 11 23:35:51.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename podtemplate 11/11/22 23:35:51.712
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:51.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:51.81
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 11/11/22 23:35:51.827
STEP: Replace a pod template 11/11/22 23:35:51.85
Nov 11 23:35:51.898: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 11 23:35:51.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5866" for this suite. 11/11/22 23:35:51.918
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":92,"skipped":1596,"failed":0}
------------------------------
• [0.248 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:35:51.711
    Nov 11 23:35:51.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename podtemplate 11/11/22 23:35:51.712
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:51.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:51.81
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 11/11/22 23:35:51.827
    STEP: Replace a pod template 11/11/22 23:35:51.85
    Nov 11 23:35:51.898: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 11 23:35:51.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5866" for this suite. 11/11/22 23:35:51.918
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:35:51.963
Nov 11 23:35:51.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename cronjob 11/11/22 23:35:51.965
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:52.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:52.05
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 11/11/22 23:35:52.07
STEP: Ensuring no jobs are scheduled 11/11/22 23:35:52.093
STEP: Ensuring no job exists by listing jobs explicitly 11/11/22 23:40:52.127
STEP: Removing cronjob 11/11/22 23:40:52.166
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 11 23:40:52.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1378" for this suite. 11/11/22 23:40:52.228
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":93,"skipped":1605,"failed":0}
------------------------------
• [SLOW TEST] [300.302 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:35:51.963
    Nov 11 23:35:51.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename cronjob 11/11/22 23:35:51.965
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:35:52.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:35:52.05
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 11/11/22 23:35:52.07
    STEP: Ensuring no jobs are scheduled 11/11/22 23:35:52.093
    STEP: Ensuring no job exists by listing jobs explicitly 11/11/22 23:40:52.127
    STEP: Removing cronjob 11/11/22 23:40:52.166
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 11 23:40:52.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1378" for this suite. 11/11/22 23:40:52.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:40:52.273
Nov 11 23:40:52.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:40:52.276
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:40:52.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:40:52.352
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Nov 11 23:40:52.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7761 version'
Nov 11 23:40:52.499: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Nov 11 23:40:52.499: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4+IKS\", GitCommit:\"e330c4230e5324d7206c1e2e588c67ba717cf496\", GitTreeState:\"clean\", BuildDate:\"2022-11-10T19:38:04Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:40:52.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7761" for this suite. 11/11/22 23:40:52.523
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":94,"skipped":1628,"failed":0}
------------------------------
• [0.275 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:40:52.273
    Nov 11 23:40:52.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:40:52.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:40:52.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:40:52.352
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Nov 11 23:40:52.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7761 version'
    Nov 11 23:40:52.499: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Nov 11 23:40:52.499: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4+IKS\", GitCommit:\"e330c4230e5324d7206c1e2e588c67ba717cf496\", GitTreeState:\"clean\", BuildDate:\"2022-11-10T19:38:04Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:40:52.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7761" for this suite. 11/11/22 23:40:52.523
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:40:52.55
Nov 11 23:40:52.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:40:52.553
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:40:52.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:40:52.628
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-5598 11/11/22 23:40:52.648
Nov 11 23:40:52.689: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5598" to be "running and ready"
Nov 11 23:40:52.708: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 19.195542ms
Nov 11 23:40:52.708: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:40:54.731: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.041664131s
Nov 11 23:40:54.731: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 11 23:40:54.731: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 11 23:40:54.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 11 23:40:55.183: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 11 23:40:55.183: INFO: stdout: "iptables"
Nov 11 23:40:55.183: INFO: proxyMode: iptables
Nov 11 23:40:55.244: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 11 23:40:55.263: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-5598 11/11/22 23:40:55.263
STEP: creating replication controller affinity-nodeport-timeout in namespace services-5598 11/11/22 23:40:55.325
I1111 23:40:55.352328      21 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-5598, replica count: 3
I1111 23:40:58.404563      21 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:40:58.466: INFO: Creating new exec pod
Nov 11 23:40:58.497: INFO: Waiting up to 5m0s for pod "execpod-affinitytvhqt" in namespace "services-5598" to be "running"
Nov 11 23:40:58.517: INFO: Pod "execpod-affinitytvhqt": Phase="Pending", Reason="", readiness=false. Elapsed: 19.094632ms
Nov 11 23:41:00.542: INFO: Pod "execpod-affinitytvhqt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044054267s
Nov 11 23:41:02.537: INFO: Pod "execpod-affinitytvhqt": Phase="Running", Reason="", readiness=true. Elapsed: 4.038668282s
Nov 11 23:41:02.537: INFO: Pod "execpod-affinitytvhqt" satisfied condition "running"
Nov 11 23:41:03.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 11 23:41:03.979: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Nov 11 23:41:03.979: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:41:03.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.204.38 80'
Nov 11 23:41:04.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.204.38 80\nConnection to 172.21.204.38 80 port [tcp/http] succeeded!\n"
Nov 11 23:41:04.393: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:41:04.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 30756'
Nov 11 23:41:04.812: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 30756\nConnection to 10.184.98.55 30756 port [tcp/*] succeeded!\n"
Nov 11 23:41:04.812: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:41:04.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 30756'
Nov 11 23:41:05.167: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 30756\nConnection to 10.241.148.113 30756 port [tcp/*] succeeded!\n"
Nov 11 23:41:05.167: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:41:05.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:30756/ ; done'
Nov 11 23:41:05.720: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
Nov 11 23:41:05.720: INFO: stdout: "\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv"
Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
Nov 11 23:41:05.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.184.98.55:30756/'
Nov 11 23:41:06.215: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
Nov 11 23:41:06.215: INFO: stdout: "affinity-nodeport-timeout-vk2hv"
Nov 11 23:41:26.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.184.98.55:30756/'
Nov 11 23:41:26.632: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
Nov 11 23:41:26.632: INFO: stdout: "affinity-nodeport-timeout-gvsxs"
Nov 11 23:41:26.632: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-5598, will wait for the garbage collector to delete the pods 11/11/22 23:41:26.69
Nov 11 23:41:26.794: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 32.904623ms
Nov 11 23:41:26.995: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 201.144211ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:41:29.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5598" for this suite. 11/11/22 23:41:30.012
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":95,"skipped":1637,"failed":0}
------------------------------
• [SLOW TEST] [37.506 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:40:52.55
    Nov 11 23:40:52.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:40:52.553
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:40:52.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:40:52.628
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-5598 11/11/22 23:40:52.648
    Nov 11 23:40:52.689: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5598" to be "running and ready"
    Nov 11 23:40:52.708: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 19.195542ms
    Nov 11 23:40:52.708: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:40:54.731: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.041664131s
    Nov 11 23:40:54.731: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 11 23:40:54.731: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 11 23:40:54.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 11 23:40:55.183: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 11 23:40:55.183: INFO: stdout: "iptables"
    Nov 11 23:40:55.183: INFO: proxyMode: iptables
    Nov 11 23:40:55.244: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 11 23:40:55.263: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-5598 11/11/22 23:40:55.263
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-5598 11/11/22 23:40:55.325
    I1111 23:40:55.352328      21 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-5598, replica count: 3
    I1111 23:40:58.404563      21 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:40:58.466: INFO: Creating new exec pod
    Nov 11 23:40:58.497: INFO: Waiting up to 5m0s for pod "execpod-affinitytvhqt" in namespace "services-5598" to be "running"
    Nov 11 23:40:58.517: INFO: Pod "execpod-affinitytvhqt": Phase="Pending", Reason="", readiness=false. Elapsed: 19.094632ms
    Nov 11 23:41:00.542: INFO: Pod "execpod-affinitytvhqt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044054267s
    Nov 11 23:41:02.537: INFO: Pod "execpod-affinitytvhqt": Phase="Running", Reason="", readiness=true. Elapsed: 4.038668282s
    Nov 11 23:41:02.537: INFO: Pod "execpod-affinitytvhqt" satisfied condition "running"
    Nov 11 23:41:03.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 11 23:41:03.979: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Nov 11 23:41:03.979: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:41:03.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.204.38 80'
    Nov 11 23:41:04.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.204.38 80\nConnection to 172.21.204.38 80 port [tcp/http] succeeded!\n"
    Nov 11 23:41:04.393: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:41:04.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 30756'
    Nov 11 23:41:04.812: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 30756\nConnection to 10.184.98.55 30756 port [tcp/*] succeeded!\n"
    Nov 11 23:41:04.812: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:41:04.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 30756'
    Nov 11 23:41:05.167: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 30756\nConnection to 10.241.148.113 30756 port [tcp/*] succeeded!\n"
    Nov 11 23:41:05.167: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:41:05.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.184.98.55:30756/ ; done'
    Nov 11 23:41:05.720: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
    Nov 11 23:41:05.720: INFO: stdout: "\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv\naffinity-nodeport-timeout-vk2hv"
    Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.720: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Received response from host: affinity-nodeport-timeout-vk2hv
    Nov 11 23:41:05.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.184.98.55:30756/'
    Nov 11 23:41:06.215: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
    Nov 11 23:41:06.215: INFO: stdout: "affinity-nodeport-timeout-vk2hv"
    Nov 11 23:41:26.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5598 exec execpod-affinitytvhqt -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.184.98.55:30756/'
    Nov 11 23:41:26.632: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.184.98.55:30756/\n"
    Nov 11 23:41:26.632: INFO: stdout: "affinity-nodeport-timeout-gvsxs"
    Nov 11 23:41:26.632: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-5598, will wait for the garbage collector to delete the pods 11/11/22 23:41:26.69
    Nov 11 23:41:26.794: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 32.904623ms
    Nov 11 23:41:26.995: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 201.144211ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:41:29.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5598" for this suite. 11/11/22 23:41:30.012
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:30.08
Nov 11 23:41:30.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:41:30.083
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:30.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:30.158
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/11/22 23:41:30.179
Nov 11 23:41:30.217: INFO: Waiting up to 5m0s for pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e" in namespace "emptydir-9095" to be "Succeeded or Failed"
Nov 11 23:41:30.237: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.197182ms
Nov 11 23:41:32.273: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056635735s
Nov 11 23:41:34.257: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039885949s
Nov 11 23:41:36.260: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043002003s
STEP: Saw pod success 11/11/22 23:41:36.26
Nov 11 23:41:36.260: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e" satisfied condition "Succeeded or Failed"
Nov 11 23:41:36.280: INFO: Trying to get logs from node 10.184.98.55 pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e container test-container: <nil>
STEP: delete the pod 11/11/22 23:41:36.417
Nov 11 23:41:36.467: INFO: Waiting for pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e to disappear
Nov 11 23:41:36.487: INFO: Pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:41:36.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9095" for this suite. 11/11/22 23:41:36.512
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":96,"skipped":1696,"failed":0}
------------------------------
• [SLOW TEST] [6.456 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:30.08
    Nov 11 23:41:30.081: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:41:30.083
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:30.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:30.158
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/11/22 23:41:30.179
    Nov 11 23:41:30.217: INFO: Waiting up to 5m0s for pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e" in namespace "emptydir-9095" to be "Succeeded or Failed"
    Nov 11 23:41:30.237: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.197182ms
    Nov 11 23:41:32.273: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056635735s
    Nov 11 23:41:34.257: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039885949s
    Nov 11 23:41:36.260: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043002003s
    STEP: Saw pod success 11/11/22 23:41:36.26
    Nov 11 23:41:36.260: INFO: Pod "pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e" satisfied condition "Succeeded or Failed"
    Nov 11 23:41:36.280: INFO: Trying to get logs from node 10.184.98.55 pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e container test-container: <nil>
    STEP: delete the pod 11/11/22 23:41:36.417
    Nov 11 23:41:36.467: INFO: Waiting for pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e to disappear
    Nov 11 23:41:36.487: INFO: Pod pod-83b1f7f0-9c4f-4e8d-960f-39ce7783721e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:41:36.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9095" for this suite. 11/11/22 23:41:36.512
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:36.559
Nov 11 23:41:36.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/11/22 23:41:36.561
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:36.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:36.627
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 11/11/22 23:41:36.647
Nov 11 23:41:36.686: INFO: Waiting up to 5m0s for pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7" in namespace "var-expansion-3523" to be "Succeeded or Failed"
Nov 11 23:41:36.706: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.110477ms
Nov 11 23:41:38.725: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038006155s
Nov 11 23:41:40.727: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040422065s
Nov 11 23:41:42.728: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04109105s
STEP: Saw pod success 11/11/22 23:41:42.728
Nov 11 23:41:42.728: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7" satisfied condition "Succeeded or Failed"
Nov 11 23:41:42.750: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 container dapi-container: <nil>
STEP: delete the pod 11/11/22 23:41:42.787
Nov 11 23:41:42.833: INFO: Waiting for pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 to disappear
Nov 11 23:41:42.854: INFO: Pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 11 23:41:42.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3523" for this suite. 11/11/22 23:41:42.878
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":97,"skipped":1777,"failed":0}
------------------------------
• [SLOW TEST] [6.346 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:36.559
    Nov 11 23:41:36.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/11/22 23:41:36.561
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:36.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:36.627
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 11/11/22 23:41:36.647
    Nov 11 23:41:36.686: INFO: Waiting up to 5m0s for pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7" in namespace "var-expansion-3523" to be "Succeeded or Failed"
    Nov 11 23:41:36.706: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.110477ms
    Nov 11 23:41:38.725: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038006155s
    Nov 11 23:41:40.727: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040422065s
    Nov 11 23:41:42.728: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04109105s
    STEP: Saw pod success 11/11/22 23:41:42.728
    Nov 11 23:41:42.728: INFO: Pod "var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7" satisfied condition "Succeeded or Failed"
    Nov 11 23:41:42.750: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 container dapi-container: <nil>
    STEP: delete the pod 11/11/22 23:41:42.787
    Nov 11 23:41:42.833: INFO: Waiting for pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 to disappear
    Nov 11 23:41:42.854: INFO: Pod var-expansion-5342aefa-5897-4b8f-8ccc-71abdc440dc7 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 11 23:41:42.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3523" for this suite. 11/11/22 23:41:42.878
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:42.907
Nov 11 23:41:42.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/11/22 23:41:42.91
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:42.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:42.989
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 11/11/22 23:41:43.01
STEP: Ensuring active pods == parallelism 11/11/22 23:41:43.046
STEP: Orphaning one of the Job's Pods 11/11/22 23:41:47.072
Nov 11 23:41:47.650: INFO: Successfully updated pod "adopt-release-dj7wn"
STEP: Checking that the Job readopts the Pod 11/11/22 23:41:47.65
Nov 11 23:41:47.650: INFO: Waiting up to 15m0s for pod "adopt-release-dj7wn" in namespace "job-2999" to be "adopted"
Nov 11 23:41:47.672: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 21.156633ms
Nov 11 23:41:49.694: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 2.044125537s
Nov 11 23:41:49.695: INFO: Pod "adopt-release-dj7wn" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 11/11/22 23:41:49.695
Nov 11 23:41:50.267: INFO: Successfully updated pod "adopt-release-dj7wn"
STEP: Checking that the Job releases the Pod 11/11/22 23:41:50.267
Nov 11 23:41:50.268: INFO: Waiting up to 15m0s for pod "adopt-release-dj7wn" in namespace "job-2999" to be "released"
Nov 11 23:41:50.287: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 19.322059ms
Nov 11 23:41:52.315: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 2.046910878s
Nov 11 23:41:52.315: INFO: Pod "adopt-release-dj7wn" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 11 23:41:52.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2999" for this suite. 11/11/22 23:41:52.341
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":98,"skipped":1777,"failed":0}
------------------------------
• [SLOW TEST] [9.458 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:42.907
    Nov 11 23:41:42.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/11/22 23:41:42.91
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:42.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:42.989
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 11/11/22 23:41:43.01
    STEP: Ensuring active pods == parallelism 11/11/22 23:41:43.046
    STEP: Orphaning one of the Job's Pods 11/11/22 23:41:47.072
    Nov 11 23:41:47.650: INFO: Successfully updated pod "adopt-release-dj7wn"
    STEP: Checking that the Job readopts the Pod 11/11/22 23:41:47.65
    Nov 11 23:41:47.650: INFO: Waiting up to 15m0s for pod "adopt-release-dj7wn" in namespace "job-2999" to be "adopted"
    Nov 11 23:41:47.672: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 21.156633ms
    Nov 11 23:41:49.694: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 2.044125537s
    Nov 11 23:41:49.695: INFO: Pod "adopt-release-dj7wn" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 11/11/22 23:41:49.695
    Nov 11 23:41:50.267: INFO: Successfully updated pod "adopt-release-dj7wn"
    STEP: Checking that the Job releases the Pod 11/11/22 23:41:50.267
    Nov 11 23:41:50.268: INFO: Waiting up to 15m0s for pod "adopt-release-dj7wn" in namespace "job-2999" to be "released"
    Nov 11 23:41:50.287: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 19.322059ms
    Nov 11 23:41:52.315: INFO: Pod "adopt-release-dj7wn": Phase="Running", Reason="", readiness=true. Elapsed: 2.046910878s
    Nov 11 23:41:52.315: INFO: Pod "adopt-release-dj7wn" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 11 23:41:52.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2999" for this suite. 11/11/22 23:41:52.341
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:52.376
Nov 11 23:41:52.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename init-container 11/11/22 23:41:52.379
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:52.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:52.459
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 11/11/22 23:41:52.48
Nov 11 23:41:52.481: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 11 23:41:57.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9379" for this suite. 11/11/22 23:41:57.152
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":99,"skipped":1809,"failed":0}
------------------------------
• [4.818 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:52.376
    Nov 11 23:41:52.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename init-container 11/11/22 23:41:52.379
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:52.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:52.459
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 11/11/22 23:41:52.48
    Nov 11 23:41:52.481: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 11 23:41:57.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9379" for this suite. 11/11/22 23:41:57.152
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:57.196
Nov 11 23:41:57.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-pred 11/11/22 23:41:57.198
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:57.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:57.275
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 11 23:41:57.297: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 11 23:41:57.341: INFO: Waiting for terminating namespaces to be deleted...
Nov 11 23:41:57.359: INFO: 
Logging pods the apiserver thinks is on node 10.184.98.55 before test
Nov 11 23:41:57.435: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:41:57.436: INFO: adopt-release-dj7wn from job-2999 started at 2022-11-11 23:41:43 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
Nov 11 23:41:57.436: INFO: adopt-release-tq8qp from job-2999 started at 2022-11-11 23:41:51 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
Nov 11 23:41:57.436: INFO: adopt-release-vp6gl from job-2999 started at 2022-11-11 23:41:43 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
Nov 11 23:41:57.436: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:41:57.436: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:41:57.436: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:41:57.436: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:41:57.436: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:41:57.436: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:41:57.436: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Nov 11 23:41:57.436: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:41:57.436: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:41:57.436: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:41:57.436: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:41:57.436: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:41:57.436: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 11 23:41:57.436: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.436: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:41:57.436: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:41:57.436: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.113 before test
Nov 11 23:41:57.549: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 11 23:41:57.549: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:41:57.549: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:41:57.549: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container autoscaler ready: true, restart count 0
Nov 11 23:41:57.549: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:41:57.549: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:41:57.549: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:41:57.549: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:41:57.549: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Nov 11 23:41:57.549: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:41:57.549: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 11 23:41:57.549: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container config-watcher ready: true, restart count 0
Nov 11 23:41:57.549: INFO: 	Container metrics-server ready: true, restart count 0
Nov 11 23:41:57.549: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 11 23:41:57.549: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.549: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:41:57.549: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 11 23:41:57.549: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.26 before test
Nov 11 23:41:57.609: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.610: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov 11 23:41:57.610: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.610: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 11 23:41:57.610: INFO: pod-init-424ce055-bedb-4d2e-811b-220d65992b4e from init-container-9379 started at 2022-11-11 23:41:52 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.610: INFO: 	Container run1 ready: true, restart count 0
Nov 11 23:41:57.610: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.610: INFO: 	Container calico-node ready: true, restart count 0
Nov 11 23:41:57.610: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.610: INFO: 	Container calico-typha ready: true, restart count 0
Nov 11 23:41:57.611: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.611: INFO: 	Container coredns ready: true, restart count 0
Nov 11 23:41:57.611: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.611: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 11 23:41:57.611: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.611: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 11 23:41:57.611: INFO: 	Container pause ready: true, restart count 0
Nov 11 23:41:57.611: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.611: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 11 23:41:57.612: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.612: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 11 23:41:57.612: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 11 23:41:57.612: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 11 23:41:57.612: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.612: INFO: 	Container e2e ready: true, restart count 0
Nov 11 23:41:57.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:41:57.612: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 11 23:41:57.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 11 23:41:57.612: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 11/11/22 23:41:57.613
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1726ac43785fd807], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 11/11/22 23:41:57.797
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:41:58.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8246" for this suite. 11/11/22 23:41:58.849
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":100,"skipped":1820,"failed":0}
------------------------------
• [1.681 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:57.196
    Nov 11 23:41:57.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-pred 11/11/22 23:41:57.198
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:57.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:57.275
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 11 23:41:57.297: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 11 23:41:57.341: INFO: Waiting for terminating namespaces to be deleted...
    Nov 11 23:41:57.359: INFO: 
    Logging pods the apiserver thinks is on node 10.184.98.55 before test
    Nov 11 23:41:57.435: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-dcwxc from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: adopt-release-dj7wn from job-2999 started at 2022-11-11 23:41:43 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: adopt-release-tq8qp from job-2999 started at 2022-11-11 23:41:51 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: adopt-release-vp6gl from job-2999 started at 2022-11-11 23:41:43 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container c ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: calico-typha-69875cbbb9-mwlr2 from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: ingress-cluster-healthcheck-5fc9658887-j96dq from kube-system started at 2022-11-11 21:01:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: metrics-server-6f6df44444-8tc95 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xlk7h from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.436: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:41:57.436: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.113 before test
    Nov 11 23:41:57.549: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.549: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 11 23:41:57.549: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.26 before test
    Nov 11 23:41:57.609: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.610: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    Nov 11 23:41:57.610: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.610: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 11 23:41:57.610: INFO: pod-init-424ce055-bedb-4d2e-811b-220d65992b4e from init-container-9379 started at 2022-11-11 23:41:52 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.610: INFO: 	Container run1 ready: true, restart count 0
    Nov 11 23:41:57.610: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.610: INFO: 	Container calico-node ready: true, restart count 0
    Nov 11 23:41:57.610: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.610: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 11 23:41:57.611: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.611: INFO: 	Container coredns ready: true, restart count 0
    Nov 11 23:41:57.611: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.611: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 11 23:41:57.611: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.611: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 11 23:41:57.611: INFO: 	Container pause ready: true, restart count 0
    Nov 11 23:41:57.611: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.611: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.612: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 11 23:41:57.612: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.612: INFO: 	Container e2e ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 11 23:41:57.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 11 23:41:57.612: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 11/11/22 23:41:57.613
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1726ac43785fd807], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 11/11/22 23:41:57.797
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:41:58.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8246" for this suite. 11/11/22 23:41:58.849
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:41:58.885
Nov 11 23:41:58.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/11/22 23:41:58.887
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:58.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:59.006
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 11/11/22 23:41:59.069
STEP: Verify that the required pods have come up. 11/11/22 23:41:59.092
Nov 11 23:41:59.111: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 11 23:42:04.134: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/11/22 23:42:04.134
STEP: Getting /status 11/11/22 23:42:04.135
Nov 11 23:42:04.162: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 11/11/22 23:42:04.162
Nov 11 23:42:04.217: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 11/11/22 23:42:04.217
Nov 11 23:42:04.228: INFO: Observed &ReplicaSet event: ADDED
Nov 11 23:42:04.228: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.229: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.230: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.230: INFO: Found replicaset test-rs in namespace replicaset-2882 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 11 23:42:04.230: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 11/11/22 23:42:04.23
Nov 11 23:42:04.231: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 11 23:42:04.270: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 11/11/22 23:42:04.27
Nov 11 23:42:04.300: INFO: Observed &ReplicaSet event: ADDED
Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.301: INFO: Observed replicaset test-rs in namespace replicaset-2882 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 11 23:42:04.302: INFO: Observed &ReplicaSet event: MODIFIED
Nov 11 23:42:04.302: INFO: Found replicaset test-rs in namespace replicaset-2882 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Nov 11 23:42:04.302: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 11 23:42:04.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2882" for this suite. 11/11/22 23:42:04.324
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":101,"skipped":1887,"failed":0}
------------------------------
• [SLOW TEST] [5.463 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:41:58.885
    Nov 11 23:41:58.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/11/22 23:41:58.887
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:41:58.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:41:59.006
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 11/11/22 23:41:59.069
    STEP: Verify that the required pods have come up. 11/11/22 23:41:59.092
    Nov 11 23:41:59.111: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 11 23:42:04.134: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/11/22 23:42:04.134
    STEP: Getting /status 11/11/22 23:42:04.135
    Nov 11 23:42:04.162: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 11/11/22 23:42:04.162
    Nov 11 23:42:04.217: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 11/11/22 23:42:04.217
    Nov 11 23:42:04.228: INFO: Observed &ReplicaSet event: ADDED
    Nov 11 23:42:04.228: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.229: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.230: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.230: INFO: Found replicaset test-rs in namespace replicaset-2882 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 11 23:42:04.230: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 11/11/22 23:42:04.23
    Nov 11 23:42:04.231: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 11 23:42:04.270: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 11/11/22 23:42:04.27
    Nov 11 23:42:04.300: INFO: Observed &ReplicaSet event: ADDED
    Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.301: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.301: INFO: Observed replicaset test-rs in namespace replicaset-2882 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 11 23:42:04.302: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 11 23:42:04.302: INFO: Found replicaset test-rs in namespace replicaset-2882 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Nov 11 23:42:04.302: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 11 23:42:04.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2882" for this suite. 11/11/22 23:42:04.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:42:04.352
Nov 11 23:42:04.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:42:04.354
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:04.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:04.434
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:42:04.451
Nov 11 23:42:04.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407" in namespace "projected-674" to be "Succeeded or Failed"
Nov 11 23:42:04.510: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 19.280537ms
Nov 11 23:42:06.528: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037295676s
Nov 11 23:42:08.534: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042773417s
Nov 11 23:42:10.531: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040448237s
STEP: Saw pod success 11/11/22 23:42:10.532
Nov 11 23:42:10.532: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407" satisfied condition "Succeeded or Failed"
Nov 11 23:42:10.552: INFO: Trying to get logs from node 10.241.148.26 pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 container client-container: <nil>
STEP: delete the pod 11/11/22 23:42:10.665
Nov 11 23:42:10.721: INFO: Waiting for pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 to disappear
Nov 11 23:42:10.740: INFO: Pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 11 23:42:10.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-674" for this suite. 11/11/22 23:42:10.756
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":102,"skipped":1902,"failed":0}
------------------------------
• [SLOW TEST] [6.426 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:42:04.352
    Nov 11 23:42:04.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:42:04.354
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:04.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:04.434
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:42:04.451
    Nov 11 23:42:04.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407" in namespace "projected-674" to be "Succeeded or Failed"
    Nov 11 23:42:04.510: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 19.280537ms
    Nov 11 23:42:06.528: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037295676s
    Nov 11 23:42:08.534: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042773417s
    Nov 11 23:42:10.531: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040448237s
    STEP: Saw pod success 11/11/22 23:42:10.532
    Nov 11 23:42:10.532: INFO: Pod "downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407" satisfied condition "Succeeded or Failed"
    Nov 11 23:42:10.552: INFO: Trying to get logs from node 10.241.148.26 pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 container client-container: <nil>
    STEP: delete the pod 11/11/22 23:42:10.665
    Nov 11 23:42:10.721: INFO: Waiting for pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 to disappear
    Nov 11 23:42:10.740: INFO: Pod downwardapi-volume-ab439045-60fc-475d-828e-0e275846a407 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 11 23:42:10.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-674" for this suite. 11/11/22 23:42:10.756
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:42:10.779
Nov 11 23:42:10.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:42:10.781
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:10.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:10.849
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 11/11/22 23:42:10.866
Nov 11 23:42:10.867: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Nov 11 23:42:10.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:11.558: INFO: stderr: ""
Nov 11 23:42:11.558: INFO: stdout: "service/agnhost-replica created\n"
Nov 11 23:42:11.558: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Nov 11 23:42:11.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:12.229: INFO: stderr: ""
Nov 11 23:42:12.229: INFO: stdout: "service/agnhost-primary created\n"
Nov 11 23:42:12.229: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 11 23:42:12.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:12.789: INFO: stderr: ""
Nov 11 23:42:12.789: INFO: stdout: "service/frontend created\n"
Nov 11 23:42:12.789: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 11 23:42:12.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:13.377: INFO: stderr: ""
Nov 11 23:42:13.377: INFO: stdout: "deployment.apps/frontend created\n"
Nov 11 23:42:13.377: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 11 23:42:13.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:13.951: INFO: stderr: ""
Nov 11 23:42:13.951: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Nov 11 23:42:13.952: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 11 23:42:13.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
Nov 11 23:42:14.642: INFO: stderr: ""
Nov 11 23:42:14.642: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 11/11/22 23:42:14.642
Nov 11 23:42:14.642: INFO: Waiting for all frontend pods to be Running.
Nov 11 23:42:19.695: INFO: Waiting for frontend to serve content.
Nov 11 23:42:19.786: INFO: Trying to add a new entry to the guestbook.
Nov 11 23:42:19.828: INFO: Verifying that added entry can be retrieved.
Nov 11 23:42:19.910: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 11/11/22 23:42:24.959
Nov 11 23:42:24.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:25.211: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:25.211: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 11/11/22 23:42:25.211
Nov 11 23:42:25.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:25.469: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:25.469: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/11/22 23:42:25.469
Nov 11 23:42:25.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:25.695: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:25.695: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/11/22 23:42:25.695
Nov 11 23:42:25.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:25.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:25.871: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/11/22 23:42:25.871
Nov 11 23:42:25.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:26.075: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:26.075: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/11/22 23:42:26.075
Nov 11 23:42:26.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
Nov 11 23:42:26.371: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:42:26.371: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:42:26.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-542" for this suite. 11/11/22 23:42:26.396
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":103,"skipped":1905,"failed":0}
------------------------------
• [SLOW TEST] [15.654 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:42:10.779
    Nov 11 23:42:10.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:42:10.781
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:10.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:10.849
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 11/11/22 23:42:10.866
    Nov 11 23:42:10.867: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Nov 11 23:42:10.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:11.558: INFO: stderr: ""
    Nov 11 23:42:11.558: INFO: stdout: "service/agnhost-replica created\n"
    Nov 11 23:42:11.558: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Nov 11 23:42:11.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:12.229: INFO: stderr: ""
    Nov 11 23:42:12.229: INFO: stdout: "service/agnhost-primary created\n"
    Nov 11 23:42:12.229: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Nov 11 23:42:12.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:12.789: INFO: stderr: ""
    Nov 11 23:42:12.789: INFO: stdout: "service/frontend created\n"
    Nov 11 23:42:12.789: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Nov 11 23:42:12.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:13.377: INFO: stderr: ""
    Nov 11 23:42:13.377: INFO: stdout: "deployment.apps/frontend created\n"
    Nov 11 23:42:13.377: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 11 23:42:13.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:13.951: INFO: stderr: ""
    Nov 11 23:42:13.951: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Nov 11 23:42:13.952: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 11 23:42:13.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 create -f -'
    Nov 11 23:42:14.642: INFO: stderr: ""
    Nov 11 23:42:14.642: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 11/11/22 23:42:14.642
    Nov 11 23:42:14.642: INFO: Waiting for all frontend pods to be Running.
    Nov 11 23:42:19.695: INFO: Waiting for frontend to serve content.
    Nov 11 23:42:19.786: INFO: Trying to add a new entry to the guestbook.
    Nov 11 23:42:19.828: INFO: Verifying that added entry can be retrieved.
    Nov 11 23:42:19.910: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 11/11/22 23:42:24.959
    Nov 11 23:42:24.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:25.211: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:25.211: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 11/11/22 23:42:25.211
    Nov 11 23:42:25.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:25.469: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:25.469: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/11/22 23:42:25.469
    Nov 11 23:42:25.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:25.695: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:25.695: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/11/22 23:42:25.695
    Nov 11 23:42:25.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:25.871: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:25.871: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/11/22 23:42:25.871
    Nov 11 23:42:25.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:26.075: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:26.075: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/11/22 23:42:26.075
    Nov 11 23:42:26.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-542 delete --grace-period=0 --force -f -'
    Nov 11 23:42:26.371: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:42:26.371: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:42:26.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-542" for this suite. 11/11/22 23:42:26.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:42:26.435
Nov 11 23:42:26.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/11/22 23:42:26.437
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:26.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:26.523
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 11/11/22 23:42:26.54
Nov 11 23:42:26.582: INFO: Waiting up to 5m0s for pod "pod-87lc9" in namespace "pods-3120" to be "running"
Nov 11 23:42:26.643: INFO: Pod "pod-87lc9": Phase="Pending", Reason="", readiness=false. Elapsed: 60.289168ms
Nov 11 23:42:28.665: INFO: Pod "pod-87lc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082677208s
Nov 11 23:42:30.667: INFO: Pod "pod-87lc9": Phase="Running", Reason="", readiness=true. Elapsed: 4.084549428s
Nov 11 23:42:30.667: INFO: Pod "pod-87lc9" satisfied condition "running"
STEP: patching /status 11/11/22 23:42:30.667
Nov 11 23:42:30.703: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 11 23:42:30.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3120" for this suite. 11/11/22 23:42:30.722
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":104,"skipped":1911,"failed":0}
------------------------------
• [4.315 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:42:26.435
    Nov 11 23:42:26.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/11/22 23:42:26.437
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:26.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:26.523
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 11/11/22 23:42:26.54
    Nov 11 23:42:26.582: INFO: Waiting up to 5m0s for pod "pod-87lc9" in namespace "pods-3120" to be "running"
    Nov 11 23:42:26.643: INFO: Pod "pod-87lc9": Phase="Pending", Reason="", readiness=false. Elapsed: 60.289168ms
    Nov 11 23:42:28.665: INFO: Pod "pod-87lc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082677208s
    Nov 11 23:42:30.667: INFO: Pod "pod-87lc9": Phase="Running", Reason="", readiness=true. Elapsed: 4.084549428s
    Nov 11 23:42:30.667: INFO: Pod "pod-87lc9" satisfied condition "running"
    STEP: patching /status 11/11/22 23:42:30.667
    Nov 11 23:42:30.703: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 11 23:42:30.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3120" for this suite. 11/11/22 23:42:30.722
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:42:30.756
Nov 11 23:42:30.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/11/22 23:42:30.758
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:30.811
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:30.828
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Nov 11 23:42:30.945: INFO: Create a RollingUpdate DaemonSet
Nov 11 23:42:30.968: INFO: Check that daemon pods launch on every node of the cluster
Nov 11 23:42:31.003: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:42:31.003: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:42:32.044: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:42:32.044: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:42:33.045: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:42:33.045: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:42:34.043: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:42:34.044: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Nov 11 23:42:34.044: INFO: Update the DaemonSet to trigger a rollout
Nov 11 23:42:34.081: INFO: Updating DaemonSet daemon-set
Nov 11 23:42:38.169: INFO: Roll back the DaemonSet before rollout is complete
Nov 11 23:42:38.210: INFO: Updating DaemonSet daemon-set
Nov 11 23:42:38.210: INFO: Make sure DaemonSet rollback is complete
Nov 11 23:42:38.230: INFO: Wrong image for pod: daemon-set-vglh6. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Nov 11 23:42:38.230: INFO: Pod daemon-set-vglh6 is not available
Nov 11 23:42:43.269: INFO: Pod daemon-set-9gnpl is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:42:43.339
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4924, will wait for the garbage collector to delete the pods 11/11/22 23:42:43.339
Nov 11 23:42:43.431: INFO: Deleting DaemonSet.extensions daemon-set took: 25.931248ms
Nov 11 23:42:43.531: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.17893ms
Nov 11 23:42:45.650: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:42:45.650: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 11 23:42:45.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26645"},"items":null}

Nov 11 23:42:45.694: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26645"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:42:45.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4924" for this suite. 11/11/22 23:42:45.799
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":105,"skipped":1934,"failed":0}
------------------------------
• [SLOW TEST] [15.064 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:42:30.756
    Nov 11 23:42:30.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/11/22 23:42:30.758
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:30.811
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:30.828
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Nov 11 23:42:30.945: INFO: Create a RollingUpdate DaemonSet
    Nov 11 23:42:30.968: INFO: Check that daemon pods launch on every node of the cluster
    Nov 11 23:42:31.003: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:42:31.003: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:42:32.044: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:42:32.044: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:42:33.045: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:42:33.045: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:42:34.043: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:42:34.044: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Nov 11 23:42:34.044: INFO: Update the DaemonSet to trigger a rollout
    Nov 11 23:42:34.081: INFO: Updating DaemonSet daemon-set
    Nov 11 23:42:38.169: INFO: Roll back the DaemonSet before rollout is complete
    Nov 11 23:42:38.210: INFO: Updating DaemonSet daemon-set
    Nov 11 23:42:38.210: INFO: Make sure DaemonSet rollback is complete
    Nov 11 23:42:38.230: INFO: Wrong image for pod: daemon-set-vglh6. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Nov 11 23:42:38.230: INFO: Pod daemon-set-vglh6 is not available
    Nov 11 23:42:43.269: INFO: Pod daemon-set-9gnpl is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:42:43.339
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4924, will wait for the garbage collector to delete the pods 11/11/22 23:42:43.339
    Nov 11 23:42:43.431: INFO: Deleting DaemonSet.extensions daemon-set took: 25.931248ms
    Nov 11 23:42:43.531: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.17893ms
    Nov 11 23:42:45.650: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:42:45.650: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 11 23:42:45.675: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26645"},"items":null}

    Nov 11 23:42:45.694: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26645"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:42:45.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4924" for this suite. 11/11/22 23:42:45.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:42:45.827
Nov 11 23:42:45.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/11/22 23:42:45.829
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:45.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:45.9
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 11/11/22 23:43:02.963
STEP: Creating a ResourceQuota 11/11/22 23:43:07.983
STEP: Ensuring resource quota status is calculated 11/11/22 23:43:08.007
STEP: Creating a ConfigMap 11/11/22 23:43:10.029
STEP: Ensuring resource quota status captures configMap creation 11/11/22 23:43:10.066
STEP: Deleting a ConfigMap 11/11/22 23:43:12.087
STEP: Ensuring resource quota status released usage 11/11/22 23:43:12.118
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 11 23:43:14.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3131" for this suite. 11/11/22 23:43:14.158
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":106,"skipped":1960,"failed":0}
------------------------------
• [SLOW TEST] [28.356 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:42:45.827
    Nov 11 23:42:45.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/11/22 23:42:45.829
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:42:45.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:42:45.9
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 11/11/22 23:43:02.963
    STEP: Creating a ResourceQuota 11/11/22 23:43:07.983
    STEP: Ensuring resource quota status is calculated 11/11/22 23:43:08.007
    STEP: Creating a ConfigMap 11/11/22 23:43:10.029
    STEP: Ensuring resource quota status captures configMap creation 11/11/22 23:43:10.066
    STEP: Deleting a ConfigMap 11/11/22 23:43:12.087
    STEP: Ensuring resource quota status released usage 11/11/22 23:43:12.118
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 11 23:43:14.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3131" for this suite. 11/11/22 23:43:14.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:43:14.186
Nov 11 23:43:14.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:43:14.189
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:14.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:14.26
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8122 11/11/22 23:43:14.28
STEP: changing the ExternalName service to type=NodePort 11/11/22 23:43:14.32
STEP: creating replication controller externalname-service in namespace services-8122 11/11/22 23:43:14.393
I1111 23:43:14.418498      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8122, replica count: 2
I1111 23:43:17.470341      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:43:17.470: INFO: Creating new exec pod
Nov 11 23:43:17.509: INFO: Waiting up to 5m0s for pod "execpodmhmt4" in namespace "services-8122" to be "running"
Nov 11 23:43:17.529: INFO: Pod "execpodmhmt4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.501583ms
Nov 11 23:43:19.549: INFO: Pod "execpodmhmt4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039277981s
Nov 11 23:43:21.551: INFO: Pod "execpodmhmt4": Phase="Running", Reason="", readiness=true. Elapsed: 4.041182912s
Nov 11 23:43:21.551: INFO: Pod "execpodmhmt4" satisfied condition "running"
Nov 11 23:43:22.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 11 23:43:23.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 11 23:43:23.007: INFO: stdout: "externalname-service-6726h"
Nov 11 23:43:23.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.124.53 80'
Nov 11 23:43:23.329: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.124.53 80\nConnection to 172.21.124.53 80 port [tcp/http] succeeded!\n"
Nov 11 23:43:23.329: INFO: stdout: "externalname-service-6726h"
Nov 11 23:43:23.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32242'
Nov 11 23:43:23.725: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 32242\nConnection to 10.241.148.113 32242 port [tcp/*] succeeded!\n"
Nov 11 23:43:23.725: INFO: stdout: "externalname-service-6726h"
Nov 11 23:43:23.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32242'
Nov 11 23:43:24.216: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32242\nConnection to 10.241.148.26 32242 port [tcp/*] succeeded!\n"
Nov 11 23:43:24.216: INFO: stdout: "externalname-service-dkw4h"
Nov 11 23:43:24.216: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:43:24.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8122" for this suite. 11/11/22 23:43:24.314
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":107,"skipped":1980,"failed":0}
------------------------------
• [SLOW TEST] [10.154 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:43:14.186
    Nov 11 23:43:14.186: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:43:14.189
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:14.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:14.26
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-8122 11/11/22 23:43:14.28
    STEP: changing the ExternalName service to type=NodePort 11/11/22 23:43:14.32
    STEP: creating replication controller externalname-service in namespace services-8122 11/11/22 23:43:14.393
    I1111 23:43:14.418498      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8122, replica count: 2
    I1111 23:43:17.470341      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:43:17.470: INFO: Creating new exec pod
    Nov 11 23:43:17.509: INFO: Waiting up to 5m0s for pod "execpodmhmt4" in namespace "services-8122" to be "running"
    Nov 11 23:43:17.529: INFO: Pod "execpodmhmt4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.501583ms
    Nov 11 23:43:19.549: INFO: Pod "execpodmhmt4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039277981s
    Nov 11 23:43:21.551: INFO: Pod "execpodmhmt4": Phase="Running", Reason="", readiness=true. Elapsed: 4.041182912s
    Nov 11 23:43:21.551: INFO: Pod "execpodmhmt4" satisfied condition "running"
    Nov 11 23:43:22.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 11 23:43:23.007: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 11 23:43:23.007: INFO: stdout: "externalname-service-6726h"
    Nov 11 23:43:23.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.124.53 80'
    Nov 11 23:43:23.329: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.124.53 80\nConnection to 172.21.124.53 80 port [tcp/http] succeeded!\n"
    Nov 11 23:43:23.329: INFO: stdout: "externalname-service-6726h"
    Nov 11 23:43:23.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32242'
    Nov 11 23:43:23.725: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.113 32242\nConnection to 10.241.148.113 32242 port [tcp/*] succeeded!\n"
    Nov 11 23:43:23.725: INFO: stdout: "externalname-service-6726h"
    Nov 11 23:43:23.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-8122 exec execpodmhmt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.26 32242'
    Nov 11 23:43:24.216: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.241.148.26 32242\nConnection to 10.241.148.26 32242 port [tcp/*] succeeded!\n"
    Nov 11 23:43:24.216: INFO: stdout: "externalname-service-dkw4h"
    Nov 11 23:43:24.216: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:43:24.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8122" for this suite. 11/11/22 23:43:24.314
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:43:24.368
Nov 11 23:43:24.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename subpath 11/11/22 23:43:24.371
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:24.423
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:24.442
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/11/22 23:43:24.458
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-gfws 11/11/22 23:43:24.5
STEP: Creating a pod to test atomic-volume-subpath 11/11/22 23:43:24.501
Nov 11 23:43:24.541: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gfws" in namespace "subpath-6285" to be "Succeeded or Failed"
Nov 11 23:43:24.561: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Pending", Reason="", readiness=false. Elapsed: 20.522256ms
Nov 11 23:43:26.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040859385s
Nov 11 23:43:28.580: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 4.038930238s
Nov 11 23:43:30.616: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 6.075812993s
Nov 11 23:43:32.583: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 8.042195287s
Nov 11 23:43:34.586: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 10.045828707s
Nov 11 23:43:36.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 12.040026329s
Nov 11 23:43:38.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 14.040765009s
Nov 11 23:43:40.590: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 16.04943352s
Nov 11 23:43:42.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 18.040226033s
Nov 11 23:43:44.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 20.040904153s
Nov 11 23:43:46.580: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 22.039838001s
Nov 11 23:43:48.605: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=false. Elapsed: 24.064341638s
Nov 11 23:43:50.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.040473349s
STEP: Saw pod success 11/11/22 23:43:50.581
Nov 11 23:43:50.581: INFO: Pod "pod-subpath-test-downwardapi-gfws" satisfied condition "Succeeded or Failed"
Nov 11 23:43:50.603: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-downwardapi-gfws container test-container-subpath-downwardapi-gfws: <nil>
STEP: delete the pod 11/11/22 23:43:50.7
Nov 11 23:43:50.747: INFO: Waiting for pod pod-subpath-test-downwardapi-gfws to disappear
Nov 11 23:43:50.766: INFO: Pod pod-subpath-test-downwardapi-gfws no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-gfws 11/11/22 23:43:50.766
Nov 11 23:43:50.767: INFO: Deleting pod "pod-subpath-test-downwardapi-gfws" in namespace "subpath-6285"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 11 23:43:50.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6285" for this suite. 11/11/22 23:43:50.807
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":108,"skipped":2049,"failed":0}
------------------------------
• [SLOW TEST] [26.461 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:43:24.368
    Nov 11 23:43:24.369: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename subpath 11/11/22 23:43:24.371
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:24.423
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:24.442
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/11/22 23:43:24.458
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-gfws 11/11/22 23:43:24.5
    STEP: Creating a pod to test atomic-volume-subpath 11/11/22 23:43:24.501
    Nov 11 23:43:24.541: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-gfws" in namespace "subpath-6285" to be "Succeeded or Failed"
    Nov 11 23:43:24.561: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Pending", Reason="", readiness=false. Elapsed: 20.522256ms
    Nov 11 23:43:26.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040859385s
    Nov 11 23:43:28.580: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 4.038930238s
    Nov 11 23:43:30.616: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 6.075812993s
    Nov 11 23:43:32.583: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 8.042195287s
    Nov 11 23:43:34.586: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 10.045828707s
    Nov 11 23:43:36.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 12.040026329s
    Nov 11 23:43:38.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 14.040765009s
    Nov 11 23:43:40.590: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 16.04943352s
    Nov 11 23:43:42.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 18.040226033s
    Nov 11 23:43:44.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 20.040904153s
    Nov 11 23:43:46.580: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=true. Elapsed: 22.039838001s
    Nov 11 23:43:48.605: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Running", Reason="", readiness=false. Elapsed: 24.064341638s
    Nov 11 23:43:50.581: INFO: Pod "pod-subpath-test-downwardapi-gfws": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.040473349s
    STEP: Saw pod success 11/11/22 23:43:50.581
    Nov 11 23:43:50.581: INFO: Pod "pod-subpath-test-downwardapi-gfws" satisfied condition "Succeeded or Failed"
    Nov 11 23:43:50.603: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-downwardapi-gfws container test-container-subpath-downwardapi-gfws: <nil>
    STEP: delete the pod 11/11/22 23:43:50.7
    Nov 11 23:43:50.747: INFO: Waiting for pod pod-subpath-test-downwardapi-gfws to disappear
    Nov 11 23:43:50.766: INFO: Pod pod-subpath-test-downwardapi-gfws no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-gfws 11/11/22 23:43:50.766
    Nov 11 23:43:50.767: INFO: Deleting pod "pod-subpath-test-downwardapi-gfws" in namespace "subpath-6285"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 11 23:43:50.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6285" for this suite. 11/11/22 23:43:50.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:43:50.836
Nov 11 23:43:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename custom-resource-definition 11/11/22 23:43:50.838
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:50.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:50.902
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Nov 11 23:43:50.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:43:51.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7869" for this suite. 11/11/22 23:43:51.65
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":109,"skipped":2065,"failed":0}
------------------------------
• [0.839 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:43:50.836
    Nov 11 23:43:50.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename custom-resource-definition 11/11/22 23:43:50.838
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:50.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:50.902
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Nov 11 23:43:50.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:43:51.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7869" for this suite. 11/11/22 23:43:51.65
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:43:51.68
Nov 11 23:43:51.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:43:51.682
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:51.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:51.745
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 11/11/22 23:43:51.762
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:43:51.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4968" for this suite. 11/11/22 23:43:51.799
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":110,"skipped":2066,"failed":0}
------------------------------
• [0.144 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:43:51.68
    Nov 11 23:43:51.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:43:51.682
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:51.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:51.745
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 11/11/22 23:43:51.762
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:43:51.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4968" for this suite. 11/11/22 23:43:51.799
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:43:51.827
Nov 11 23:43:51.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:43:51.83
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:51.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:51.895
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Nov 11 23:43:51.971: INFO: created pod
Nov 11 23:43:51.971: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1531" to be "Succeeded or Failed"
Nov 11 23:43:51.990: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 19.155513ms
Nov 11 23:43:54.010: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038798989s
Nov 11 23:43:56.047: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.076421283s
Nov 11 23:43:58.017: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045814477s
STEP: Saw pod success 11/11/22 23:43:58.017
Nov 11 23:43:58.017: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Nov 11 23:44:28.018: INFO: polling logs
Nov 11 23:44:28.055: INFO: Pod logs: 
I1111 23:43:54.014997       1 log.go:195] OK: Got token
I1111 23:43:54.015069       1 log.go:195] validating with in-cluster discovery
I1111 23:43:54.020027       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1111 23:43:54.020172       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1531:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668210832, NotBefore:1668210232, IssuedAt:1668210232, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1531", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2c81989-0555-4340-99b3-002a124ffd02"}}}
I1111 23:43:54.044438       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1111 23:43:54.060539       1 log.go:195] OK: Validated signature on JWT
I1111 23:43:54.060750       1 log.go:195] OK: Got valid claims from token!
I1111 23:43:54.060849       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1531:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668210832, NotBefore:1668210232, IssuedAt:1668210232, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1531", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2c81989-0555-4340-99b3-002a124ffd02"}}}

Nov 11 23:44:28.055: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:44:28.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1531" for this suite. 11/11/22 23:44:28.118
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":111,"skipped":2087,"failed":0}
------------------------------
• [SLOW TEST] [36.343 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:43:51.827
    Nov 11 23:43:51.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:43:51.83
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:43:51.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:43:51.895
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Nov 11 23:43:51.971: INFO: created pod
    Nov 11 23:43:51.971: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1531" to be "Succeeded or Failed"
    Nov 11 23:43:51.990: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 19.155513ms
    Nov 11 23:43:54.010: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038798989s
    Nov 11 23:43:56.047: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.076421283s
    Nov 11 23:43:58.017: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045814477s
    STEP: Saw pod success 11/11/22 23:43:58.017
    Nov 11 23:43:58.017: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Nov 11 23:44:28.018: INFO: polling logs
    Nov 11 23:44:28.055: INFO: Pod logs: 
    I1111 23:43:54.014997       1 log.go:195] OK: Got token
    I1111 23:43:54.015069       1 log.go:195] validating with in-cluster discovery
    I1111 23:43:54.020027       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1111 23:43:54.020172       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1531:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668210832, NotBefore:1668210232, IssuedAt:1668210232, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1531", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2c81989-0555-4340-99b3-002a124ffd02"}}}
    I1111 23:43:54.044438       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1111 23:43:54.060539       1 log.go:195] OK: Validated signature on JWT
    I1111 23:43:54.060750       1 log.go:195] OK: Got valid claims from token!
    I1111 23:43:54.060849       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1531:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668210832, NotBefore:1668210232, IssuedAt:1668210232, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1531", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"c2c81989-0555-4340-99b3-002a124ffd02"}}}

    Nov 11 23:44:28.055: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:44:28.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1531" for this suite. 11/11/22 23:44:28.118
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:28.176
Nov 11 23:44:28.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename tables 11/11/22 23:44:28.179
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.248
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Nov 11 23:44:28.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-1138" for this suite. 11/11/22 23:44:28.306
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":112,"skipped":2108,"failed":0}
------------------------------
• [0.153 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:28.176
    Nov 11 23:44:28.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename tables 11/11/22 23:44:28.179
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.248
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Nov 11 23:44:28.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-1138" for this suite. 11/11/22 23:44:28.306
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:28.331
Nov 11 23:44:28.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename runtimeclass 11/11/22 23:44:28.333
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.423
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Nov 11 23:44:28.501: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4744 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 11 23:44:28.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4744" for this suite. 11/11/22 23:44:28.581
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":113,"skipped":2112,"failed":0}
------------------------------
• [0.275 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:28.331
    Nov 11 23:44:28.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename runtimeclass 11/11/22 23:44:28.333
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.423
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Nov 11 23:44:28.501: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4744 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 11 23:44:28.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4744" for this suite. 11/11/22 23:44:28.581
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:28.61
Nov 11 23:44:28.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:44:28.611
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.685
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-131ee898-5006-4102-8d83-3efe03624521 11/11/22 23:44:28.702
STEP: Creating a pod to test consume configMaps 11/11/22 23:44:28.719
Nov 11 23:44:28.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f" in namespace "configmap-1070" to be "Succeeded or Failed"
Nov 11 23:44:28.782: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.628174ms
Nov 11 23:44:30.803: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039168072s
Nov 11 23:44:32.804: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0400497s
Nov 11 23:44:34.803: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03967162s
STEP: Saw pod success 11/11/22 23:44:34.803
Nov 11 23:44:34.804: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f" satisfied condition "Succeeded or Failed"
Nov 11 23:44:34.823: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:44:34.86
Nov 11 23:44:34.924: INFO: Waiting for pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f to disappear
Nov 11 23:44:34.944: INFO: Pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:44:34.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1070" for this suite. 11/11/22 23:44:34.966
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":114,"skipped":2203,"failed":0}
------------------------------
• [SLOW TEST] [6.380 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:28.61
    Nov 11 23:44:28.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:44:28.611
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:28.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:28.685
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-131ee898-5006-4102-8d83-3efe03624521 11/11/22 23:44:28.702
    STEP: Creating a pod to test consume configMaps 11/11/22 23:44:28.719
    Nov 11 23:44:28.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f" in namespace "configmap-1070" to be "Succeeded or Failed"
    Nov 11 23:44:28.782: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.628174ms
    Nov 11 23:44:30.803: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039168072s
    Nov 11 23:44:32.804: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0400497s
    Nov 11 23:44:34.803: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03967162s
    STEP: Saw pod success 11/11/22 23:44:34.803
    Nov 11 23:44:34.804: INFO: Pod "pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f" satisfied condition "Succeeded or Failed"
    Nov 11 23:44:34.823: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:44:34.86
    Nov 11 23:44:34.924: INFO: Waiting for pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f to disappear
    Nov 11 23:44:34.944: INFO: Pod pod-configmaps-755c4c0b-9980-4b25-b577-4a59ae63d51f no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:44:34.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1070" for this suite. 11/11/22 23:44:34.966
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:34.993
Nov 11 23:44:34.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context 11/11/22 23:44:34.995
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:35.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:35.071
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/11/22 23:44:35.087
Nov 11 23:44:35.125: INFO: Waiting up to 5m0s for pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da" in namespace "security-context-5488" to be "Succeeded or Failed"
Nov 11 23:44:35.146: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 20.627247ms
Nov 11 23:44:37.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040367768s
Nov 11 23:44:39.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04059474s
Nov 11 23:44:41.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040921479s
STEP: Saw pod success 11/11/22 23:44:41.167
Nov 11 23:44:41.167: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da" satisfied condition "Succeeded or Failed"
Nov 11 23:44:41.186: INFO: Trying to get logs from node 10.184.98.55 pod security-context-d2875363-f08e-4451-bb23-a47909eff3da container test-container: <nil>
STEP: delete the pod 11/11/22 23:44:41.221
Nov 11 23:44:41.275: INFO: Waiting for pod security-context-d2875363-f08e-4451-bb23-a47909eff3da to disappear
Nov 11 23:44:41.294: INFO: Pod security-context-d2875363-f08e-4451-bb23-a47909eff3da no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 11 23:44:41.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5488" for this suite. 11/11/22 23:44:41.314
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":115,"skipped":2221,"failed":0}
------------------------------
• [SLOW TEST] [6.342 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:34.993
    Nov 11 23:44:34.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context 11/11/22 23:44:34.995
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:35.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:35.071
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/11/22 23:44:35.087
    Nov 11 23:44:35.125: INFO: Waiting up to 5m0s for pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da" in namespace "security-context-5488" to be "Succeeded or Failed"
    Nov 11 23:44:35.146: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 20.627247ms
    Nov 11 23:44:37.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040367768s
    Nov 11 23:44:39.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04059474s
    Nov 11 23:44:41.166: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040921479s
    STEP: Saw pod success 11/11/22 23:44:41.167
    Nov 11 23:44:41.167: INFO: Pod "security-context-d2875363-f08e-4451-bb23-a47909eff3da" satisfied condition "Succeeded or Failed"
    Nov 11 23:44:41.186: INFO: Trying to get logs from node 10.184.98.55 pod security-context-d2875363-f08e-4451-bb23-a47909eff3da container test-container: <nil>
    STEP: delete the pod 11/11/22 23:44:41.221
    Nov 11 23:44:41.275: INFO: Waiting for pod security-context-d2875363-f08e-4451-bb23-a47909eff3da to disappear
    Nov 11 23:44:41.294: INFO: Pod security-context-d2875363-f08e-4451-bb23-a47909eff3da no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 11 23:44:41.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5488" for this suite. 11/11/22 23:44:41.314
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:41.341
Nov 11 23:44:41.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:44:41.343
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:41.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:41.412
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-467ce323-7d33-4cf7-8a84-b9247e84be52 11/11/22 23:44:41.428
STEP: Creating a pod to test consume secrets 11/11/22 23:44:41.45
Nov 11 23:44:41.490: INFO: Waiting up to 5m0s for pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc" in namespace "secrets-302" to be "Succeeded or Failed"
Nov 11 23:44:41.509: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.716916ms
Nov 11 23:44:43.531: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041116301s
Nov 11 23:44:45.529: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03910508s
Nov 11 23:44:47.530: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039981877s
STEP: Saw pod success 11/11/22 23:44:47.53
Nov 11 23:44:47.530: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc" satisfied condition "Succeeded or Failed"
Nov 11 23:44:47.548: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc container secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:44:47.584
Nov 11 23:44:47.641: INFO: Waiting for pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc to disappear
Nov 11 23:44:47.663: INFO: Pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:44:47.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-302" for this suite. 11/11/22 23:44:47.685
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":116,"skipped":2245,"failed":0}
------------------------------
• [SLOW TEST] [6.369 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:41.341
    Nov 11 23:44:41.342: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:44:41.343
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:41.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:41.412
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-467ce323-7d33-4cf7-8a84-b9247e84be52 11/11/22 23:44:41.428
    STEP: Creating a pod to test consume secrets 11/11/22 23:44:41.45
    Nov 11 23:44:41.490: INFO: Waiting up to 5m0s for pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc" in namespace "secrets-302" to be "Succeeded or Failed"
    Nov 11 23:44:41.509: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.716916ms
    Nov 11 23:44:43.531: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041116301s
    Nov 11 23:44:45.529: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03910508s
    Nov 11 23:44:47.530: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039981877s
    STEP: Saw pod success 11/11/22 23:44:47.53
    Nov 11 23:44:47.530: INFO: Pod "pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc" satisfied condition "Succeeded or Failed"
    Nov 11 23:44:47.548: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc container secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:44:47.584
    Nov 11 23:44:47.641: INFO: Waiting for pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc to disappear
    Nov 11 23:44:47.663: INFO: Pod pod-secrets-0fde8d87-a700-4605-a5fd-4e6a00262cdc no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:44:47.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-302" for this suite. 11/11/22 23:44:47.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:47.717
Nov 11 23:44:47.717: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:44:47.719
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:47.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:47.803
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-cefc78a1-7cdd-483d-bbe2-ce1380550ee5 11/11/22 23:44:47.823
STEP: Creating a pod to test consume secrets 11/11/22 23:44:47.845
Nov 11 23:44:47.892: INFO: Waiting up to 5m0s for pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9" in namespace "secrets-4230" to be "Succeeded or Failed"
Nov 11 23:44:47.926: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 33.847357ms
Nov 11 23:44:49.946: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054285243s
Nov 11 23:44:51.973: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0815506s
Nov 11 23:44:53.948: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05596804s
STEP: Saw pod success 11/11/22 23:44:53.948
Nov 11 23:44:53.948: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9" satisfied condition "Succeeded or Failed"
Nov 11 23:44:53.967: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 container secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:44:54.007
Nov 11 23:44:54.066: INFO: Waiting for pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 to disappear
Nov 11 23:44:54.085: INFO: Pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:44:54.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4230" for this suite. 11/11/22 23:44:54.107
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":117,"skipped":2282,"failed":0}
------------------------------
• [SLOW TEST] [6.415 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:47.717
    Nov 11 23:44:47.717: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:44:47.719
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:47.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:47.803
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-cefc78a1-7cdd-483d-bbe2-ce1380550ee5 11/11/22 23:44:47.823
    STEP: Creating a pod to test consume secrets 11/11/22 23:44:47.845
    Nov 11 23:44:47.892: INFO: Waiting up to 5m0s for pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9" in namespace "secrets-4230" to be "Succeeded or Failed"
    Nov 11 23:44:47.926: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 33.847357ms
    Nov 11 23:44:49.946: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054285243s
    Nov 11 23:44:51.973: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0815506s
    Nov 11 23:44:53.948: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05596804s
    STEP: Saw pod success 11/11/22 23:44:53.948
    Nov 11 23:44:53.948: INFO: Pod "pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9" satisfied condition "Succeeded or Failed"
    Nov 11 23:44:53.967: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 container secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:44:54.007
    Nov 11 23:44:54.066: INFO: Waiting for pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 to disappear
    Nov 11 23:44:54.085: INFO: Pod pod-secrets-96140a68-bf9e-4198-ba80-daf00fb498a9 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:44:54.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4230" for this suite. 11/11/22 23:44:54.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:44:54.135
Nov 11 23:44:54.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/11/22 23:44:54.137
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:54.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:54.208
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 11/11/22 23:44:54.267
STEP: waiting for Deployment to be created 11/11/22 23:44:54.293
STEP: waiting for all Replicas to be Ready 11/11/22 23:44:54.303
Nov 11 23:44:54.313: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.313: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.321: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.321: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.355: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.355: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.427: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:54.427: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 11 23:44:56.536: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 11 23:44:56.536: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 11 23:44:57.267: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 11/11/22 23:44:57.267
W1111 23:44:57.294756      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 11 23:44:57.303: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 11/11/22 23:44:57.303
Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.319: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.324: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.324: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.367: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.367: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:44:57.391: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:44:57.391: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:44:57.410: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:44:57.410: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:00.625: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:45:00.625: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:45:00.683: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
STEP: listing Deployments 11/11/22 23:45:00.683
Nov 11 23:45:00.706: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 11/11/22 23:45:00.706
Nov 11 23:45:00.747: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 11/11/22 23:45:00.747
Nov 11 23:45:00.774: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:00.774: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:00.796: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:00.824: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:00.841: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:03.288: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:03.689: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:03.781: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:03.809: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 11 23:45:06.373: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 11/11/22 23:45:06.432
STEP: fetching the DeploymentStatus 11/11/22 23:45:06.459
Nov 11 23:45:06.515: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:06.516: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:06.516: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:06.518: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:06.519: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
Nov 11 23:45:06.520: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:45:06.520: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3
Nov 11 23:45:06.524: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:45:06.525: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
Nov 11 23:45:06.526: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3
STEP: deleting the Deployment 11/11/22 23:45:06.526
Nov 11 23:45:06.575: INFO: observed event type MODIFIED
Nov 11 23:45:06.576: INFO: observed event type MODIFIED
Nov 11 23:45:06.576: INFO: observed event type MODIFIED
Nov 11 23:45:06.576: INFO: observed event type MODIFIED
Nov 11 23:45:06.577: INFO: observed event type MODIFIED
Nov 11 23:45:06.577: INFO: observed event type MODIFIED
Nov 11 23:45:06.577: INFO: observed event type MODIFIED
Nov 11 23:45:06.577: INFO: observed event type MODIFIED
Nov 11 23:45:06.577: INFO: observed event type MODIFIED
Nov 11 23:45:06.578: INFO: observed event type MODIFIED
Nov 11 23:45:06.578: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 11 23:45:06.600: INFO: Log out all the ReplicaSets if there is no deployment created
Nov 11 23:45:06.619: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-7743  99278576-90d7-40f8-98a1-00a18c5aa884 27372 4 2022-11-11 23:44:57 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3ed17 0xc002a3ed18}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3eda0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Nov 11 23:45:06.639: INFO: pod: "test-deployment-54cc775c4b-wg49s":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-wg49s test-deployment-54cc775c4b- deployment-7743  ad781622-a3c5-4f40-b67d-48e036249da5 27368 0 2022-11-11 23:45:00 +0000 UTC 2022-11-11 23:45:07 +0000 UTC 0xc002a3f248 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:df5786e6819da9cf93713adae3821f840373845ea350397128072873d74f13d4 cni.projectcalico.org/podIP:172.30.194.127/32 cni.projectcalico.org/podIPs:172.30.194.127/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 99278576-90d7-40f8-98a1-00a18c5aa884 0xc002a3f277 0xc002a3f278}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99278576-90d7-40f8-98a1-00a18c5aa884\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.127\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mfb8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mfb8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.127,StartTime:2022-11-11 23:45:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://4879684d4e8068e375601f51fd49170a902976a5881daf8c1d70a9950e256c0b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.127,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Nov 11 23:45:06.640: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-7743  0a662696-266b-4f1d-be86-11407f66e8cd 27364 2 2022-11-11 23:45:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3ee07 0xc002a3ee08}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3ee90 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Nov 11 23:45:06.664: INFO: pod: "test-deployment-7c7d8d58c8-6287g":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-6287g test-deployment-7c7d8d58c8- deployment-7743  73702cf8-02f5-4c30-9239-adac92489390 27327 0 2022-11-11 23:45:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:e55578c8b84b3ee0d9a4fcacff2cc37e49beebfa5e0e08f50a6350675914e219 cni.projectcalico.org/podIP:172.30.146.7/32 cni.projectcalico.org/podIPs:172.30.146.7/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 0a662696-266b-4f1d-be86-11407f66e8cd 0xc002a3fee7 0xc002a3fee8}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a662696-266b-4f1d-be86-11407f66e8cd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fg794,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fg794,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.7,StartTime:2022-11-11 23:45:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ad7ee7ec2eeb147a3d52667e09196e817a2b0246d32d9ae8adfa807ab0fd44ce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Nov 11 23:45:06.664: INFO: pod: "test-deployment-7c7d8d58c8-gwm67":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-gwm67 test-deployment-7c7d8d58c8- deployment-7743  0e9be2e2-c9f4-4baf-bdba-52cdbc711525 27363 0 2022-11-11 23:45:03 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:c5b10af656068ec1d3cf043d6a5d0ff6f4ea5ad0a4cbe9901f5f04e1638b8083 cni.projectcalico.org/podIP:172.30.194.68/32 cni.projectcalico.org/podIPs:172.30.194.68/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 0a662696-266b-4f1d-be86-11407f66e8cd 0xc005082127 0xc005082128}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a662696-266b-4f1d-be86-11407f66e8cd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ltt75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ltt75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.68,StartTime:2022-11-11 23:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aea22ccb857bd7ff6984c347e8a86cc9e31596952b8245a1e8e17200cd8953d6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Nov 11 23:45:06.665: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-7743  496737d1-7a60-47d0-889c-a49370ce771a 27277 3 2022-11-11 23:44:54 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3eef7 0xc002a3eef8}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3ef80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 11 23:45:06.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7743" for this suite. 11/11/22 23:45:06.719
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":118,"skipped":2289,"failed":0}
------------------------------
• [SLOW TEST] [12.609 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:44:54.135
    Nov 11 23:44:54.136: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/11/22 23:44:54.137
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:44:54.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:44:54.208
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 11/11/22 23:44:54.267
    STEP: waiting for Deployment to be created 11/11/22 23:44:54.293
    STEP: waiting for all Replicas to be Ready 11/11/22 23:44:54.303
    Nov 11 23:44:54.313: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.313: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.321: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.321: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.355: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.355: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.427: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:54.427: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 11 23:44:56.536: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 11 23:44:56.536: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 11 23:44:57.267: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 11/11/22 23:44:57.267
    W1111 23:44:57.294756      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 11 23:44:57.303: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 11/11/22 23:44:57.303
    Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.315: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.316: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 0
    Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:44:57.317: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.318: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.319: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.324: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.324: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.367: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.367: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:44:57.391: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:44:57.391: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:44:57.410: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:44:57.410: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:00.625: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:45:00.625: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:45:00.683: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    STEP: listing Deployments 11/11/22 23:45:00.683
    Nov 11 23:45:00.706: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 11/11/22 23:45:00.706
    Nov 11 23:45:00.747: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 11/11/22 23:45:00.747
    Nov 11 23:45:00.774: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:00.774: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:00.796: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:00.824: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:00.841: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:03.288: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:03.689: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:03.781: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:03.809: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 11 23:45:06.373: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 11/11/22 23:45:06.432
    STEP: fetching the DeploymentStatus 11/11/22 23:45:06.459
    Nov 11 23:45:06.515: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:06.516: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:06.516: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:06.518: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:06.519: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 1
    Nov 11 23:45:06.520: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:45:06.520: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3
    Nov 11 23:45:06.524: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:45:06.525: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 2
    Nov 11 23:45:06.526: INFO: observed Deployment test-deployment in namespace deployment-7743 with ReadyReplicas 3
    STEP: deleting the Deployment 11/11/22 23:45:06.526
    Nov 11 23:45:06.575: INFO: observed event type MODIFIED
    Nov 11 23:45:06.576: INFO: observed event type MODIFIED
    Nov 11 23:45:06.576: INFO: observed event type MODIFIED
    Nov 11 23:45:06.576: INFO: observed event type MODIFIED
    Nov 11 23:45:06.577: INFO: observed event type MODIFIED
    Nov 11 23:45:06.577: INFO: observed event type MODIFIED
    Nov 11 23:45:06.577: INFO: observed event type MODIFIED
    Nov 11 23:45:06.577: INFO: observed event type MODIFIED
    Nov 11 23:45:06.577: INFO: observed event type MODIFIED
    Nov 11 23:45:06.578: INFO: observed event type MODIFIED
    Nov 11 23:45:06.578: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 11 23:45:06.600: INFO: Log out all the ReplicaSets if there is no deployment created
    Nov 11 23:45:06.619: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-7743  99278576-90d7-40f8-98a1-00a18c5aa884 27372 4 2022-11-11 23:44:57 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3ed17 0xc002a3ed18}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3eda0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Nov 11 23:45:06.639: INFO: pod: "test-deployment-54cc775c4b-wg49s":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-wg49s test-deployment-54cc775c4b- deployment-7743  ad781622-a3c5-4f40-b67d-48e036249da5 27368 0 2022-11-11 23:45:00 +0000 UTC 2022-11-11 23:45:07 +0000 UTC 0xc002a3f248 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:df5786e6819da9cf93713adae3821f840373845ea350397128072873d74f13d4 cni.projectcalico.org/podIP:172.30.194.127/32 cni.projectcalico.org/podIPs:172.30.194.127/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 99278576-90d7-40f8-98a1-00a18c5aa884 0xc002a3f277 0xc002a3f278}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"99278576-90d7-40f8-98a1-00a18c5aa884\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.127\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mfb8n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mfb8n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.127,StartTime:2022-11-11 23:45:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://4879684d4e8068e375601f51fd49170a902976a5881daf8c1d70a9950e256c0b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.127,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Nov 11 23:45:06.640: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-7743  0a662696-266b-4f1d-be86-11407f66e8cd 27364 2 2022-11-11 23:45:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3ee07 0xc002a3ee08}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3ee90 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Nov 11 23:45:06.664: INFO: pod: "test-deployment-7c7d8d58c8-6287g":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-6287g test-deployment-7c7d8d58c8- deployment-7743  73702cf8-02f5-4c30-9239-adac92489390 27327 0 2022-11-11 23:45:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:e55578c8b84b3ee0d9a4fcacff2cc37e49beebfa5e0e08f50a6350675914e219 cni.projectcalico.org/podIP:172.30.146.7/32 cni.projectcalico.org/podIPs:172.30.146.7/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 0a662696-266b-4f1d-be86-11407f66e8cd 0xc002a3fee7 0xc002a3fee8}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a662696-266b-4f1d-be86-11407f66e8cd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fg794,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fg794,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.7,StartTime:2022-11-11 23:45:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ad7ee7ec2eeb147a3d52667e09196e817a2b0246d32d9ae8adfa807ab0fd44ce,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Nov 11 23:45:06.664: INFO: pod: "test-deployment-7c7d8d58c8-gwm67":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-gwm67 test-deployment-7c7d8d58c8- deployment-7743  0e9be2e2-c9f4-4baf-bdba-52cdbc711525 27363 0 2022-11-11 23:45:03 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:c5b10af656068ec1d3cf043d6a5d0ff6f4ea5ad0a4cbe9901f5f04e1638b8083 cni.projectcalico.org/podIP:172.30.194.68/32 cni.projectcalico.org/podIPs:172.30.194.68/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 0a662696-266b-4f1d-be86-11407f66e8cd 0xc005082127 0xc005082128}] [] [{kube-controller-manager Update v1 2022-11-11 23:45:03 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0a662696-266b-4f1d-be86-11407f66e8cd\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-11 23:45:04 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-11 23:45:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ltt75,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ltt75,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-11 23:45:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.68,StartTime:2022-11-11 23:45:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-11 23:45:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://aea22ccb857bd7ff6984c347e8a86cc9e31596952b8245a1e8e17200cd8953d6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Nov 11 23:45:06.665: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-7743  496737d1-7a60-47d0-889c-a49370ce771a 27277 3 2022-11-11 23:44:54 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment cf7e5a0b-652c-4737-ae64-0cc08c42b8f3 0xc002a3eef7 0xc002a3eef8}] [] [{kube-controller-manager Update apps/v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cf7e5a0b-652c-4737-ae64-0cc08c42b8f3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-11 23:45:00 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002a3ef80 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 11 23:45:06.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7743" for this suite. 11/11/22 23:45:06.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:45:06.753
Nov 11 23:45:06.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/11/22 23:45:06.757
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:06.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:06.831
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 11/11/22 23:45:06.939
STEP: watching for Pod to be ready 11/11/22 23:45:06.982
Nov 11 23:45:06.994: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions []
Nov 11 23:45:06.994: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
Nov 11 23:45:07.033: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
Nov 11 23:45:08.442: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
Nov 11 23:45:09.669: INFO: Found Pod pod-test in namespace pods-9706 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 11/11/22 23:45:09.691
STEP: getting the Pod and ensuring that it's patched 11/11/22 23:45:09.722
STEP: replacing the Pod's status Ready condition to False 11/11/22 23:45:09.75
STEP: check the Pod again to ensure its Ready conditions are False 11/11/22 23:45:09.832
STEP: deleting the Pod via a Collection with a LabelSelector 11/11/22 23:45:09.832
STEP: watching for the Pod to be deleted 11/11/22 23:45:09.88
Nov 11 23:45:09.890: INFO: observed event type MODIFIED
Nov 11 23:45:11.660: INFO: observed event type MODIFIED
Nov 11 23:45:12.137: INFO: observed event type MODIFIED
Nov 11 23:45:12.672: INFO: observed event type MODIFIED
Nov 11 23:45:12.987: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 11 23:45:13.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9706" for this suite. 11/11/22 23:45:13.058
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":119,"skipped":2327,"failed":0}
------------------------------
• [SLOW TEST] [6.346 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:45:06.753
    Nov 11 23:45:06.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/11/22 23:45:06.757
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:06.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:06.831
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 11/11/22 23:45:06.939
    STEP: watching for Pod to be ready 11/11/22 23:45:06.982
    Nov 11 23:45:06.994: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Nov 11 23:45:06.994: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
    Nov 11 23:45:07.033: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
    Nov 11 23:45:08.442: INFO: observed Pod pod-test in namespace pods-9706 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
    Nov 11 23:45:09.669: INFO: Found Pod pod-test in namespace pods-9706 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-11 23:45:06 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 11/11/22 23:45:09.691
    STEP: getting the Pod and ensuring that it's patched 11/11/22 23:45:09.722
    STEP: replacing the Pod's status Ready condition to False 11/11/22 23:45:09.75
    STEP: check the Pod again to ensure its Ready conditions are False 11/11/22 23:45:09.832
    STEP: deleting the Pod via a Collection with a LabelSelector 11/11/22 23:45:09.832
    STEP: watching for the Pod to be deleted 11/11/22 23:45:09.88
    Nov 11 23:45:09.890: INFO: observed event type MODIFIED
    Nov 11 23:45:11.660: INFO: observed event type MODIFIED
    Nov 11 23:45:12.137: INFO: observed event type MODIFIED
    Nov 11 23:45:12.672: INFO: observed event type MODIFIED
    Nov 11 23:45:12.987: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 11 23:45:13.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9706" for this suite. 11/11/22 23:45:13.058
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:45:13.105
Nov 11 23:45:13.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/11/22 23:45:13.108
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:13.2
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:13.243
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Nov 11 23:45:13.330: INFO: Waiting up to 2m0s for pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" in namespace "var-expansion-3693" to be "container 0 failed with reason CreateContainerConfigError"
Nov 11 23:45:13.351: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 20.976769ms
Nov 11 23:45:15.371: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040745263s
Nov 11 23:45:17.375: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045597068s
Nov 11 23:45:17.375: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 11 23:45:17.375: INFO: Deleting pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" in namespace "var-expansion-3693"
Nov 11 23:45:17.427: INFO: Wait up to 5m0s for pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 11 23:45:19.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3693" for this suite. 11/11/22 23:45:19.506
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":120,"skipped":2344,"failed":0}
------------------------------
• [SLOW TEST] [6.425 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:45:13.105
    Nov 11 23:45:13.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/11/22 23:45:13.108
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:13.2
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:13.243
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Nov 11 23:45:13.330: INFO: Waiting up to 2m0s for pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" in namespace "var-expansion-3693" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 11 23:45:13.351: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 20.976769ms
    Nov 11 23:45:15.371: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040745263s
    Nov 11 23:45:17.375: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045597068s
    Nov 11 23:45:17.375: INFO: Pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 11 23:45:17.375: INFO: Deleting pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" in namespace "var-expansion-3693"
    Nov 11 23:45:17.427: INFO: Wait up to 5m0s for pod "var-expansion-607ef197-26b6-44d7-b0df-b5aaffebf569" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 11 23:45:19.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3693" for this suite. 11/11/22 23:45:19.506
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:45:19.542
Nov 11 23:45:19.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:45:19.545
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:19.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:19.615
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 11/11/22 23:45:19.635
Nov 11 23:45:19.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 create -f -'
Nov 11 23:45:20.140: INFO: stderr: ""
Nov 11 23:45:20.140: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 11/11/22 23:45:20.14
Nov 11 23:45:20.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 diff -f -'
Nov 11 23:45:20.751: INFO: rc: 1
Nov 11 23:45:20.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 delete -f -'
Nov 11 23:45:21.029: INFO: stderr: ""
Nov 11 23:45:21.029: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:45:21.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7513" for this suite. 11/11/22 23:45:21.055
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":121,"skipped":2399,"failed":0}
------------------------------
• [1.535 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:45:19.542
    Nov 11 23:45:19.542: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:45:19.545
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:19.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:19.615
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 11/11/22 23:45:19.635
    Nov 11 23:45:19.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 create -f -'
    Nov 11 23:45:20.140: INFO: stderr: ""
    Nov 11 23:45:20.140: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 11/11/22 23:45:20.14
    Nov 11 23:45:20.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 diff -f -'
    Nov 11 23:45:20.751: INFO: rc: 1
    Nov 11 23:45:20.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7513 delete -f -'
    Nov 11 23:45:21.029: INFO: stderr: ""
    Nov 11 23:45:21.029: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:45:21.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7513" for this suite. 11/11/22 23:45:21.055
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:45:21.078
Nov 11 23:45:21.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption 11/11/22 23:45:21.08
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:21.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:21.211
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 11 23:45:21.351: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 11 23:46:21.549: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:46:21.567
Nov 11 23:46:21.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption-path 11/11/22 23:46:21.569
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:46:21.623
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:46:21.641
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 11/11/22 23:46:21.66
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/11/22 23:46:21.661
Nov 11 23:46:21.703: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-934" to be "running"
Nov 11 23:46:21.722: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.930654ms
Nov 11 23:46:23.752: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049383297s
Nov 11 23:46:25.742: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.038866669s
Nov 11 23:46:25.742: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/11/22 23:46:25.762
Nov 11 23:46:25.822: INFO: found a healthy node: 10.184.98.55
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Nov 11 23:46:46.208: INFO: pods created so far: [1 1 1]
Nov 11 23:46:46.208: INFO: length of pods created so far: 3
Nov 11 23:46:50.253: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Nov 11 23:46:57.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-934" for this suite. 11/11/22 23:46:57.28
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:46:57.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7358" for this suite. 11/11/22 23:46:57.501
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":122,"skipped":2404,"failed":0}
------------------------------
• [SLOW TEST] [96.629 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:45:21.078
    Nov 11 23:45:21.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption 11/11/22 23:45:21.08
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:45:21.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:45:21.211
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 11 23:45:21.351: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 11 23:46:21.549: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:46:21.567
    Nov 11 23:46:21.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption-path 11/11/22 23:46:21.569
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:46:21.623
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:46:21.641
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 11/11/22 23:46:21.66
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/11/22 23:46:21.661
    Nov 11 23:46:21.703: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-934" to be "running"
    Nov 11 23:46:21.722: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.930654ms
    Nov 11 23:46:23.752: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049383297s
    Nov 11 23:46:25.742: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.038866669s
    Nov 11 23:46:25.742: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/11/22 23:46:25.762
    Nov 11 23:46:25.822: INFO: found a healthy node: 10.184.98.55
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Nov 11 23:46:46.208: INFO: pods created so far: [1 1 1]
    Nov 11 23:46:46.208: INFO: length of pods created so far: 3
    Nov 11 23:46:50.253: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Nov 11 23:46:57.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-934" for this suite. 11/11/22 23:46:57.28
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:46:57.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7358" for this suite. 11/11/22 23:46:57.501
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:46:57.712
Nov 11 23:46:57.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/11/22 23:46:57.715
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:46:57.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:46:57.784
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Nov 11 23:46:57.843: INFO: Waiting up to 5m0s for pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298" in namespace "pods-5591" to be "running and ready"
Nov 11 23:46:57.864: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298": Phase="Pending", Reason="", readiness=false. Elapsed: 21.604459ms
Nov 11 23:46:57.864: INFO: The phase of Pod server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:46:59.885: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298": Phase="Running", Reason="", readiness=true. Elapsed: 2.042700069s
Nov 11 23:46:59.886: INFO: The phase of Pod server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298 is Running (Ready = true)
Nov 11 23:46:59.886: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298" satisfied condition "running and ready"
Nov 11 23:46:59.970: INFO: Waiting up to 5m0s for pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175" in namespace "pods-5591" to be "Succeeded or Failed"
Nov 11 23:47:00.001: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 30.366254ms
Nov 11 23:47:02.022: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051750953s
Nov 11 23:47:04.022: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051630088s
Nov 11 23:47:06.020: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049552311s
STEP: Saw pod success 11/11/22 23:47:06.021
Nov 11 23:47:06.021: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175" satisfied condition "Succeeded or Failed"
Nov 11 23:47:06.046: INFO: Trying to get logs from node 10.184.98.55 pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 container env3cont: <nil>
STEP: delete the pod 11/11/22 23:47:06.191
Nov 11 23:47:06.249: INFO: Waiting for pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 to disappear
Nov 11 23:47:06.270: INFO: Pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 11 23:47:06.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5591" for this suite. 11/11/22 23:47:06.295
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":123,"skipped":2416,"failed":0}
------------------------------
• [SLOW TEST] [8.606 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:46:57.712
    Nov 11 23:46:57.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/11/22 23:46:57.715
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:46:57.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:46:57.784
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Nov 11 23:46:57.843: INFO: Waiting up to 5m0s for pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298" in namespace "pods-5591" to be "running and ready"
    Nov 11 23:46:57.864: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298": Phase="Pending", Reason="", readiness=false. Elapsed: 21.604459ms
    Nov 11 23:46:57.864: INFO: The phase of Pod server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:46:59.885: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298": Phase="Running", Reason="", readiness=true. Elapsed: 2.042700069s
    Nov 11 23:46:59.886: INFO: The phase of Pod server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298 is Running (Ready = true)
    Nov 11 23:46:59.886: INFO: Pod "server-envvars-d1261e35-3c5f-435c-bbae-f3d00a2c5298" satisfied condition "running and ready"
    Nov 11 23:46:59.970: INFO: Waiting up to 5m0s for pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175" in namespace "pods-5591" to be "Succeeded or Failed"
    Nov 11 23:47:00.001: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 30.366254ms
    Nov 11 23:47:02.022: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051750953s
    Nov 11 23:47:04.022: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051630088s
    Nov 11 23:47:06.020: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049552311s
    STEP: Saw pod success 11/11/22 23:47:06.021
    Nov 11 23:47:06.021: INFO: Pod "client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175" satisfied condition "Succeeded or Failed"
    Nov 11 23:47:06.046: INFO: Trying to get logs from node 10.184.98.55 pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 container env3cont: <nil>
    STEP: delete the pod 11/11/22 23:47:06.191
    Nov 11 23:47:06.249: INFO: Waiting for pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 to disappear
    Nov 11 23:47:06.270: INFO: Pod client-envvars-ad8f3bb2-6448-4f57-a36b-40d6bfa0b175 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 11 23:47:06.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5591" for this suite. 11/11/22 23:47:06.295
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:06.332
Nov 11 23:47:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:47:06.333
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:06.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:06.404
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:47:06.468
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:47:07.847
STEP: Deploying the webhook pod 11/11/22 23:47:07.884
STEP: Wait for the deployment to be ready 11/11/22 23:47:07.931
Nov 11 23:47:07.971: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:47:10.031: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 47, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:47:12.076
STEP: Verifying the service has paired with the endpoint 11/11/22 23:47:12.112
Nov 11 23:47:13.113: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 11/11/22 23:47:13.364
STEP: Creating a configMap that should be mutated 11/11/22 23:47:13.47
STEP: Deleting the collection of validation webhooks 11/11/22 23:47:13.784
STEP: Creating a configMap that should not be mutated 11/11/22 23:47:13.995
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:47:14.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-257" for this suite. 11/11/22 23:47:14.063
STEP: Destroying namespace "webhook-257-markers" for this suite. 11/11/22 23:47:14.087
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":124,"skipped":2430,"failed":0}
------------------------------
• [SLOW TEST] [7.920 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:06.332
    Nov 11 23:47:06.332: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:47:06.333
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:06.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:06.404
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:47:06.468
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:47:07.847
    STEP: Deploying the webhook pod 11/11/22 23:47:07.884
    STEP: Wait for the deployment to be ready 11/11/22 23:47:07.931
    Nov 11 23:47:07.971: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:47:10.031: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 47, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 47, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:47:12.076
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:47:12.112
    Nov 11 23:47:13.113: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 11/11/22 23:47:13.364
    STEP: Creating a configMap that should be mutated 11/11/22 23:47:13.47
    STEP: Deleting the collection of validation webhooks 11/11/22 23:47:13.784
    STEP: Creating a configMap that should not be mutated 11/11/22 23:47:13.995
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:47:14.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-257" for this suite. 11/11/22 23:47:14.063
    STEP: Destroying namespace "webhook-257-markers" for this suite. 11/11/22 23:47:14.087
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:14.255
Nov 11 23:47:14.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:47:14.257
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:14.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:14.324
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 11/11/22 23:47:14.342
Nov 11 23:47:14.381: INFO: Waiting up to 5m0s for pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb" in namespace "emptydir-9564" to be "Succeeded or Failed"
Nov 11 23:47:14.399: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.737393ms
Nov 11 23:47:16.420: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039647148s
Nov 11 23:47:18.419: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038586033s
Nov 11 23:47:20.423: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042267326s
STEP: Saw pod success 11/11/22 23:47:20.423
Nov 11 23:47:20.424: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb" satisfied condition "Succeeded or Failed"
Nov 11 23:47:20.443: INFO: Trying to get logs from node 10.184.98.55 pod pod-7664b957-3662-40eb-81f2-97f92a1688cb container test-container: <nil>
STEP: delete the pod 11/11/22 23:47:20.511
Nov 11 23:47:20.558: INFO: Waiting for pod pod-7664b957-3662-40eb-81f2-97f92a1688cb to disappear
Nov 11 23:47:20.578: INFO: Pod pod-7664b957-3662-40eb-81f2-97f92a1688cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:47:20.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9564" for this suite. 11/11/22 23:47:20.602
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":125,"skipped":2455,"failed":0}
------------------------------
• [SLOW TEST] [6.372 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:14.255
    Nov 11 23:47:14.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:47:14.257
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:14.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:14.324
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/11/22 23:47:14.342
    Nov 11 23:47:14.381: INFO: Waiting up to 5m0s for pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb" in namespace "emptydir-9564" to be "Succeeded or Failed"
    Nov 11 23:47:14.399: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.737393ms
    Nov 11 23:47:16.420: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039647148s
    Nov 11 23:47:18.419: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038586033s
    Nov 11 23:47:20.423: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042267326s
    STEP: Saw pod success 11/11/22 23:47:20.423
    Nov 11 23:47:20.424: INFO: Pod "pod-7664b957-3662-40eb-81f2-97f92a1688cb" satisfied condition "Succeeded or Failed"
    Nov 11 23:47:20.443: INFO: Trying to get logs from node 10.184.98.55 pod pod-7664b957-3662-40eb-81f2-97f92a1688cb container test-container: <nil>
    STEP: delete the pod 11/11/22 23:47:20.511
    Nov 11 23:47:20.558: INFO: Waiting for pod pod-7664b957-3662-40eb-81f2-97f92a1688cb to disappear
    Nov 11 23:47:20.578: INFO: Pod pod-7664b957-3662-40eb-81f2-97f92a1688cb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:47:20.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9564" for this suite. 11/11/22 23:47:20.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:20.63
Nov 11 23:47:20.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename podtemplate 11/11/22 23:47:20.632
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:20.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:20.704
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 11 23:47:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2322" for this suite. 11/11/22 23:47:20.893
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":126,"skipped":2464,"failed":0}
------------------------------
• [0.288 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:20.63
    Nov 11 23:47:20.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename podtemplate 11/11/22 23:47:20.632
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:20.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:20.704
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 11 23:47:20.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2322" for this suite. 11/11/22 23:47:20.893
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:20.92
Nov 11 23:47:20.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svc-latency 11/11/22 23:47:20.925
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:20.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:20.996
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Nov 11 23:47:21.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: creating replication controller svc-latency-rc in namespace svc-latency-687 11/11/22 23:47:21.018
I1111 23:47:21.064105      21 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-687, replica count: 1
I1111 23:47:22.115856      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 23:47:23.116724      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1111 23:47:24.117902      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:47:24.259: INFO: Created: latency-svc-xs2jz
Nov 11 23:47:24.267: INFO: Got endpoints: latency-svc-xs2jz [49.110932ms]
Nov 11 23:47:24.310: INFO: Created: latency-svc-j5j6c
Nov 11 23:47:24.316: INFO: Got endpoints: latency-svc-j5j6c [47.36813ms]
Nov 11 23:47:24.327: INFO: Created: latency-svc-brg6b
Nov 11 23:47:24.332: INFO: Got endpoints: latency-svc-brg6b [63.197775ms]
Nov 11 23:47:24.341: INFO: Created: latency-svc-5mjzl
Nov 11 23:47:24.347: INFO: Got endpoints: latency-svc-5mjzl [78.45727ms]
Nov 11 23:47:24.356: INFO: Created: latency-svc-5mhh6
Nov 11 23:47:24.379: INFO: Got endpoints: latency-svc-5mhh6 [111.056109ms]
Nov 11 23:47:24.391: INFO: Created: latency-svc-vvltb
Nov 11 23:47:24.399: INFO: Got endpoints: latency-svc-vvltb [130.939143ms]
Nov 11 23:47:24.405: INFO: Created: latency-svc-xxbjv
Nov 11 23:47:24.411: INFO: Got endpoints: latency-svc-xxbjv [142.33778ms]
Nov 11 23:47:24.421: INFO: Created: latency-svc-qgzn6
Nov 11 23:47:24.431: INFO: Got endpoints: latency-svc-qgzn6 [162.319144ms]
Nov 11 23:47:24.437: INFO: Created: latency-svc-48v5x
Nov 11 23:47:24.444: INFO: Got endpoints: latency-svc-48v5x [175.462097ms]
Nov 11 23:47:24.453: INFO: Created: latency-svc-rmxfk
Nov 11 23:47:24.459: INFO: Got endpoints: latency-svc-rmxfk [191.258398ms]
Nov 11 23:47:24.474: INFO: Created: latency-svc-wcpxt
Nov 11 23:47:24.474: INFO: Got endpoints: latency-svc-wcpxt [204.694758ms]
Nov 11 23:47:24.485: INFO: Created: latency-svc-7gmpl
Nov 11 23:47:24.492: INFO: Got endpoints: latency-svc-7gmpl [223.833037ms]
Nov 11 23:47:24.501: INFO: Created: latency-svc-mbxzm
Nov 11 23:47:24.507: INFO: Got endpoints: latency-svc-mbxzm [238.051838ms]
Nov 11 23:47:24.544: INFO: Created: latency-svc-jjc2q
Nov 11 23:47:24.549: INFO: Got endpoints: latency-svc-jjc2q [279.715359ms]
Nov 11 23:47:24.563: INFO: Created: latency-svc-j9sd5
Nov 11 23:47:24.569: INFO: Got endpoints: latency-svc-j9sd5 [300.739673ms]
Nov 11 23:47:24.581: INFO: Created: latency-svc-7q9gm
Nov 11 23:47:24.588: INFO: Got endpoints: latency-svc-7q9gm [319.094679ms]
Nov 11 23:47:24.597: INFO: Created: latency-svc-8gd5c
Nov 11 23:47:24.607: INFO: Got endpoints: latency-svc-8gd5c [290.727697ms]
Nov 11 23:47:24.613: INFO: Created: latency-svc-7tzd6
Nov 11 23:47:24.644: INFO: Got endpoints: latency-svc-7tzd6 [311.884449ms]
Nov 11 23:47:24.688: INFO: Created: latency-svc-4tsqk
Nov 11 23:47:24.695: INFO: Got endpoints: latency-svc-4tsqk [346.718719ms]
Nov 11 23:47:24.732: INFO: Created: latency-svc-4dnxb
Nov 11 23:47:24.740: INFO: Got endpoints: latency-svc-4dnxb [361.136649ms]
Nov 11 23:47:24.749: INFO: Created: latency-svc-br5ql
Nov 11 23:47:24.758: INFO: Got endpoints: latency-svc-br5ql [359.003971ms]
Nov 11 23:47:24.772: INFO: Created: latency-svc-zftq9
Nov 11 23:47:24.780: INFO: Got endpoints: latency-svc-zftq9 [368.536159ms]
Nov 11 23:47:24.786: INFO: Created: latency-svc-qs75w
Nov 11 23:47:24.790: INFO: Got endpoints: latency-svc-qs75w [359.81893ms]
Nov 11 23:47:24.811: INFO: Created: latency-svc-hrpm4
Nov 11 23:47:24.823: INFO: Got endpoints: latency-svc-hrpm4 [378.774004ms]
Nov 11 23:47:24.845: INFO: Created: latency-svc-tfwpg
Nov 11 23:47:24.850: INFO: Got endpoints: latency-svc-tfwpg [390.563914ms]
Nov 11 23:47:24.859: INFO: Created: latency-svc-8nnks
Nov 11 23:47:24.864: INFO: Got endpoints: latency-svc-8nnks [389.788904ms]
Nov 11 23:47:24.874: INFO: Created: latency-svc-6nhp6
Nov 11 23:47:24.883: INFO: Got endpoints: latency-svc-6nhp6 [390.473658ms]
Nov 11 23:47:24.890: INFO: Created: latency-svc-zszqj
Nov 11 23:47:24.898: INFO: Got endpoints: latency-svc-zszqj [390.837942ms]
Nov 11 23:47:24.906: INFO: Created: latency-svc-nwrsz
Nov 11 23:47:24.911: INFO: Got endpoints: latency-svc-nwrsz [362.417571ms]
Nov 11 23:47:24.921: INFO: Created: latency-svc-2qzs2
Nov 11 23:47:24.927: INFO: Got endpoints: latency-svc-2qzs2 [357.625604ms]
Nov 11 23:47:24.964: INFO: Created: latency-svc-2mf7t
Nov 11 23:47:24.964: INFO: Got endpoints: latency-svc-2mf7t [376.383509ms]
Nov 11 23:47:24.965: INFO: Created: latency-svc-b4q8f
Nov 11 23:47:24.976: INFO: Got endpoints: latency-svc-b4q8f [368.986141ms]
Nov 11 23:47:24.978: INFO: Created: latency-svc-ptmk9
Nov 11 23:47:24.992: INFO: Got endpoints: latency-svc-ptmk9 [348.489513ms]
Nov 11 23:47:25.003: INFO: Created: latency-svc-j5q5m
Nov 11 23:47:25.013: INFO: Got endpoints: latency-svc-j5q5m [318.347962ms]
Nov 11 23:47:25.022: INFO: Created: latency-svc-247nl
Nov 11 23:47:25.036: INFO: Got endpoints: latency-svc-247nl [295.25223ms]
Nov 11 23:47:25.049: INFO: Created: latency-svc-kgdp9
Nov 11 23:47:25.068: INFO: Created: latency-svc-vxdrb
Nov 11 23:47:25.115: INFO: Created: latency-svc-8qf52
Nov 11 23:47:25.117: INFO: Got endpoints: latency-svc-kgdp9 [359.219704ms]
Nov 11 23:47:25.118: INFO: Created: latency-svc-p2qd7
Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-p2qd7 [329.981842ms]
Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-8qf52 [298.383488ms]
Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-vxdrb [341.094026ms]
Nov 11 23:47:25.135: INFO: Created: latency-svc-gzpdz
Nov 11 23:47:25.137: INFO: Created: latency-svc-vf5n5
Nov 11 23:47:25.137: INFO: Got endpoints: latency-svc-vf5n5 [287.005591ms]
Nov 11 23:47:25.139: INFO: Got endpoints: latency-svc-gzpdz [275.143693ms]
Nov 11 23:47:25.188: INFO: Created: latency-svc-p6gbj
Nov 11 23:47:25.188: INFO: Created: latency-svc-4xvwc
Nov 11 23:47:25.189: INFO: Created: latency-svc-2drzs
Nov 11 23:47:25.190: INFO: Got endpoints: latency-svc-p6gbj [306.693137ms]
Nov 11 23:47:25.190: INFO: Got endpoints: latency-svc-4xvwc [291.8605ms]
Nov 11 23:47:25.192: INFO: Got endpoints: latency-svc-2drzs [280.53631ms]
Nov 11 23:47:25.201: INFO: Created: latency-svc-42fc8
Nov 11 23:47:25.240: INFO: Created: latency-svc-7nthp
Nov 11 23:47:25.240: INFO: Got endpoints: latency-svc-7nthp [275.640661ms]
Nov 11 23:47:25.241: INFO: Got endpoints: latency-svc-42fc8 [312.937689ms]
Nov 11 23:47:25.241: INFO: Created: latency-svc-ndv85
Nov 11 23:47:25.245: INFO: Got endpoints: latency-svc-ndv85 [269.161803ms]
Nov 11 23:47:25.254: INFO: Created: latency-svc-pg7gh
Nov 11 23:47:25.261: INFO: Got endpoints: latency-svc-pg7gh [269.079823ms]
Nov 11 23:47:25.272: INFO: Created: latency-svc-gdcmd
Nov 11 23:47:25.278: INFO: Got endpoints: latency-svc-gdcmd [264.170415ms]
Nov 11 23:47:25.289: INFO: Created: latency-svc-snhlw
Nov 11 23:47:25.293: INFO: Got endpoints: latency-svc-snhlw [257.207003ms]
Nov 11 23:47:25.307: INFO: Created: latency-svc-vcv28
Nov 11 23:47:25.319: INFO: Got endpoints: latency-svc-vcv28 [197.5592ms]
Nov 11 23:47:25.323: INFO: Created: latency-svc-kl2r4
Nov 11 23:47:25.347: INFO: Got endpoints: latency-svc-kl2r4 [228.518118ms]
Nov 11 23:47:25.355: INFO: Created: latency-svc-hcbds
Nov 11 23:47:25.356: INFO: Created: latency-svc-klwnp
Nov 11 23:47:25.357: INFO: Got endpoints: latency-svc-klwnp [236.168684ms]
Nov 11 23:47:25.361: INFO: Got endpoints: latency-svc-hcbds [239.920538ms]
Nov 11 23:47:25.371: INFO: Created: latency-svc-tlm26
Nov 11 23:47:25.376: INFO: Got endpoints: latency-svc-tlm26 [238.758534ms]
Nov 11 23:47:25.386: INFO: Created: latency-svc-shzzb
Nov 11 23:47:25.391: INFO: Got endpoints: latency-svc-shzzb [252.016082ms]
Nov 11 23:47:25.401: INFO: Created: latency-svc-4jc27
Nov 11 23:47:25.407: INFO: Got endpoints: latency-svc-4jc27 [217.786352ms]
Nov 11 23:47:25.419: INFO: Created: latency-svc-jdvmx
Nov 11 23:47:25.423: INFO: Got endpoints: latency-svc-jdvmx [230.87981ms]
Nov 11 23:47:25.435: INFO: Created: latency-svc-76llg
Nov 11 23:47:25.440: INFO: Got endpoints: latency-svc-76llg [249.718708ms]
Nov 11 23:47:25.451: INFO: Created: latency-svc-8gzrg
Nov 11 23:47:25.455: INFO: Got endpoints: latency-svc-8gzrg [214.369853ms]
Nov 11 23:47:25.466: INFO: Created: latency-svc-jjphg
Nov 11 23:47:25.471: INFO: Got endpoints: latency-svc-jjphg [230.648199ms]
Nov 11 23:47:25.483: INFO: Created: latency-svc-cr5d8
Nov 11 23:47:25.488: INFO: Got endpoints: latency-svc-cr5d8 [242.556277ms]
Nov 11 23:47:25.497: INFO: Created: latency-svc-7pt88
Nov 11 23:47:25.507: INFO: Got endpoints: latency-svc-7pt88 [245.977476ms]
Nov 11 23:47:25.514: INFO: Created: latency-svc-r8pq6
Nov 11 23:47:25.519: INFO: Got endpoints: latency-svc-r8pq6 [240.934985ms]
Nov 11 23:47:25.530: INFO: Created: latency-svc-mkwxz
Nov 11 23:47:25.535: INFO: Got endpoints: latency-svc-mkwxz [242.229974ms]
Nov 11 23:47:25.804: INFO: Created: latency-svc-xgg2z
Nov 11 23:47:25.811: INFO: Created: latency-svc-4szkl
Nov 11 23:47:25.812: INFO: Created: latency-svc-ghxwn
Nov 11 23:47:25.812: INFO: Created: latency-svc-hgrbb
Nov 11 23:47:25.814: INFO: Created: latency-svc-q7rzh
Nov 11 23:47:25.812: INFO: Created: latency-svc-c9t6m
Nov 11 23:47:25.816: INFO: Created: latency-svc-76sbw
Nov 11 23:47:25.818: INFO: Created: latency-svc-ghwcz
Nov 11 23:47:25.819: INFO: Created: latency-svc-hkb4c
Nov 11 23:47:25.819: INFO: Created: latency-svc-gt2kb
Nov 11 23:47:25.820: INFO: Got endpoints: latency-svc-hgrbb [500.775796ms]
Nov 11 23:47:25.820: INFO: Created: latency-svc-n2tlz
Nov 11 23:47:25.821: INFO: Created: latency-svc-5t4qt
Nov 11 23:47:25.821: INFO: Got endpoints: latency-svc-xgg2z [445.028332ms]
Nov 11 23:47:25.822: INFO: Created: latency-svc-67fb9
Nov 11 23:47:25.822: INFO: Created: latency-svc-rppfj
Nov 11 23:47:25.824: INFO: Created: latency-svc-4kkqm
Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-4szkl [424.046866ms]
Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-ghxwn [408.270599ms]
Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-c9t6m [474.340677ms]
Nov 11 23:47:25.834: INFO: Got endpoints: latency-svc-q7rzh [487.099329ms]
Nov 11 23:47:25.835: INFO: Got endpoints: latency-svc-ghwcz [443.908193ms]
Nov 11 23:47:25.836: INFO: Got endpoints: latency-svc-rppfj [380.352284ms]
Nov 11 23:47:25.836: INFO: Got endpoints: latency-svc-5t4qt [364.340642ms]
Nov 11 23:47:25.839: INFO: Got endpoints: latency-svc-76sbw [398.96584ms]
Nov 11 23:47:25.838: INFO: Got endpoints: latency-svc-gt2kb [330.400459ms]
Nov 11 23:47:25.841: INFO: Got endpoints: latency-svc-4kkqm [353.364108ms]
Nov 11 23:47:25.842: INFO: Got endpoints: latency-svc-hkb4c [323.392986ms]
Nov 11 23:47:25.843: INFO: Got endpoints: latency-svc-67fb9 [481.680095ms]
Nov 11 23:47:25.843: INFO: Got endpoints: latency-svc-n2tlz [307.743545ms]
Nov 11 23:47:25.860: INFO: Created: latency-svc-9grg9
Nov 11 23:47:25.869: INFO: Got endpoints: latency-svc-9grg9 [48.684246ms]
Nov 11 23:47:25.880: INFO: Created: latency-svc-xlhqg
Nov 11 23:47:25.885: INFO: Got endpoints: latency-svc-xlhqg [64.217794ms]
Nov 11 23:47:25.897: INFO: Created: latency-svc-wnr6g
Nov 11 23:47:25.902: INFO: Got endpoints: latency-svc-wnr6g [70.110846ms]
Nov 11 23:47:25.913: INFO: Created: latency-svc-vbbxp
Nov 11 23:47:25.920: INFO: Got endpoints: latency-svc-vbbxp [87.042217ms]
Nov 11 23:47:25.945: INFO: Created: latency-svc-x5g7t
Nov 11 23:47:25.954: INFO: Got endpoints: latency-svc-x5g7t [120.073977ms]
Nov 11 23:47:25.964: INFO: Created: latency-svc-xgbhs
Nov 11 23:47:25.979: INFO: Created: latency-svc-hjtjd
Nov 11 23:47:25.987: INFO: Got endpoints: latency-svc-hjtjd [153.977044ms]
Nov 11 23:47:25.990: INFO: Got endpoints: latency-svc-xgbhs [154.375883ms]
Nov 11 23:47:25.996: INFO: Created: latency-svc-2lkrm
Nov 11 23:47:26.001: INFO: Got endpoints: latency-svc-2lkrm [162.029558ms]
Nov 11 23:47:26.013: INFO: Created: latency-svc-bsf77
Nov 11 23:47:26.019: INFO: Got endpoints: latency-svc-bsf77 [179.671084ms]
Nov 11 23:47:26.028: INFO: Created: latency-svc-d88qh
Nov 11 23:47:26.036: INFO: Got endpoints: latency-svc-d88qh [196.885ms]
Nov 11 23:47:26.044: INFO: Created: latency-svc-7hk88
Nov 11 23:47:26.048: INFO: Got endpoints: latency-svc-7hk88 [208.364066ms]
Nov 11 23:47:26.060: INFO: Created: latency-svc-d9lcj
Nov 11 23:47:26.065: INFO: Got endpoints: latency-svc-d9lcj [222.530139ms]
Nov 11 23:47:26.080: INFO: Created: latency-svc-qpx7n
Nov 11 23:47:26.085: INFO: Got endpoints: latency-svc-qpx7n [242.590364ms]
Nov 11 23:47:26.093: INFO: Created: latency-svc-m4fxd
Nov 11 23:47:26.099: INFO: Got endpoints: latency-svc-m4fxd [255.933329ms]
Nov 11 23:47:26.108: INFO: Created: latency-svc-vll79
Nov 11 23:47:26.114: INFO: Got endpoints: latency-svc-vll79 [272.857199ms]
Nov 11 23:47:26.121: INFO: Created: latency-svc-g6xsp
Nov 11 23:47:26.129: INFO: Got endpoints: latency-svc-g6xsp [259.449643ms]
Nov 11 23:47:26.139: INFO: Created: latency-svc-n26jp
Nov 11 23:47:26.144: INFO: Got endpoints: latency-svc-n26jp [258.681417ms]
Nov 11 23:47:26.154: INFO: Created: latency-svc-pj4q8
Nov 11 23:47:26.159: INFO: Got endpoints: latency-svc-pj4q8 [256.626917ms]
Nov 11 23:47:26.173: INFO: Created: latency-svc-pcc5n
Nov 11 23:47:26.180: INFO: Got endpoints: latency-svc-pcc5n [259.743366ms]
Nov 11 23:47:26.189: INFO: Created: latency-svc-nss6c
Nov 11 23:47:26.194: INFO: Got endpoints: latency-svc-nss6c [239.342079ms]
Nov 11 23:47:26.208: INFO: Created: latency-svc-kmk48
Nov 11 23:47:26.215: INFO: Got endpoints: latency-svc-kmk48 [227.286487ms]
Nov 11 23:47:26.225: INFO: Created: latency-svc-zxmdn
Nov 11 23:47:26.236: INFO: Got endpoints: latency-svc-zxmdn [245.997178ms]
Nov 11 23:47:26.242: INFO: Created: latency-svc-lrwk4
Nov 11 23:47:26.246: INFO: Got endpoints: latency-svc-lrwk4 [245.256106ms]
Nov 11 23:47:26.256: INFO: Created: latency-svc-c2mfl
Nov 11 23:47:26.264: INFO: Got endpoints: latency-svc-c2mfl [244.488953ms]
Nov 11 23:47:26.282: INFO: Created: latency-svc-b5rlf
Nov 11 23:47:26.289: INFO: Got endpoints: latency-svc-b5rlf [252.414844ms]
Nov 11 23:47:26.299: INFO: Created: latency-svc-jlg6x
Nov 11 23:47:26.309: INFO: Got endpoints: latency-svc-jlg6x [260.785837ms]
Nov 11 23:47:26.319: INFO: Created: latency-svc-q8jg7
Nov 11 23:47:26.326: INFO: Got endpoints: latency-svc-q8jg7 [260.988767ms]
Nov 11 23:47:26.333: INFO: Created: latency-svc-2658k
Nov 11 23:47:26.343: INFO: Got endpoints: latency-svc-2658k [256.35476ms]
Nov 11 23:47:26.351: INFO: Created: latency-svc-c6blj
Nov 11 23:47:26.357: INFO: Got endpoints: latency-svc-c6blj [257.36788ms]
Nov 11 23:47:26.366: INFO: Created: latency-svc-dhzzr
Nov 11 23:47:26.373: INFO: Got endpoints: latency-svc-dhzzr [258.542847ms]
Nov 11 23:47:26.383: INFO: Created: latency-svc-sbjhf
Nov 11 23:47:26.388: INFO: Got endpoints: latency-svc-sbjhf [259.647583ms]
Nov 11 23:47:26.400: INFO: Created: latency-svc-zhrgp
Nov 11 23:47:26.406: INFO: Got endpoints: latency-svc-zhrgp [261.98636ms]
Nov 11 23:47:26.421: INFO: Created: latency-svc-22m7q
Nov 11 23:47:26.426: INFO: Got endpoints: latency-svc-22m7q [266.40413ms]
Nov 11 23:47:26.433: INFO: Created: latency-svc-kpqkh
Nov 11 23:47:26.497: INFO: Got endpoints: latency-svc-kpqkh [317.019681ms]
Nov 11 23:47:26.500: INFO: Created: latency-svc-cj865
Nov 11 23:47:26.506: INFO: Got endpoints: latency-svc-cj865 [311.753991ms]
Nov 11 23:47:26.500: INFO: Created: latency-svc-g8w96
Nov 11 23:47:26.502: INFO: Created: latency-svc-plv6w
Nov 11 23:47:26.503: INFO: Created: latency-svc-4qmph
Nov 11 23:47:26.509: INFO: Got endpoints: latency-svc-g8w96 [270.05029ms]
Nov 11 23:47:26.510: INFO: Got endpoints: latency-svc-4qmph [263.085217ms]
Nov 11 23:47:26.510: INFO: Got endpoints: latency-svc-plv6w [295.200049ms]
Nov 11 23:47:26.514: INFO: Created: latency-svc-c4zmj
Nov 11 23:47:26.519: INFO: Got endpoints: latency-svc-c4zmj [255.453542ms]
Nov 11 23:47:26.530: INFO: Created: latency-svc-8s2cx
Nov 11 23:47:26.536: INFO: Got endpoints: latency-svc-8s2cx [247.361212ms]
Nov 11 23:47:26.779: INFO: Created: latency-svc-xbmsw
Nov 11 23:47:26.780: INFO: Created: latency-svc-gqbs6
Nov 11 23:47:26.782: INFO: Created: latency-svc-t8ffl
Nov 11 23:47:26.782: INFO: Created: latency-svc-7rcl6
Nov 11 23:47:26.802: INFO: Created: latency-svc-62d7d
Nov 11 23:47:26.803: INFO: Created: latency-svc-58x7h
Nov 11 23:47:26.803: INFO: Created: latency-svc-fb79p
Nov 11 23:47:26.804: INFO: Created: latency-svc-t89hh
Nov 11 23:47:26.804: INFO: Created: latency-svc-j7hvx
Nov 11 23:47:26.804: INFO: Created: latency-svc-b2dgh
Nov 11 23:47:26.805: INFO: Created: latency-svc-2rvmw
Nov 11 23:47:26.806: INFO: Created: latency-svc-fc4fz
Nov 11 23:47:26.808: INFO: Created: latency-svc-v8fnj
Nov 11 23:47:26.809: INFO: Created: latency-svc-wwzns
Nov 11 23:47:26.809: INFO: Created: latency-svc-wjdlr
Nov 11 23:47:26.809: INFO: Got endpoints: latency-svc-gqbs6 [403.315305ms]
Nov 11 23:47:26.810: INFO: Got endpoints: latency-svc-t89hh [483.106511ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-7rcl6 [300.495484ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-xbmsw [301.573587ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-t8ffl [306.252773ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-wjdlr [454.705136ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-fb79p [468.649519ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-j7hvx [275.025816ms]
Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-v8fnj [502.340266ms]
Nov 11 23:47:26.815: INFO: Got endpoints: latency-svc-2rvmw [294.348273ms]
Nov 11 23:47:26.816: INFO: Got endpoints: latency-svc-wwzns [442.853528ms]
Nov 11 23:47:26.817: INFO: Got endpoints: latency-svc-62d7d [391.082881ms]
Nov 11 23:47:26.818: INFO: Got endpoints: latency-svc-b2dgh [311.116626ms]
Nov 11 23:47:26.819: INFO: Got endpoints: latency-svc-fc4fz [308.886156ms]
Nov 11 23:47:26.819: INFO: Got endpoints: latency-svc-58x7h [430.998666ms]
Nov 11 23:47:26.845: INFO: Created: latency-svc-wplkz
Nov 11 23:47:26.849: INFO: Got endpoints: latency-svc-wplkz [39.816212ms]
Nov 11 23:47:26.861: INFO: Created: latency-svc-7dcgp
Nov 11 23:47:26.866: INFO: Got endpoints: latency-svc-7dcgp [56.080752ms]
Nov 11 23:47:26.877: INFO: Created: latency-svc-bv7x9
Nov 11 23:47:26.900: INFO: Got endpoints: latency-svc-bv7x9 [88.49099ms]
Nov 11 23:47:26.902: INFO: Created: latency-svc-825j2
Nov 11 23:47:26.915: INFO: Got endpoints: latency-svc-825j2 [103.001127ms]
Nov 11 23:47:26.929: INFO: Created: latency-svc-mk88d
Nov 11 23:47:26.939: INFO: Got endpoints: latency-svc-mk88d [125.904473ms]
Nov 11 23:47:26.946: INFO: Created: latency-svc-bmqsl
Nov 11 23:47:26.953: INFO: Got endpoints: latency-svc-bmqsl [140.517068ms]
Nov 11 23:47:26.963: INFO: Created: latency-svc-ffz7x
Nov 11 23:47:26.974: INFO: Got endpoints: latency-svc-ffz7x [160.535645ms]
Nov 11 23:47:26.989: INFO: Created: latency-svc-gftjl
Nov 11 23:47:26.993: INFO: Got endpoints: latency-svc-gftjl [179.257343ms]
Nov 11 23:47:27.010: INFO: Created: latency-svc-vdcv6
Nov 11 23:47:27.015: INFO: Got endpoints: latency-svc-vdcv6 [199.31199ms]
Nov 11 23:47:27.035: INFO: Created: latency-svc-fwkdf
Nov 11 23:47:27.039: INFO: Got endpoints: latency-svc-fwkdf [224.941992ms]
Nov 11 23:47:27.055: INFO: Created: latency-svc-z46wq
Nov 11 23:47:27.065: INFO: Got endpoints: latency-svc-z46wq [247.017477ms]
Nov 11 23:47:27.082: INFO: Created: latency-svc-hvx47
Nov 11 23:47:27.088: INFO: Got endpoints: latency-svc-hvx47 [273.690634ms]
Nov 11 23:47:27.102: INFO: Created: latency-svc-87hbs
Nov 11 23:47:27.107: INFO: Got endpoints: latency-svc-87hbs [290.161605ms]
Nov 11 23:47:27.116: INFO: Created: latency-svc-plg4m
Nov 11 23:47:27.123: INFO: Got endpoints: latency-svc-plg4m [304.633553ms]
Nov 11 23:47:27.131: INFO: Created: latency-svc-tk5rk
Nov 11 23:47:27.139: INFO: Got endpoints: latency-svc-tk5rk [319.213468ms]
Nov 11 23:47:27.148: INFO: Created: latency-svc-8c89f
Nov 11 23:47:27.153: INFO: Got endpoints: latency-svc-8c89f [303.636001ms]
Nov 11 23:47:27.164: INFO: Created: latency-svc-25bjf
Nov 11 23:47:27.169: INFO: Got endpoints: latency-svc-25bjf [303.383725ms]
Nov 11 23:47:27.180: INFO: Created: latency-svc-99kb8
Nov 11 23:47:27.183: INFO: Got endpoints: latency-svc-99kb8 [282.933184ms]
Nov 11 23:47:27.198: INFO: Created: latency-svc-bfjx4
Nov 11 23:47:27.206: INFO: Got endpoints: latency-svc-bfjx4 [290.268855ms]
Nov 11 23:47:27.215: INFO: Created: latency-svc-j7bqq
Nov 11 23:47:27.220: INFO: Got endpoints: latency-svc-j7bqq [280.939065ms]
Nov 11 23:47:27.232: INFO: Created: latency-svc-jjhm9
Nov 11 23:47:27.237: INFO: Got endpoints: latency-svc-jjhm9 [283.309643ms]
Nov 11 23:47:27.245: INFO: Created: latency-svc-rcjnh
Nov 11 23:47:27.252: INFO: Got endpoints: latency-svc-rcjnh [277.958902ms]
Nov 11 23:47:27.265: INFO: Created: latency-svc-j2wj2
Nov 11 23:47:27.273: INFO: Got endpoints: latency-svc-j2wj2 [279.786055ms]
Nov 11 23:47:27.282: INFO: Created: latency-svc-x4snn
Nov 11 23:47:27.287: INFO: Got endpoints: latency-svc-x4snn [271.161592ms]
Nov 11 23:47:27.303: INFO: Created: latency-svc-trwl9
Nov 11 23:47:27.314: INFO: Got endpoints: latency-svc-trwl9 [274.628802ms]
Nov 11 23:47:27.324: INFO: Created: latency-svc-5ks2t
Nov 11 23:47:27.332: INFO: Got endpoints: latency-svc-5ks2t [266.209428ms]
Nov 11 23:47:27.344: INFO: Created: latency-svc-w6hms
Nov 11 23:47:27.349: INFO: Got endpoints: latency-svc-w6hms [260.558388ms]
Nov 11 23:47:27.361: INFO: Created: latency-svc-lc5q9
Nov 11 23:47:27.367: INFO: Got endpoints: latency-svc-lc5q9 [259.792181ms]
Nov 11 23:47:27.379: INFO: Created: latency-svc-tf88d
Nov 11 23:47:27.386: INFO: Got endpoints: latency-svc-tf88d [262.300171ms]
Nov 11 23:47:27.392: INFO: Created: latency-svc-pvg5q
Nov 11 23:47:27.398: INFO: Got endpoints: latency-svc-pvg5q [258.877623ms]
Nov 11 23:47:27.411: INFO: Created: latency-svc-42w7m
Nov 11 23:47:27.417: INFO: Got endpoints: latency-svc-42w7m [263.506021ms]
Nov 11 23:47:27.427: INFO: Created: latency-svc-6qw56
Nov 11 23:47:27.432: INFO: Got endpoints: latency-svc-6qw56 [262.430043ms]
Nov 11 23:47:27.444: INFO: Created: latency-svc-29g7b
Nov 11 23:47:27.449: INFO: Got endpoints: latency-svc-29g7b [265.374928ms]
Nov 11 23:47:27.460: INFO: Created: latency-svc-hljsg
Nov 11 23:47:27.466: INFO: Got endpoints: latency-svc-hljsg [260.158932ms]
Nov 11 23:47:27.475: INFO: Created: latency-svc-2c4gr
Nov 11 23:47:27.482: INFO: Got endpoints: latency-svc-2c4gr [262.164497ms]
Nov 11 23:47:27.492: INFO: Created: latency-svc-29nq7
Nov 11 23:47:27.499: INFO: Got endpoints: latency-svc-29nq7 [261.776579ms]
Nov 11 23:47:27.510: INFO: Created: latency-svc-bzw8j
Nov 11 23:47:27.514: INFO: Got endpoints: latency-svc-bzw8j [262.059056ms]
Nov 11 23:47:27.525: INFO: Created: latency-svc-s4zxk
Nov 11 23:47:27.533: INFO: Got endpoints: latency-svc-s4zxk [259.566902ms]
Nov 11 23:47:27.540: INFO: Created: latency-svc-fqnxm
Nov 11 23:47:27.547: INFO: Got endpoints: latency-svc-fqnxm [260.750515ms]
Nov 11 23:47:27.556: INFO: Created: latency-svc-bcxzr
Nov 11 23:47:27.566: INFO: Got endpoints: latency-svc-bcxzr [251.436605ms]
Nov 11 23:47:27.583: INFO: Created: latency-svc-l9dhn
Nov 11 23:47:27.589: INFO: Got endpoints: latency-svc-l9dhn [257.607711ms]
Nov 11 23:47:27.600: INFO: Created: latency-svc-nwdns
Nov 11 23:47:27.607: INFO: Got endpoints: latency-svc-nwdns [257.351851ms]
Nov 11 23:47:27.617: INFO: Created: latency-svc-4tgkj
Nov 11 23:47:27.624: INFO: Got endpoints: latency-svc-4tgkj [256.670872ms]
Nov 11 23:47:27.634: INFO: Created: latency-svc-2vtkm
Nov 11 23:47:27.639: INFO: Got endpoints: latency-svc-2vtkm [252.887666ms]
Nov 11 23:47:27.649: INFO: Created: latency-svc-wq8jz
Nov 11 23:47:27.655: INFO: Got endpoints: latency-svc-wq8jz [257.659131ms]
Nov 11 23:47:27.671: INFO: Created: latency-svc-s9pwk
Nov 11 23:47:27.676: INFO: Got endpoints: latency-svc-s9pwk [258.449182ms]
Nov 11 23:47:27.688: INFO: Created: latency-svc-rt7xn
Nov 11 23:47:27.696: INFO: Got endpoints: latency-svc-rt7xn [264.562383ms]
Nov 11 23:47:27.733: INFO: Created: latency-svc-dmldx
Nov 11 23:47:27.734: INFO: Got endpoints: latency-svc-dmldx [285.074556ms]
Nov 11 23:47:27.735: INFO: Created: latency-svc-wk5dt
Nov 11 23:47:27.736: INFO: Got endpoints: latency-svc-wk5dt [269.486214ms]
Nov 11 23:47:27.739: INFO: Created: latency-svc-qvw2h
Nov 11 23:47:27.776: INFO: Created: latency-svc-rwsrn
Nov 11 23:47:27.777: INFO: Created: latency-svc-fb4gw
Nov 11 23:47:27.778: INFO: Got endpoints: latency-svc-qvw2h [295.337462ms]
Nov 11 23:47:27.779: INFO: Got endpoints: latency-svc-rwsrn [264.335817ms]
Nov 11 23:47:27.779: INFO: Got endpoints: latency-svc-fb4gw [280.425928ms]
Nov 11 23:47:27.821: INFO: Created: latency-svc-65qrn
Nov 11 23:47:27.822: INFO: Created: latency-svc-dsccl
Nov 11 23:47:27.822: INFO: Created: latency-svc-5kw7n
Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-5kw7n [274.338722ms]
Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-dsccl [292.637314ms]
Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-65qrn [307.694577ms]
Nov 11 23:47:27.867: INFO: Created: latency-svc-4g8pl
Nov 11 23:47:27.870: INFO: Created: latency-svc-gk7hk
Nov 11 23:47:27.871: INFO: Got endpoints: latency-svc-gk7hk [264.230152ms]
Nov 11 23:47:27.871: INFO: Got endpoints: latency-svc-4g8pl [281.782363ms]
Nov 11 23:47:27.872: INFO: Created: latency-svc-d58n4
Nov 11 23:47:27.879: INFO: Got endpoints: latency-svc-d58n4 [255.179066ms]
Nov 11 23:47:27.885: INFO: Created: latency-svc-gvn7h
Nov 11 23:47:27.892: INFO: Got endpoints: latency-svc-gvn7h [253.248924ms]
Nov 11 23:47:27.905: INFO: Created: latency-svc-gknt4
Nov 11 23:47:27.907: INFO: Got endpoints: latency-svc-gknt4 [251.455852ms]
Nov 11 23:47:27.921: INFO: Created: latency-svc-sjscg
Nov 11 23:47:27.927: INFO: Got endpoints: latency-svc-sjscg [251.524173ms]
Nov 11 23:47:27.939: INFO: Created: latency-svc-m8xl8
Nov 11 23:47:27.944: INFO: Got endpoints: latency-svc-m8xl8 [248.03991ms]
Nov 11 23:47:27.959: INFO: Created: latency-svc-h74pj
Nov 11 23:47:27.963: INFO: Got endpoints: latency-svc-h74pj [227.51615ms]
Nov 11 23:47:27.969: INFO: Created: latency-svc-8p6kw
Nov 11 23:47:27.985: INFO: Got endpoints: latency-svc-8p6kw [250.63821ms]
Nov 11 23:47:27.990: INFO: Created: latency-svc-q2h7s
Nov 11 23:47:28.007: INFO: Got endpoints: latency-svc-q2h7s [227.878985ms]
Nov 11 23:47:28.007: INFO: Created: latency-svc-628pr
Nov 11 23:47:28.011: INFO: Got endpoints: latency-svc-628pr [233.316952ms]
Nov 11 23:47:28.011: INFO: Latencies: [39.816212ms 47.36813ms 48.684246ms 56.080752ms 63.197775ms 64.217794ms 70.110846ms 78.45727ms 87.042217ms 88.49099ms 103.001127ms 111.056109ms 120.073977ms 125.904473ms 130.939143ms 140.517068ms 142.33778ms 153.977044ms 154.375883ms 160.535645ms 162.029558ms 162.319144ms 175.462097ms 179.257343ms 179.671084ms 191.258398ms 196.885ms 197.5592ms 199.31199ms 204.694758ms 208.364066ms 214.369853ms 217.786352ms 222.530139ms 223.833037ms 224.941992ms 227.286487ms 227.51615ms 227.878985ms 228.518118ms 230.648199ms 230.87981ms 233.316952ms 236.168684ms 238.051838ms 238.758534ms 239.342079ms 239.920538ms 240.934985ms 242.229974ms 242.556277ms 242.590364ms 244.488953ms 245.256106ms 245.977476ms 245.997178ms 247.017477ms 247.361212ms 248.03991ms 249.718708ms 250.63821ms 251.436605ms 251.455852ms 251.524173ms 252.016082ms 252.414844ms 252.887666ms 253.248924ms 255.179066ms 255.453542ms 255.933329ms 256.35476ms 256.626917ms 256.670872ms 257.207003ms 257.351851ms 257.36788ms 257.607711ms 257.659131ms 258.449182ms 258.542847ms 258.681417ms 258.877623ms 259.449643ms 259.566902ms 259.647583ms 259.743366ms 259.792181ms 260.158932ms 260.558388ms 260.750515ms 260.785837ms 260.988767ms 261.776579ms 261.98636ms 262.059056ms 262.164497ms 262.300171ms 262.430043ms 263.085217ms 263.506021ms 264.170415ms 264.230152ms 264.335817ms 264.562383ms 265.374928ms 266.209428ms 266.40413ms 269.079823ms 269.161803ms 269.486214ms 270.05029ms 271.161592ms 272.857199ms 273.690634ms 274.338722ms 274.628802ms 275.025816ms 275.143693ms 275.640661ms 277.958902ms 279.715359ms 279.786055ms 280.425928ms 280.53631ms 280.939065ms 281.782363ms 282.933184ms 283.309643ms 285.074556ms 287.005591ms 290.161605ms 290.268855ms 290.727697ms 291.8605ms 292.637314ms 294.348273ms 295.200049ms 295.25223ms 295.337462ms 298.383488ms 300.495484ms 300.739673ms 301.573587ms 303.383725ms 303.636001ms 304.633553ms 306.252773ms 306.693137ms 307.694577ms 307.743545ms 308.886156ms 311.116626ms 311.753991ms 311.884449ms 312.937689ms 317.019681ms 318.347962ms 319.094679ms 319.213468ms 323.392986ms 329.981842ms 330.400459ms 341.094026ms 346.718719ms 348.489513ms 353.364108ms 357.625604ms 359.003971ms 359.219704ms 359.81893ms 361.136649ms 362.417571ms 364.340642ms 368.536159ms 368.986141ms 376.383509ms 378.774004ms 380.352284ms 389.788904ms 390.473658ms 390.563914ms 390.837942ms 391.082881ms 398.96584ms 403.315305ms 408.270599ms 424.046866ms 430.998666ms 442.853528ms 443.908193ms 445.028332ms 454.705136ms 468.649519ms 474.340677ms 481.680095ms 483.106511ms 487.099329ms 500.775796ms 502.340266ms]
Nov 11 23:47:28.011: INFO: 50 %ile: 263.506021ms
Nov 11 23:47:28.011: INFO: 90 %ile: 390.473658ms
Nov 11 23:47:28.011: INFO: 99 %ile: 500.775796ms
Nov 11 23:47:28.011: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Nov 11 23:47:28.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-687" for this suite. 11/11/22 23:47:28.044
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":127,"skipped":2465,"failed":0}
------------------------------
• [SLOW TEST] [7.149 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:20.92
    Nov 11 23:47:20.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svc-latency 11/11/22 23:47:20.925
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:20.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:20.996
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Nov 11 23:47:21.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-687 11/11/22 23:47:21.018
    I1111 23:47:21.064105      21 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-687, replica count: 1
    I1111 23:47:22.115856      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1111 23:47:23.116724      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1111 23:47:24.117902      21 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:47:24.259: INFO: Created: latency-svc-xs2jz
    Nov 11 23:47:24.267: INFO: Got endpoints: latency-svc-xs2jz [49.110932ms]
    Nov 11 23:47:24.310: INFO: Created: latency-svc-j5j6c
    Nov 11 23:47:24.316: INFO: Got endpoints: latency-svc-j5j6c [47.36813ms]
    Nov 11 23:47:24.327: INFO: Created: latency-svc-brg6b
    Nov 11 23:47:24.332: INFO: Got endpoints: latency-svc-brg6b [63.197775ms]
    Nov 11 23:47:24.341: INFO: Created: latency-svc-5mjzl
    Nov 11 23:47:24.347: INFO: Got endpoints: latency-svc-5mjzl [78.45727ms]
    Nov 11 23:47:24.356: INFO: Created: latency-svc-5mhh6
    Nov 11 23:47:24.379: INFO: Got endpoints: latency-svc-5mhh6 [111.056109ms]
    Nov 11 23:47:24.391: INFO: Created: latency-svc-vvltb
    Nov 11 23:47:24.399: INFO: Got endpoints: latency-svc-vvltb [130.939143ms]
    Nov 11 23:47:24.405: INFO: Created: latency-svc-xxbjv
    Nov 11 23:47:24.411: INFO: Got endpoints: latency-svc-xxbjv [142.33778ms]
    Nov 11 23:47:24.421: INFO: Created: latency-svc-qgzn6
    Nov 11 23:47:24.431: INFO: Got endpoints: latency-svc-qgzn6 [162.319144ms]
    Nov 11 23:47:24.437: INFO: Created: latency-svc-48v5x
    Nov 11 23:47:24.444: INFO: Got endpoints: latency-svc-48v5x [175.462097ms]
    Nov 11 23:47:24.453: INFO: Created: latency-svc-rmxfk
    Nov 11 23:47:24.459: INFO: Got endpoints: latency-svc-rmxfk [191.258398ms]
    Nov 11 23:47:24.474: INFO: Created: latency-svc-wcpxt
    Nov 11 23:47:24.474: INFO: Got endpoints: latency-svc-wcpxt [204.694758ms]
    Nov 11 23:47:24.485: INFO: Created: latency-svc-7gmpl
    Nov 11 23:47:24.492: INFO: Got endpoints: latency-svc-7gmpl [223.833037ms]
    Nov 11 23:47:24.501: INFO: Created: latency-svc-mbxzm
    Nov 11 23:47:24.507: INFO: Got endpoints: latency-svc-mbxzm [238.051838ms]
    Nov 11 23:47:24.544: INFO: Created: latency-svc-jjc2q
    Nov 11 23:47:24.549: INFO: Got endpoints: latency-svc-jjc2q [279.715359ms]
    Nov 11 23:47:24.563: INFO: Created: latency-svc-j9sd5
    Nov 11 23:47:24.569: INFO: Got endpoints: latency-svc-j9sd5 [300.739673ms]
    Nov 11 23:47:24.581: INFO: Created: latency-svc-7q9gm
    Nov 11 23:47:24.588: INFO: Got endpoints: latency-svc-7q9gm [319.094679ms]
    Nov 11 23:47:24.597: INFO: Created: latency-svc-8gd5c
    Nov 11 23:47:24.607: INFO: Got endpoints: latency-svc-8gd5c [290.727697ms]
    Nov 11 23:47:24.613: INFO: Created: latency-svc-7tzd6
    Nov 11 23:47:24.644: INFO: Got endpoints: latency-svc-7tzd6 [311.884449ms]
    Nov 11 23:47:24.688: INFO: Created: latency-svc-4tsqk
    Nov 11 23:47:24.695: INFO: Got endpoints: latency-svc-4tsqk [346.718719ms]
    Nov 11 23:47:24.732: INFO: Created: latency-svc-4dnxb
    Nov 11 23:47:24.740: INFO: Got endpoints: latency-svc-4dnxb [361.136649ms]
    Nov 11 23:47:24.749: INFO: Created: latency-svc-br5ql
    Nov 11 23:47:24.758: INFO: Got endpoints: latency-svc-br5ql [359.003971ms]
    Nov 11 23:47:24.772: INFO: Created: latency-svc-zftq9
    Nov 11 23:47:24.780: INFO: Got endpoints: latency-svc-zftq9 [368.536159ms]
    Nov 11 23:47:24.786: INFO: Created: latency-svc-qs75w
    Nov 11 23:47:24.790: INFO: Got endpoints: latency-svc-qs75w [359.81893ms]
    Nov 11 23:47:24.811: INFO: Created: latency-svc-hrpm4
    Nov 11 23:47:24.823: INFO: Got endpoints: latency-svc-hrpm4 [378.774004ms]
    Nov 11 23:47:24.845: INFO: Created: latency-svc-tfwpg
    Nov 11 23:47:24.850: INFO: Got endpoints: latency-svc-tfwpg [390.563914ms]
    Nov 11 23:47:24.859: INFO: Created: latency-svc-8nnks
    Nov 11 23:47:24.864: INFO: Got endpoints: latency-svc-8nnks [389.788904ms]
    Nov 11 23:47:24.874: INFO: Created: latency-svc-6nhp6
    Nov 11 23:47:24.883: INFO: Got endpoints: latency-svc-6nhp6 [390.473658ms]
    Nov 11 23:47:24.890: INFO: Created: latency-svc-zszqj
    Nov 11 23:47:24.898: INFO: Got endpoints: latency-svc-zszqj [390.837942ms]
    Nov 11 23:47:24.906: INFO: Created: latency-svc-nwrsz
    Nov 11 23:47:24.911: INFO: Got endpoints: latency-svc-nwrsz [362.417571ms]
    Nov 11 23:47:24.921: INFO: Created: latency-svc-2qzs2
    Nov 11 23:47:24.927: INFO: Got endpoints: latency-svc-2qzs2 [357.625604ms]
    Nov 11 23:47:24.964: INFO: Created: latency-svc-2mf7t
    Nov 11 23:47:24.964: INFO: Got endpoints: latency-svc-2mf7t [376.383509ms]
    Nov 11 23:47:24.965: INFO: Created: latency-svc-b4q8f
    Nov 11 23:47:24.976: INFO: Got endpoints: latency-svc-b4q8f [368.986141ms]
    Nov 11 23:47:24.978: INFO: Created: latency-svc-ptmk9
    Nov 11 23:47:24.992: INFO: Got endpoints: latency-svc-ptmk9 [348.489513ms]
    Nov 11 23:47:25.003: INFO: Created: latency-svc-j5q5m
    Nov 11 23:47:25.013: INFO: Got endpoints: latency-svc-j5q5m [318.347962ms]
    Nov 11 23:47:25.022: INFO: Created: latency-svc-247nl
    Nov 11 23:47:25.036: INFO: Got endpoints: latency-svc-247nl [295.25223ms]
    Nov 11 23:47:25.049: INFO: Created: latency-svc-kgdp9
    Nov 11 23:47:25.068: INFO: Created: latency-svc-vxdrb
    Nov 11 23:47:25.115: INFO: Created: latency-svc-8qf52
    Nov 11 23:47:25.117: INFO: Got endpoints: latency-svc-kgdp9 [359.219704ms]
    Nov 11 23:47:25.118: INFO: Created: latency-svc-p2qd7
    Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-p2qd7 [329.981842ms]
    Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-8qf52 [298.383488ms]
    Nov 11 23:47:25.121: INFO: Got endpoints: latency-svc-vxdrb [341.094026ms]
    Nov 11 23:47:25.135: INFO: Created: latency-svc-gzpdz
    Nov 11 23:47:25.137: INFO: Created: latency-svc-vf5n5
    Nov 11 23:47:25.137: INFO: Got endpoints: latency-svc-vf5n5 [287.005591ms]
    Nov 11 23:47:25.139: INFO: Got endpoints: latency-svc-gzpdz [275.143693ms]
    Nov 11 23:47:25.188: INFO: Created: latency-svc-p6gbj
    Nov 11 23:47:25.188: INFO: Created: latency-svc-4xvwc
    Nov 11 23:47:25.189: INFO: Created: latency-svc-2drzs
    Nov 11 23:47:25.190: INFO: Got endpoints: latency-svc-p6gbj [306.693137ms]
    Nov 11 23:47:25.190: INFO: Got endpoints: latency-svc-4xvwc [291.8605ms]
    Nov 11 23:47:25.192: INFO: Got endpoints: latency-svc-2drzs [280.53631ms]
    Nov 11 23:47:25.201: INFO: Created: latency-svc-42fc8
    Nov 11 23:47:25.240: INFO: Created: latency-svc-7nthp
    Nov 11 23:47:25.240: INFO: Got endpoints: latency-svc-7nthp [275.640661ms]
    Nov 11 23:47:25.241: INFO: Got endpoints: latency-svc-42fc8 [312.937689ms]
    Nov 11 23:47:25.241: INFO: Created: latency-svc-ndv85
    Nov 11 23:47:25.245: INFO: Got endpoints: latency-svc-ndv85 [269.161803ms]
    Nov 11 23:47:25.254: INFO: Created: latency-svc-pg7gh
    Nov 11 23:47:25.261: INFO: Got endpoints: latency-svc-pg7gh [269.079823ms]
    Nov 11 23:47:25.272: INFO: Created: latency-svc-gdcmd
    Nov 11 23:47:25.278: INFO: Got endpoints: latency-svc-gdcmd [264.170415ms]
    Nov 11 23:47:25.289: INFO: Created: latency-svc-snhlw
    Nov 11 23:47:25.293: INFO: Got endpoints: latency-svc-snhlw [257.207003ms]
    Nov 11 23:47:25.307: INFO: Created: latency-svc-vcv28
    Nov 11 23:47:25.319: INFO: Got endpoints: latency-svc-vcv28 [197.5592ms]
    Nov 11 23:47:25.323: INFO: Created: latency-svc-kl2r4
    Nov 11 23:47:25.347: INFO: Got endpoints: latency-svc-kl2r4 [228.518118ms]
    Nov 11 23:47:25.355: INFO: Created: latency-svc-hcbds
    Nov 11 23:47:25.356: INFO: Created: latency-svc-klwnp
    Nov 11 23:47:25.357: INFO: Got endpoints: latency-svc-klwnp [236.168684ms]
    Nov 11 23:47:25.361: INFO: Got endpoints: latency-svc-hcbds [239.920538ms]
    Nov 11 23:47:25.371: INFO: Created: latency-svc-tlm26
    Nov 11 23:47:25.376: INFO: Got endpoints: latency-svc-tlm26 [238.758534ms]
    Nov 11 23:47:25.386: INFO: Created: latency-svc-shzzb
    Nov 11 23:47:25.391: INFO: Got endpoints: latency-svc-shzzb [252.016082ms]
    Nov 11 23:47:25.401: INFO: Created: latency-svc-4jc27
    Nov 11 23:47:25.407: INFO: Got endpoints: latency-svc-4jc27 [217.786352ms]
    Nov 11 23:47:25.419: INFO: Created: latency-svc-jdvmx
    Nov 11 23:47:25.423: INFO: Got endpoints: latency-svc-jdvmx [230.87981ms]
    Nov 11 23:47:25.435: INFO: Created: latency-svc-76llg
    Nov 11 23:47:25.440: INFO: Got endpoints: latency-svc-76llg [249.718708ms]
    Nov 11 23:47:25.451: INFO: Created: latency-svc-8gzrg
    Nov 11 23:47:25.455: INFO: Got endpoints: latency-svc-8gzrg [214.369853ms]
    Nov 11 23:47:25.466: INFO: Created: latency-svc-jjphg
    Nov 11 23:47:25.471: INFO: Got endpoints: latency-svc-jjphg [230.648199ms]
    Nov 11 23:47:25.483: INFO: Created: latency-svc-cr5d8
    Nov 11 23:47:25.488: INFO: Got endpoints: latency-svc-cr5d8 [242.556277ms]
    Nov 11 23:47:25.497: INFO: Created: latency-svc-7pt88
    Nov 11 23:47:25.507: INFO: Got endpoints: latency-svc-7pt88 [245.977476ms]
    Nov 11 23:47:25.514: INFO: Created: latency-svc-r8pq6
    Nov 11 23:47:25.519: INFO: Got endpoints: latency-svc-r8pq6 [240.934985ms]
    Nov 11 23:47:25.530: INFO: Created: latency-svc-mkwxz
    Nov 11 23:47:25.535: INFO: Got endpoints: latency-svc-mkwxz [242.229974ms]
    Nov 11 23:47:25.804: INFO: Created: latency-svc-xgg2z
    Nov 11 23:47:25.811: INFO: Created: latency-svc-4szkl
    Nov 11 23:47:25.812: INFO: Created: latency-svc-ghxwn
    Nov 11 23:47:25.812: INFO: Created: latency-svc-hgrbb
    Nov 11 23:47:25.814: INFO: Created: latency-svc-q7rzh
    Nov 11 23:47:25.812: INFO: Created: latency-svc-c9t6m
    Nov 11 23:47:25.816: INFO: Created: latency-svc-76sbw
    Nov 11 23:47:25.818: INFO: Created: latency-svc-ghwcz
    Nov 11 23:47:25.819: INFO: Created: latency-svc-hkb4c
    Nov 11 23:47:25.819: INFO: Created: latency-svc-gt2kb
    Nov 11 23:47:25.820: INFO: Got endpoints: latency-svc-hgrbb [500.775796ms]
    Nov 11 23:47:25.820: INFO: Created: latency-svc-n2tlz
    Nov 11 23:47:25.821: INFO: Created: latency-svc-5t4qt
    Nov 11 23:47:25.821: INFO: Got endpoints: latency-svc-xgg2z [445.028332ms]
    Nov 11 23:47:25.822: INFO: Created: latency-svc-67fb9
    Nov 11 23:47:25.822: INFO: Created: latency-svc-rppfj
    Nov 11 23:47:25.824: INFO: Created: latency-svc-4kkqm
    Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-4szkl [424.046866ms]
    Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-ghxwn [408.270599ms]
    Nov 11 23:47:25.832: INFO: Got endpoints: latency-svc-c9t6m [474.340677ms]
    Nov 11 23:47:25.834: INFO: Got endpoints: latency-svc-q7rzh [487.099329ms]
    Nov 11 23:47:25.835: INFO: Got endpoints: latency-svc-ghwcz [443.908193ms]
    Nov 11 23:47:25.836: INFO: Got endpoints: latency-svc-rppfj [380.352284ms]
    Nov 11 23:47:25.836: INFO: Got endpoints: latency-svc-5t4qt [364.340642ms]
    Nov 11 23:47:25.839: INFO: Got endpoints: latency-svc-76sbw [398.96584ms]
    Nov 11 23:47:25.838: INFO: Got endpoints: latency-svc-gt2kb [330.400459ms]
    Nov 11 23:47:25.841: INFO: Got endpoints: latency-svc-4kkqm [353.364108ms]
    Nov 11 23:47:25.842: INFO: Got endpoints: latency-svc-hkb4c [323.392986ms]
    Nov 11 23:47:25.843: INFO: Got endpoints: latency-svc-67fb9 [481.680095ms]
    Nov 11 23:47:25.843: INFO: Got endpoints: latency-svc-n2tlz [307.743545ms]
    Nov 11 23:47:25.860: INFO: Created: latency-svc-9grg9
    Nov 11 23:47:25.869: INFO: Got endpoints: latency-svc-9grg9 [48.684246ms]
    Nov 11 23:47:25.880: INFO: Created: latency-svc-xlhqg
    Nov 11 23:47:25.885: INFO: Got endpoints: latency-svc-xlhqg [64.217794ms]
    Nov 11 23:47:25.897: INFO: Created: latency-svc-wnr6g
    Nov 11 23:47:25.902: INFO: Got endpoints: latency-svc-wnr6g [70.110846ms]
    Nov 11 23:47:25.913: INFO: Created: latency-svc-vbbxp
    Nov 11 23:47:25.920: INFO: Got endpoints: latency-svc-vbbxp [87.042217ms]
    Nov 11 23:47:25.945: INFO: Created: latency-svc-x5g7t
    Nov 11 23:47:25.954: INFO: Got endpoints: latency-svc-x5g7t [120.073977ms]
    Nov 11 23:47:25.964: INFO: Created: latency-svc-xgbhs
    Nov 11 23:47:25.979: INFO: Created: latency-svc-hjtjd
    Nov 11 23:47:25.987: INFO: Got endpoints: latency-svc-hjtjd [153.977044ms]
    Nov 11 23:47:25.990: INFO: Got endpoints: latency-svc-xgbhs [154.375883ms]
    Nov 11 23:47:25.996: INFO: Created: latency-svc-2lkrm
    Nov 11 23:47:26.001: INFO: Got endpoints: latency-svc-2lkrm [162.029558ms]
    Nov 11 23:47:26.013: INFO: Created: latency-svc-bsf77
    Nov 11 23:47:26.019: INFO: Got endpoints: latency-svc-bsf77 [179.671084ms]
    Nov 11 23:47:26.028: INFO: Created: latency-svc-d88qh
    Nov 11 23:47:26.036: INFO: Got endpoints: latency-svc-d88qh [196.885ms]
    Nov 11 23:47:26.044: INFO: Created: latency-svc-7hk88
    Nov 11 23:47:26.048: INFO: Got endpoints: latency-svc-7hk88 [208.364066ms]
    Nov 11 23:47:26.060: INFO: Created: latency-svc-d9lcj
    Nov 11 23:47:26.065: INFO: Got endpoints: latency-svc-d9lcj [222.530139ms]
    Nov 11 23:47:26.080: INFO: Created: latency-svc-qpx7n
    Nov 11 23:47:26.085: INFO: Got endpoints: latency-svc-qpx7n [242.590364ms]
    Nov 11 23:47:26.093: INFO: Created: latency-svc-m4fxd
    Nov 11 23:47:26.099: INFO: Got endpoints: latency-svc-m4fxd [255.933329ms]
    Nov 11 23:47:26.108: INFO: Created: latency-svc-vll79
    Nov 11 23:47:26.114: INFO: Got endpoints: latency-svc-vll79 [272.857199ms]
    Nov 11 23:47:26.121: INFO: Created: latency-svc-g6xsp
    Nov 11 23:47:26.129: INFO: Got endpoints: latency-svc-g6xsp [259.449643ms]
    Nov 11 23:47:26.139: INFO: Created: latency-svc-n26jp
    Nov 11 23:47:26.144: INFO: Got endpoints: latency-svc-n26jp [258.681417ms]
    Nov 11 23:47:26.154: INFO: Created: latency-svc-pj4q8
    Nov 11 23:47:26.159: INFO: Got endpoints: latency-svc-pj4q8 [256.626917ms]
    Nov 11 23:47:26.173: INFO: Created: latency-svc-pcc5n
    Nov 11 23:47:26.180: INFO: Got endpoints: latency-svc-pcc5n [259.743366ms]
    Nov 11 23:47:26.189: INFO: Created: latency-svc-nss6c
    Nov 11 23:47:26.194: INFO: Got endpoints: latency-svc-nss6c [239.342079ms]
    Nov 11 23:47:26.208: INFO: Created: latency-svc-kmk48
    Nov 11 23:47:26.215: INFO: Got endpoints: latency-svc-kmk48 [227.286487ms]
    Nov 11 23:47:26.225: INFO: Created: latency-svc-zxmdn
    Nov 11 23:47:26.236: INFO: Got endpoints: latency-svc-zxmdn [245.997178ms]
    Nov 11 23:47:26.242: INFO: Created: latency-svc-lrwk4
    Nov 11 23:47:26.246: INFO: Got endpoints: latency-svc-lrwk4 [245.256106ms]
    Nov 11 23:47:26.256: INFO: Created: latency-svc-c2mfl
    Nov 11 23:47:26.264: INFO: Got endpoints: latency-svc-c2mfl [244.488953ms]
    Nov 11 23:47:26.282: INFO: Created: latency-svc-b5rlf
    Nov 11 23:47:26.289: INFO: Got endpoints: latency-svc-b5rlf [252.414844ms]
    Nov 11 23:47:26.299: INFO: Created: latency-svc-jlg6x
    Nov 11 23:47:26.309: INFO: Got endpoints: latency-svc-jlg6x [260.785837ms]
    Nov 11 23:47:26.319: INFO: Created: latency-svc-q8jg7
    Nov 11 23:47:26.326: INFO: Got endpoints: latency-svc-q8jg7 [260.988767ms]
    Nov 11 23:47:26.333: INFO: Created: latency-svc-2658k
    Nov 11 23:47:26.343: INFO: Got endpoints: latency-svc-2658k [256.35476ms]
    Nov 11 23:47:26.351: INFO: Created: latency-svc-c6blj
    Nov 11 23:47:26.357: INFO: Got endpoints: latency-svc-c6blj [257.36788ms]
    Nov 11 23:47:26.366: INFO: Created: latency-svc-dhzzr
    Nov 11 23:47:26.373: INFO: Got endpoints: latency-svc-dhzzr [258.542847ms]
    Nov 11 23:47:26.383: INFO: Created: latency-svc-sbjhf
    Nov 11 23:47:26.388: INFO: Got endpoints: latency-svc-sbjhf [259.647583ms]
    Nov 11 23:47:26.400: INFO: Created: latency-svc-zhrgp
    Nov 11 23:47:26.406: INFO: Got endpoints: latency-svc-zhrgp [261.98636ms]
    Nov 11 23:47:26.421: INFO: Created: latency-svc-22m7q
    Nov 11 23:47:26.426: INFO: Got endpoints: latency-svc-22m7q [266.40413ms]
    Nov 11 23:47:26.433: INFO: Created: latency-svc-kpqkh
    Nov 11 23:47:26.497: INFO: Got endpoints: latency-svc-kpqkh [317.019681ms]
    Nov 11 23:47:26.500: INFO: Created: latency-svc-cj865
    Nov 11 23:47:26.506: INFO: Got endpoints: latency-svc-cj865 [311.753991ms]
    Nov 11 23:47:26.500: INFO: Created: latency-svc-g8w96
    Nov 11 23:47:26.502: INFO: Created: latency-svc-plv6w
    Nov 11 23:47:26.503: INFO: Created: latency-svc-4qmph
    Nov 11 23:47:26.509: INFO: Got endpoints: latency-svc-g8w96 [270.05029ms]
    Nov 11 23:47:26.510: INFO: Got endpoints: latency-svc-4qmph [263.085217ms]
    Nov 11 23:47:26.510: INFO: Got endpoints: latency-svc-plv6w [295.200049ms]
    Nov 11 23:47:26.514: INFO: Created: latency-svc-c4zmj
    Nov 11 23:47:26.519: INFO: Got endpoints: latency-svc-c4zmj [255.453542ms]
    Nov 11 23:47:26.530: INFO: Created: latency-svc-8s2cx
    Nov 11 23:47:26.536: INFO: Got endpoints: latency-svc-8s2cx [247.361212ms]
    Nov 11 23:47:26.779: INFO: Created: latency-svc-xbmsw
    Nov 11 23:47:26.780: INFO: Created: latency-svc-gqbs6
    Nov 11 23:47:26.782: INFO: Created: latency-svc-t8ffl
    Nov 11 23:47:26.782: INFO: Created: latency-svc-7rcl6
    Nov 11 23:47:26.802: INFO: Created: latency-svc-62d7d
    Nov 11 23:47:26.803: INFO: Created: latency-svc-58x7h
    Nov 11 23:47:26.803: INFO: Created: latency-svc-fb79p
    Nov 11 23:47:26.804: INFO: Created: latency-svc-t89hh
    Nov 11 23:47:26.804: INFO: Created: latency-svc-j7hvx
    Nov 11 23:47:26.804: INFO: Created: latency-svc-b2dgh
    Nov 11 23:47:26.805: INFO: Created: latency-svc-2rvmw
    Nov 11 23:47:26.806: INFO: Created: latency-svc-fc4fz
    Nov 11 23:47:26.808: INFO: Created: latency-svc-v8fnj
    Nov 11 23:47:26.809: INFO: Created: latency-svc-wwzns
    Nov 11 23:47:26.809: INFO: Created: latency-svc-wjdlr
    Nov 11 23:47:26.809: INFO: Got endpoints: latency-svc-gqbs6 [403.315305ms]
    Nov 11 23:47:26.810: INFO: Got endpoints: latency-svc-t89hh [483.106511ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-7rcl6 [300.495484ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-xbmsw [301.573587ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-t8ffl [306.252773ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-wjdlr [454.705136ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-fb79p [468.649519ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-j7hvx [275.025816ms]
    Nov 11 23:47:26.811: INFO: Got endpoints: latency-svc-v8fnj [502.340266ms]
    Nov 11 23:47:26.815: INFO: Got endpoints: latency-svc-2rvmw [294.348273ms]
    Nov 11 23:47:26.816: INFO: Got endpoints: latency-svc-wwzns [442.853528ms]
    Nov 11 23:47:26.817: INFO: Got endpoints: latency-svc-62d7d [391.082881ms]
    Nov 11 23:47:26.818: INFO: Got endpoints: latency-svc-b2dgh [311.116626ms]
    Nov 11 23:47:26.819: INFO: Got endpoints: latency-svc-fc4fz [308.886156ms]
    Nov 11 23:47:26.819: INFO: Got endpoints: latency-svc-58x7h [430.998666ms]
    Nov 11 23:47:26.845: INFO: Created: latency-svc-wplkz
    Nov 11 23:47:26.849: INFO: Got endpoints: latency-svc-wplkz [39.816212ms]
    Nov 11 23:47:26.861: INFO: Created: latency-svc-7dcgp
    Nov 11 23:47:26.866: INFO: Got endpoints: latency-svc-7dcgp [56.080752ms]
    Nov 11 23:47:26.877: INFO: Created: latency-svc-bv7x9
    Nov 11 23:47:26.900: INFO: Got endpoints: latency-svc-bv7x9 [88.49099ms]
    Nov 11 23:47:26.902: INFO: Created: latency-svc-825j2
    Nov 11 23:47:26.915: INFO: Got endpoints: latency-svc-825j2 [103.001127ms]
    Nov 11 23:47:26.929: INFO: Created: latency-svc-mk88d
    Nov 11 23:47:26.939: INFO: Got endpoints: latency-svc-mk88d [125.904473ms]
    Nov 11 23:47:26.946: INFO: Created: latency-svc-bmqsl
    Nov 11 23:47:26.953: INFO: Got endpoints: latency-svc-bmqsl [140.517068ms]
    Nov 11 23:47:26.963: INFO: Created: latency-svc-ffz7x
    Nov 11 23:47:26.974: INFO: Got endpoints: latency-svc-ffz7x [160.535645ms]
    Nov 11 23:47:26.989: INFO: Created: latency-svc-gftjl
    Nov 11 23:47:26.993: INFO: Got endpoints: latency-svc-gftjl [179.257343ms]
    Nov 11 23:47:27.010: INFO: Created: latency-svc-vdcv6
    Nov 11 23:47:27.015: INFO: Got endpoints: latency-svc-vdcv6 [199.31199ms]
    Nov 11 23:47:27.035: INFO: Created: latency-svc-fwkdf
    Nov 11 23:47:27.039: INFO: Got endpoints: latency-svc-fwkdf [224.941992ms]
    Nov 11 23:47:27.055: INFO: Created: latency-svc-z46wq
    Nov 11 23:47:27.065: INFO: Got endpoints: latency-svc-z46wq [247.017477ms]
    Nov 11 23:47:27.082: INFO: Created: latency-svc-hvx47
    Nov 11 23:47:27.088: INFO: Got endpoints: latency-svc-hvx47 [273.690634ms]
    Nov 11 23:47:27.102: INFO: Created: latency-svc-87hbs
    Nov 11 23:47:27.107: INFO: Got endpoints: latency-svc-87hbs [290.161605ms]
    Nov 11 23:47:27.116: INFO: Created: latency-svc-plg4m
    Nov 11 23:47:27.123: INFO: Got endpoints: latency-svc-plg4m [304.633553ms]
    Nov 11 23:47:27.131: INFO: Created: latency-svc-tk5rk
    Nov 11 23:47:27.139: INFO: Got endpoints: latency-svc-tk5rk [319.213468ms]
    Nov 11 23:47:27.148: INFO: Created: latency-svc-8c89f
    Nov 11 23:47:27.153: INFO: Got endpoints: latency-svc-8c89f [303.636001ms]
    Nov 11 23:47:27.164: INFO: Created: latency-svc-25bjf
    Nov 11 23:47:27.169: INFO: Got endpoints: latency-svc-25bjf [303.383725ms]
    Nov 11 23:47:27.180: INFO: Created: latency-svc-99kb8
    Nov 11 23:47:27.183: INFO: Got endpoints: latency-svc-99kb8 [282.933184ms]
    Nov 11 23:47:27.198: INFO: Created: latency-svc-bfjx4
    Nov 11 23:47:27.206: INFO: Got endpoints: latency-svc-bfjx4 [290.268855ms]
    Nov 11 23:47:27.215: INFO: Created: latency-svc-j7bqq
    Nov 11 23:47:27.220: INFO: Got endpoints: latency-svc-j7bqq [280.939065ms]
    Nov 11 23:47:27.232: INFO: Created: latency-svc-jjhm9
    Nov 11 23:47:27.237: INFO: Got endpoints: latency-svc-jjhm9 [283.309643ms]
    Nov 11 23:47:27.245: INFO: Created: latency-svc-rcjnh
    Nov 11 23:47:27.252: INFO: Got endpoints: latency-svc-rcjnh [277.958902ms]
    Nov 11 23:47:27.265: INFO: Created: latency-svc-j2wj2
    Nov 11 23:47:27.273: INFO: Got endpoints: latency-svc-j2wj2 [279.786055ms]
    Nov 11 23:47:27.282: INFO: Created: latency-svc-x4snn
    Nov 11 23:47:27.287: INFO: Got endpoints: latency-svc-x4snn [271.161592ms]
    Nov 11 23:47:27.303: INFO: Created: latency-svc-trwl9
    Nov 11 23:47:27.314: INFO: Got endpoints: latency-svc-trwl9 [274.628802ms]
    Nov 11 23:47:27.324: INFO: Created: latency-svc-5ks2t
    Nov 11 23:47:27.332: INFO: Got endpoints: latency-svc-5ks2t [266.209428ms]
    Nov 11 23:47:27.344: INFO: Created: latency-svc-w6hms
    Nov 11 23:47:27.349: INFO: Got endpoints: latency-svc-w6hms [260.558388ms]
    Nov 11 23:47:27.361: INFO: Created: latency-svc-lc5q9
    Nov 11 23:47:27.367: INFO: Got endpoints: latency-svc-lc5q9 [259.792181ms]
    Nov 11 23:47:27.379: INFO: Created: latency-svc-tf88d
    Nov 11 23:47:27.386: INFO: Got endpoints: latency-svc-tf88d [262.300171ms]
    Nov 11 23:47:27.392: INFO: Created: latency-svc-pvg5q
    Nov 11 23:47:27.398: INFO: Got endpoints: latency-svc-pvg5q [258.877623ms]
    Nov 11 23:47:27.411: INFO: Created: latency-svc-42w7m
    Nov 11 23:47:27.417: INFO: Got endpoints: latency-svc-42w7m [263.506021ms]
    Nov 11 23:47:27.427: INFO: Created: latency-svc-6qw56
    Nov 11 23:47:27.432: INFO: Got endpoints: latency-svc-6qw56 [262.430043ms]
    Nov 11 23:47:27.444: INFO: Created: latency-svc-29g7b
    Nov 11 23:47:27.449: INFO: Got endpoints: latency-svc-29g7b [265.374928ms]
    Nov 11 23:47:27.460: INFO: Created: latency-svc-hljsg
    Nov 11 23:47:27.466: INFO: Got endpoints: latency-svc-hljsg [260.158932ms]
    Nov 11 23:47:27.475: INFO: Created: latency-svc-2c4gr
    Nov 11 23:47:27.482: INFO: Got endpoints: latency-svc-2c4gr [262.164497ms]
    Nov 11 23:47:27.492: INFO: Created: latency-svc-29nq7
    Nov 11 23:47:27.499: INFO: Got endpoints: latency-svc-29nq7 [261.776579ms]
    Nov 11 23:47:27.510: INFO: Created: latency-svc-bzw8j
    Nov 11 23:47:27.514: INFO: Got endpoints: latency-svc-bzw8j [262.059056ms]
    Nov 11 23:47:27.525: INFO: Created: latency-svc-s4zxk
    Nov 11 23:47:27.533: INFO: Got endpoints: latency-svc-s4zxk [259.566902ms]
    Nov 11 23:47:27.540: INFO: Created: latency-svc-fqnxm
    Nov 11 23:47:27.547: INFO: Got endpoints: latency-svc-fqnxm [260.750515ms]
    Nov 11 23:47:27.556: INFO: Created: latency-svc-bcxzr
    Nov 11 23:47:27.566: INFO: Got endpoints: latency-svc-bcxzr [251.436605ms]
    Nov 11 23:47:27.583: INFO: Created: latency-svc-l9dhn
    Nov 11 23:47:27.589: INFO: Got endpoints: latency-svc-l9dhn [257.607711ms]
    Nov 11 23:47:27.600: INFO: Created: latency-svc-nwdns
    Nov 11 23:47:27.607: INFO: Got endpoints: latency-svc-nwdns [257.351851ms]
    Nov 11 23:47:27.617: INFO: Created: latency-svc-4tgkj
    Nov 11 23:47:27.624: INFO: Got endpoints: latency-svc-4tgkj [256.670872ms]
    Nov 11 23:47:27.634: INFO: Created: latency-svc-2vtkm
    Nov 11 23:47:27.639: INFO: Got endpoints: latency-svc-2vtkm [252.887666ms]
    Nov 11 23:47:27.649: INFO: Created: latency-svc-wq8jz
    Nov 11 23:47:27.655: INFO: Got endpoints: latency-svc-wq8jz [257.659131ms]
    Nov 11 23:47:27.671: INFO: Created: latency-svc-s9pwk
    Nov 11 23:47:27.676: INFO: Got endpoints: latency-svc-s9pwk [258.449182ms]
    Nov 11 23:47:27.688: INFO: Created: latency-svc-rt7xn
    Nov 11 23:47:27.696: INFO: Got endpoints: latency-svc-rt7xn [264.562383ms]
    Nov 11 23:47:27.733: INFO: Created: latency-svc-dmldx
    Nov 11 23:47:27.734: INFO: Got endpoints: latency-svc-dmldx [285.074556ms]
    Nov 11 23:47:27.735: INFO: Created: latency-svc-wk5dt
    Nov 11 23:47:27.736: INFO: Got endpoints: latency-svc-wk5dt [269.486214ms]
    Nov 11 23:47:27.739: INFO: Created: latency-svc-qvw2h
    Nov 11 23:47:27.776: INFO: Created: latency-svc-rwsrn
    Nov 11 23:47:27.777: INFO: Created: latency-svc-fb4gw
    Nov 11 23:47:27.778: INFO: Got endpoints: latency-svc-qvw2h [295.337462ms]
    Nov 11 23:47:27.779: INFO: Got endpoints: latency-svc-rwsrn [264.335817ms]
    Nov 11 23:47:27.779: INFO: Got endpoints: latency-svc-fb4gw [280.425928ms]
    Nov 11 23:47:27.821: INFO: Created: latency-svc-65qrn
    Nov 11 23:47:27.822: INFO: Created: latency-svc-dsccl
    Nov 11 23:47:27.822: INFO: Created: latency-svc-5kw7n
    Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-5kw7n [274.338722ms]
    Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-dsccl [292.637314ms]
    Nov 11 23:47:27.840: INFO: Got endpoints: latency-svc-65qrn [307.694577ms]
    Nov 11 23:47:27.867: INFO: Created: latency-svc-4g8pl
    Nov 11 23:47:27.870: INFO: Created: latency-svc-gk7hk
    Nov 11 23:47:27.871: INFO: Got endpoints: latency-svc-gk7hk [264.230152ms]
    Nov 11 23:47:27.871: INFO: Got endpoints: latency-svc-4g8pl [281.782363ms]
    Nov 11 23:47:27.872: INFO: Created: latency-svc-d58n4
    Nov 11 23:47:27.879: INFO: Got endpoints: latency-svc-d58n4 [255.179066ms]
    Nov 11 23:47:27.885: INFO: Created: latency-svc-gvn7h
    Nov 11 23:47:27.892: INFO: Got endpoints: latency-svc-gvn7h [253.248924ms]
    Nov 11 23:47:27.905: INFO: Created: latency-svc-gknt4
    Nov 11 23:47:27.907: INFO: Got endpoints: latency-svc-gknt4 [251.455852ms]
    Nov 11 23:47:27.921: INFO: Created: latency-svc-sjscg
    Nov 11 23:47:27.927: INFO: Got endpoints: latency-svc-sjscg [251.524173ms]
    Nov 11 23:47:27.939: INFO: Created: latency-svc-m8xl8
    Nov 11 23:47:27.944: INFO: Got endpoints: latency-svc-m8xl8 [248.03991ms]
    Nov 11 23:47:27.959: INFO: Created: latency-svc-h74pj
    Nov 11 23:47:27.963: INFO: Got endpoints: latency-svc-h74pj [227.51615ms]
    Nov 11 23:47:27.969: INFO: Created: latency-svc-8p6kw
    Nov 11 23:47:27.985: INFO: Got endpoints: latency-svc-8p6kw [250.63821ms]
    Nov 11 23:47:27.990: INFO: Created: latency-svc-q2h7s
    Nov 11 23:47:28.007: INFO: Got endpoints: latency-svc-q2h7s [227.878985ms]
    Nov 11 23:47:28.007: INFO: Created: latency-svc-628pr
    Nov 11 23:47:28.011: INFO: Got endpoints: latency-svc-628pr [233.316952ms]
    Nov 11 23:47:28.011: INFO: Latencies: [39.816212ms 47.36813ms 48.684246ms 56.080752ms 63.197775ms 64.217794ms 70.110846ms 78.45727ms 87.042217ms 88.49099ms 103.001127ms 111.056109ms 120.073977ms 125.904473ms 130.939143ms 140.517068ms 142.33778ms 153.977044ms 154.375883ms 160.535645ms 162.029558ms 162.319144ms 175.462097ms 179.257343ms 179.671084ms 191.258398ms 196.885ms 197.5592ms 199.31199ms 204.694758ms 208.364066ms 214.369853ms 217.786352ms 222.530139ms 223.833037ms 224.941992ms 227.286487ms 227.51615ms 227.878985ms 228.518118ms 230.648199ms 230.87981ms 233.316952ms 236.168684ms 238.051838ms 238.758534ms 239.342079ms 239.920538ms 240.934985ms 242.229974ms 242.556277ms 242.590364ms 244.488953ms 245.256106ms 245.977476ms 245.997178ms 247.017477ms 247.361212ms 248.03991ms 249.718708ms 250.63821ms 251.436605ms 251.455852ms 251.524173ms 252.016082ms 252.414844ms 252.887666ms 253.248924ms 255.179066ms 255.453542ms 255.933329ms 256.35476ms 256.626917ms 256.670872ms 257.207003ms 257.351851ms 257.36788ms 257.607711ms 257.659131ms 258.449182ms 258.542847ms 258.681417ms 258.877623ms 259.449643ms 259.566902ms 259.647583ms 259.743366ms 259.792181ms 260.158932ms 260.558388ms 260.750515ms 260.785837ms 260.988767ms 261.776579ms 261.98636ms 262.059056ms 262.164497ms 262.300171ms 262.430043ms 263.085217ms 263.506021ms 264.170415ms 264.230152ms 264.335817ms 264.562383ms 265.374928ms 266.209428ms 266.40413ms 269.079823ms 269.161803ms 269.486214ms 270.05029ms 271.161592ms 272.857199ms 273.690634ms 274.338722ms 274.628802ms 275.025816ms 275.143693ms 275.640661ms 277.958902ms 279.715359ms 279.786055ms 280.425928ms 280.53631ms 280.939065ms 281.782363ms 282.933184ms 283.309643ms 285.074556ms 287.005591ms 290.161605ms 290.268855ms 290.727697ms 291.8605ms 292.637314ms 294.348273ms 295.200049ms 295.25223ms 295.337462ms 298.383488ms 300.495484ms 300.739673ms 301.573587ms 303.383725ms 303.636001ms 304.633553ms 306.252773ms 306.693137ms 307.694577ms 307.743545ms 308.886156ms 311.116626ms 311.753991ms 311.884449ms 312.937689ms 317.019681ms 318.347962ms 319.094679ms 319.213468ms 323.392986ms 329.981842ms 330.400459ms 341.094026ms 346.718719ms 348.489513ms 353.364108ms 357.625604ms 359.003971ms 359.219704ms 359.81893ms 361.136649ms 362.417571ms 364.340642ms 368.536159ms 368.986141ms 376.383509ms 378.774004ms 380.352284ms 389.788904ms 390.473658ms 390.563914ms 390.837942ms 391.082881ms 398.96584ms 403.315305ms 408.270599ms 424.046866ms 430.998666ms 442.853528ms 443.908193ms 445.028332ms 454.705136ms 468.649519ms 474.340677ms 481.680095ms 483.106511ms 487.099329ms 500.775796ms 502.340266ms]
    Nov 11 23:47:28.011: INFO: 50 %ile: 263.506021ms
    Nov 11 23:47:28.011: INFO: 90 %ile: 390.473658ms
    Nov 11 23:47:28.011: INFO: 99 %ile: 500.775796ms
    Nov 11 23:47:28.011: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Nov 11 23:47:28.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-687" for this suite. 11/11/22 23:47:28.044
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:28.074
Nov 11 23:47:28.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:47:28.076
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:28.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:28.149
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-4044 11/11/22 23:47:28.167
STEP: creating replication controller nodeport-test in namespace services-4044 11/11/22 23:47:28.229
I1111 23:47:28.266441      21 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4044, replica count: 2
I1111 23:47:31.317879      21 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:47:31.317: INFO: Creating new exec pod
Nov 11 23:47:31.368: INFO: Waiting up to 5m0s for pod "execpodvllqq" in namespace "services-4044" to be "running"
Nov 11 23:47:31.386: INFO: Pod "execpodvllqq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.446482ms
Nov 11 23:47:33.408: INFO: Pod "execpodvllqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040240427s
Nov 11 23:47:35.408: INFO: Pod "execpodvllqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.039859682s
Nov 11 23:47:35.408: INFO: Pod "execpodvllqq" satisfied condition "running"
Nov 11 23:47:36.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 11 23:47:36.863: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 11 23:47:36.863: INFO: stdout: ""
Nov 11 23:47:37.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 11 23:47:38.346: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 11 23:47:38.346: INFO: stdout: ""
Nov 11 23:47:38.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 11 23:47:39.359: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 11 23:47:39.359: INFO: stdout: "nodeport-test-k76ls"
Nov 11 23:47:39.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.21.122 80'
Nov 11 23:47:39.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.21.122 80\nConnection to 172.21.21.122 80 port [tcp/http] succeeded!\n"
Nov 11 23:47:39.761: INFO: stdout: "nodeport-test-xwzdd"
Nov 11 23:47:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 32719'
Nov 11 23:47:40.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 32719\nConnection to 10.184.98.55 32719 port [tcp/*] succeeded!\n"
Nov 11 23:47:40.205: INFO: stdout: "nodeport-test-xwzdd"
Nov 11 23:47:40.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32719'
Nov 11 23:47:40.676: INFO: stderr: "+ nc -v -t -w 2 10.241.148.113 32719\n+ echo hostName\nConnection to 10.241.148.113 32719 port [tcp/*] succeeded!\n"
Nov 11 23:47:40.676: INFO: stdout: "nodeport-test-xwzdd"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:47:40.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4044" for this suite. 11/11/22 23:47:40.703
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":128,"skipped":2467,"failed":0}
------------------------------
• [SLOW TEST] [12.653 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:28.074
    Nov 11 23:47:28.075: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:47:28.076
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:28.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:28.149
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-4044 11/11/22 23:47:28.167
    STEP: creating replication controller nodeport-test in namespace services-4044 11/11/22 23:47:28.229
    I1111 23:47:28.266441      21 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4044, replica count: 2
    I1111 23:47:31.317879      21 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:47:31.317: INFO: Creating new exec pod
    Nov 11 23:47:31.368: INFO: Waiting up to 5m0s for pod "execpodvllqq" in namespace "services-4044" to be "running"
    Nov 11 23:47:31.386: INFO: Pod "execpodvllqq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.446482ms
    Nov 11 23:47:33.408: INFO: Pod "execpodvllqq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040240427s
    Nov 11 23:47:35.408: INFO: Pod "execpodvllqq": Phase="Running", Reason="", readiness=true. Elapsed: 4.039859682s
    Nov 11 23:47:35.408: INFO: Pod "execpodvllqq" satisfied condition "running"
    Nov 11 23:47:36.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 11 23:47:36.863: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 11 23:47:36.863: INFO: stdout: ""
    Nov 11 23:47:37.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 11 23:47:38.346: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 11 23:47:38.346: INFO: stdout: ""
    Nov 11 23:47:38.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 11 23:47:39.359: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 11 23:47:39.359: INFO: stdout: "nodeport-test-k76ls"
    Nov 11 23:47:39.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.21.122 80'
    Nov 11 23:47:39.761: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.21.122 80\nConnection to 172.21.21.122 80 port [tcp/http] succeeded!\n"
    Nov 11 23:47:39.761: INFO: stdout: "nodeport-test-xwzdd"
    Nov 11 23:47:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.184.98.55 32719'
    Nov 11 23:47:40.205: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.184.98.55 32719\nConnection to 10.184.98.55 32719 port [tcp/*] succeeded!\n"
    Nov 11 23:47:40.205: INFO: stdout: "nodeport-test-xwzdd"
    Nov 11 23:47:40.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4044 exec execpodvllqq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.241.148.113 32719'
    Nov 11 23:47:40.676: INFO: stderr: "+ nc -v -t -w 2 10.241.148.113 32719\n+ echo hostName\nConnection to 10.241.148.113 32719 port [tcp/*] succeeded!\n"
    Nov 11 23:47:40.676: INFO: stdout: "nodeport-test-xwzdd"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:47:40.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4044" for this suite. 11/11/22 23:47:40.703
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:40.728
Nov 11 23:47:40.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:47:40.731
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:40.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:40.799
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-9841/configmap-test-ea3620c5-b804-4a5f-a4a0-8a5cc59ddafb 11/11/22 23:47:40.818
STEP: Creating a pod to test consume configMaps 11/11/22 23:47:40.838
Nov 11 23:47:40.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db" in namespace "configmap-9841" to be "Succeeded or Failed"
Nov 11 23:47:40.907: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676312ms
Nov 11 23:47:42.930: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053660977s
Nov 11 23:47:44.926: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050018075s
Nov 11 23:47:46.929: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052566681s
STEP: Saw pod success 11/11/22 23:47:46.929
Nov 11 23:47:46.932: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db" satisfied condition "Succeeded or Failed"
Nov 11 23:47:46.954: INFO: Trying to get logs from node 10.241.148.26 pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db container env-test: <nil>
STEP: delete the pod 11/11/22 23:47:47.113
Nov 11 23:47:47.168: INFO: Waiting for pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db to disappear
Nov 11 23:47:47.189: INFO: Pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:47:47.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9841" for this suite. 11/11/22 23:47:47.214
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":129,"skipped":2474,"failed":0}
------------------------------
• [SLOW TEST] [6.510 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:40.728
    Nov 11 23:47:40.729: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:47:40.731
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:40.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:40.799
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-9841/configmap-test-ea3620c5-b804-4a5f-a4a0-8a5cc59ddafb 11/11/22 23:47:40.818
    STEP: Creating a pod to test consume configMaps 11/11/22 23:47:40.838
    Nov 11 23:47:40.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db" in namespace "configmap-9841" to be "Succeeded or Failed"
    Nov 11 23:47:40.907: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676312ms
    Nov 11 23:47:42.930: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053660977s
    Nov 11 23:47:44.926: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050018075s
    Nov 11 23:47:46.929: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052566681s
    STEP: Saw pod success 11/11/22 23:47:46.929
    Nov 11 23:47:46.932: INFO: Pod "pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db" satisfied condition "Succeeded or Failed"
    Nov 11 23:47:46.954: INFO: Trying to get logs from node 10.241.148.26 pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db container env-test: <nil>
    STEP: delete the pod 11/11/22 23:47:47.113
    Nov 11 23:47:47.168: INFO: Waiting for pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db to disappear
    Nov 11 23:47:47.189: INFO: Pod pod-configmaps-23e78029-7872-4178-af0d-83657d3b09db no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:47:47.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9841" for this suite. 11/11/22 23:47:47.214
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:47:47.239
Nov 11 23:47:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/11/22 23:47:47.241
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:47.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:47.319
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 11 23:48:47.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8728" for this suite. 11/11/22 23:48:47.442
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":130,"skipped":2475,"failed":0}
------------------------------
• [SLOW TEST] [60.229 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:47:47.239
    Nov 11 23:47:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/11/22 23:47:47.241
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:47:47.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:47:47.319
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 11 23:48:47.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8728" for this suite. 11/11/22 23:48:47.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:48:47.469
Nov 11 23:48:47.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:48:47.471
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:48:47.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:48:47.566
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9034 11/11/22 23:48:47.581
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 11/11/22 23:48:47.601
STEP: Creating stateful set ss in namespace statefulset-9034 11/11/22 23:48:47.623
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9034 11/11/22 23:48:47.646
Nov 11 23:48:47.665: INFO: Found 0 stateful pods, waiting for 1
Nov 11 23:48:57.687: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/11/22 23:48:57.687
Nov 11 23:48:57.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:48:58.142: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:48:58.142: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:48:58.142: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:48:58.163: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 11 23:49:08.202: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:49:08.202: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:49:08.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999758s
Nov 11 23:49:09.325: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.960676505s
Nov 11 23:49:10.349: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.938880181s
Nov 11 23:49:11.368: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.915810959s
Nov 11 23:49:12.390: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.895847727s
Nov 11 23:49:13.413: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.87332303s
Nov 11 23:49:14.433: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.850826427s
Nov 11 23:49:15.462: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.831413037s
Nov 11 23:49:16.481: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.80289856s
Nov 11 23:49:17.502: INFO: Verifying statefulset ss doesn't scale past 1 for another 783.064431ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9034 11/11/22 23:49:18.503
Nov 11 23:49:18.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:49:18.977: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:49:18.977: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:49:18.977: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:49:18.998: INFO: Found 1 stateful pods, waiting for 3
Nov 11 23:49:29.020: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:49:29.020: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 11 23:49:29.020: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 11/11/22 23:49:29.02
STEP: Scale down will halt with unhealthy stateful pod 11/11/22 23:49:29.021
Nov 11 23:49:29.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:49:29.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:49:29.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:49:29.499: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:49:29.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:49:29.897: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:49:29.897: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:49:29.897: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:49:29.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 11 23:49:30.267: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 11 23:49:30.267: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 11 23:49:30.267: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 11 23:49:30.268: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:49:30.286: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 11 23:49:40.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:49:40.327: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:49:40.327: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 11 23:49:40.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999996953s
Nov 11 23:49:41.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.973927183s
Nov 11 23:49:42.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.952914773s
Nov 11 23:49:43.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.929953681s
Nov 11 23:49:44.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.908393686s
Nov 11 23:49:45.504: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.88775828s
Nov 11 23:49:46.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.864222318s
Nov 11 23:49:47.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.826363606s
Nov 11 23:49:48.584: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.805342663s
Nov 11 23:49:49.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 784.160292ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9034 11/11/22 23:49:50.605
Nov 11 23:49:50.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:49:51.024: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:49:51.024: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:49:51.024: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:49:51.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:49:51.513: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:49:51.513: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:49:51.513: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:49:51.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 11 23:49:51.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 11 23:49:51.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 11 23:49:51.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 11 23:49:51.932: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 11/11/22 23:50:02.022
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 11 23:50:02.022: INFO: Deleting all statefulset in ns statefulset-9034
Nov 11 23:50:02.047: INFO: Scaling statefulset ss to 0
Nov 11 23:50:02.129: INFO: Waiting for statefulset status.replicas updated to 0
Nov 11 23:50:02.148: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 11 23:50:02.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9034" for this suite. 11/11/22 23:50:02.273
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":131,"skipped":2486,"failed":0}
------------------------------
• [SLOW TEST] [74.831 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:48:47.469
    Nov 11 23:48:47.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:48:47.471
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:48:47.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:48:47.566
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9034 11/11/22 23:48:47.581
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 11/11/22 23:48:47.601
    STEP: Creating stateful set ss in namespace statefulset-9034 11/11/22 23:48:47.623
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9034 11/11/22 23:48:47.646
    Nov 11 23:48:47.665: INFO: Found 0 stateful pods, waiting for 1
    Nov 11 23:48:57.687: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/11/22 23:48:57.687
    Nov 11 23:48:57.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:48:58.142: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:48:58.142: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:48:58.142: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:48:58.163: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 11 23:49:08.202: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:49:08.202: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:49:08.304: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999758s
    Nov 11 23:49:09.325: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.960676505s
    Nov 11 23:49:10.349: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.938880181s
    Nov 11 23:49:11.368: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.915810959s
    Nov 11 23:49:12.390: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.895847727s
    Nov 11 23:49:13.413: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.87332303s
    Nov 11 23:49:14.433: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.850826427s
    Nov 11 23:49:15.462: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.831413037s
    Nov 11 23:49:16.481: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.80289856s
    Nov 11 23:49:17.502: INFO: Verifying statefulset ss doesn't scale past 1 for another 783.064431ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9034 11/11/22 23:49:18.503
    Nov 11 23:49:18.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:49:18.977: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:49:18.977: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:49:18.977: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:49:18.998: INFO: Found 1 stateful pods, waiting for 3
    Nov 11 23:49:29.020: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:49:29.020: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 11 23:49:29.020: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 11/11/22 23:49:29.02
    STEP: Scale down will halt with unhealthy stateful pod 11/11/22 23:49:29.021
    Nov 11 23:49:29.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:49:29.498: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:49:29.498: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:49:29.499: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:49:29.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:49:29.897: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:49:29.897: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:49:29.897: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:49:29.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 11 23:49:30.267: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 11 23:49:30.267: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 11 23:49:30.267: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 11 23:49:30.268: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:49:30.286: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Nov 11 23:49:40.327: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:49:40.327: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:49:40.327: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 11 23:49:40.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999996953s
    Nov 11 23:49:41.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.973927183s
    Nov 11 23:49:42.438: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.952914773s
    Nov 11 23:49:43.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.929953681s
    Nov 11 23:49:44.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.908393686s
    Nov 11 23:49:45.504: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.88775828s
    Nov 11 23:49:46.542: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.864222318s
    Nov 11 23:49:47.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.826363606s
    Nov 11 23:49:48.584: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.805342663s
    Nov 11 23:49:49.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 784.160292ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9034 11/11/22 23:49:50.605
    Nov 11 23:49:50.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:49:51.024: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:49:51.024: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:49:51.024: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:49:51.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:49:51.513: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:49:51.513: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:49:51.513: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:49:51.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=statefulset-9034 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 11 23:49:51.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 11 23:49:51.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 11 23:49:51.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 11 23:49:51.932: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 11/11/22 23:50:02.022
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 11 23:50:02.022: INFO: Deleting all statefulset in ns statefulset-9034
    Nov 11 23:50:02.047: INFO: Scaling statefulset ss to 0
    Nov 11 23:50:02.129: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 11 23:50:02.148: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 11 23:50:02.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9034" for this suite. 11/11/22 23:50:02.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:02.321
Nov 11 23:50:02.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:50:02.324
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:02.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:02.411
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 11/11/22 23:50:02.445
STEP: waiting for available Endpoint 11/11/22 23:50:02.465
STEP: listing all Endpoints 11/11/22 23:50:02.474
STEP: updating the Endpoint 11/11/22 23:50:02.491
STEP: fetching the Endpoint 11/11/22 23:50:02.522
STEP: patching the Endpoint 11/11/22 23:50:02.538
STEP: fetching the Endpoint 11/11/22 23:50:02.574
STEP: deleting the Endpoint by Collection 11/11/22 23:50:02.596
STEP: waiting for Endpoint deletion 11/11/22 23:50:02.626
STEP: fetching the Endpoint 11/11/22 23:50:02.635
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:50:02.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3116" for this suite. 11/11/22 23:50:02.675
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":132,"skipped":2552,"failed":0}
------------------------------
• [0.380 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:02.321
    Nov 11 23:50:02.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:50:02.324
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:02.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:02.411
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 11/11/22 23:50:02.445
    STEP: waiting for available Endpoint 11/11/22 23:50:02.465
    STEP: listing all Endpoints 11/11/22 23:50:02.474
    STEP: updating the Endpoint 11/11/22 23:50:02.491
    STEP: fetching the Endpoint 11/11/22 23:50:02.522
    STEP: patching the Endpoint 11/11/22 23:50:02.538
    STEP: fetching the Endpoint 11/11/22 23:50:02.574
    STEP: deleting the Endpoint by Collection 11/11/22 23:50:02.596
    STEP: waiting for Endpoint deletion 11/11/22 23:50:02.626
    STEP: fetching the Endpoint 11/11/22 23:50:02.635
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:50:02.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3116" for this suite. 11/11/22 23:50:02.675
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:02.709
Nov 11 23:50:02.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubelet-test 11/11/22 23:50:02.711
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:02.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:02.802
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 11 23:50:02.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3298" for this suite. 11/11/22 23:50:02.917
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":133,"skipped":2566,"failed":0}
------------------------------
• [0.233 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:02.709
    Nov 11 23:50:02.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubelet-test 11/11/22 23:50:02.711
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:02.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:02.802
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 11 23:50:02.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3298" for this suite. 11/11/22 23:50:02.917
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:02.944
Nov 11 23:50:02.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename init-container 11/11/22 23:50:02.946
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:03.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:03.04
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 11/11/22 23:50:03.058
Nov 11 23:50:03.059: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 11 23:50:08.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1856" for this suite. 11/11/22 23:50:08.379
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":134,"skipped":2567,"failed":0}
------------------------------
• [SLOW TEST] [5.462 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:02.944
    Nov 11 23:50:02.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename init-container 11/11/22 23:50:02.946
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:03.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:03.04
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 11/11/22 23:50:03.058
    Nov 11 23:50:03.059: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 11 23:50:08.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1856" for this suite. 11/11/22 23:50:08.379
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:08.414
Nov 11 23:50:08.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/11/22 23:50:08.419
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:08.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:08.52
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 11/11/22 23:50:08.537
Nov 11 23:50:08.575: INFO: Waiting up to 5m0s for pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9" in namespace "downward-api-9373" to be "Succeeded or Failed"
Nov 11 23:50:08.595: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.956976ms
Nov 11 23:50:10.614: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03864906s
Nov 11 23:50:12.617: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041538328s
STEP: Saw pod success 11/11/22 23:50:12.617
Nov 11 23:50:12.617: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9" satisfied condition "Succeeded or Failed"
Nov 11 23:50:12.636: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 container dapi-container: <nil>
STEP: delete the pod 11/11/22 23:50:12.752
Nov 11 23:50:12.817: INFO: Waiting for pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 to disappear
Nov 11 23:50:12.852: INFO: Pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 11 23:50:12.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9373" for this suite. 11/11/22 23:50:12.876
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":135,"skipped":2592,"failed":0}
------------------------------
• [4.491 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:08.414
    Nov 11 23:50:08.414: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/11/22 23:50:08.419
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:08.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:08.52
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 11/11/22 23:50:08.537
    Nov 11 23:50:08.575: INFO: Waiting up to 5m0s for pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9" in namespace "downward-api-9373" to be "Succeeded or Failed"
    Nov 11 23:50:08.595: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.956976ms
    Nov 11 23:50:10.614: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03864906s
    Nov 11 23:50:12.617: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041538328s
    STEP: Saw pod success 11/11/22 23:50:12.617
    Nov 11 23:50:12.617: INFO: Pod "downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9" satisfied condition "Succeeded or Failed"
    Nov 11 23:50:12.636: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 container dapi-container: <nil>
    STEP: delete the pod 11/11/22 23:50:12.752
    Nov 11 23:50:12.817: INFO: Waiting for pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 to disappear
    Nov 11 23:50:12.852: INFO: Pod downward-api-38d203c3-4406-40c0-8542-0726d9c7cdd9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 11 23:50:12.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9373" for this suite. 11/11/22 23:50:12.876
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:12.907
Nov 11 23:50:12.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/11/22 23:50:12.91
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:12.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:12.981
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Nov 11 23:50:13.084: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 11/11/22 23:50:13.107
Nov 11 23:50:13.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:13.130: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 11/11/22 23:50:13.13
Nov 11 23:50:13.223: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:13.223: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:14.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:14.244: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:15.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:15.242: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:16.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 11 23:50:16.242: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 11/11/22 23:50:16.259
Nov 11 23:50:16.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 11 23:50:16.336: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Nov 11 23:50:17.359: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:17.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/11/22 23:50:17.359
Nov 11 23:50:17.409: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:17.409: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:18.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:18.428: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:19.430: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:19.430: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:20.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:20.429: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:50:21.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 11 23:50:21.430: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:50:21.459
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5295, will wait for the garbage collector to delete the pods 11/11/22 23:50:21.459
Nov 11 23:50:21.550: INFO: Deleting DaemonSet.extensions daemon-set took: 24.985578ms
Nov 11 23:50:21.651: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.229742ms
Nov 11 23:50:24.573: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:50:24.573: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 11 23:50:24.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30528"},"items":null}

Nov 11 23:50:24.608: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30529"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:50:24.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5295" for this suite. 11/11/22 23:50:24.806
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":136,"skipped":2594,"failed":0}
------------------------------
• [SLOW TEST] [11.956 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:12.907
    Nov 11 23:50:12.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/11/22 23:50:12.91
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:12.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:12.981
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Nov 11 23:50:13.084: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 11/11/22 23:50:13.107
    Nov 11 23:50:13.130: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:13.130: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 11/11/22 23:50:13.13
    Nov 11 23:50:13.223: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:13.223: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:14.244: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:14.244: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:15.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:15.242: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:16.242: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 11 23:50:16.242: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 11/11/22 23:50:16.259
    Nov 11 23:50:16.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 11 23:50:16.336: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Nov 11 23:50:17.359: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:17.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/11/22 23:50:17.359
    Nov 11 23:50:17.409: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:17.409: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:18.428: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:18.428: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:19.430: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:19.430: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:20.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:20.429: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:50:21.429: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 11 23:50:21.430: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:50:21.459
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5295, will wait for the garbage collector to delete the pods 11/11/22 23:50:21.459
    Nov 11 23:50:21.550: INFO: Deleting DaemonSet.extensions daemon-set took: 24.985578ms
    Nov 11 23:50:21.651: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.229742ms
    Nov 11 23:50:24.573: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:50:24.573: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 11 23:50:24.588: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30528"},"items":null}

    Nov 11 23:50:24.608: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30529"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:50:24.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5295" for this suite. 11/11/22 23:50:24.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:24.865
Nov 11 23:50:24.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:50:24.868
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:24.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:24.942
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 11/11/22 23:50:24.958
Nov 11 23:50:24.995: INFO: Waiting up to 5m0s for pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b" in namespace "projected-746" to be "running and ready"
Nov 11 23:50:25.014: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.25074ms
Nov 11 23:50:25.014: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:50:27.034: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038455277s
Nov 11 23:50:27.034: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:50:29.036: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Running", Reason="", readiness=true. Elapsed: 4.040292019s
Nov 11 23:50:29.036: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Running (Ready = true)
Nov 11 23:50:29.036: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b" satisfied condition "running and ready"
Nov 11 23:50:29.676: INFO: Successfully updated pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 11 23:50:31.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-746" for this suite. 11/11/22 23:50:31.785
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":137,"skipped":2610,"failed":0}
------------------------------
• [SLOW TEST] [6.944 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:24.865
    Nov 11 23:50:24.866: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:50:24.868
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:24.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:24.942
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 11/11/22 23:50:24.958
    Nov 11 23:50:24.995: INFO: Waiting up to 5m0s for pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b" in namespace "projected-746" to be "running and ready"
    Nov 11 23:50:25.014: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.25074ms
    Nov 11 23:50:25.014: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:50:27.034: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038455277s
    Nov 11 23:50:27.034: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:50:29.036: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b": Phase="Running", Reason="", readiness=true. Elapsed: 4.040292019s
    Nov 11 23:50:29.036: INFO: The phase of Pod labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b is Running (Ready = true)
    Nov 11 23:50:29.036: INFO: Pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b" satisfied condition "running and ready"
    Nov 11 23:50:29.676: INFO: Successfully updated pod "labelsupdate2a0543a5-72c6-477a-80fc-9f85d301468b"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 11 23:50:31.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-746" for this suite. 11/11/22 23:50:31.785
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:31.811
Nov 11 23:50:31.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/11/22 23:50:31.812
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:31.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:31.882
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 11/11/22 23:50:31.898
Nov 11 23:50:31.944: INFO: Waiting up to 5m0s for pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf" in namespace "emptydir-3194" to be "Succeeded or Failed"
Nov 11 23:50:31.963: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.546017ms
Nov 11 23:50:33.983: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038492518s
Nov 11 23:50:35.981: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036972537s
Nov 11 23:50:37.983: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039254459s
STEP: Saw pod success 11/11/22 23:50:37.984
Nov 11 23:50:37.984: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf" satisfied condition "Succeeded or Failed"
Nov 11 23:50:38.039: INFO: Trying to get logs from node 10.184.98.55 pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf container test-container: <nil>
STEP: delete the pod 11/11/22 23:50:38.105
Nov 11 23:50:38.169: INFO: Waiting for pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf to disappear
Nov 11 23:50:38.192: INFO: Pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 11 23:50:38.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3194" for this suite. 11/11/22 23:50:38.215
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2614,"failed":0}
------------------------------
• [SLOW TEST] [6.429 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:31.811
    Nov 11 23:50:31.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/11/22 23:50:31.812
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:31.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:31.882
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/11/22 23:50:31.898
    Nov 11 23:50:31.944: INFO: Waiting up to 5m0s for pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf" in namespace "emptydir-3194" to be "Succeeded or Failed"
    Nov 11 23:50:31.963: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.546017ms
    Nov 11 23:50:33.983: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038492518s
    Nov 11 23:50:35.981: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036972537s
    Nov 11 23:50:37.983: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039254459s
    STEP: Saw pod success 11/11/22 23:50:37.984
    Nov 11 23:50:37.984: INFO: Pod "pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf" satisfied condition "Succeeded or Failed"
    Nov 11 23:50:38.039: INFO: Trying to get logs from node 10.184.98.55 pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf container test-container: <nil>
    STEP: delete the pod 11/11/22 23:50:38.105
    Nov 11 23:50:38.169: INFO: Waiting for pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf to disappear
    Nov 11 23:50:38.192: INFO: Pod pod-6f85de72-43e5-4026-a7e2-3fbcfc304eaf no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 11 23:50:38.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3194" for this suite. 11/11/22 23:50:38.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:38.245
Nov 11 23:50:38.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/11/22 23:50:38.249
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:38.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:38.373
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 11/11/22 23:50:38.392
STEP: Ensuring job reaches completions 11/11/22 23:50:38.414
STEP: Ensuring pods with index for job exist 11/11/22 23:50:48.433
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 11 23:50:48.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4476" for this suite. 11/11/22 23:50:48.477
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":139,"skipped":2657,"failed":0}
------------------------------
• [SLOW TEST] [10.256 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:38.245
    Nov 11 23:50:38.245: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/11/22 23:50:38.249
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:38.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:38.373
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 11/11/22 23:50:38.392
    STEP: Ensuring job reaches completions 11/11/22 23:50:38.414
    STEP: Ensuring pods with index for job exist 11/11/22 23:50:48.433
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 11 23:50:48.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4476" for this suite. 11/11/22 23:50:48.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:50:48.508
Nov 11 23:50:48.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:50:48.51
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:48.557
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:48.573
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/11/22 23:50:48.591
Nov 11 23:50:48.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:50:53.480: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:51:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8922" for this suite. 11/11/22 23:51:19.069
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":140,"skipped":2668,"failed":0}
------------------------------
• [SLOW TEST] [30.588 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:50:48.508
    Nov 11 23:50:48.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:50:48.51
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:50:48.557
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:50:48.573
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/11/22 23:50:48.591
    Nov 11 23:50:48.593: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:50:53.480: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:51:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8922" for this suite. 11/11/22 23:51:19.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:51:19.1
Nov 11 23:51:19.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/11/22 23:51:19.101
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:19.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:19.171
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Nov 11 23:51:19.226: INFO: Waiting up to 5m0s for pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42" in namespace "container-probe-1558" to be "running and ready"
Nov 11 23:51:19.245: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Pending", Reason="", readiness=false. Elapsed: 18.209936ms
Nov 11 23:51:19.245: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:51:21.269: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042191885s
Nov 11 23:51:21.269: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Pending, waiting for it to be Running (with Ready = true)
Nov 11 23:51:23.264: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 4.03704138s
Nov 11 23:51:23.264: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:25.263: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 6.03699719s
Nov 11 23:51:25.264: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:27.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 8.039126735s
Nov 11 23:51:27.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:29.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 10.038712114s
Nov 11 23:51:29.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:31.280: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 12.053924536s
Nov 11 23:51:31.281: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:33.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 14.038641441s
Nov 11 23:51:33.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:35.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 16.038016817s
Nov 11 23:51:35.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:37.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 18.03901191s
Nov 11 23:51:37.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:39.264: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 20.037867714s
Nov 11 23:51:39.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
Nov 11 23:51:41.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=true. Elapsed: 22.039197388s
Nov 11 23:51:41.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = true)
Nov 11 23:51:41.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42" satisfied condition "running and ready"
Nov 11 23:51:41.286: INFO: Container started at 2022-11-11 23:51:20 +0000 UTC, pod became ready at 2022-11-11 23:51:39 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 11 23:51:41.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1558" for this suite. 11/11/22 23:51:41.309
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":141,"skipped":2691,"failed":0}
------------------------------
• [SLOW TEST] [22.234 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:51:19.1
    Nov 11 23:51:19.100: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/11/22 23:51:19.101
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:19.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:19.171
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Nov 11 23:51:19.226: INFO: Waiting up to 5m0s for pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42" in namespace "container-probe-1558" to be "running and ready"
    Nov 11 23:51:19.245: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Pending", Reason="", readiness=false. Elapsed: 18.209936ms
    Nov 11 23:51:19.245: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:51:21.269: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042191885s
    Nov 11 23:51:21.269: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Pending, waiting for it to be Running (with Ready = true)
    Nov 11 23:51:23.264: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 4.03704138s
    Nov 11 23:51:23.264: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:25.263: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 6.03699719s
    Nov 11 23:51:25.264: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:27.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 8.039126735s
    Nov 11 23:51:27.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:29.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 10.038712114s
    Nov 11 23:51:29.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:31.280: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 12.053924536s
    Nov 11 23:51:31.281: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:33.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 14.038641441s
    Nov 11 23:51:33.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:35.265: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 16.038016817s
    Nov 11 23:51:35.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:37.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 18.03901191s
    Nov 11 23:51:37.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:39.264: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=false. Elapsed: 20.037867714s
    Nov 11 23:51:39.265: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = false)
    Nov 11 23:51:41.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42": Phase="Running", Reason="", readiness=true. Elapsed: 22.039197388s
    Nov 11 23:51:41.266: INFO: The phase of Pod test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42 is Running (Ready = true)
    Nov 11 23:51:41.266: INFO: Pod "test-webserver-d8b0b187-9989-47a2-a762-50733bb95b42" satisfied condition "running and ready"
    Nov 11 23:51:41.286: INFO: Container started at 2022-11-11 23:51:20 +0000 UTC, pod became ready at 2022-11-11 23:51:39 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 11 23:51:41.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1558" for this suite. 11/11/22 23:51:41.309
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:51:41.337
Nov 11 23:51:41.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:51:41.339
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:41.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:41.411
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-5ee66e9c-50d5-4715-90a5-2cb48e55c57f 11/11/22 23:51:41.43
STEP: Creating a pod to test consume configMaps 11/11/22 23:51:41.445
Nov 11 23:51:41.483: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da" in namespace "configmap-9704" to be "Succeeded or Failed"
Nov 11 23:51:41.501: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 17.465561ms
Nov 11 23:51:43.521: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037960535s
Nov 11 23:51:45.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036353049s
Nov 11 23:51:47.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036949696s
STEP: Saw pod success 11/11/22 23:51:47.52
Nov 11 23:51:47.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da" satisfied condition "Succeeded or Failed"
Nov 11 23:51:47.540: INFO: Trying to get logs from node 10.241.148.26 pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:51:47.643
Nov 11 23:51:47.706: INFO: Waiting for pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da to disappear
Nov 11 23:51:47.723: INFO: Pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:51:47.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9704" for this suite. 11/11/22 23:51:47.74
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":142,"skipped":2699,"failed":0}
------------------------------
• [SLOW TEST] [6.428 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:51:41.337
    Nov 11 23:51:41.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:51:41.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:41.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:41.411
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-5ee66e9c-50d5-4715-90a5-2cb48e55c57f 11/11/22 23:51:41.43
    STEP: Creating a pod to test consume configMaps 11/11/22 23:51:41.445
    Nov 11 23:51:41.483: INFO: Waiting up to 5m0s for pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da" in namespace "configmap-9704" to be "Succeeded or Failed"
    Nov 11 23:51:41.501: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 17.465561ms
    Nov 11 23:51:43.521: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037960535s
    Nov 11 23:51:45.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036353049s
    Nov 11 23:51:47.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036949696s
    STEP: Saw pod success 11/11/22 23:51:47.52
    Nov 11 23:51:47.520: INFO: Pod "pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da" satisfied condition "Succeeded or Failed"
    Nov 11 23:51:47.540: INFO: Trying to get logs from node 10.241.148.26 pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:51:47.643
    Nov 11 23:51:47.706: INFO: Waiting for pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da to disappear
    Nov 11 23:51:47.723: INFO: Pod pod-configmaps-7ab697d9-a9fd-4308-b0de-469beef997da no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:51:47.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9704" for this suite. 11/11/22 23:51:47.74
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:51:47.768
Nov 11 23:51:47.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:51:47.77
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:47.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:47.851
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  11/11/22 23:51:47.865
Nov 11 23:51:47.903: INFO: Waiting up to 5m0s for pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26" in namespace "svcaccounts-3763" to be "Succeeded or Failed"
Nov 11 23:51:47.969: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 65.954645ms
Nov 11 23:51:49.991: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088283582s
Nov 11 23:51:51.991: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.088414169s
Nov 11 23:51:53.988: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085038033s
STEP: Saw pod success 11/11/22 23:51:53.988
Nov 11 23:51:53.989: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26" satisfied condition "Succeeded or Failed"
Nov 11 23:51:54.008: INFO: Trying to get logs from node 10.241.148.26 pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:51:54.05
Nov 11 23:51:54.127: INFO: Waiting for pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 to disappear
Nov 11 23:51:54.146: INFO: Pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:51:54.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3763" for this suite. 11/11/22 23:51:54.164
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":143,"skipped":2704,"failed":0}
------------------------------
• [SLOW TEST] [6.420 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:51:47.768
    Nov 11 23:51:47.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:51:47.77
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:47.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:47.851
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  11/11/22 23:51:47.865
    Nov 11 23:51:47.903: INFO: Waiting up to 5m0s for pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26" in namespace "svcaccounts-3763" to be "Succeeded or Failed"
    Nov 11 23:51:47.969: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 65.954645ms
    Nov 11 23:51:49.991: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088283582s
    Nov 11 23:51:51.991: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.088414169s
    Nov 11 23:51:53.988: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085038033s
    STEP: Saw pod success 11/11/22 23:51:53.988
    Nov 11 23:51:53.989: INFO: Pod "test-pod-38d1b04a-9537-42d0-add6-d96046285e26" satisfied condition "Succeeded or Failed"
    Nov 11 23:51:54.008: INFO: Trying to get logs from node 10.241.148.26 pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:51:54.05
    Nov 11 23:51:54.127: INFO: Waiting for pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 to disappear
    Nov 11 23:51:54.146: INFO: Pod test-pod-38d1b04a-9537-42d0-add6-d96046285e26 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:51:54.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3763" for this suite. 11/11/22 23:51:54.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:51:54.193
Nov 11 23:51:54.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:51:54.195
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:54.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:54.265
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-ae0b1cb6-729c-4476-8534-105fec841523 11/11/22 23:51:54.283
STEP: Creating a pod to test consume configMaps 11/11/22 23:51:54.302
Nov 11 23:51:54.340: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1" in namespace "projected-6712" to be "Succeeded or Failed"
Nov 11 23:51:54.359: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.171208ms
Nov 11 23:51:56.381: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03996581s
Nov 11 23:51:58.380: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039562875s
Nov 11 23:52:00.379: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038524972s
STEP: Saw pod success 11/11/22 23:52:00.379
Nov 11 23:52:00.380: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1" satisfied condition "Succeeded or Failed"
Nov 11 23:52:00.400: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 container projected-configmap-volume-test: <nil>
STEP: delete the pod 11/11/22 23:52:00.438
Nov 11 23:52:00.496: INFO: Waiting for pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 to disappear
Nov 11 23:52:00.526: INFO: Pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 11 23:52:00.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6712" for this suite. 11/11/22 23:52:00.547
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":144,"skipped":2747,"failed":0}
------------------------------
• [SLOW TEST] [6.381 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:51:54.193
    Nov 11 23:51:54.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:51:54.195
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:51:54.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:51:54.265
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-ae0b1cb6-729c-4476-8534-105fec841523 11/11/22 23:51:54.283
    STEP: Creating a pod to test consume configMaps 11/11/22 23:51:54.302
    Nov 11 23:51:54.340: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1" in namespace "projected-6712" to be "Succeeded or Failed"
    Nov 11 23:51:54.359: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.171208ms
    Nov 11 23:51:56.381: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03996581s
    Nov 11 23:51:58.380: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039562875s
    Nov 11 23:52:00.379: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038524972s
    STEP: Saw pod success 11/11/22 23:52:00.379
    Nov 11 23:52:00.380: INFO: Pod "pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1" satisfied condition "Succeeded or Failed"
    Nov 11 23:52:00.400: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:52:00.438
    Nov 11 23:52:00.496: INFO: Waiting for pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 to disappear
    Nov 11 23:52:00.526: INFO: Pod pod-projected-configmaps-ef46212d-ae9c-4115-acc2-c28ae7fc48a1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 11 23:52:00.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6712" for this suite. 11/11/22 23:52:00.547
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:00.577
Nov 11 23:52:00.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/11/22 23:52:00.579
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:00.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:00.647
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 11/11/22 23:52:00.667
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 11/11/22 23:52:00.685
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 11/11/22 23:52:00.686
STEP: creating a pod to probe DNS 11/11/22 23:52:00.687
STEP: submitting the pod to kubernetes 11/11/22 23:52:00.687
Nov 11 23:52:00.728: INFO: Waiting up to 15m0s for pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac" in namespace "dns-8714" to be "running"
Nov 11 23:52:00.747: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Pending", Reason="", readiness=false. Elapsed: 18.88661ms
Nov 11 23:52:02.770: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041510634s
Nov 11 23:52:04.764: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Running", Reason="", readiness=true. Elapsed: 4.035923454s
Nov 11 23:52:04.764: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac" satisfied condition "running"
STEP: retrieving the pod 11/11/22 23:52:04.764
STEP: looking for the results for each expected name from probers 11/11/22 23:52:04.793
Nov 11 23:52:04.989: INFO: DNS probes using dns-8714/dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac succeeded

STEP: deleting the pod 11/11/22 23:52:04.989
STEP: deleting the test headless service 11/11/22 23:52:05.069
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 11 23:52:05.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8714" for this suite. 11/11/22 23:52:05.125
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":145,"skipped":2751,"failed":0}
------------------------------
• [4.572 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:00.577
    Nov 11 23:52:00.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/11/22 23:52:00.579
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:00.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:00.647
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 11/11/22 23:52:00.667
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     11/11/22 23:52:00.685
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8714.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     11/11/22 23:52:00.686
    STEP: creating a pod to probe DNS 11/11/22 23:52:00.687
    STEP: submitting the pod to kubernetes 11/11/22 23:52:00.687
    Nov 11 23:52:00.728: INFO: Waiting up to 15m0s for pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac" in namespace "dns-8714" to be "running"
    Nov 11 23:52:00.747: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Pending", Reason="", readiness=false. Elapsed: 18.88661ms
    Nov 11 23:52:02.770: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041510634s
    Nov 11 23:52:04.764: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac": Phase="Running", Reason="", readiness=true. Elapsed: 4.035923454s
    Nov 11 23:52:04.764: INFO: Pod "dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac" satisfied condition "running"
    STEP: retrieving the pod 11/11/22 23:52:04.764
    STEP: looking for the results for each expected name from probers 11/11/22 23:52:04.793
    Nov 11 23:52:04.989: INFO: DNS probes using dns-8714/dns-test-a5f24d53-b559-4e41-ad02-fdf9d4e6d0ac succeeded

    STEP: deleting the pod 11/11/22 23:52:04.989
    STEP: deleting the test headless service 11/11/22 23:52:05.069
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 11 23:52:05.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8714" for this suite. 11/11/22 23:52:05.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:05.153
Nov 11 23:52:05.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:52:05.153
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.224
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:52:05.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2071" for this suite. 11/11/22 23:52:05.415
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":146,"skipped":2770,"failed":0}
------------------------------
• [0.286 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:05.153
    Nov 11 23:52:05.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:52:05.153
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.224
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:52:05.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2071" for this suite. 11/11/22 23:52:05.415
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:05.44
Nov 11 23:52:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:52:05.441
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.511
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 11/11/22 23:52:05.53
Nov 11 23:52:05.531: INFO: Creating e2e-svc-a-vn9nw
Nov 11 23:52:05.570: INFO: Creating e2e-svc-b-jgsmc
Nov 11 23:52:05.608: INFO: Creating e2e-svc-c-x8fdc
STEP: deleting service collection 11/11/22 23:52:05.665
Nov 11 23:52:05.781: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:52:05.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6131" for this suite. 11/11/22 23:52:05.8
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":147,"skipped":2779,"failed":0}
------------------------------
• [0.409 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:05.44
    Nov 11 23:52:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:52:05.441
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.511
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 11/11/22 23:52:05.53
    Nov 11 23:52:05.531: INFO: Creating e2e-svc-a-vn9nw
    Nov 11 23:52:05.570: INFO: Creating e2e-svc-b-jgsmc
    Nov 11 23:52:05.608: INFO: Creating e2e-svc-c-x8fdc
    STEP: deleting service collection 11/11/22 23:52:05.665
    Nov 11 23:52:05.781: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:52:05.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6131" for this suite. 11/11/22 23:52:05.8
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:05.869
Nov 11 23:52:05.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-runtime 11/11/22 23:52:05.872
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.941
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 11/11/22 23:52:05.956
STEP: wait for the container to reach Succeeded 11/11/22 23:52:05.996
STEP: get the container status 11/11/22 23:52:11.123
STEP: the container should be terminated 11/11/22 23:52:11.142
STEP: the termination message should be set 11/11/22 23:52:11.142
Nov 11 23:52:11.142: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 11/11/22 23:52:11.142
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 11 23:52:11.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4287" for this suite. 11/11/22 23:52:11.26
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":148,"skipped":2797,"failed":0}
------------------------------
• [SLOW TEST] [5.445 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:05.869
    Nov 11 23:52:05.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-runtime 11/11/22 23:52:05.872
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:05.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:05.941
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 11/11/22 23:52:05.956
    STEP: wait for the container to reach Succeeded 11/11/22 23:52:05.996
    STEP: get the container status 11/11/22 23:52:11.123
    STEP: the container should be terminated 11/11/22 23:52:11.142
    STEP: the termination message should be set 11/11/22 23:52:11.142
    Nov 11 23:52:11.142: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 11/11/22 23:52:11.142
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 11 23:52:11.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4287" for this suite. 11/11/22 23:52:11.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:11.318
Nov 11 23:52:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename endpointslice 11/11/22 23:52:11.32
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:11.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:11.415
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 11/11/22 23:52:16.719
STEP: referencing matching pods with named port 11/11/22 23:52:21.752
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/11/22 23:52:26.827
STEP: recreating EndpointSlices after they've been deleted 11/11/22 23:52:31.937
Nov 11 23:52:32.143: INFO: EndpointSlice for Service endpointslice-7499/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 11 23:52:42.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7499" for this suite. 11/11/22 23:52:42.201
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":149,"skipped":2811,"failed":0}
------------------------------
• [SLOW TEST] [30.909 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:11.318
    Nov 11 23:52:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename endpointslice 11/11/22 23:52:11.32
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:11.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:11.415
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 11/11/22 23:52:16.719
    STEP: referencing matching pods with named port 11/11/22 23:52:21.752
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/11/22 23:52:26.827
    STEP: recreating EndpointSlices after they've been deleted 11/11/22 23:52:31.937
    Nov 11 23:52:32.143: INFO: EndpointSlice for Service endpointslice-7499/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 11 23:52:42.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7499" for this suite. 11/11/22 23:52:42.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:42.26
Nov 11 23:52:42.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:52:42.262
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:42.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:42.348
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-1da20dd1-959f-4ffb-bb5b-58b8b6769cb7 11/11/22 23:52:42.365
STEP: Creating a pod to test consume secrets 11/11/22 23:52:42.388
Nov 11 23:52:42.428: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f" in namespace "projected-9331" to be "Succeeded or Failed"
Nov 11 23:52:42.448: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.731356ms
Nov 11 23:52:44.483: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055304475s
Nov 11 23:52:46.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045045883s
Nov 11 23:52:48.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044830542s
STEP: Saw pod success 11/11/22 23:52:48.473
Nov 11 23:52:48.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f" satisfied condition "Succeeded or Failed"
Nov 11 23:52:48.493: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f container projected-secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:52:48.569
Nov 11 23:52:48.630: INFO: Waiting for pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f to disappear
Nov 11 23:52:48.647: INFO: Pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 11 23:52:48.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9331" for this suite. 11/11/22 23:52:48.666
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":150,"skipped":2918,"failed":0}
------------------------------
• [SLOW TEST] [6.430 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:42.26
    Nov 11 23:52:42.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:52:42.262
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:42.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:42.348
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-1da20dd1-959f-4ffb-bb5b-58b8b6769cb7 11/11/22 23:52:42.365
    STEP: Creating a pod to test consume secrets 11/11/22 23:52:42.388
    Nov 11 23:52:42.428: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f" in namespace "projected-9331" to be "Succeeded or Failed"
    Nov 11 23:52:42.448: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.731356ms
    Nov 11 23:52:44.483: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055304475s
    Nov 11 23:52:46.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045045883s
    Nov 11 23:52:48.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044830542s
    STEP: Saw pod success 11/11/22 23:52:48.473
    Nov 11 23:52:48.473: INFO: Pod "pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f" satisfied condition "Succeeded or Failed"
    Nov 11 23:52:48.493: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:52:48.569
    Nov 11 23:52:48.630: INFO: Waiting for pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f to disappear
    Nov 11 23:52:48.647: INFO: Pod pod-projected-secrets-5c4c1d88-046c-43df-a883-c6062430d94f no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 11 23:52:48.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9331" for this suite. 11/11/22 23:52:48.666
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:52:48.697
Nov 11 23:52:48.697: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename cronjob 11/11/22 23:52:48.7
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:48.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:48.76
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 11/11/22 23:52:48.775
STEP: Ensuring a job is scheduled 11/11/22 23:52:48.795
STEP: Ensuring exactly one is scheduled 11/11/22 23:53:00.812
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/11/22 23:53:00.826
STEP: Ensuring the job is replaced with a new one 11/11/22 23:53:00.848
STEP: Removing cronjob 11/11/22 23:54:00.871
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 11 23:54:00.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-362" for this suite. 11/11/22 23:54:00.915
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":151,"skipped":2923,"failed":0}
------------------------------
• [SLOW TEST] [72.256 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:52:48.697
    Nov 11 23:52:48.697: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename cronjob 11/11/22 23:52:48.7
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:52:48.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:52:48.76
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 11/11/22 23:52:48.775
    STEP: Ensuring a job is scheduled 11/11/22 23:52:48.795
    STEP: Ensuring exactly one is scheduled 11/11/22 23:53:00.812
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/11/22 23:53:00.826
    STEP: Ensuring the job is replaced with a new one 11/11/22 23:53:00.848
    STEP: Removing cronjob 11/11/22 23:54:00.871
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 11 23:54:00.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-362" for this suite. 11/11/22 23:54:00.915
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:00.953
Nov 11 23:54:00.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:54:00.955
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:01.023
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1338 11/11/22 23:54:01.042
STEP: changing the ExternalName service to type=ClusterIP 11/11/22 23:54:01.061
STEP: creating replication controller externalname-service in namespace services-1338 11/11/22 23:54:01.111
I1111 23:54:01.142292      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1338, replica count: 2
I1111 23:54:04.193733      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:54:04.193: INFO: Creating new exec pod
Nov 11 23:54:04.230: INFO: Waiting up to 5m0s for pod "execpodsh797" in namespace "services-1338" to be "running"
Nov 11 23:54:04.275: INFO: Pod "execpodsh797": Phase="Pending", Reason="", readiness=false. Elapsed: 44.675581ms
Nov 11 23:54:06.295: INFO: Pod "execpodsh797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064331541s
Nov 11 23:54:08.301: INFO: Pod "execpodsh797": Phase="Running", Reason="", readiness=true. Elapsed: 4.070107097s
Nov 11 23:54:08.301: INFO: Pod "execpodsh797" satisfied condition "running"
Nov 11 23:54:09.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-1338 exec execpodsh797 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 11 23:54:09.777: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 11 23:54:09.777: INFO: stdout: "externalname-service-sbj2f"
Nov 11 23:54:09.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-1338 exec execpodsh797 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.205.25 80'
Nov 11 23:54:10.330: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.205.25 80\nConnection to 172.21.205.25 80 port [tcp/http] succeeded!\n"
Nov 11 23:54:10.331: INFO: stdout: "externalname-service-sbj2f"
Nov 11 23:54:10.331: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:54:10.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1338" for this suite. 11/11/22 23:54:10.428
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":152,"skipped":2924,"failed":0}
------------------------------
• [SLOW TEST] [9.500 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:00.953
    Nov 11 23:54:00.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:54:00.955
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:01.023
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-1338 11/11/22 23:54:01.042
    STEP: changing the ExternalName service to type=ClusterIP 11/11/22 23:54:01.061
    STEP: creating replication controller externalname-service in namespace services-1338 11/11/22 23:54:01.111
    I1111 23:54:01.142292      21 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1338, replica count: 2
    I1111 23:54:04.193733      21 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:54:04.193: INFO: Creating new exec pod
    Nov 11 23:54:04.230: INFO: Waiting up to 5m0s for pod "execpodsh797" in namespace "services-1338" to be "running"
    Nov 11 23:54:04.275: INFO: Pod "execpodsh797": Phase="Pending", Reason="", readiness=false. Elapsed: 44.675581ms
    Nov 11 23:54:06.295: INFO: Pod "execpodsh797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064331541s
    Nov 11 23:54:08.301: INFO: Pod "execpodsh797": Phase="Running", Reason="", readiness=true. Elapsed: 4.070107097s
    Nov 11 23:54:08.301: INFO: Pod "execpodsh797" satisfied condition "running"
    Nov 11 23:54:09.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-1338 exec execpodsh797 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 11 23:54:09.777: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 11 23:54:09.777: INFO: stdout: "externalname-service-sbj2f"
    Nov 11 23:54:09.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-1338 exec execpodsh797 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.205.25 80'
    Nov 11 23:54:10.330: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.205.25 80\nConnection to 172.21.205.25 80 port [tcp/http] succeeded!\n"
    Nov 11 23:54:10.331: INFO: stdout: "externalname-service-sbj2f"
    Nov 11 23:54:10.331: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:54:10.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1338" for this suite. 11/11/22 23:54:10.428
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:10.454
Nov 11 23:54:10.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/11/22 23:54:10.458
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:10.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:10.534
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-7caf7de8-f0c8-41d2-ae7f-11bd06eeb886 11/11/22 23:54:10.55
STEP: Creating a pod to test consume secrets 11/11/22 23:54:10.58
Nov 11 23:54:10.621: INFO: Waiting up to 5m0s for pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4" in namespace "secrets-9488" to be "Succeeded or Failed"
Nov 11 23:54:10.641: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.380998ms
Nov 11 23:54:12.663: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041604308s
Nov 11 23:54:14.662: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04033111s
Nov 11 23:54:16.672: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051014062s
STEP: Saw pod success 11/11/22 23:54:16.672
Nov 11 23:54:16.673: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4" satisfied condition "Succeeded or Failed"
Nov 11 23:54:16.692: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 container secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:54:16.73
Nov 11 23:54:16.789: INFO: Waiting for pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 to disappear
Nov 11 23:54:16.807: INFO: Pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 11 23:54:16.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9488" for this suite. 11/11/22 23:54:16.834
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":153,"skipped":2928,"failed":0}
------------------------------
• [SLOW TEST] [6.406 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:10.454
    Nov 11 23:54:10.455: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/11/22 23:54:10.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:10.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:10.534
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-7caf7de8-f0c8-41d2-ae7f-11bd06eeb886 11/11/22 23:54:10.55
    STEP: Creating a pod to test consume secrets 11/11/22 23:54:10.58
    Nov 11 23:54:10.621: INFO: Waiting up to 5m0s for pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4" in namespace "secrets-9488" to be "Succeeded or Failed"
    Nov 11 23:54:10.641: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.380998ms
    Nov 11 23:54:12.663: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041604308s
    Nov 11 23:54:14.662: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04033111s
    Nov 11 23:54:16.672: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051014062s
    STEP: Saw pod success 11/11/22 23:54:16.672
    Nov 11 23:54:16.673: INFO: Pod "pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4" satisfied condition "Succeeded or Failed"
    Nov 11 23:54:16.692: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 container secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:54:16.73
    Nov 11 23:54:16.789: INFO: Waiting for pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 to disappear
    Nov 11 23:54:16.807: INFO: Pod pod-secrets-33c53e00-2718-4a1e-83db-5760fe38b5c4 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 11 23:54:16.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9488" for this suite. 11/11/22 23:54:16.834
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:16.867
Nov 11 23:54:16.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:54:16.871
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:16.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:16.948
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-786f1018-54df-4f55-8bc8-df877430673f 11/11/22 23:54:16.966
STEP: Creating a pod to test consume configMaps 11/11/22 23:54:16.987
Nov 11 23:54:17.049: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019" in namespace "projected-3661" to be "Succeeded or Failed"
Nov 11 23:54:17.070: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 20.478075ms
Nov 11 23:54:19.107: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057567133s
Nov 11 23:54:21.094: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044187277s
Nov 11 23:54:23.092: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042672915s
STEP: Saw pod success 11/11/22 23:54:23.092
Nov 11 23:54:23.093: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019" satisfied condition "Succeeded or Failed"
Nov 11 23:54:23.112: INFO: Trying to get logs from node 10.241.148.26 pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:54:23.23
Nov 11 23:54:23.306: INFO: Waiting for pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 to disappear
Nov 11 23:54:23.324: INFO: Pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 11 23:54:23.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3661" for this suite. 11/11/22 23:54:23.346
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":154,"skipped":2945,"failed":0}
------------------------------
• [SLOW TEST] [6.503 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:16.867
    Nov 11 23:54:16.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:54:16.871
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:16.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:16.948
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-786f1018-54df-4f55-8bc8-df877430673f 11/11/22 23:54:16.966
    STEP: Creating a pod to test consume configMaps 11/11/22 23:54:16.987
    Nov 11 23:54:17.049: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019" in namespace "projected-3661" to be "Succeeded or Failed"
    Nov 11 23:54:17.070: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 20.478075ms
    Nov 11 23:54:19.107: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057567133s
    Nov 11 23:54:21.094: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044187277s
    Nov 11 23:54:23.092: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042672915s
    STEP: Saw pod success 11/11/22 23:54:23.092
    Nov 11 23:54:23.093: INFO: Pod "pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019" satisfied condition "Succeeded or Failed"
    Nov 11 23:54:23.112: INFO: Trying to get logs from node 10.241.148.26 pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:54:23.23
    Nov 11 23:54:23.306: INFO: Waiting for pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 to disappear
    Nov 11 23:54:23.324: INFO: Pod pod-projected-configmaps-f262e1c1-e9ca-4c39-9ff0-bc0434e48019 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 11 23:54:23.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3661" for this suite. 11/11/22 23:54:23.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:23.373
Nov 11 23:54:23.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/11/22 23:54:23.375
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:23.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:23.448
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Nov 11 23:54:23.555: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:54:23.577
Nov 11 23:54:23.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:54:23.619: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:54:24.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:54:24.664: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:54:25.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:54:25.695: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 11 23:54:26.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:54:26.664: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 11/11/22 23:54:26.738
STEP: Check that daemon pods images are updated. 11/11/22 23:54:26.786
Nov 11 23:54:26.809: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:26.809: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:27.859: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:27.859: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:28.884: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:28.884: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:29.852: INFO: Pod daemon-set-9kkhc is not available
Nov 11 23:54:29.853: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:29.853: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:30.875: INFO: Pod daemon-set-9kkhc is not available
Nov 11 23:54:30.875: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:30.875: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:31.850: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:32.848: INFO: Pod daemon-set-d5dcg is not available
Nov 11 23:54:32.848: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:33.853: INFO: Pod daemon-set-d5dcg is not available
Nov 11 23:54:33.853: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:34.852: INFO: Pod daemon-set-d5dcg is not available
Nov 11 23:54:34.852: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 11 23:54:36.851: INFO: Pod daemon-set-tqlqd is not available
STEP: Check that daemon pods are still running on every node of the cluster. 11/11/22 23:54:36.874
Nov 11 23:54:36.919: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:54:36.919: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
Nov 11 23:54:38.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 11 23:54:38.017: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
Nov 11 23:54:38.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 11 23:54:38.966: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:54:39.091
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4712, will wait for the garbage collector to delete the pods 11/11/22 23:54:39.092
Nov 11 23:54:39.197: INFO: Deleting DaemonSet.extensions daemon-set took: 24.546774ms
Nov 11 23:54:39.298: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.261191ms
Nov 11 23:54:42.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 11 23:54:42.522: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 11 23:54:42.536: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31797"},"items":null}

Nov 11 23:54:42.556: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31797"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:54:42.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4712" for this suite. 11/11/22 23:54:42.667
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":155,"skipped":2967,"failed":0}
------------------------------
• [SLOW TEST] [19.320 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:23.373
    Nov 11 23:54:23.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/11/22 23:54:23.375
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:23.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:23.448
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Nov 11 23:54:23.555: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 11/11/22 23:54:23.577
    Nov 11 23:54:23.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:54:23.619: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:54:24.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:54:24.664: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:54:25.695: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:54:25.695: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 11 23:54:26.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:54:26.664: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 11/11/22 23:54:26.738
    STEP: Check that daemon pods images are updated. 11/11/22 23:54:26.786
    Nov 11 23:54:26.809: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:26.809: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:27.859: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:27.859: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:28.884: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:28.884: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:29.852: INFO: Pod daemon-set-9kkhc is not available
    Nov 11 23:54:29.853: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:29.853: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:30.875: INFO: Pod daemon-set-9kkhc is not available
    Nov 11 23:54:30.875: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:30.875: INFO: Wrong image for pod: daemon-set-vxgtg. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:31.850: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:32.848: INFO: Pod daemon-set-d5dcg is not available
    Nov 11 23:54:32.848: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:33.853: INFO: Pod daemon-set-d5dcg is not available
    Nov 11 23:54:33.853: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:34.852: INFO: Pod daemon-set-d5dcg is not available
    Nov 11 23:54:34.852: INFO: Wrong image for pod: daemon-set-ppf88. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 11 23:54:36.851: INFO: Pod daemon-set-tqlqd is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 11/11/22 23:54:36.874
    Nov 11 23:54:36.919: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:54:36.919: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
    Nov 11 23:54:38.017: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 11 23:54:38.017: INFO: Node 10.241.148.26 is running 0 daemon pod, expected 1
    Nov 11 23:54:38.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 11 23:54:38.966: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/11/22 23:54:39.091
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4712, will wait for the garbage collector to delete the pods 11/11/22 23:54:39.092
    Nov 11 23:54:39.197: INFO: Deleting DaemonSet.extensions daemon-set took: 24.546774ms
    Nov 11 23:54:39.298: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.261191ms
    Nov 11 23:54:42.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 11 23:54:42.522: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 11 23:54:42.536: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31797"},"items":null}

    Nov 11 23:54:42.556: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31797"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:54:42.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4712" for this suite. 11/11/22 23:54:42.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:42.708
Nov 11 23:54:42.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename ingress 11/11/22 23:54:42.711
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:42.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:42.778
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 11/11/22 23:54:42.798
STEP: getting /apis/networking.k8s.io 11/11/22 23:54:42.82
STEP: getting /apis/networking.k8s.iov1 11/11/22 23:54:42.827
STEP: creating 11/11/22 23:54:42.835
STEP: getting 11/11/22 23:54:42.926
STEP: listing 11/11/22 23:54:42.947
STEP: watching 11/11/22 23:54:42.969
Nov 11 23:54:42.969: INFO: starting watch
STEP: cluster-wide listing 11/11/22 23:54:42.979
STEP: cluster-wide watching 11/11/22 23:54:43.003
Nov 11 23:54:43.003: INFO: starting watch
STEP: patching 11/11/22 23:54:43.014
STEP: updating 11/11/22 23:54:43.061
Nov 11 23:54:43.143: INFO: waiting for watch events with expected annotations
Nov 11 23:54:43.146: INFO: saw patched and updated annotations
STEP: patching /status 11/11/22 23:54:43.147
STEP: updating /status 11/11/22 23:54:43.174
STEP: get /status 11/11/22 23:54:43.231
STEP: deleting 11/11/22 23:54:43.255
STEP: deleting a collection 11/11/22 23:54:43.33
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Nov 11 23:54:43.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-357" for this suite. 11/11/22 23:54:43.459
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":156,"skipped":3013,"failed":0}
------------------------------
• [0.777 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:42.708
    Nov 11 23:54:42.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename ingress 11/11/22 23:54:42.711
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:42.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:42.778
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 11/11/22 23:54:42.798
    STEP: getting /apis/networking.k8s.io 11/11/22 23:54:42.82
    STEP: getting /apis/networking.k8s.iov1 11/11/22 23:54:42.827
    STEP: creating 11/11/22 23:54:42.835
    STEP: getting 11/11/22 23:54:42.926
    STEP: listing 11/11/22 23:54:42.947
    STEP: watching 11/11/22 23:54:42.969
    Nov 11 23:54:42.969: INFO: starting watch
    STEP: cluster-wide listing 11/11/22 23:54:42.979
    STEP: cluster-wide watching 11/11/22 23:54:43.003
    Nov 11 23:54:43.003: INFO: starting watch
    STEP: patching 11/11/22 23:54:43.014
    STEP: updating 11/11/22 23:54:43.061
    Nov 11 23:54:43.143: INFO: waiting for watch events with expected annotations
    Nov 11 23:54:43.146: INFO: saw patched and updated annotations
    STEP: patching /status 11/11/22 23:54:43.147
    STEP: updating /status 11/11/22 23:54:43.174
    STEP: get /status 11/11/22 23:54:43.231
    STEP: deleting 11/11/22 23:54:43.255
    STEP: deleting a collection 11/11/22 23:54:43.33
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Nov 11 23:54:43.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-357" for this suite. 11/11/22 23:54:43.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:43.49
Nov 11 23:54:43.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption 11/11/22 23:54:43.493
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:43.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:43.563
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 11/11/22 23:54:43.603
STEP: Updating PodDisruptionBudget status 11/11/22 23:54:45.639
STEP: Waiting for all pods to be running 11/11/22 23:54:45.678
Nov 11 23:54:45.710: INFO: running pods: 0 < 1
Nov 11 23:54:47.731: INFO: running pods: 0 < 1
STEP: locating a running pod 11/11/22 23:54:49.731
STEP: Waiting for the pdb to be processed 11/11/22 23:54:49.789
STEP: Patching PodDisruptionBudget status 11/11/22 23:54:49.827
STEP: Waiting for the pdb to be processed 11/11/22 23:54:49.872
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 11 23:54:49.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3373" for this suite. 11/11/22 23:54:49.922
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":157,"skipped":3020,"failed":0}
------------------------------
• [SLOW TEST] [6.482 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:43.49
    Nov 11 23:54:43.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption 11/11/22 23:54:43.493
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:43.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:43.563
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 11/11/22 23:54:43.603
    STEP: Updating PodDisruptionBudget status 11/11/22 23:54:45.639
    STEP: Waiting for all pods to be running 11/11/22 23:54:45.678
    Nov 11 23:54:45.710: INFO: running pods: 0 < 1
    Nov 11 23:54:47.731: INFO: running pods: 0 < 1
    STEP: locating a running pod 11/11/22 23:54:49.731
    STEP: Waiting for the pdb to be processed 11/11/22 23:54:49.789
    STEP: Patching PodDisruptionBudget status 11/11/22 23:54:49.827
    STEP: Waiting for the pdb to be processed 11/11/22 23:54:49.872
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 11 23:54:49.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3373" for this suite. 11/11/22 23:54:49.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:54:49.977
Nov 11 23:54:49.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/11/22 23:54:49.979
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:50.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:50.074
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 in namespace container-probe-1274 11/11/22 23:54:50.094
Nov 11 23:54:50.138: INFO: Waiting up to 5m0s for pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551" in namespace "container-probe-1274" to be "not pending"
Nov 11 23:54:50.156: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Pending", Reason="", readiness=false. Elapsed: 18.341845ms
Nov 11 23:54:52.177: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039250047s
Nov 11 23:54:54.179: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Running", Reason="", readiness=true. Elapsed: 4.040711506s
Nov 11 23:54:54.179: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551" satisfied condition "not pending"
Nov 11 23:54:54.179: INFO: Started pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 in namespace container-probe-1274
STEP: checking the pod's current state and verifying that restartCount is present 11/11/22 23:54:54.179
Nov 11 23:54:54.199: INFO: Initial restart count of pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 is 0
Nov 11 23:55:42.742: INFO: Restart count of pod container-probe-1274/busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 is now 1 (48.543324299s elapsed)
STEP: deleting the pod 11/11/22 23:55:42.742
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 11 23:55:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1274" for this suite. 11/11/22 23:55:42.819
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":158,"skipped":3031,"failed":0}
------------------------------
• [SLOW TEST] [52.865 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:54:49.977
    Nov 11 23:54:49.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/11/22 23:54:49.979
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:54:50.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:54:50.074
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 in namespace container-probe-1274 11/11/22 23:54:50.094
    Nov 11 23:54:50.138: INFO: Waiting up to 5m0s for pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551" in namespace "container-probe-1274" to be "not pending"
    Nov 11 23:54:50.156: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Pending", Reason="", readiness=false. Elapsed: 18.341845ms
    Nov 11 23:54:52.177: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039250047s
    Nov 11 23:54:54.179: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551": Phase="Running", Reason="", readiness=true. Elapsed: 4.040711506s
    Nov 11 23:54:54.179: INFO: Pod "busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551" satisfied condition "not pending"
    Nov 11 23:54:54.179: INFO: Started pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 in namespace container-probe-1274
    STEP: checking the pod's current state and verifying that restartCount is present 11/11/22 23:54:54.179
    Nov 11 23:54:54.199: INFO: Initial restart count of pod busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 is 0
    Nov 11 23:55:42.742: INFO: Restart count of pod container-probe-1274/busybox-2d3a94e7-5519-4924-9a93-e1a578ee9551 is now 1 (48.543324299s elapsed)
    STEP: deleting the pod 11/11/22 23:55:42.742
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 11 23:55:42.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1274" for this suite. 11/11/22 23:55:42.819
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:55:42.86
Nov 11 23:55:42.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:55:42.862
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:55:42.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:55:42.96
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Nov 11 23:55:42.996: INFO: Got root ca configmap in namespace "svcaccounts-8699"
Nov 11 23:55:43.022: INFO: Deleted root ca configmap in namespace "svcaccounts-8699"
STEP: waiting for a new root ca configmap created 11/11/22 23:55:43.523
Nov 11 23:55:43.538: INFO: Recreated root ca configmap in namespace "svcaccounts-8699"
Nov 11 23:55:43.558: INFO: Updated root ca configmap in namespace "svcaccounts-8699"
STEP: waiting for the root ca configmap reconciled 11/11/22 23:55:44.059
Nov 11 23:55:44.074: INFO: Reconciled root ca configmap in namespace "svcaccounts-8699"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:55:44.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8699" for this suite. 11/11/22 23:55:44.099
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":159,"skipped":3061,"failed":0}
------------------------------
• [1.264 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:55:42.86
    Nov 11 23:55:42.860: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:55:42.862
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:55:42.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:55:42.96
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Nov 11 23:55:42.996: INFO: Got root ca configmap in namespace "svcaccounts-8699"
    Nov 11 23:55:43.022: INFO: Deleted root ca configmap in namespace "svcaccounts-8699"
    STEP: waiting for a new root ca configmap created 11/11/22 23:55:43.523
    Nov 11 23:55:43.538: INFO: Recreated root ca configmap in namespace "svcaccounts-8699"
    Nov 11 23:55:43.558: INFO: Updated root ca configmap in namespace "svcaccounts-8699"
    STEP: waiting for the root ca configmap reconciled 11/11/22 23:55:44.059
    Nov 11 23:55:44.074: INFO: Reconciled root ca configmap in namespace "svcaccounts-8699"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:55:44.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8699" for this suite. 11/11/22 23:55:44.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:55:44.128
Nov 11 23:55:44.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption 11/11/22 23:55:44.13
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:55:44.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:55:44.203
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 11 23:55:44.374: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 11 23:56:44.530: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:56:44.544
Nov 11 23:56:44.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption-path 11/11/22 23:56:44.547
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:44.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:44.616
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Nov 11 23:56:44.699: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Nov 11 23:56:44.718: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Nov 11 23:56:44.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2080" for this suite. 11/11/22 23:56:44.833
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:56:44.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2388" for this suite. 11/11/22 23:56:44.934
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":160,"skipped":3081,"failed":0}
------------------------------
• [SLOW TEST] [61.043 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:55:44.128
    Nov 11 23:55:44.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption 11/11/22 23:55:44.13
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:55:44.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:55:44.203
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 11 23:55:44.374: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 11 23:56:44.530: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:56:44.544
    Nov 11 23:56:44.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption-path 11/11/22 23:56:44.547
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:44.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:44.616
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Nov 11 23:56:44.699: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Nov 11 23:56:44.718: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Nov 11 23:56:44.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-2080" for this suite. 11/11/22 23:56:44.833
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:56:44.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2388" for this suite. 11/11/22 23:56:44.934
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:56:45.181
Nov 11 23:56:45.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:56:45.183
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:45.236
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:45.252
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 11/11/22 23:56:45.271
Nov 11 23:56:45.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd" in namespace "projected-9941" to be "Succeeded or Failed"
Nov 11 23:56:45.329: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.392319ms
Nov 11 23:56:47.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045339371s
Nov 11 23:56:49.351: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039825659s
Nov 11 23:56:51.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04519744s
STEP: Saw pod success 11/11/22 23:56:51.356
Nov 11 23:56:51.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd" satisfied condition "Succeeded or Failed"
Nov 11 23:56:51.392: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd container client-container: <nil>
STEP: delete the pod 11/11/22 23:56:51.508
Nov 11 23:56:51.561: INFO: Waiting for pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd to disappear
Nov 11 23:56:51.580: INFO: Pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 11 23:56:51.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9941" for this suite. 11/11/22 23:56:51.605
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":161,"skipped":3120,"failed":0}
------------------------------
• [SLOW TEST] [6.448 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:56:45.181
    Nov 11 23:56:45.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:56:45.183
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:45.236
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:45.252
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 11/11/22 23:56:45.271
    Nov 11 23:56:45.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd" in namespace "projected-9941" to be "Succeeded or Failed"
    Nov 11 23:56:45.329: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.392319ms
    Nov 11 23:56:47.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045339371s
    Nov 11 23:56:49.351: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039825659s
    Nov 11 23:56:51.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04519744s
    STEP: Saw pod success 11/11/22 23:56:51.356
    Nov 11 23:56:51.356: INFO: Pod "downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd" satisfied condition "Succeeded or Failed"
    Nov 11 23:56:51.392: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd container client-container: <nil>
    STEP: delete the pod 11/11/22 23:56:51.508
    Nov 11 23:56:51.561: INFO: Waiting for pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd to disappear
    Nov 11 23:56:51.580: INFO: Pod downwardapi-volume-be4b39a0-143a-48ce-978f-63731da0fefd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 11 23:56:51.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9941" for this suite. 11/11/22 23:56:51.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:56:51.64
Nov 11 23:56:51.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename endpointslice 11/11/22 23:56:51.642
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:51.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:51.712
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 11/11/22 23:56:51.727
STEP: getting /apis/discovery.k8s.io 11/11/22 23:56:51.744
STEP: getting /apis/discovery.k8s.iov1 11/11/22 23:56:51.753
STEP: creating 11/11/22 23:56:51.761
STEP: getting 11/11/22 23:56:51.836
STEP: listing 11/11/22 23:56:51.875
STEP: watching 11/11/22 23:56:51.894
Nov 11 23:56:51.894: INFO: starting watch
STEP: cluster-wide listing 11/11/22 23:56:51.902
STEP: cluster-wide watching 11/11/22 23:56:51.929
Nov 11 23:56:51.929: INFO: starting watch
STEP: patching 11/11/22 23:56:51.937
STEP: updating 11/11/22 23:56:51.962
Nov 11 23:56:52.007: INFO: waiting for watch events with expected annotations
Nov 11 23:56:52.007: INFO: saw patched and updated annotations
STEP: deleting 11/11/22 23:56:52.008
STEP: deleting a collection 11/11/22 23:56:52.08
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 11 23:56:52.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4392" for this suite. 11/11/22 23:56:52.186
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":162,"skipped":3137,"failed":0}
------------------------------
• [0.569 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:56:51.64
    Nov 11 23:56:51.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename endpointslice 11/11/22 23:56:51.642
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:51.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:51.712
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 11/11/22 23:56:51.727
    STEP: getting /apis/discovery.k8s.io 11/11/22 23:56:51.744
    STEP: getting /apis/discovery.k8s.iov1 11/11/22 23:56:51.753
    STEP: creating 11/11/22 23:56:51.761
    STEP: getting 11/11/22 23:56:51.836
    STEP: listing 11/11/22 23:56:51.875
    STEP: watching 11/11/22 23:56:51.894
    Nov 11 23:56:51.894: INFO: starting watch
    STEP: cluster-wide listing 11/11/22 23:56:51.902
    STEP: cluster-wide watching 11/11/22 23:56:51.929
    Nov 11 23:56:51.929: INFO: starting watch
    STEP: patching 11/11/22 23:56:51.937
    STEP: updating 11/11/22 23:56:51.962
    Nov 11 23:56:52.007: INFO: waiting for watch events with expected annotations
    Nov 11 23:56:52.007: INFO: saw patched and updated annotations
    STEP: deleting 11/11/22 23:56:52.008
    STEP: deleting a collection 11/11/22 23:56:52.08
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 11 23:56:52.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4392" for this suite. 11/11/22 23:56:52.186
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:56:52.213
Nov 11 23:56:52.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/11/22 23:56:52.217
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:52.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:52.294
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-3366 11/11/22 23:56:52.316
STEP: creating service affinity-clusterip-transition in namespace services-3366 11/11/22 23:56:52.317
STEP: creating replication controller affinity-clusterip-transition in namespace services-3366 11/11/22 23:56:52.358
I1111 23:56:52.384332      21 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3366, replica count: 3
I1111 23:56:55.435504      21 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 11 23:56:55.467: INFO: Creating new exec pod
Nov 11 23:56:55.524: INFO: Waiting up to 5m0s for pod "execpod-affinitypfq5q" in namespace "services-3366" to be "running"
Nov 11 23:56:55.544: INFO: Pod "execpod-affinitypfq5q": Phase="Pending", Reason="", readiness=false. Elapsed: 20.369285ms
Nov 11 23:56:57.567: INFO: Pod "execpod-affinitypfq5q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042790694s
Nov 11 23:56:59.566: INFO: Pod "execpod-affinitypfq5q": Phase="Running", Reason="", readiness=true. Elapsed: 4.041827971s
Nov 11 23:56:59.566: INFO: Pod "execpod-affinitypfq5q" satisfied condition "running"
Nov 11 23:57:00.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Nov 11 23:57:00.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Nov 11 23:57:00.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:57:00.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.51.14 80'
Nov 11 23:57:01.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.51.14 80\nConnection to 172.21.51.14 80 port [tcp/http] succeeded!\n"
Nov 11 23:57:01.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 11 23:57:01.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
Nov 11 23:57:01.988: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
Nov 11 23:57:01.988: INFO: stdout: "\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj"
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:31.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
Nov 11 23:57:32.579: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
Nov 11 23:57:32.579: INFO: stdout: "\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-ptxf7"
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-ptxf7
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-ptxf7
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
Nov 11 23:57:32.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
Nov 11 23:57:33.262: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
Nov 11 23:57:33.262: INFO: stdout: "\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6"
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
Nov 11 23:57:33.262: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3366, will wait for the garbage collector to delete the pods 11/11/22 23:57:33.307
Nov 11 23:57:33.433: INFO: Deleting ReplicationController affinity-clusterip-transition took: 56.659303ms
Nov 11 23:57:33.534: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.216967ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 11 23:57:36.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3366" for this suite. 11/11/22 23:57:36.413
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":163,"skipped":3140,"failed":0}
------------------------------
• [SLOW TEST] [44.233 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:56:52.213
    Nov 11 23:56:52.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/11/22 23:56:52.217
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:56:52.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:56:52.294
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-3366 11/11/22 23:56:52.316
    STEP: creating service affinity-clusterip-transition in namespace services-3366 11/11/22 23:56:52.317
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3366 11/11/22 23:56:52.358
    I1111 23:56:52.384332      21 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3366, replica count: 3
    I1111 23:56:55.435504      21 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 11 23:56:55.467: INFO: Creating new exec pod
    Nov 11 23:56:55.524: INFO: Waiting up to 5m0s for pod "execpod-affinitypfq5q" in namespace "services-3366" to be "running"
    Nov 11 23:56:55.544: INFO: Pod "execpod-affinitypfq5q": Phase="Pending", Reason="", readiness=false. Elapsed: 20.369285ms
    Nov 11 23:56:57.567: INFO: Pod "execpod-affinitypfq5q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042790694s
    Nov 11 23:56:59.566: INFO: Pod "execpod-affinitypfq5q": Phase="Running", Reason="", readiness=true. Elapsed: 4.041827971s
    Nov 11 23:56:59.566: INFO: Pod "execpod-affinitypfq5q" satisfied condition "running"
    Nov 11 23:57:00.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Nov 11 23:57:00.972: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Nov 11 23:57:00.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:57:00.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.51.14 80'
    Nov 11 23:57:01.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.51.14 80\nConnection to 172.21.51.14 80 port [tcp/http] succeeded!\n"
    Nov 11 23:57:01.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 11 23:57:01.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
    Nov 11 23:57:01.988: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
    Nov 11 23:57:01.988: INFO: stdout: "\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj"
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:01.988: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:31.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
    Nov 11 23:57:32.579: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
    Nov 11 23:57:32.579: INFO: stdout: "\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-ptxf7\naffinity-clusterip-transition-gjprj\naffinity-clusterip-transition-ptxf7"
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-ptxf7
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-ptxf7
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.579: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-gjprj
    Nov 11 23:57:32.580: INFO: Received response from host: affinity-clusterip-transition-ptxf7
    Nov 11 23:57:32.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-3366 exec execpod-affinitypfq5q -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.51.14:80/ ; done'
    Nov 11 23:57:33.262: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.51.14:80/\n"
    Nov 11 23:57:33.262: INFO: stdout: "\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6\naffinity-clusterip-transition-2mkt6"
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Received response from host: affinity-clusterip-transition-2mkt6
    Nov 11 23:57:33.262: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3366, will wait for the garbage collector to delete the pods 11/11/22 23:57:33.307
    Nov 11 23:57:33.433: INFO: Deleting ReplicationController affinity-clusterip-transition took: 56.659303ms
    Nov 11 23:57:33.534: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.216967ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 11 23:57:36.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3366" for this suite. 11/11/22 23:57:36.413
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:57:36.453
Nov 11 23:57:36.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/11/22 23:57:36.456
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:36.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:36.527
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/11/22 23:57:36.597
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:57:37.329
STEP: Deploying the webhook pod 11/11/22 23:57:37.359
STEP: Wait for the deployment to be ready 11/11/22 23:57:37.427
Nov 11 23:57:37.465: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 11 23:57:39.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/11/22 23:57:41.541
STEP: Verifying the service has paired with the endpoint 11/11/22 23:57:41.578
Nov 11 23:57:42.578: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 11/11/22 23:57:42.607
STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.706
STEP: Updating a validating webhook configuration's rules to not include the create operation 11/11/22 23:57:42.764
STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.804
STEP: Patching a validating webhook configuration's rules to include the create operation 11/11/22 23:57:42.846
STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.875
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:57:42.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9627" for this suite. 11/11/22 23:57:42.948
STEP: Destroying namespace "webhook-9627-markers" for this suite. 11/11/22 23:57:42.971
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":164,"skipped":3149,"failed":0}
------------------------------
• [SLOW TEST] [6.689 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:57:36.453
    Nov 11 23:57:36.453: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/11/22 23:57:36.456
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:36.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:36.527
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/11/22 23:57:36.597
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/11/22 23:57:37.329
    STEP: Deploying the webhook pod 11/11/22 23:57:37.359
    STEP: Wait for the deployment to be ready 11/11/22 23:57:37.427
    Nov 11 23:57:37.465: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 11 23:57:39.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 11, 23, 57, 37, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/11/22 23:57:41.541
    STEP: Verifying the service has paired with the endpoint 11/11/22 23:57:41.578
    Nov 11 23:57:42.578: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 11/11/22 23:57:42.607
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.706
    STEP: Updating a validating webhook configuration's rules to not include the create operation 11/11/22 23:57:42.764
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.804
    STEP: Patching a validating webhook configuration's rules to include the create operation 11/11/22 23:57:42.846
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/11/22 23:57:42.875
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:57:42.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9627" for this suite. 11/11/22 23:57:42.948
    STEP: Destroying namespace "webhook-9627-markers" for this suite. 11/11/22 23:57:42.971
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:57:43.146
Nov 11 23:57:43.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename endpointslice 11/11/22 23:57:43.148
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.245
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 11 23:57:43.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4200" for this suite. 11/11/22 23:57:43.443
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":165,"skipped":3176,"failed":0}
------------------------------
• [0.322 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:57:43.146
    Nov 11 23:57:43.146: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename endpointslice 11/11/22 23:57:43.148
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.245
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 11 23:57:43.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4200" for this suite. 11/11/22 23:57:43.443
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:57:43.469
Nov 11 23:57:43.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename watch 11/11/22 23:57:43.471
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.538
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 11/11/22 23:57:43.554
STEP: creating a new configmap 11/11/22 23:57:43.561
STEP: modifying the configmap once 11/11/22 23:57:43.579
STEP: closing the watch once it receives two notifications 11/11/22 23:57:43.614
Nov 11 23:57:43.614: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32465 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:57:43.614: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32466 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 11/11/22 23:57:43.615
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/11/22 23:57:43.651
STEP: deleting the configmap 11/11/22 23:57:43.66
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/11/22 23:57:43.707
Nov 11 23:57:43.707: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32467 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 11 23:57:43.709: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32468 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 11 23:57:43.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-266" for this suite. 11/11/22 23:57:43.731
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":166,"skipped":3179,"failed":0}
------------------------------
• [0.288 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:57:43.469
    Nov 11 23:57:43.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename watch 11/11/22 23:57:43.471
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.538
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 11/11/22 23:57:43.554
    STEP: creating a new configmap 11/11/22 23:57:43.561
    STEP: modifying the configmap once 11/11/22 23:57:43.579
    STEP: closing the watch once it receives two notifications 11/11/22 23:57:43.614
    Nov 11 23:57:43.614: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32465 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:57:43.614: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32466 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 11/11/22 23:57:43.615
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/11/22 23:57:43.651
    STEP: deleting the configmap 11/11/22 23:57:43.66
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/11/22 23:57:43.707
    Nov 11 23:57:43.707: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32467 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 11 23:57:43.709: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-266  c98a8697-d375-448a-a7a3-871ed81c371d 32468 0 2022-11-11 23:57:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-11 23:57:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 11 23:57:43.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-266" for this suite. 11/11/22 23:57:43.731
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:57:43.757
Nov 11 23:57:43.757: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/11/22 23:57:43.759
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.81
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.825
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 11/11/22 23:57:43.839
Nov 11 23:57:43.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 create -f -'
Nov 11 23:57:44.159: INFO: stderr: ""
Nov 11 23:57:44.159: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:44.159
Nov 11 23:57:44.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:57:44.330: INFO: stderr: ""
Nov 11 23:57:44.330: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
Nov 11 23:57:44.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:44.484: INFO: stderr: ""
Nov 11 23:57:44.484: INFO: stdout: ""
Nov 11 23:57:44.484: INFO: update-demo-nautilus-bsp4h is created but not running
Nov 11 23:57:49.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:57:49.655: INFO: stderr: ""
Nov 11 23:57:49.655: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
Nov 11 23:57:49.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:49.821: INFO: stderr: ""
Nov 11 23:57:49.822: INFO: stdout: "true"
Nov 11 23:57:49.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:57:49.954: INFO: stderr: ""
Nov 11 23:57:49.954: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:57:49.954: INFO: validating pod update-demo-nautilus-bsp4h
Nov 11 23:57:50.027: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:57:50.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:57:50.027: INFO: update-demo-nautilus-bsp4h is verified up and running
Nov 11 23:57:50.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-mj7vc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:50.203: INFO: stderr: ""
Nov 11 23:57:50.203: INFO: stdout: "true"
Nov 11 23:57:50.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-mj7vc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:57:50.366: INFO: stderr: ""
Nov 11 23:57:50.366: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:57:50.366: INFO: validating pod update-demo-nautilus-mj7vc
Nov 11 23:57:50.451: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:57:50.451: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:57:50.451: INFO: update-demo-nautilus-mj7vc is verified up and running
STEP: scaling down the replication controller 11/11/22 23:57:50.451
Nov 11 23:57:50.453: INFO: scanned /root for discovery docs: <nil>
Nov 11 23:57:50.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Nov 11 23:57:51.677: INFO: stderr: ""
Nov 11 23:57:51.677: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:51.677
Nov 11 23:57:51.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:57:51.837: INFO: stderr: ""
Nov 11 23:57:51.837: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
STEP: Replicas for name=update-demo: expected=1 actual=2 11/11/22 23:57:51.837
Nov 11 23:57:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:57:57.001: INFO: stderr: ""
Nov 11 23:57:57.001: INFO: stdout: "update-demo-nautilus-bsp4h "
Nov 11 23:57:57.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:57.154: INFO: stderr: ""
Nov 11 23:57:57.154: INFO: stdout: "true"
Nov 11 23:57:57.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:57:57.310: INFO: stderr: ""
Nov 11 23:57:57.310: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:57:57.310: INFO: validating pod update-demo-nautilus-bsp4h
Nov 11 23:57:57.338: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:57:57.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:57:57.338: INFO: update-demo-nautilus-bsp4h is verified up and running
STEP: scaling up the replication controller 11/11/22 23:57:57.338
Nov 11 23:57:57.343: INFO: scanned /root for discovery docs: <nil>
Nov 11 23:57:57.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Nov 11 23:57:58.594: INFO: stderr: ""
Nov 11 23:57:58.594: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:58.594
Nov 11 23:57:58.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:57:58.814: INFO: stderr: ""
Nov 11 23:57:58.814: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-z8cm4 "
Nov 11 23:57:58.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:59.049: INFO: stderr: ""
Nov 11 23:57:59.049: INFO: stdout: "true"
Nov 11 23:57:59.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:57:59.152: INFO: stderr: ""
Nov 11 23:57:59.152: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:57:59.152: INFO: validating pod update-demo-nautilus-bsp4h
Nov 11 23:57:59.177: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:57:59.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:57:59.177: INFO: update-demo-nautilus-bsp4h is verified up and running
Nov 11 23:57:59.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:57:59.280: INFO: stderr: ""
Nov 11 23:57:59.280: INFO: stdout: ""
Nov 11 23:57:59.280: INFO: update-demo-nautilus-z8cm4 is created but not running
Nov 11 23:58:04.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 11 23:58:04.447: INFO: stderr: ""
Nov 11 23:58:04.447: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-z8cm4 "
Nov 11 23:58:04.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:58:04.636: INFO: stderr: ""
Nov 11 23:58:04.636: INFO: stdout: "true"
Nov 11 23:58:04.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:58:04.792: INFO: stderr: ""
Nov 11 23:58:04.793: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:58:04.793: INFO: validating pod update-demo-nautilus-bsp4h
Nov 11 23:58:04.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:58:04.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:58:04.819: INFO: update-demo-nautilus-bsp4h is verified up and running
Nov 11 23:58:04.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 11 23:58:04.977: INFO: stderr: ""
Nov 11 23:58:04.977: INFO: stdout: "true"
Nov 11 23:58:04.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 11 23:58:05.185: INFO: stderr: ""
Nov 11 23:58:05.185: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 11 23:58:05.185: INFO: validating pod update-demo-nautilus-z8cm4
Nov 11 23:58:05.261: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 11 23:58:05.261: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 11 23:58:05.261: INFO: update-demo-nautilus-z8cm4 is verified up and running
STEP: using delete to clean up resources 11/11/22 23:58:05.261
Nov 11 23:58:05.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 delete --grace-period=0 --force -f -'
Nov 11 23:58:05.444: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 11 23:58:05.444: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 11 23:58:05.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get rc,svc -l name=update-demo --no-headers'
Nov 11 23:58:05.647: INFO: stderr: "No resources found in kubectl-401 namespace.\n"
Nov 11 23:58:05.647: INFO: stdout: ""
Nov 11 23:58:05.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 11 23:58:05.858: INFO: stderr: ""
Nov 11 23:58:05.858: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 11 23:58:05.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-401" for this suite. 11/11/22 23:58:05.923
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":167,"skipped":3183,"failed":0}
------------------------------
• [SLOW TEST] [22.192 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:57:43.757
    Nov 11 23:57:43.757: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/11/22 23:57:43.759
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:57:43.81
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:57:43.825
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 11/11/22 23:57:43.839
    Nov 11 23:57:43.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 create -f -'
    Nov 11 23:57:44.159: INFO: stderr: ""
    Nov 11 23:57:44.159: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:44.159
    Nov 11 23:57:44.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:57:44.330: INFO: stderr: ""
    Nov 11 23:57:44.330: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
    Nov 11 23:57:44.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:44.484: INFO: stderr: ""
    Nov 11 23:57:44.484: INFO: stdout: ""
    Nov 11 23:57:44.484: INFO: update-demo-nautilus-bsp4h is created but not running
    Nov 11 23:57:49.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:57:49.655: INFO: stderr: ""
    Nov 11 23:57:49.655: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
    Nov 11 23:57:49.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:49.821: INFO: stderr: ""
    Nov 11 23:57:49.822: INFO: stdout: "true"
    Nov 11 23:57:49.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:57:49.954: INFO: stderr: ""
    Nov 11 23:57:49.954: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:57:49.954: INFO: validating pod update-demo-nautilus-bsp4h
    Nov 11 23:57:50.027: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:57:50.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:57:50.027: INFO: update-demo-nautilus-bsp4h is verified up and running
    Nov 11 23:57:50.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-mj7vc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:50.203: INFO: stderr: ""
    Nov 11 23:57:50.203: INFO: stdout: "true"
    Nov 11 23:57:50.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-mj7vc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:57:50.366: INFO: stderr: ""
    Nov 11 23:57:50.366: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:57:50.366: INFO: validating pod update-demo-nautilus-mj7vc
    Nov 11 23:57:50.451: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:57:50.451: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:57:50.451: INFO: update-demo-nautilus-mj7vc is verified up and running
    STEP: scaling down the replication controller 11/11/22 23:57:50.451
    Nov 11 23:57:50.453: INFO: scanned /root for discovery docs: <nil>
    Nov 11 23:57:50.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Nov 11 23:57:51.677: INFO: stderr: ""
    Nov 11 23:57:51.677: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:51.677
    Nov 11 23:57:51.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:57:51.837: INFO: stderr: ""
    Nov 11 23:57:51.837: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-mj7vc "
    STEP: Replicas for name=update-demo: expected=1 actual=2 11/11/22 23:57:51.837
    Nov 11 23:57:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:57:57.001: INFO: stderr: ""
    Nov 11 23:57:57.001: INFO: stdout: "update-demo-nautilus-bsp4h "
    Nov 11 23:57:57.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:57.154: INFO: stderr: ""
    Nov 11 23:57:57.154: INFO: stdout: "true"
    Nov 11 23:57:57.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:57:57.310: INFO: stderr: ""
    Nov 11 23:57:57.310: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:57:57.310: INFO: validating pod update-demo-nautilus-bsp4h
    Nov 11 23:57:57.338: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:57:57.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:57:57.338: INFO: update-demo-nautilus-bsp4h is verified up and running
    STEP: scaling up the replication controller 11/11/22 23:57:57.338
    Nov 11 23:57:57.343: INFO: scanned /root for discovery docs: <nil>
    Nov 11 23:57:57.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Nov 11 23:57:58.594: INFO: stderr: ""
    Nov 11 23:57:58.594: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/11/22 23:57:58.594
    Nov 11 23:57:58.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:57:58.814: INFO: stderr: ""
    Nov 11 23:57:58.814: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-z8cm4 "
    Nov 11 23:57:58.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:59.049: INFO: stderr: ""
    Nov 11 23:57:59.049: INFO: stdout: "true"
    Nov 11 23:57:59.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:57:59.152: INFO: stderr: ""
    Nov 11 23:57:59.152: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:57:59.152: INFO: validating pod update-demo-nautilus-bsp4h
    Nov 11 23:57:59.177: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:57:59.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:57:59.177: INFO: update-demo-nautilus-bsp4h is verified up and running
    Nov 11 23:57:59.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:57:59.280: INFO: stderr: ""
    Nov 11 23:57:59.280: INFO: stdout: ""
    Nov 11 23:57:59.280: INFO: update-demo-nautilus-z8cm4 is created but not running
    Nov 11 23:58:04.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 11 23:58:04.447: INFO: stderr: ""
    Nov 11 23:58:04.447: INFO: stdout: "update-demo-nautilus-bsp4h update-demo-nautilus-z8cm4 "
    Nov 11 23:58:04.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:58:04.636: INFO: stderr: ""
    Nov 11 23:58:04.636: INFO: stdout: "true"
    Nov 11 23:58:04.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-bsp4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:58:04.792: INFO: stderr: ""
    Nov 11 23:58:04.793: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:58:04.793: INFO: validating pod update-demo-nautilus-bsp4h
    Nov 11 23:58:04.819: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:58:04.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:58:04.819: INFO: update-demo-nautilus-bsp4h is verified up and running
    Nov 11 23:58:04.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 11 23:58:04.977: INFO: stderr: ""
    Nov 11 23:58:04.977: INFO: stdout: "true"
    Nov 11 23:58:04.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods update-demo-nautilus-z8cm4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 11 23:58:05.185: INFO: stderr: ""
    Nov 11 23:58:05.185: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 11 23:58:05.185: INFO: validating pod update-demo-nautilus-z8cm4
    Nov 11 23:58:05.261: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 11 23:58:05.261: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 11 23:58:05.261: INFO: update-demo-nautilus-z8cm4 is verified up and running
    STEP: using delete to clean up resources 11/11/22 23:58:05.261
    Nov 11 23:58:05.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 delete --grace-period=0 --force -f -'
    Nov 11 23:58:05.444: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 11 23:58:05.444: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 11 23:58:05.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get rc,svc -l name=update-demo --no-headers'
    Nov 11 23:58:05.647: INFO: stderr: "No resources found in kubectl-401 namespace.\n"
    Nov 11 23:58:05.647: INFO: stdout: ""
    Nov 11 23:58:05.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-401 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 11 23:58:05.858: INFO: stderr: ""
    Nov 11 23:58:05.858: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 11 23:58:05.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-401" for this suite. 11/11/22 23:58:05.923
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:58:05.952
Nov 11 23:58:05.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:58:05.955
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:06.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:06.024
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 11/11/22 23:58:06.043
Nov 11 23:58:06.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: mark a version not serverd 11/11/22 23:58:22.761
STEP: check the unserved version gets removed 11/11/22 23:58:22.799
STEP: check the other version is not changed 11/11/22 23:58:29.399
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:58:40.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6075" for this suite. 11/11/22 23:58:40.831
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":168,"skipped":3193,"failed":0}
------------------------------
• [SLOW TEST] [34.904 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:58:05.952
    Nov 11 23:58:05.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:58:05.955
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:06.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:06.024
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 11/11/22 23:58:06.043
    Nov 11 23:58:06.045: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: mark a version not serverd 11/11/22 23:58:22.761
    STEP: check the unserved version gets removed 11/11/22 23:58:22.799
    STEP: check the other version is not changed 11/11/22 23:58:29.399
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:58:40.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6075" for this suite. 11/11/22 23:58:40.831
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:58:40.862
Nov 11 23:58:40.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/11/22 23:58:40.865
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:40.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:40.948
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-6ee777ec-1273-42bc-a685-e99d745f1f87 11/11/22 23:58:40.959
STEP: Creating a pod to test consume secrets 11/11/22 23:58:40.991
Nov 11 23:58:41.036: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c" in namespace "projected-6998" to be "Succeeded or Failed"
Nov 11 23:58:41.054: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.705746ms
Nov 11 23:58:43.076: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040064453s
Nov 11 23:58:45.074: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037684291s
Nov 11 23:58:47.077: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040204451s
STEP: Saw pod success 11/11/22 23:58:47.077
Nov 11 23:58:47.077: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c" satisfied condition "Succeeded or Failed"
Nov 11 23:58:47.098: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c container projected-secret-volume-test: <nil>
STEP: delete the pod 11/11/22 23:58:47.213
Nov 11 23:58:47.259: INFO: Waiting for pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c to disappear
Nov 11 23:58:47.280: INFO: Pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 11 23:58:47.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6998" for this suite. 11/11/22 23:58:47.301
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":169,"skipped":3197,"failed":0}
------------------------------
• [SLOW TEST] [6.464 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:58:40.862
    Nov 11 23:58:40.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/11/22 23:58:40.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:40.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:40.948
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-6ee777ec-1273-42bc-a685-e99d745f1f87 11/11/22 23:58:40.959
    STEP: Creating a pod to test consume secrets 11/11/22 23:58:40.991
    Nov 11 23:58:41.036: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c" in namespace "projected-6998" to be "Succeeded or Failed"
    Nov 11 23:58:41.054: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.705746ms
    Nov 11 23:58:43.076: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040064453s
    Nov 11 23:58:45.074: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037684291s
    Nov 11 23:58:47.077: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040204451s
    STEP: Saw pod success 11/11/22 23:58:47.077
    Nov 11 23:58:47.077: INFO: Pod "pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c" satisfied condition "Succeeded or Failed"
    Nov 11 23:58:47.098: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/11/22 23:58:47.213
    Nov 11 23:58:47.259: INFO: Waiting for pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c to disappear
    Nov 11 23:58:47.280: INFO: Pod pod-projected-secrets-7df57399-4b2f-4c56-9d5d-09195d30448c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 11 23:58:47.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6998" for this suite. 11/11/22 23:58:47.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:58:47.342
Nov 11 23:58:47.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/11/22 23:58:47.344
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:47.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:47.428
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 11/11/22 23:58:47.449
STEP: Wait for the Deployment to create new ReplicaSet 11/11/22 23:58:47.472
STEP: delete the deployment 11/11/22 23:58:47.492
STEP: wait for all rs to be garbage collected 11/11/22 23:58:47.575
STEP: expected 0 rs, got 1 rs 11/11/22 23:58:47.613
STEP: expected 0 pods, got 2 pods 11/11/22 23:58:47.632
STEP: Gathering metrics 11/11/22 23:58:48.19
W1111 23:58:48.268380      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 11 23:58:48.268: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 11 23:58:48.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-550" for this suite. 11/11/22 23:58:48.289
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":170,"skipped":3220,"failed":0}
------------------------------
• [0.971 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:58:47.342
    Nov 11 23:58:47.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/11/22 23:58:47.344
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:47.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:47.428
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 11/11/22 23:58:47.449
    STEP: Wait for the Deployment to create new ReplicaSet 11/11/22 23:58:47.472
    STEP: delete the deployment 11/11/22 23:58:47.492
    STEP: wait for all rs to be garbage collected 11/11/22 23:58:47.575
    STEP: expected 0 rs, got 1 rs 11/11/22 23:58:47.613
    STEP: expected 0 pods, got 2 pods 11/11/22 23:58:47.632
    STEP: Gathering metrics 11/11/22 23:58:48.19
    W1111 23:58:48.268380      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 11 23:58:48.268: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 11 23:58:48.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-550" for this suite. 11/11/22 23:58:48.289
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:58:48.317
Nov 11 23:58:48.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename namespaces 11/11/22 23:58:48.319
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:48.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:48.394
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 11/11/22 23:58:48.412
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:48.468
STEP: Creating a service in the namespace 11/11/22 23:58:48.488
STEP: Deleting the namespace 11/11/22 23:58:48.525
STEP: Waiting for the namespace to be removed. 11/11/22 23:58:48.549
STEP: Recreating the namespace 11/11/22 23:58:54.566
STEP: Verifying there is no service in the namespace 11/11/22 23:58:54.648
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 11 23:58:54.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6869" for this suite. 11/11/22 23:58:54.687
STEP: Destroying namespace "nsdeletetest-3813" for this suite. 11/11/22 23:58:54.717
Nov 11 23:58:54.738: INFO: Namespace nsdeletetest-3813 was already deleted
STEP: Destroying namespace "nsdeletetest-4682" for this suite. 11/11/22 23:58:54.738
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":171,"skipped":3263,"failed":0}
------------------------------
• [SLOW TEST] [6.445 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:58:48.317
    Nov 11 23:58:48.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename namespaces 11/11/22 23:58:48.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:48.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:48.394
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 11/11/22 23:58:48.412
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:48.468
    STEP: Creating a service in the namespace 11/11/22 23:58:48.488
    STEP: Deleting the namespace 11/11/22 23:58:48.525
    STEP: Waiting for the namespace to be removed. 11/11/22 23:58:48.549
    STEP: Recreating the namespace 11/11/22 23:58:54.566
    STEP: Verifying there is no service in the namespace 11/11/22 23:58:54.648
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 11 23:58:54.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-6869" for this suite. 11/11/22 23:58:54.687
    STEP: Destroying namespace "nsdeletetest-3813" for this suite. 11/11/22 23:58:54.717
    Nov 11 23:58:54.738: INFO: Namespace nsdeletetest-3813 was already deleted
    STEP: Destroying namespace "nsdeletetest-4682" for this suite. 11/11/22 23:58:54.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:58:54.776
Nov 11 23:58:54.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/11/22 23:58:54.777
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:54.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:54.849
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-6d92bbbb-e43f-4b2f-9d89-ac4cbec99f7e 11/11/22 23:58:54.87
STEP: Creating a pod to test consume configMaps 11/11/22 23:58:54.89
Nov 11 23:58:54.928: INFO: Waiting up to 5m0s for pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71" in namespace "configmap-1405" to be "Succeeded or Failed"
Nov 11 23:58:54.951: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Pending", Reason="", readiness=false. Elapsed: 22.647657ms
Nov 11 23:58:56.972: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043527817s
Nov 11 23:58:58.970: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Running", Reason="", readiness=true. Elapsed: 4.0419074s
Nov 11 23:59:00.974: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Running", Reason="", readiness=false. Elapsed: 6.045482425s
Nov 11 23:59:02.983: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.054619389s
STEP: Saw pod success 11/11/22 23:59:02.983
Nov 11 23:59:02.983: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71" satisfied condition "Succeeded or Failed"
Nov 11 23:59:03.002: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 container agnhost-container: <nil>
STEP: delete the pod 11/11/22 23:59:03.043
Nov 11 23:59:03.097: INFO: Waiting for pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 to disappear
Nov 11 23:59:03.115: INFO: Pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 11 23:59:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1405" for this suite. 11/11/22 23:59:03.137
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":172,"skipped":3326,"failed":0}
------------------------------
• [SLOW TEST] [8.385 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:58:54.776
    Nov 11 23:58:54.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/11/22 23:58:54.777
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:58:54.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:58:54.849
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-6d92bbbb-e43f-4b2f-9d89-ac4cbec99f7e 11/11/22 23:58:54.87
    STEP: Creating a pod to test consume configMaps 11/11/22 23:58:54.89
    Nov 11 23:58:54.928: INFO: Waiting up to 5m0s for pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71" in namespace "configmap-1405" to be "Succeeded or Failed"
    Nov 11 23:58:54.951: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Pending", Reason="", readiness=false. Elapsed: 22.647657ms
    Nov 11 23:58:56.972: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043527817s
    Nov 11 23:58:58.970: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Running", Reason="", readiness=true. Elapsed: 4.0419074s
    Nov 11 23:59:00.974: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Running", Reason="", readiness=false. Elapsed: 6.045482425s
    Nov 11 23:59:02.983: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.054619389s
    STEP: Saw pod success 11/11/22 23:59:02.983
    Nov 11 23:59:02.983: INFO: Pod "pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71" satisfied condition "Succeeded or Failed"
    Nov 11 23:59:03.002: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 container agnhost-container: <nil>
    STEP: delete the pod 11/11/22 23:59:03.043
    Nov 11 23:59:03.097: INFO: Waiting for pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 to disappear
    Nov 11 23:59:03.115: INFO: Pod pod-configmaps-93c6a49e-0223-4782-ac27-e6e733927d71 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 11 23:59:03.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1405" for this suite. 11/11/22 23:59:03.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:59:03.163
Nov 11 23:59:03.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:59:03.166
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:03.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:03.239
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 11/11/22 23:59:03.258
STEP: watching for the ServiceAccount to be added 11/11/22 23:59:03.298
STEP: patching the ServiceAccount 11/11/22 23:59:03.308
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/11/22 23:59:03.328
STEP: deleting the ServiceAccount 11/11/22 23:59:03.351
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 11 23:59:03.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1313" for this suite. 11/11/22 23:59:03.418
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":173,"skipped":3332,"failed":0}
------------------------------
• [0.278 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:59:03.163
    Nov 11 23:59:03.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename svcaccounts 11/11/22 23:59:03.166
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:03.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:03.239
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 11/11/22 23:59:03.258
    STEP: watching for the ServiceAccount to be added 11/11/22 23:59:03.298
    STEP: patching the ServiceAccount 11/11/22 23:59:03.308
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/11/22 23:59:03.328
    STEP: deleting the ServiceAccount 11/11/22 23:59:03.351
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 11 23:59:03.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1313" for this suite. 11/11/22 23:59:03.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:59:03.444
Nov 11 23:59:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/11/22 23:59:03.447
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:03.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:03.544
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 11/11/22 23:59:03.584
STEP: create the rc2 11/11/22 23:59:03.611
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/11/22 23:59:08.691
STEP: delete the rc simpletest-rc-to-be-deleted 11/11/22 23:59:10.641
STEP: wait for the rc to be deleted 11/11/22 23:59:10.672
STEP: Gathering metrics 11/11/22 23:59:15.779
W1111 23:59:15.948007      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 11 23:59:15.948: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 11 23:59:15.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-286z2" in namespace "gc-9009"
Nov 11 23:59:16.023: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lvgk" in namespace "gc-9009"
Nov 11 23:59:16.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sbn4" in namespace "gc-9009"
Nov 11 23:59:16.154: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fz5j" in namespace "gc-9009"
Nov 11 23:59:16.206: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gbgh" in namespace "gc-9009"
Nov 11 23:59:16.268: INFO: Deleting pod "simpletest-rc-to-be-deleted-4ld9p" in namespace "gc-9009"
Nov 11 23:59:16.404: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nx4t" in namespace "gc-9009"
Nov 11 23:59:16.518: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rmjs" in namespace "gc-9009"
Nov 11 23:59:16.575: INFO: Deleting pod "simpletest-rc-to-be-deleted-4shwf" in namespace "gc-9009"
Nov 11 23:59:16.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vtkk" in namespace "gc-9009"
Nov 11 23:59:16.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w6sf" in namespace "gc-9009"
Nov 11 23:59:16.818: INFO: Deleting pod "simpletest-rc-to-be-deleted-5c7ph" in namespace "gc-9009"
Nov 11 23:59:16.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mswm" in namespace "gc-9009"
Nov 11 23:59:16.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-62f7l" in namespace "gc-9009"
Nov 11 23:59:16.990: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h8gx" in namespace "gc-9009"
Nov 11 23:59:17.072: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hpvn" in namespace "gc-9009"
Nov 11 23:59:17.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l7st" in namespace "gc-9009"
Nov 11 23:59:17.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rwlm" in namespace "gc-9009"
Nov 11 23:59:17.252: INFO: Deleting pod "simpletest-rc-to-be-deleted-7g54n" in namespace "gc-9009"
Nov 11 23:59:17.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hp6n" in namespace "gc-9009"
Nov 11 23:59:17.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jqc2" in namespace "gc-9009"
Nov 11 23:59:17.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bfsx" in namespace "gc-9009"
Nov 11 23:59:17.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-999rw" in namespace "gc-9009"
Nov 11 23:59:17.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fs2v" in namespace "gc-9009"
Nov 11 23:59:17.599: INFO: Deleting pod "simpletest-rc-to-be-deleted-9lh8n" in namespace "gc-9009"
Nov 11 23:59:17.668: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qg2s" in namespace "gc-9009"
Nov 11 23:59:17.736: INFO: Deleting pod "simpletest-rc-to-be-deleted-b424j" in namespace "gc-9009"
Nov 11 23:59:17.840: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4kmj" in namespace "gc-9009"
Nov 11 23:59:17.890: INFO: Deleting pod "simpletest-rc-to-be-deleted-bc2vx" in namespace "gc-9009"
Nov 11 23:59:17.938: INFO: Deleting pod "simpletest-rc-to-be-deleted-bdwsp" in namespace "gc-9009"
Nov 11 23:59:17.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2f7j" in namespace "gc-9009"
Nov 11 23:59:18.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7r48" in namespace "gc-9009"
Nov 11 23:59:18.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-cq5th" in namespace "gc-9009"
Nov 11 23:59:18.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctbc6" in namespace "gc-9009"
Nov 11 23:59:18.252: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk4lv" in namespace "gc-9009"
Nov 11 23:59:18.349: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnl9z" in namespace "gc-9009"
Nov 11 23:59:18.441: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtbxg" in namespace "gc-9009"
Nov 11 23:59:18.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzwpp" in namespace "gc-9009"
Nov 11 23:59:18.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-f67f9" in namespace "gc-9009"
Nov 11 23:59:18.657: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbff4" in namespace "gc-9009"
Nov 11 23:59:18.735: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdxrq" in namespace "gc-9009"
Nov 11 23:59:18.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffm4h" in namespace "gc-9009"
Nov 11 23:59:18.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj4hg" in namespace "gc-9009"
Nov 11 23:59:18.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-frh7s" in namespace "gc-9009"
Nov 11 23:59:19.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-fwkc6" in namespace "gc-9009"
Nov 11 23:59:19.109: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxjgb" in namespace "gc-9009"
Nov 11 23:59:19.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbz64" in namespace "gc-9009"
Nov 11 23:59:19.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6j4b" in namespace "gc-9009"
Nov 11 23:59:19.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-hh584" in namespace "gc-9009"
Nov 11 23:59:19.392: INFO: Deleting pod "simpletest-rc-to-be-deleted-hnkzd" in namespace "gc-9009"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 11 23:59:19.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9009" for this suite. 11/11/22 23:59:19.469
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":174,"skipped":3337,"failed":0}
------------------------------
• [SLOW TEST] [16.053 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:59:03.444
    Nov 11 23:59:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/11/22 23:59:03.447
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:03.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:03.544
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 11/11/22 23:59:03.584
    STEP: create the rc2 11/11/22 23:59:03.611
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/11/22 23:59:08.691
    STEP: delete the rc simpletest-rc-to-be-deleted 11/11/22 23:59:10.641
    STEP: wait for the rc to be deleted 11/11/22 23:59:10.672
    STEP: Gathering metrics 11/11/22 23:59:15.779
    W1111 23:59:15.948007      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 11 23:59:15.948: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 11 23:59:15.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-286z2" in namespace "gc-9009"
    Nov 11 23:59:16.023: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lvgk" in namespace "gc-9009"
    Nov 11 23:59:16.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sbn4" in namespace "gc-9009"
    Nov 11 23:59:16.154: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fz5j" in namespace "gc-9009"
    Nov 11 23:59:16.206: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gbgh" in namespace "gc-9009"
    Nov 11 23:59:16.268: INFO: Deleting pod "simpletest-rc-to-be-deleted-4ld9p" in namespace "gc-9009"
    Nov 11 23:59:16.404: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nx4t" in namespace "gc-9009"
    Nov 11 23:59:16.518: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rmjs" in namespace "gc-9009"
    Nov 11 23:59:16.575: INFO: Deleting pod "simpletest-rc-to-be-deleted-4shwf" in namespace "gc-9009"
    Nov 11 23:59:16.667: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vtkk" in namespace "gc-9009"
    Nov 11 23:59:16.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w6sf" in namespace "gc-9009"
    Nov 11 23:59:16.818: INFO: Deleting pod "simpletest-rc-to-be-deleted-5c7ph" in namespace "gc-9009"
    Nov 11 23:59:16.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-5mswm" in namespace "gc-9009"
    Nov 11 23:59:16.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-62f7l" in namespace "gc-9009"
    Nov 11 23:59:16.990: INFO: Deleting pod "simpletest-rc-to-be-deleted-6h8gx" in namespace "gc-9009"
    Nov 11 23:59:17.072: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hpvn" in namespace "gc-9009"
    Nov 11 23:59:17.130: INFO: Deleting pod "simpletest-rc-to-be-deleted-6l7st" in namespace "gc-9009"
    Nov 11 23:59:17.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rwlm" in namespace "gc-9009"
    Nov 11 23:59:17.252: INFO: Deleting pod "simpletest-rc-to-be-deleted-7g54n" in namespace "gc-9009"
    Nov 11 23:59:17.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hp6n" in namespace "gc-9009"
    Nov 11 23:59:17.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-7jqc2" in namespace "gc-9009"
    Nov 11 23:59:17.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-8bfsx" in namespace "gc-9009"
    Nov 11 23:59:17.485: INFO: Deleting pod "simpletest-rc-to-be-deleted-999rw" in namespace "gc-9009"
    Nov 11 23:59:17.544: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fs2v" in namespace "gc-9009"
    Nov 11 23:59:17.599: INFO: Deleting pod "simpletest-rc-to-be-deleted-9lh8n" in namespace "gc-9009"
    Nov 11 23:59:17.668: INFO: Deleting pod "simpletest-rc-to-be-deleted-9qg2s" in namespace "gc-9009"
    Nov 11 23:59:17.736: INFO: Deleting pod "simpletest-rc-to-be-deleted-b424j" in namespace "gc-9009"
    Nov 11 23:59:17.840: INFO: Deleting pod "simpletest-rc-to-be-deleted-b4kmj" in namespace "gc-9009"
    Nov 11 23:59:17.890: INFO: Deleting pod "simpletest-rc-to-be-deleted-bc2vx" in namespace "gc-9009"
    Nov 11 23:59:17.938: INFO: Deleting pod "simpletest-rc-to-be-deleted-bdwsp" in namespace "gc-9009"
    Nov 11 23:59:17.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-c2f7j" in namespace "gc-9009"
    Nov 11 23:59:18.071: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7r48" in namespace "gc-9009"
    Nov 11 23:59:18.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-cq5th" in namespace "gc-9009"
    Nov 11 23:59:18.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctbc6" in namespace "gc-9009"
    Nov 11 23:59:18.252: INFO: Deleting pod "simpletest-rc-to-be-deleted-dk4lv" in namespace "gc-9009"
    Nov 11 23:59:18.349: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnl9z" in namespace "gc-9009"
    Nov 11 23:59:18.441: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtbxg" in namespace "gc-9009"
    Nov 11 23:59:18.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzwpp" in namespace "gc-9009"
    Nov 11 23:59:18.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-f67f9" in namespace "gc-9009"
    Nov 11 23:59:18.657: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbff4" in namespace "gc-9009"
    Nov 11 23:59:18.735: INFO: Deleting pod "simpletest-rc-to-be-deleted-fdxrq" in namespace "gc-9009"
    Nov 11 23:59:18.854: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffm4h" in namespace "gc-9009"
    Nov 11 23:59:18.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-fj4hg" in namespace "gc-9009"
    Nov 11 23:59:18.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-frh7s" in namespace "gc-9009"
    Nov 11 23:59:19.056: INFO: Deleting pod "simpletest-rc-to-be-deleted-fwkc6" in namespace "gc-9009"
    Nov 11 23:59:19.109: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxjgb" in namespace "gc-9009"
    Nov 11 23:59:19.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-gbz64" in namespace "gc-9009"
    Nov 11 23:59:19.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6j4b" in namespace "gc-9009"
    Nov 11 23:59:19.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-hh584" in namespace "gc-9009"
    Nov 11 23:59:19.392: INFO: Deleting pod "simpletest-rc-to-be-deleted-hnkzd" in namespace "gc-9009"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 11 23:59:19.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9009" for this suite. 11/11/22 23:59:19.469
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:59:19.5
Nov 11 23:59:19.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:59:19.508
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:19.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:19.615
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/11/22 23:59:19.646
Nov 11 23:59:19.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 11 23:59:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 11 23:59:51.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6425" for this suite. 11/11/22 23:59:51.568
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":175,"skipped":3344,"failed":0}
------------------------------
• [SLOW TEST] [32.091 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:59:19.5
    Nov 11 23:59:19.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/11/22 23:59:19.508
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:19.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:19.615
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/11/22 23:59:19.646
    Nov 11 23:59:19.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 11 23:59:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 11 23:59:51.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6425" for this suite. 11/11/22 23:59:51.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/11/22 23:59:51.597
Nov 11 23:59:51.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/11/22 23:59:51.599
STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:51.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:51.656
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4104 11/11/22 23:59:51.67
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Nov 11 23:59:51.749: INFO: Found 0 stateful pods, waiting for 1
Nov 12 00:00:01.764: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 11/12/22 00:00:01.79
W1112 00:00:01.818529      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 12 00:00:01.849: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:00:01.849: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
Nov 12 00:00:11.868: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:00:11.868: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 11/12/22 00:00:11.897
STEP: Delete all of the StatefulSets 11/12/22 00:00:11.911
STEP: Verify that StatefulSets have been deleted 11/12/22 00:00:11.94
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 00:00:11.952: INFO: Deleting all statefulset in ns statefulset-4104
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 00:00:11.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4104" for this suite. 11/12/22 00:00:12.019
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":176,"skipped":3355,"failed":0}
------------------------------
• [SLOW TEST] [20.446 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/11/22 23:59:51.597
    Nov 11 23:59:51.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/11/22 23:59:51.599
    STEP: Waiting for a default service account to be provisioned in namespace 11/11/22 23:59:51.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/11/22 23:59:51.656
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4104 11/11/22 23:59:51.67
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Nov 11 23:59:51.749: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 00:00:01.764: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 11/12/22 00:00:01.79
    W1112 00:00:01.818529      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 12 00:00:01.849: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:00:01.849: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
    Nov 12 00:00:11.868: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:00:11.868: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 11/12/22 00:00:11.897
    STEP: Delete all of the StatefulSets 11/12/22 00:00:11.911
    STEP: Verify that StatefulSets have been deleted 11/12/22 00:00:11.94
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 00:00:11.952: INFO: Deleting all statefulset in ns statefulset-4104
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 00:00:11.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4104" for this suite. 11/12/22 00:00:12.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:12.051
Nov 12 00:00:12.051: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename certificates 11/12/22 00:00:12.052
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:12.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:12.115
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 11/12/22 00:00:13.438
STEP: getting /apis/certificates.k8s.io 11/12/22 00:00:13.45
STEP: getting /apis/certificates.k8s.io/v1 11/12/22 00:00:13.456
STEP: creating 11/12/22 00:00:13.464
STEP: getting 11/12/22 00:00:13.522
STEP: listing 11/12/22 00:00:13.538
STEP: watching 11/12/22 00:00:13.555
Nov 12 00:00:13.555: INFO: starting watch
STEP: patching 11/12/22 00:00:13.571
STEP: updating 11/12/22 00:00:13.593
Nov 12 00:00:13.611: INFO: waiting for watch events with expected annotations
Nov 12 00:00:13.611: INFO: saw patched and updated annotations
STEP: getting /approval 11/12/22 00:00:13.611
STEP: patching /approval 11/12/22 00:00:13.625
STEP: updating /approval 11/12/22 00:00:13.648
STEP: getting /status 11/12/22 00:00:13.667
STEP: patching /status 11/12/22 00:00:13.682
STEP: updating /status 11/12/22 00:00:13.72
STEP: deleting 11/12/22 00:00:13.744
STEP: deleting a collection 11/12/22 00:00:13.794
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:00:13.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-4188" for this suite. 11/12/22 00:00:13.881
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":177,"skipped":3376,"failed":0}
------------------------------
• [1.857 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:12.051
    Nov 12 00:00:12.051: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename certificates 11/12/22 00:00:12.052
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:12.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:12.115
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 11/12/22 00:00:13.438
    STEP: getting /apis/certificates.k8s.io 11/12/22 00:00:13.45
    STEP: getting /apis/certificates.k8s.io/v1 11/12/22 00:00:13.456
    STEP: creating 11/12/22 00:00:13.464
    STEP: getting 11/12/22 00:00:13.522
    STEP: listing 11/12/22 00:00:13.538
    STEP: watching 11/12/22 00:00:13.555
    Nov 12 00:00:13.555: INFO: starting watch
    STEP: patching 11/12/22 00:00:13.571
    STEP: updating 11/12/22 00:00:13.593
    Nov 12 00:00:13.611: INFO: waiting for watch events with expected annotations
    Nov 12 00:00:13.611: INFO: saw patched and updated annotations
    STEP: getting /approval 11/12/22 00:00:13.611
    STEP: patching /approval 11/12/22 00:00:13.625
    STEP: updating /approval 11/12/22 00:00:13.648
    STEP: getting /status 11/12/22 00:00:13.667
    STEP: patching /status 11/12/22 00:00:13.682
    STEP: updating /status 11/12/22 00:00:13.72
    STEP: deleting 11/12/22 00:00:13.744
    STEP: deleting a collection 11/12/22 00:00:13.794
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:00:13.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-4188" for this suite. 11/12/22 00:00:13.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:13.919
Nov 12 00:00:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename csistoragecapacity 11/12/22 00:00:13.921
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:13.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:13.986
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 11/12/22 00:00:14
STEP: getting /apis/storage.k8s.io 11/12/22 00:00:14.012
STEP: getting /apis/storage.k8s.io/v1 11/12/22 00:00:14.019
STEP: creating 11/12/22 00:00:14.025
STEP: watching 11/12/22 00:00:14.101
Nov 12 00:00:14.101: INFO: starting watch
STEP: getting 11/12/22 00:00:14.142
STEP: listing in namespace 11/12/22 00:00:14.186
STEP: listing across namespaces 11/12/22 00:00:14.202
STEP: patching 11/12/22 00:00:14.215
STEP: updating 11/12/22 00:00:14.232
Nov 12 00:00:14.253: INFO: waiting for watch events with expected annotations in namespace
Nov 12 00:00:14.254: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 11/12/22 00:00:14.255
STEP: deleting a collection 11/12/22 00:00:14.371
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Nov 12 00:00:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-678" for this suite. 11/12/22 00:00:14.449
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":178,"skipped":3445,"failed":0}
------------------------------
• [0.555 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:13.919
    Nov 12 00:00:13.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename csistoragecapacity 11/12/22 00:00:13.921
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:13.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:13.986
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 11/12/22 00:00:14
    STEP: getting /apis/storage.k8s.io 11/12/22 00:00:14.012
    STEP: getting /apis/storage.k8s.io/v1 11/12/22 00:00:14.019
    STEP: creating 11/12/22 00:00:14.025
    STEP: watching 11/12/22 00:00:14.101
    Nov 12 00:00:14.101: INFO: starting watch
    STEP: getting 11/12/22 00:00:14.142
    STEP: listing in namespace 11/12/22 00:00:14.186
    STEP: listing across namespaces 11/12/22 00:00:14.202
    STEP: patching 11/12/22 00:00:14.215
    STEP: updating 11/12/22 00:00:14.232
    Nov 12 00:00:14.253: INFO: waiting for watch events with expected annotations in namespace
    Nov 12 00:00:14.254: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 11/12/22 00:00:14.255
    STEP: deleting a collection 11/12/22 00:00:14.371
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Nov 12 00:00:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-678" for this suite. 11/12/22 00:00:14.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:14.493
Nov 12 00:00:14.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:00:14.5
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:14.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:14.561
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:00:14.635
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:00:15.905
STEP: Deploying the webhook pod 11/12/22 00:00:15.94
STEP: Wait for the deployment to be ready 11/12/22 00:00:15.978
Nov 12 00:00:16.011: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 00:00:18.088: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:00:20.105
STEP: Verifying the service has paired with the endpoint 11/12/22 00:00:20.14
Nov 12 00:00:21.141: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 11/12/22 00:00:21.187
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/12/22 00:00:21.192
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 00:00:21.192
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/12/22 00:00:21.192
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/12/22 00:00:21.197
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 00:00:21.197
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 00:00:21.204
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:00:21.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1955" for this suite. 11/12/22 00:00:21.222
STEP: Destroying namespace "webhook-1955-markers" for this suite. 11/12/22 00:00:21.253
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":179,"skipped":3482,"failed":0}
------------------------------
• [SLOW TEST] [6.956 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:14.493
    Nov 12 00:00:14.493: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:00:14.5
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:14.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:14.561
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:00:14.635
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:00:15.905
    STEP: Deploying the webhook pod 11/12/22 00:00:15.94
    STEP: Wait for the deployment to be ready 11/12/22 00:00:15.978
    Nov 12 00:00:16.011: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 00:00:18.088: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 16, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:00:20.105
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:00:20.14
    Nov 12 00:00:21.141: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 11/12/22 00:00:21.187
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/12/22 00:00:21.192
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 00:00:21.192
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/12/22 00:00:21.192
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/12/22 00:00:21.197
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 00:00:21.197
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 00:00:21.204
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:00:21.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1955" for this suite. 11/12/22 00:00:21.222
    STEP: Destroying namespace "webhook-1955-markers" for this suite. 11/12/22 00:00:21.253
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:21.451
Nov 12 00:00:21.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:00:21.453
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:21.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:21.512
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:00:21.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3694" for this suite. 11/12/22 00:00:21.711
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":180,"skipped":3507,"failed":0}
------------------------------
• [0.294 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:21.451
    Nov 12 00:00:21.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:00:21.453
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:21.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:21.512
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:00:21.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3694" for this suite. 11/12/22 00:00:21.711
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:21.748
Nov 12 00:00:21.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:00:21.75
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:21.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:21.817
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:00:21.878
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:00:23.24
STEP: Deploying the webhook pod 11/12/22 00:00:23.26
STEP: Wait for the deployment to be ready 11/12/22 00:00:23.306
Nov 12 00:00:23.336: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 00:00:25.394: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:00:27.415
STEP: Verifying the service has paired with the endpoint 11/12/22 00:00:27.449
Nov 12 00:00:28.449: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 00:00:28.467
STEP: create a pod 11/12/22 00:00:28.577
Nov 12 00:00:28.608: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2249" to be "running"
Nov 12 00:00:28.622: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.315501ms
Nov 12 00:00:30.639: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030302577s
Nov 12 00:00:32.635: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.026562809s
Nov 12 00:00:32.635: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 11/12/22 00:00:32.635
Nov 12 00:00:32.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=webhook-2249 attach --namespace=webhook-2249 to-be-attached-pod -i -c=container1'
Nov 12 00:00:32.858: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:00:32.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2249" for this suite. 11/12/22 00:00:32.911
STEP: Destroying namespace "webhook-2249-markers" for this suite. 11/12/22 00:00:32.94
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":181,"skipped":3520,"failed":0}
------------------------------
• [SLOW TEST] [11.356 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:21.748
    Nov 12 00:00:21.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:00:21.75
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:21.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:21.817
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:00:21.878
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:00:23.24
    STEP: Deploying the webhook pod 11/12/22 00:00:23.26
    STEP: Wait for the deployment to be ready 11/12/22 00:00:23.306
    Nov 12 00:00:23.336: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 00:00:25.394: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 0, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:00:27.415
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:00:27.449
    Nov 12 00:00:28.449: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 00:00:28.467
    STEP: create a pod 11/12/22 00:00:28.577
    Nov 12 00:00:28.608: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2249" to be "running"
    Nov 12 00:00:28.622: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.315501ms
    Nov 12 00:00:30.639: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030302577s
    Nov 12 00:00:32.635: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.026562809s
    Nov 12 00:00:32.635: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 11/12/22 00:00:32.635
    Nov 12 00:00:32.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=webhook-2249 attach --namespace=webhook-2249 to-be-attached-pod -i -c=container1'
    Nov 12 00:00:32.858: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:00:32.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2249" for this suite. 11/12/22 00:00:32.911
    STEP: Destroying namespace "webhook-2249-markers" for this suite. 11/12/22 00:00:32.94
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:33.105
Nov 12 00:00:33.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:00:33.108
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:33.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:33.173
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:00:33.188
Nov 12 00:00:33.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f" in namespace "projected-1026" to be "Succeeded or Failed"
Nov 12 00:00:33.230: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.208066ms
Nov 12 00:00:35.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02477689s
Nov 12 00:00:37.244: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02659005s
Nov 12 00:00:39.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024276236s
STEP: Saw pod success 11/12/22 00:00:39.242
Nov 12 00:00:39.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f" satisfied condition "Succeeded or Failed"
Nov 12 00:00:39.256: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f container client-container: <nil>
STEP: delete the pod 11/12/22 00:00:39.38
Nov 12 00:00:39.414: INFO: Waiting for pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f to disappear
Nov 12 00:00:39.426: INFO: Pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:00:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1026" for this suite. 11/12/22 00:00:39.445
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":182,"skipped":3522,"failed":0}
------------------------------
• [SLOW TEST] [6.402 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:33.105
    Nov 12 00:00:33.105: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:00:33.108
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:33.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:33.173
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:00:33.188
    Nov 12 00:00:33.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f" in namespace "projected-1026" to be "Succeeded or Failed"
    Nov 12 00:00:33.230: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.208066ms
    Nov 12 00:00:35.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02477689s
    Nov 12 00:00:37.244: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02659005s
    Nov 12 00:00:39.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024276236s
    STEP: Saw pod success 11/12/22 00:00:39.242
    Nov 12 00:00:39.242: INFO: Pod "downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f" satisfied condition "Succeeded or Failed"
    Nov 12 00:00:39.256: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f container client-container: <nil>
    STEP: delete the pod 11/12/22 00:00:39.38
    Nov 12 00:00:39.414: INFO: Waiting for pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f to disappear
    Nov 12 00:00:39.426: INFO: Pod downwardapi-volume-52e61a11-cefd-44d1-a351-620fdd410a8f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:00:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1026" for this suite. 11/12/22 00:00:39.445
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:39.515
Nov 12 00:00:39.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename endpointslicemirroring 11/12/22 00:00:39.517
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:39.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:39.67
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 11/12/22 00:00:39.718
Nov 12 00:00:39.801: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 11/12/22 00:00:41.817
STEP: mirroring deletion of a custom Endpoint 11/12/22 00:00:41.857
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Nov 12 00:00:41.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-5123" for this suite. 11/12/22 00:00:41.927
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":183,"skipped":3525,"failed":0}
------------------------------
• [2.437 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:39.515
    Nov 12 00:00:39.516: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename endpointslicemirroring 11/12/22 00:00:39.517
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:39.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:39.67
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 11/12/22 00:00:39.718
    Nov 12 00:00:39.801: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 11/12/22 00:00:41.817
    STEP: mirroring deletion of a custom Endpoint 11/12/22 00:00:41.857
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Nov 12 00:00:41.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-5123" for this suite. 11/12/22 00:00:41.927
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:41.96
Nov 12 00:00:41.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/12/22 00:00:41.962
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:42.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:42.023
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 11/12/22 00:00:42.037
STEP: delete the rc 11/12/22 00:00:47.079
STEP: wait for all pods to be garbage collected 11/12/22 00:00:47.1
STEP: Gathering metrics 11/12/22 00:00:52.125
W1112 00:00:52.161209      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 00:00:52.161: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 00:00:52.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8783" for this suite. 11/12/22 00:00:52.182
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":184,"skipped":3582,"failed":0}
------------------------------
• [SLOW TEST] [10.246 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:41.96
    Nov 12 00:00:41.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/12/22 00:00:41.962
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:42.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:42.023
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 11/12/22 00:00:42.037
    STEP: delete the rc 11/12/22 00:00:47.079
    STEP: wait for all pods to be garbage collected 11/12/22 00:00:47.1
    STEP: Gathering metrics 11/12/22 00:00:52.125
    W1112 00:00:52.161209      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 00:00:52.161: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 00:00:52.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8783" for this suite. 11/12/22 00:00:52.182
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:52.215
Nov 12 00:00:52.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:00:52.217
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:52.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:52.286
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 11/12/22 00:00:52.303
Nov 12 00:00:52.334: INFO: Waiting up to 5m0s for pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d" in namespace "downward-api-1740" to be "Succeeded or Failed"
Nov 12 00:00:52.348: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.456407ms
Nov 12 00:00:54.361: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026086424s
Nov 12 00:00:56.360: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025482847s
Nov 12 00:00:58.367: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032839342s
STEP: Saw pod success 11/12/22 00:00:58.368
Nov 12 00:00:58.369: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d" satisfied condition "Succeeded or Failed"
Nov 12 00:00:58.381: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d container dapi-container: <nil>
STEP: delete the pod 11/12/22 00:00:58.413
Nov 12 00:00:58.445: INFO: Waiting for pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d to disappear
Nov 12 00:00:58.458: INFO: Pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 00:00:58.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1740" for this suite. 11/12/22 00:00:58.48
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":185,"skipped":3605,"failed":0}
------------------------------
• [SLOW TEST] [6.293 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:52.215
    Nov 12 00:00:52.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:00:52.217
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:52.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:52.286
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 11/12/22 00:00:52.303
    Nov 12 00:00:52.334: INFO: Waiting up to 5m0s for pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d" in namespace "downward-api-1740" to be "Succeeded or Failed"
    Nov 12 00:00:52.348: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.456407ms
    Nov 12 00:00:54.361: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026086424s
    Nov 12 00:00:56.360: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025482847s
    Nov 12 00:00:58.367: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032839342s
    STEP: Saw pod success 11/12/22 00:00:58.368
    Nov 12 00:00:58.369: INFO: Pod "downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d" satisfied condition "Succeeded or Failed"
    Nov 12 00:00:58.381: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d container dapi-container: <nil>
    STEP: delete the pod 11/12/22 00:00:58.413
    Nov 12 00:00:58.445: INFO: Waiting for pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d to disappear
    Nov 12 00:00:58.458: INFO: Pod downward-api-a6adf34f-f77b-4751-9cbe-6fe501cb4c0d no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 00:00:58.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1740" for this suite. 11/12/22 00:00:58.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:58.514
Nov 12 00:00:58.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption 11/12/22 00:00:58.516
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:58.576
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:58.599
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 11/12/22 00:00:58.613
STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.633
STEP: updating the pdb 11/12/22 00:00:58.647
STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.681
STEP: patching the pdb 11/12/22 00:00:58.696
STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.733
STEP: Waiting for the pdb to be deleted 11/12/22 00:00:58.773
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 00:00:58.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2552" for this suite. 11/12/22 00:00:58.807
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":186,"skipped":3616,"failed":0}
------------------------------
• [0.318 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:58.514
    Nov 12 00:00:58.515: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption 11/12/22 00:00:58.516
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:58.576
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:58.599
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 11/12/22 00:00:58.613
    STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.633
    STEP: updating the pdb 11/12/22 00:00:58.647
    STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.681
    STEP: patching the pdb 11/12/22 00:00:58.696
    STEP: Waiting for the pdb to be processed 11/12/22 00:00:58.733
    STEP: Waiting for the pdb to be deleted 11/12/22 00:00:58.773
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 00:00:58.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2552" for this suite. 11/12/22 00:00:58.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:00:58.836
Nov 12 00:00:58.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:00:58.838
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:58.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:58.905
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Nov 12 00:00:58.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:01:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8548" for this suite. 11/12/22 00:01:05.573
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":187,"skipped":3632,"failed":0}
------------------------------
• [SLOW TEST] [6.769 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:00:58.836
    Nov 12 00:00:58.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:00:58.838
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:00:58.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:00:58.905
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Nov 12 00:00:58.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:01:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8548" for this suite. 11/12/22 00:01:05.573
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:01:05.606
Nov 12 00:01:05.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sysctl 11/12/22 00:01:05.608
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:05.668
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:05.678
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/12/22 00:01:05.689
STEP: Watching for error events or started pod 11/12/22 00:01:05.721
STEP: Waiting for pod completion 11/12/22 00:01:09.754
Nov 12 00:01:09.754: INFO: Waiting up to 3m0s for pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784" in namespace "sysctl-1381" to be "completed"
Nov 12 00:01:09.776: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784": Phase="Pending", Reason="", readiness=false. Elapsed: 22.247015ms
Nov 12 00:01:11.789: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035291708s
Nov 12 00:01:11.790: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784" satisfied condition "completed"
STEP: Checking that the pod succeeded 11/12/22 00:01:11.803
STEP: Getting logs from the pod 11/12/22 00:01:11.803
STEP: Checking that the sysctl is actually updated 11/12/22 00:01:11.831
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 00:01:11.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1381" for this suite. 11/12/22 00:01:11.854
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":188,"skipped":3636,"failed":0}
------------------------------
• [SLOW TEST] [6.275 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:01:05.606
    Nov 12 00:01:05.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sysctl 11/12/22 00:01:05.608
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:05.668
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:05.678
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/12/22 00:01:05.689
    STEP: Watching for error events or started pod 11/12/22 00:01:05.721
    STEP: Waiting for pod completion 11/12/22 00:01:09.754
    Nov 12 00:01:09.754: INFO: Waiting up to 3m0s for pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784" in namespace "sysctl-1381" to be "completed"
    Nov 12 00:01:09.776: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784": Phase="Pending", Reason="", readiness=false. Elapsed: 22.247015ms
    Nov 12 00:01:11.789: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035291708s
    Nov 12 00:01:11.790: INFO: Pod "sysctl-4466c517-2c3b-445d-a055-728c8faf1784" satisfied condition "completed"
    STEP: Checking that the pod succeeded 11/12/22 00:01:11.803
    STEP: Getting logs from the pod 11/12/22 00:01:11.803
    STEP: Checking that the sysctl is actually updated 11/12/22 00:01:11.831
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 00:01:11.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1381" for this suite. 11/12/22 00:01:11.854
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:01:11.89
Nov 12 00:01:11.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:01:11.892
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:11.949
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:11.963
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 11/12/22 00:01:11.977
Nov 12 00:01:12.009: INFO: Waiting up to 5m0s for pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f" in namespace "projected-2740" to be "running and ready"
Nov 12 00:01:12.022: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.132859ms
Nov 12 00:01:12.022: INFO: The phase of Pod annotationupdatec6087771-9a7a-4189-a218-153beb5c859f is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:01:14.037: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f": Phase="Running", Reason="", readiness=true. Elapsed: 2.027486643s
Nov 12 00:01:14.037: INFO: The phase of Pod annotationupdatec6087771-9a7a-4189-a218-153beb5c859f is Running (Ready = true)
Nov 12 00:01:14.037: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f" satisfied condition "running and ready"
Nov 12 00:01:14.624: INFO: Successfully updated pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:01:16.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2740" for this suite. 11/12/22 00:01:16.702
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":189,"skipped":3643,"failed":0}
------------------------------
• [4.839 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:01:11.89
    Nov 12 00:01:11.891: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:01:11.892
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:11.949
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:11.963
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 11/12/22 00:01:11.977
    Nov 12 00:01:12.009: INFO: Waiting up to 5m0s for pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f" in namespace "projected-2740" to be "running and ready"
    Nov 12 00:01:12.022: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.132859ms
    Nov 12 00:01:12.022: INFO: The phase of Pod annotationupdatec6087771-9a7a-4189-a218-153beb5c859f is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:01:14.037: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f": Phase="Running", Reason="", readiness=true. Elapsed: 2.027486643s
    Nov 12 00:01:14.037: INFO: The phase of Pod annotationupdatec6087771-9a7a-4189-a218-153beb5c859f is Running (Ready = true)
    Nov 12 00:01:14.037: INFO: Pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f" satisfied condition "running and ready"
    Nov 12 00:01:14.624: INFO: Successfully updated pod "annotationupdatec6087771-9a7a-4189-a218-153beb5c859f"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:01:16.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2740" for this suite. 11/12/22 00:01:16.702
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:01:16.75
Nov 12 00:01:16.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:01:16.753
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:16.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:16.815
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/12/22 00:01:16.828
Nov 12 00:01:16.859: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-730  ea73b1bf-eb5e-4430-b12c-9f073e1ca889 35538 0 2022-11-12 00:01:16 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-12 00:01:16 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2kxm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2kxm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:01:16.859: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-730" to be "running and ready"
Nov 12 00:01:16.872: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 12.763436ms
Nov 12 00:01:16.872: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:01:18.886: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027138324s
Nov 12 00:01:18.886: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:01:20.884: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.024683005s
Nov 12 00:01:20.884: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Nov 12 00:01:20.884: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 11/12/22 00:01:20.885
Nov 12 00:01:20.885: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-730 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:01:20.885: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:01:20.887: INFO: ExecWithOptions: Clientset creation
Nov 12 00:01:20.887: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-730/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 11/12/22 00:01:21.149
Nov 12 00:01:21.150: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-730 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:01:21.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:01:21.152: INFO: ExecWithOptions: Clientset creation
Nov 12 00:01:21.152: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-730/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:01:21.414: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:01:21.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-730" for this suite. 11/12/22 00:01:21.47
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":190,"skipped":3712,"failed":0}
------------------------------
• [4.747 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:01:16.75
    Nov 12 00:01:16.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:01:16.753
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:16.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:16.815
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/12/22 00:01:16.828
    Nov 12 00:01:16.859: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-730  ea73b1bf-eb5e-4430-b12c-9f073e1ca889 35538 0 2022-11-12 00:01:16 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-12 00:01:16 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2kxm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2kxm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:01:16.859: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-730" to be "running and ready"
    Nov 12 00:01:16.872: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 12.763436ms
    Nov 12 00:01:16.872: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:01:18.886: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027138324s
    Nov 12 00:01:18.886: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:01:20.884: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.024683005s
    Nov 12 00:01:20.884: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Nov 12 00:01:20.884: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 11/12/22 00:01:20.885
    Nov 12 00:01:20.885: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-730 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:01:20.885: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:01:20.887: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:01:20.887: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-730/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 11/12/22 00:01:21.149
    Nov 12 00:01:21.150: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-730 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:01:21.150: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:01:21.152: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:01:21.152: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/dns-730/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:01:21.414: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:01:21.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-730" for this suite. 11/12/22 00:01:21.47
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:01:21.501
Nov 12 00:01:21.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:01:21.502
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:21.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:21.56
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:01:21.572
Nov 12 00:01:21.604: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea" in namespace "downward-api-8413" to be "Succeeded or Failed"
Nov 12 00:01:21.616: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385361ms
Nov 12 00:01:23.630: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025693693s
Nov 12 00:01:25.630: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Running", Reason="", readiness=false. Elapsed: 4.025804802s
Nov 12 00:01:27.628: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024476158s
STEP: Saw pod success 11/12/22 00:01:27.628
Nov 12 00:01:27.629: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea" satisfied condition "Succeeded or Failed"
Nov 12 00:01:27.660: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea container client-container: <nil>
STEP: delete the pod 11/12/22 00:01:27.713
Nov 12 00:01:27.749: INFO: Waiting for pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea to disappear
Nov 12 00:01:27.766: INFO: Pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:01:27.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8413" for this suite. 11/12/22 00:01:27.814
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":191,"skipped":3722,"failed":0}
------------------------------
• [SLOW TEST] [6.336 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:01:21.501
    Nov 12 00:01:21.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:01:21.502
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:21.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:21.56
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:01:21.572
    Nov 12 00:01:21.604: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea" in namespace "downward-api-8413" to be "Succeeded or Failed"
    Nov 12 00:01:21.616: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Pending", Reason="", readiness=false. Elapsed: 12.385361ms
    Nov 12 00:01:23.630: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025693693s
    Nov 12 00:01:25.630: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Running", Reason="", readiness=false. Elapsed: 4.025804802s
    Nov 12 00:01:27.628: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024476158s
    STEP: Saw pod success 11/12/22 00:01:27.628
    Nov 12 00:01:27.629: INFO: Pod "downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea" satisfied condition "Succeeded or Failed"
    Nov 12 00:01:27.660: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea container client-container: <nil>
    STEP: delete the pod 11/12/22 00:01:27.713
    Nov 12 00:01:27.749: INFO: Waiting for pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea to disappear
    Nov 12 00:01:27.766: INFO: Pod downwardapi-volume-7568a2e6-c948-4cf6-a182-3b52edf859ea no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:01:27.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8413" for this suite. 11/12/22 00:01:27.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:01:27.84
Nov 12 00:01:27.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:01:27.843
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:27.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:27.922
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-5b2270d3-a2a6-4e30-908a-22d1201af5a8 11/12/22 00:01:27.954
STEP: Creating secret with name s-test-opt-upd-a0a30457-fde1-4f2e-9837-3ecd42c0b09e 11/12/22 00:01:27.969
STEP: Creating the pod 11/12/22 00:01:27.985
Nov 12 00:01:28.020: INFO: Waiting up to 5m0s for pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76" in namespace "secrets-1447" to be "running and ready"
Nov 12 00:01:28.031: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Pending", Reason="", readiness=false. Elapsed: 11.277268ms
Nov 12 00:01:28.032: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:01:30.045: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025112496s
Nov 12 00:01:30.045: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:01:32.046: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Running", Reason="", readiness=true. Elapsed: 4.025385296s
Nov 12 00:01:32.046: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Running (Ready = true)
Nov 12 00:01:32.046: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-5b2270d3-a2a6-4e30-908a-22d1201af5a8 11/12/22 00:01:32.145
STEP: Updating secret s-test-opt-upd-a0a30457-fde1-4f2e-9837-3ecd42c0b09e 11/12/22 00:01:32.176
STEP: Creating secret with name s-test-opt-create-ad2e2e2d-b81d-4394-8eb0-2fd32b1e2687 11/12/22 00:01:32.191
STEP: waiting to observe update in volume 11/12/22 00:01:32.21
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:02:35.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1447" for this suite. 11/12/22 00:02:35.429
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":192,"skipped":3729,"failed":0}
------------------------------
• [SLOW TEST] [67.616 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:01:27.84
    Nov 12 00:01:27.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:01:27.843
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:01:27.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:01:27.922
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-5b2270d3-a2a6-4e30-908a-22d1201af5a8 11/12/22 00:01:27.954
    STEP: Creating secret with name s-test-opt-upd-a0a30457-fde1-4f2e-9837-3ecd42c0b09e 11/12/22 00:01:27.969
    STEP: Creating the pod 11/12/22 00:01:27.985
    Nov 12 00:01:28.020: INFO: Waiting up to 5m0s for pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76" in namespace "secrets-1447" to be "running and ready"
    Nov 12 00:01:28.031: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Pending", Reason="", readiness=false. Elapsed: 11.277268ms
    Nov 12 00:01:28.032: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:01:30.045: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025112496s
    Nov 12 00:01:30.045: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:01:32.046: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76": Phase="Running", Reason="", readiness=true. Elapsed: 4.025385296s
    Nov 12 00:01:32.046: INFO: The phase of Pod pod-secrets-9e850d91-b767-427a-be0c-873072538c76 is Running (Ready = true)
    Nov 12 00:01:32.046: INFO: Pod "pod-secrets-9e850d91-b767-427a-be0c-873072538c76" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-5b2270d3-a2a6-4e30-908a-22d1201af5a8 11/12/22 00:01:32.145
    STEP: Updating secret s-test-opt-upd-a0a30457-fde1-4f2e-9837-3ecd42c0b09e 11/12/22 00:01:32.176
    STEP: Creating secret with name s-test-opt-create-ad2e2e2d-b81d-4394-8eb0-2fd32b1e2687 11/12/22 00:01:32.191
    STEP: waiting to observe update in volume 11/12/22 00:01:32.21
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:02:35.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1447" for this suite. 11/12/22 00:02:35.429
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:02:35.458
Nov 12 00:02:35.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:02:35.461
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:02:35.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:02:35.569
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/12/22 00:02:35.632
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/12/22 00:02:35.637
STEP: creating a pod to probe DNS 11/12/22 00:02:35.637
STEP: submitting the pod to kubernetes 11/12/22 00:02:35.638
Nov 12 00:02:35.670: INFO: Waiting up to 15m0s for pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929" in namespace "dns-681" to be "running"
Nov 12 00:02:35.710: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 39.976786ms
Nov 12 00:02:37.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055203979s
Nov 12 00:02:39.728: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05785673s
Nov 12 00:02:41.743: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072719013s
Nov 12 00:02:43.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 8.056948531s
Nov 12 00:02:45.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056413068s
Nov 12 00:02:47.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 12.056165741s
Nov 12 00:02:49.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 14.055675805s
Nov 12 00:02:51.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Running", Reason="", readiness=true. Elapsed: 16.055194696s
Nov 12 00:02:51.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929" satisfied condition "running"
STEP: retrieving the pod 11/12/22 00:02:51.727
STEP: looking for the results for each expected name from probers 11/12/22 00:02:51.741
Nov 12 00:02:51.844: INFO: DNS probes using dns-681/dns-test-a924e948-061b-4a42-b384-fb91bd7a5929 succeeded

STEP: deleting the pod 11/12/22 00:02:51.844
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:02:51.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-681" for this suite. 11/12/22 00:02:51.911
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":193,"skipped":3743,"failed":0}
------------------------------
• [SLOW TEST] [16.477 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:02:35.458
    Nov 12 00:02:35.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:02:35.461
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:02:35.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:02:35.569
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/12/22 00:02:35.632
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/12/22 00:02:35.637
    STEP: creating a pod to probe DNS 11/12/22 00:02:35.637
    STEP: submitting the pod to kubernetes 11/12/22 00:02:35.638
    Nov 12 00:02:35.670: INFO: Waiting up to 15m0s for pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929" in namespace "dns-681" to be "running"
    Nov 12 00:02:35.710: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 39.976786ms
    Nov 12 00:02:37.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055203979s
    Nov 12 00:02:39.728: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05785673s
    Nov 12 00:02:41.743: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072719013s
    Nov 12 00:02:43.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 8.056948531s
    Nov 12 00:02:45.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056413068s
    Nov 12 00:02:47.727: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 12.056165741s
    Nov 12 00:02:49.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Pending", Reason="", readiness=false. Elapsed: 14.055675805s
    Nov 12 00:02:51.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929": Phase="Running", Reason="", readiness=true. Elapsed: 16.055194696s
    Nov 12 00:02:51.726: INFO: Pod "dns-test-a924e948-061b-4a42-b384-fb91bd7a5929" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 00:02:51.727
    STEP: looking for the results for each expected name from probers 11/12/22 00:02:51.741
    Nov 12 00:02:51.844: INFO: DNS probes using dns-681/dns-test-a924e948-061b-4a42-b384-fb91bd7a5929 succeeded

    STEP: deleting the pod 11/12/22 00:02:51.844
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:02:51.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-681" for this suite. 11/12/22 00:02:51.911
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:02:51.935
Nov 12 00:02:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:02:51.937
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:02:51.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:02:51.998
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 11/12/22 00:02:52.01
STEP: Ensuring ResourceQuota status is calculated 11/12/22 00:02:52.03
STEP: Creating a ResourceQuota with not terminating scope 11/12/22 00:02:54.047
STEP: Ensuring ResourceQuota status is calculated 11/12/22 00:02:54.065
STEP: Creating a long running pod 11/12/22 00:02:56.082
STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/12/22 00:02:56.129
STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/12/22 00:02:58.147
STEP: Deleting the pod 11/12/22 00:03:00.163
STEP: Ensuring resource quota status released the pod usage 11/12/22 00:03:00.189
STEP: Creating a terminating pod 11/12/22 00:03:02.21
STEP: Ensuring resource quota with terminating scope captures the pod usage 11/12/22 00:03:02.247
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/12/22 00:03:04.264
STEP: Deleting the pod 11/12/22 00:03:06.28
STEP: Ensuring resource quota status released the pod usage 11/12/22 00:03:06.314
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:03:08.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3859" for this suite. 11/12/22 00:03:08.357
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":194,"skipped":3745,"failed":0}
------------------------------
• [SLOW TEST] [16.446 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:02:51.935
    Nov 12 00:02:51.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:02:51.937
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:02:51.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:02:51.998
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 11/12/22 00:02:52.01
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 00:02:52.03
    STEP: Creating a ResourceQuota with not terminating scope 11/12/22 00:02:54.047
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 00:02:54.065
    STEP: Creating a long running pod 11/12/22 00:02:56.082
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/12/22 00:02:56.129
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/12/22 00:02:58.147
    STEP: Deleting the pod 11/12/22 00:03:00.163
    STEP: Ensuring resource quota status released the pod usage 11/12/22 00:03:00.189
    STEP: Creating a terminating pod 11/12/22 00:03:02.21
    STEP: Ensuring resource quota with terminating scope captures the pod usage 11/12/22 00:03:02.247
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/12/22 00:03:04.264
    STEP: Deleting the pod 11/12/22 00:03:06.28
    STEP: Ensuring resource quota status released the pod usage 11/12/22 00:03:06.314
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:03:08.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3859" for this suite. 11/12/22 00:03:08.357
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:03:08.385
Nov 12 00:03:08.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename subpath 11/12/22 00:03:08.386
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:03:08.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:03:08.478
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 00:03:08.494
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-zkf9 11/12/22 00:03:08.526
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:03:08.526
Nov 12 00:03:08.559: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zkf9" in namespace "subpath-404" to be "Succeeded or Failed"
Nov 12 00:03:08.572: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.212047ms
Nov 12 00:03:10.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.027025833s
Nov 12 00:03:12.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 4.027765694s
Nov 12 00:03:14.587: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 6.028675655s
Nov 12 00:03:16.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 8.026661515s
Nov 12 00:03:18.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 10.026678046s
Nov 12 00:03:20.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 12.024740824s
Nov 12 00:03:22.588: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 14.029742581s
Nov 12 00:03:24.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 16.024627371s
Nov 12 00:03:26.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 18.024807397s
Nov 12 00:03:28.584: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 20.02551795s
Nov 12 00:03:30.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 22.02457332s
Nov 12 00:03:32.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=false. Elapsed: 24.026941926s
Nov 12 00:03:34.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.02618193s
STEP: Saw pod success 11/12/22 00:03:34.585
Nov 12 00:03:34.586: INFO: Pod "pod-subpath-test-secret-zkf9" satisfied condition "Succeeded or Failed"
Nov 12 00:03:34.602: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-secret-zkf9 container test-container-subpath-secret-zkf9: <nil>
STEP: delete the pod 11/12/22 00:03:34.633
Nov 12 00:03:34.670: INFO: Waiting for pod pod-subpath-test-secret-zkf9 to disappear
Nov 12 00:03:34.683: INFO: Pod pod-subpath-test-secret-zkf9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-zkf9 11/12/22 00:03:34.684
Nov 12 00:03:34.684: INFO: Deleting pod "pod-subpath-test-secret-zkf9" in namespace "subpath-404"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 00:03:34.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-404" for this suite. 11/12/22 00:03:34.716
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":195,"skipped":3749,"failed":0}
------------------------------
• [SLOW TEST] [26.393 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:03:08.385
    Nov 12 00:03:08.385: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename subpath 11/12/22 00:03:08.386
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:03:08.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:03:08.478
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 00:03:08.494
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-zkf9 11/12/22 00:03:08.526
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:03:08.526
    Nov 12 00:03:08.559: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zkf9" in namespace "subpath-404" to be "Succeeded or Failed"
    Nov 12 00:03:08.572: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.212047ms
    Nov 12 00:03:10.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.027025833s
    Nov 12 00:03:12.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 4.027765694s
    Nov 12 00:03:14.587: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 6.028675655s
    Nov 12 00:03:16.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 8.026661515s
    Nov 12 00:03:18.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 10.026678046s
    Nov 12 00:03:20.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 12.024740824s
    Nov 12 00:03:22.588: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 14.029742581s
    Nov 12 00:03:24.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 16.024627371s
    Nov 12 00:03:26.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 18.024807397s
    Nov 12 00:03:28.584: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 20.02551795s
    Nov 12 00:03:30.583: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=true. Elapsed: 22.02457332s
    Nov 12 00:03:32.586: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Running", Reason="", readiness=false. Elapsed: 24.026941926s
    Nov 12 00:03:34.585: INFO: Pod "pod-subpath-test-secret-zkf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.02618193s
    STEP: Saw pod success 11/12/22 00:03:34.585
    Nov 12 00:03:34.586: INFO: Pod "pod-subpath-test-secret-zkf9" satisfied condition "Succeeded or Failed"
    Nov 12 00:03:34.602: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-secret-zkf9 container test-container-subpath-secret-zkf9: <nil>
    STEP: delete the pod 11/12/22 00:03:34.633
    Nov 12 00:03:34.670: INFO: Waiting for pod pod-subpath-test-secret-zkf9 to disappear
    Nov 12 00:03:34.683: INFO: Pod pod-subpath-test-secret-zkf9 no longer exists
    STEP: Deleting pod pod-subpath-test-secret-zkf9 11/12/22 00:03:34.684
    Nov 12 00:03:34.684: INFO: Deleting pod "pod-subpath-test-secret-zkf9" in namespace "subpath-404"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 00:03:34.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-404" for this suite. 11/12/22 00:03:34.716
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:03:34.788
Nov 12 00:03:34.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/12/22 00:03:34.791
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:03:34.846
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:03:34.866
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 11/12/22 00:03:34.881
Nov 12 00:03:34.935: INFO: Waiting up to 2m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696" to be "running"
Nov 12 00:03:34.948: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 13.512652ms
Nov 12 00:03:36.960: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025114994s
Nov 12 00:03:38.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026854619s
Nov 12 00:03:40.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025743163s
Nov 12 00:03:42.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040271181s
Nov 12 00:03:44.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026747165s
Nov 12 00:03:46.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029808701s
Nov 12 00:03:48.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026058633s
Nov 12 00:03:50.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 16.026223194s
Nov 12 00:03:52.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 18.02709803s
Nov 12 00:03:54.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027530636s
Nov 12 00:03:56.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 22.026382986s
Nov 12 00:03:58.960: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025122438s
Nov 12 00:04:00.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 26.026788444s
Nov 12 00:04:02.968: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 28.032843269s
Nov 12 00:04:04.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 30.027778595s
Nov 12 00:04:06.980: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 32.044636018s
Nov 12 00:04:08.966: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 34.031208065s
Nov 12 00:04:10.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 36.028973219s
Nov 12 00:04:12.974: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 38.038897495s
Nov 12 00:04:14.991: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 40.056013468s
Nov 12 00:04:16.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 42.027535536s
Nov 12 00:04:18.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 44.0284983s
Nov 12 00:04:20.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 46.057969669s
Nov 12 00:04:22.978: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 48.043446709s
Nov 12 00:04:24.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 50.057571131s
Nov 12 00:04:26.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 52.03016902s
Nov 12 00:04:28.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 54.030477178s
Nov 12 00:04:30.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 56.030182538s
Nov 12 00:04:32.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 58.02874158s
Nov 12 00:04:34.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.040479747s
Nov 12 00:04:36.979: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.044259553s
Nov 12 00:04:38.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028787327s
Nov 12 00:04:40.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.028977267s
Nov 12 00:04:42.985: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.050485169s
Nov 12 00:04:44.989: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.054270336s
Nov 12 00:04:46.967: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.032208212s
Nov 12 00:04:48.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.029417039s
Nov 12 00:04:50.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.040038353s
Nov 12 00:04:52.990: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.054714995s
Nov 12 00:04:54.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.029609061s
Nov 12 00:04:56.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.029330638s
Nov 12 00:04:58.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.028303146s
Nov 12 00:05:00.968: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.032902976s
Nov 12 00:05:02.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.030402873s
Nov 12 00:05:04.967: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.032029815s
Nov 12 00:05:06.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.026831869s
Nov 12 00:05:08.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.03011235s
Nov 12 00:05:10.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.029990546s
Nov 12 00:05:12.980: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.044680765s
Nov 12 00:05:14.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.030548103s
Nov 12 00:05:16.970: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.034608743s
Nov 12 00:05:18.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.029415685s
Nov 12 00:05:20.966: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.03144182s
Nov 12 00:05:22.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.029304089s
Nov 12 00:05:24.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.058114993s
Nov 12 00:05:26.985: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.050298356s
Nov 12 00:05:28.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.029056345s
Nov 12 00:05:30.986: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.050861665s
Nov 12 00:05:32.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.028980709s
Nov 12 00:05:34.994: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.058645s
Nov 12 00:05:35.007: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.072182957s
STEP: updating the pod 11/12/22 00:05:35.007
Nov 12 00:05:35.562: INFO: Successfully updated pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708"
STEP: waiting for pod running 11/12/22 00:05:35.563
Nov 12 00:05:35.563: INFO: Waiting up to 2m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696" to be "running"
Nov 12 00:05:35.579: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 15.37338ms
Nov 12 00:05:37.615: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Running", Reason="", readiness=true. Elapsed: 2.051540284s
Nov 12 00:05:37.615: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" satisfied condition "running"
STEP: deleting the pod gracefully 11/12/22 00:05:37.615
Nov 12 00:05:37.616: INFO: Deleting pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696"
Nov 12 00:05:37.655: INFO: Wait up to 5m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 00:06:09.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2696" for this suite. 11/12/22 00:06:09.798
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":196,"skipped":3791,"failed":0}
------------------------------
• [SLOW TEST] [155.052 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:03:34.788
    Nov 12 00:03:34.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/12/22 00:03:34.791
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:03:34.846
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:03:34.866
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 11/12/22 00:03:34.881
    Nov 12 00:03:34.935: INFO: Waiting up to 2m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696" to be "running"
    Nov 12 00:03:34.948: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 13.512652ms
    Nov 12 00:03:36.960: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025114994s
    Nov 12 00:03:38.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026854619s
    Nov 12 00:03:40.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025743163s
    Nov 12 00:03:42.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040271181s
    Nov 12 00:03:44.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026747165s
    Nov 12 00:03:46.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 12.029808701s
    Nov 12 00:03:48.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026058633s
    Nov 12 00:03:50.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 16.026223194s
    Nov 12 00:03:52.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 18.02709803s
    Nov 12 00:03:54.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027530636s
    Nov 12 00:03:56.961: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 22.026382986s
    Nov 12 00:03:58.960: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 24.025122438s
    Nov 12 00:04:00.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 26.026788444s
    Nov 12 00:04:02.968: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 28.032843269s
    Nov 12 00:04:04.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 30.027778595s
    Nov 12 00:04:06.980: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 32.044636018s
    Nov 12 00:04:08.966: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 34.031208065s
    Nov 12 00:04:10.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 36.028973219s
    Nov 12 00:04:12.974: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 38.038897495s
    Nov 12 00:04:14.991: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 40.056013468s
    Nov 12 00:04:16.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 42.027535536s
    Nov 12 00:04:18.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 44.0284983s
    Nov 12 00:04:20.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 46.057969669s
    Nov 12 00:04:22.978: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 48.043446709s
    Nov 12 00:04:24.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 50.057571131s
    Nov 12 00:04:26.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 52.03016902s
    Nov 12 00:04:28.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 54.030477178s
    Nov 12 00:04:30.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 56.030182538s
    Nov 12 00:04:32.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 58.02874158s
    Nov 12 00:04:34.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.040479747s
    Nov 12 00:04:36.979: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.044259553s
    Nov 12 00:04:38.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.028787327s
    Nov 12 00:04:40.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.028977267s
    Nov 12 00:04:42.985: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.050485169s
    Nov 12 00:04:44.989: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.054270336s
    Nov 12 00:04:46.967: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.032208212s
    Nov 12 00:04:48.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.029417039s
    Nov 12 00:04:50.975: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.040038353s
    Nov 12 00:04:52.990: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.054714995s
    Nov 12 00:04:54.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.029609061s
    Nov 12 00:04:56.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.029330638s
    Nov 12 00:04:58.963: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.028303146s
    Nov 12 00:05:00.968: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.032902976s
    Nov 12 00:05:02.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.030402873s
    Nov 12 00:05:04.967: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.032029815s
    Nov 12 00:05:06.962: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.026831869s
    Nov 12 00:05:08.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.03011235s
    Nov 12 00:05:10.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.029990546s
    Nov 12 00:05:12.980: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.044680765s
    Nov 12 00:05:14.965: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.030548103s
    Nov 12 00:05:16.970: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.034608743s
    Nov 12 00:05:18.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.029415685s
    Nov 12 00:05:20.966: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.03144182s
    Nov 12 00:05:22.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.029304089s
    Nov 12 00:05:24.993: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.058114993s
    Nov 12 00:05:26.985: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.050298356s
    Nov 12 00:05:28.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.029056345s
    Nov 12 00:05:30.986: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.050861665s
    Nov 12 00:05:32.964: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.028980709s
    Nov 12 00:05:34.994: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.058645s
    Nov 12 00:05:35.007: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.072182957s
    STEP: updating the pod 11/12/22 00:05:35.007
    Nov 12 00:05:35.562: INFO: Successfully updated pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708"
    STEP: waiting for pod running 11/12/22 00:05:35.563
    Nov 12 00:05:35.563: INFO: Waiting up to 2m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696" to be "running"
    Nov 12 00:05:35.579: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Pending", Reason="", readiness=false. Elapsed: 15.37338ms
    Nov 12 00:05:37.615: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708": Phase="Running", Reason="", readiness=true. Elapsed: 2.051540284s
    Nov 12 00:05:37.615: INFO: Pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" satisfied condition "running"
    STEP: deleting the pod gracefully 11/12/22 00:05:37.615
    Nov 12 00:05:37.616: INFO: Deleting pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" in namespace "var-expansion-2696"
    Nov 12 00:05:37.655: INFO: Wait up to 5m0s for pod "var-expansion-65e7612e-8db4-4c67-a751-8a8e1f399708" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 00:06:09.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2696" for this suite. 11/12/22 00:06:09.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:06:09.851
Nov 12 00:06:09.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename lease-test 11/12/22 00:06:09.855
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:09.921
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:09.94
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Nov 12 00:06:10.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4271" for this suite. 11/12/22 00:06:10.417
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":197,"skipped":3815,"failed":0}
------------------------------
• [0.595 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:06:09.851
    Nov 12 00:06:09.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename lease-test 11/12/22 00:06:09.855
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:09.921
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:09.94
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Nov 12 00:06:10.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-4271" for this suite. 11/12/22 00:06:10.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:06:10.454
Nov 12 00:06:10.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:06:10.456
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:10.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:10.542
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6042.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6042.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 11/12/22 00:06:10.567
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6042.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6042.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 11/12/22 00:06:10.568
STEP: creating a pod to probe /etc/hosts 11/12/22 00:06:10.568
STEP: submitting the pod to kubernetes 11/12/22 00:06:10.569
Nov 12 00:06:10.600: INFO: Waiting up to 15m0s for pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e" in namespace "dns-6042" to be "running"
Nov 12 00:06:10.616: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.102354ms
Nov 12 00:06:12.635: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03490538s
Nov 12 00:06:14.660: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Running", Reason="", readiness=true. Elapsed: 4.060702004s
Nov 12 00:06:14.661: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e" satisfied condition "running"
STEP: retrieving the pod 11/12/22 00:06:14.661
STEP: looking for the results for each expected name from probers 11/12/22 00:06:14.68
Nov 12 00:06:14.838: INFO: DNS probes using dns-6042/dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e succeeded

STEP: deleting the pod 11/12/22 00:06:14.838
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:06:14.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6042" for this suite. 11/12/22 00:06:14.978
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":198,"skipped":3837,"failed":0}
------------------------------
• [4.583 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:06:10.454
    Nov 12 00:06:10.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:06:10.456
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:10.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:10.542
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6042.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6042.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     11/12/22 00:06:10.567
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6042.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6042.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     11/12/22 00:06:10.568
    STEP: creating a pod to probe /etc/hosts 11/12/22 00:06:10.568
    STEP: submitting the pod to kubernetes 11/12/22 00:06:10.569
    Nov 12 00:06:10.600: INFO: Waiting up to 15m0s for pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e" in namespace "dns-6042" to be "running"
    Nov 12 00:06:10.616: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.102354ms
    Nov 12 00:06:12.635: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03490538s
    Nov 12 00:06:14.660: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e": Phase="Running", Reason="", readiness=true. Elapsed: 4.060702004s
    Nov 12 00:06:14.661: INFO: Pod "dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 00:06:14.661
    STEP: looking for the results for each expected name from probers 11/12/22 00:06:14.68
    Nov 12 00:06:14.838: INFO: DNS probes using dns-6042/dns-test-3f1a50b3-7875-436b-9645-06d9e7d9293e succeeded

    STEP: deleting the pod 11/12/22 00:06:14.838
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:06:14.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6042" for this suite. 11/12/22 00:06:14.978
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:06:15.038
Nov 12 00:06:15.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename prestop 11/12/22 00:06:15.041
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:15.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:15.106
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-3157 11/12/22 00:06:15.129
STEP: Waiting for pods to come up. 11/12/22 00:06:15.161
Nov 12 00:06:15.161: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-3157" to be "running"
Nov 12 00:06:15.193: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 31.866489ms
Nov 12 00:06:17.207: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045621211s
Nov 12 00:06:19.235: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.073800292s
Nov 12 00:06:19.235: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-3157 11/12/22 00:06:19.246
Nov 12 00:06:19.265: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-3157" to be "running"
Nov 12 00:06:19.304: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 38.687734ms
Nov 12 00:06:21.321: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056130999s
Nov 12 00:06:23.325: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.059458054s
Nov 12 00:06:23.325: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 11/12/22 00:06:23.325
Nov 12 00:06:28.407: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 11/12/22 00:06:28.407
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Nov 12 00:06:28.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3157" for this suite. 11/12/22 00:06:28.49
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":199,"skipped":3840,"failed":0}
------------------------------
• [SLOW TEST] [13.480 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:06:15.038
    Nov 12 00:06:15.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename prestop 11/12/22 00:06:15.041
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:15.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:15.106
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-3157 11/12/22 00:06:15.129
    STEP: Waiting for pods to come up. 11/12/22 00:06:15.161
    Nov 12 00:06:15.161: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-3157" to be "running"
    Nov 12 00:06:15.193: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 31.866489ms
    Nov 12 00:06:17.207: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045621211s
    Nov 12 00:06:19.235: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.073800292s
    Nov 12 00:06:19.235: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-3157 11/12/22 00:06:19.246
    Nov 12 00:06:19.265: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-3157" to be "running"
    Nov 12 00:06:19.304: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 38.687734ms
    Nov 12 00:06:21.321: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056130999s
    Nov 12 00:06:23.325: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.059458054s
    Nov 12 00:06:23.325: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 11/12/22 00:06:23.325
    Nov 12 00:06:28.407: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 11/12/22 00:06:28.407
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Nov 12 00:06:28.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-3157" for this suite. 11/12/22 00:06:28.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:06:28.521
Nov 12 00:06:28.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename taint-multiple-pods 11/12/22 00:06:28.524
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:28.592
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:28.61
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Nov 12 00:06:28.632: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 00:07:28.785: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Nov 12 00:07:28.803: INFO: Starting informer...
STEP: Starting pods... 11/12/22 00:07:28.803
Nov 12 00:07:29.105: INFO: Pod1 is running on 10.184.98.55. Tainting Node
Nov 12 00:07:29.351: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7153" to be "running"
Nov 12 00:07:29.365: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.270768ms
Nov 12 00:07:31.380: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029798227s
Nov 12 00:07:33.381: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.03023182s
Nov 12 00:07:33.381: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Nov 12 00:07:33.381: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7153" to be "running"
Nov 12 00:07:33.395: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 14.10701ms
Nov 12 00:07:33.395: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Nov 12 00:07:33.395: INFO: Pod2 is running on 10.184.98.55. Tainting Node
STEP: Trying to apply a taint on the Node 11/12/22 00:07:33.395
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:07:33.441
STEP: Waiting for Pod1 and Pod2 to be deleted 11/12/22 00:07:33.463
Nov 12 00:07:39.958: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 12 00:08:00.102: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:08:00.16
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:08:00.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7153" for this suite. 11/12/22 00:08:00.205
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":200,"skipped":3847,"failed":0}
------------------------------
• [SLOW TEST] [91.716 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:06:28.521
    Nov 12 00:06:28.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename taint-multiple-pods 11/12/22 00:06:28.524
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:06:28.592
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:06:28.61
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Nov 12 00:06:28.632: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 00:07:28.785: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Nov 12 00:07:28.803: INFO: Starting informer...
    STEP: Starting pods... 11/12/22 00:07:28.803
    Nov 12 00:07:29.105: INFO: Pod1 is running on 10.184.98.55. Tainting Node
    Nov 12 00:07:29.351: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-7153" to be "running"
    Nov 12 00:07:29.365: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.270768ms
    Nov 12 00:07:31.380: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029798227s
    Nov 12 00:07:33.381: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.03023182s
    Nov 12 00:07:33.381: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Nov 12 00:07:33.381: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-7153" to be "running"
    Nov 12 00:07:33.395: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 14.10701ms
    Nov 12 00:07:33.395: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Nov 12 00:07:33.395: INFO: Pod2 is running on 10.184.98.55. Tainting Node
    STEP: Trying to apply a taint on the Node 11/12/22 00:07:33.395
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:07:33.441
    STEP: Waiting for Pod1 and Pod2 to be deleted 11/12/22 00:07:33.463
    Nov 12 00:07:39.958: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Nov 12 00:08:00.102: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:08:00.16
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:08:00.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-7153" for this suite. 11/12/22 00:08:00.205
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:08:00.243
Nov 12 00:08:00.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:08:00.245
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:00.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:00.313
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:08:00.333
Nov 12 00:08:00.365: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642" in namespace "downward-api-1363" to be "Succeeded or Failed"
Nov 12 00:08:00.380: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 14.34972ms
Nov 12 00:08:02.396: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030467099s
Nov 12 00:08:04.395: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029879672s
Nov 12 00:08:06.395: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029987787s
STEP: Saw pod success 11/12/22 00:08:06.396
Nov 12 00:08:06.397: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642" satisfied condition "Succeeded or Failed"
Nov 12 00:08:06.415: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 container client-container: <nil>
STEP: delete the pod 11/12/22 00:08:06.507
Nov 12 00:08:06.542: INFO: Waiting for pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 to disappear
Nov 12 00:08:06.559: INFO: Pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:08:06.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1363" for this suite. 11/12/22 00:08:06.585
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":201,"skipped":3852,"failed":0}
------------------------------
• [SLOW TEST] [6.375 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:08:00.243
    Nov 12 00:08:00.243: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:08:00.245
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:00.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:00.313
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:08:00.333
    Nov 12 00:08:00.365: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642" in namespace "downward-api-1363" to be "Succeeded or Failed"
    Nov 12 00:08:00.380: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 14.34972ms
    Nov 12 00:08:02.396: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030467099s
    Nov 12 00:08:04.395: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029879672s
    Nov 12 00:08:06.395: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029987787s
    STEP: Saw pod success 11/12/22 00:08:06.396
    Nov 12 00:08:06.397: INFO: Pod "downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642" satisfied condition "Succeeded or Failed"
    Nov 12 00:08:06.415: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 container client-container: <nil>
    STEP: delete the pod 11/12/22 00:08:06.507
    Nov 12 00:08:06.542: INFO: Waiting for pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 to disappear
    Nov 12 00:08:06.559: INFO: Pod downwardapi-volume-6e4dbcd0-3fbb-43a6-8513-0368c47d8642 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:08:06.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1363" for this suite. 11/12/22 00:08:06.585
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:08:06.622
Nov 12 00:08:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:08:06.624
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:06.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:06.712
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 11/12/22 00:08:06.731
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6880;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6880;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +notcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_tcp@PTR;sleep 1; done
 11/12/22 00:08:06.784
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6880;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6880;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +notcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_tcp@PTR;sleep 1; done
 11/12/22 00:08:06.785
STEP: creating a pod to probe DNS 11/12/22 00:08:06.785
STEP: submitting the pod to kubernetes 11/12/22 00:08:06.785
Nov 12 00:08:06.822: INFO: Waiting up to 15m0s for pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea" in namespace "dns-6880" to be "running"
Nov 12 00:08:06.845: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 22.703263ms
Nov 12 00:08:08.863: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040275674s
Nov 12 00:08:10.861: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Running", Reason="", readiness=true. Elapsed: 4.038901019s
Nov 12 00:08:10.861: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea" satisfied condition "running"
STEP: retrieving the pod 11/12/22 00:08:10.861
STEP: looking for the results for each expected name from probers 11/12/22 00:08:10.878
Nov 12 00:08:10.923: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:10.958: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:10.977: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:10.996: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.015: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.033: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.052: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.073: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.175: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.197: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.226: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.244: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.263: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.282: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.301: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.319: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:11.404: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:16.428: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.447: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.467: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.485: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.505: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.523: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.543: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.568: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.680: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.698: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.715: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.769: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.788: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.806: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.825: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:16.916: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:21.428: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.446: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.464: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.484: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.502: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.520: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.540: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.559: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.665: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.684: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.702: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.754: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.772: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.790: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.809: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:21.883: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:26.435: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.461: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.479: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.498: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.517: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.535: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.553: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.571: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.688: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.708: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.735: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.754: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.771: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.790: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.810: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.828: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:26.903: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:31.426: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.447: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.466: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.486: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.506: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.525: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.545: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.565: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.660: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.679: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.698: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.737: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.755: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.775: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:31.869: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:36.425: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.445: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.464: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.481: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.521: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.545: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.564: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.673: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.694: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.715: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.760: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.779: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.799: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.824: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
Nov 12 00:08:36.904: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

Nov 12 00:08:41.948: INFO: DNS probes using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea succeeded

STEP: deleting the pod 11/12/22 00:08:41.948
STEP: deleting the test service 11/12/22 00:08:42.02
STEP: deleting the test headless service 11/12/22 00:08:42.084
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:08:42.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6880" for this suite. 11/12/22 00:08:42.181
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":202,"skipped":3862,"failed":0}
------------------------------
• [SLOW TEST] [35.588 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:08:06.622
    Nov 12 00:08:06.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:08:06.624
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:06.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:06.712
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 11/12/22 00:08:06.731
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6880;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6880;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +notcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_tcp@PTR;sleep 1; done
     11/12/22 00:08:06.784
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6880;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6880;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6880.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6880.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6880.svc;check="$$(dig +notcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_udp@PTR;check="$$(dig +tcp +noall +answer +search 92.176.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.176.92_tcp@PTR;sleep 1; done
     11/12/22 00:08:06.785
    STEP: creating a pod to probe DNS 11/12/22 00:08:06.785
    STEP: submitting the pod to kubernetes 11/12/22 00:08:06.785
    Nov 12 00:08:06.822: INFO: Waiting up to 15m0s for pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea" in namespace "dns-6880" to be "running"
    Nov 12 00:08:06.845: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 22.703263ms
    Nov 12 00:08:08.863: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040275674s
    Nov 12 00:08:10.861: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea": Phase="Running", Reason="", readiness=true. Elapsed: 4.038901019s
    Nov 12 00:08:10.861: INFO: Pod "dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 00:08:10.861
    STEP: looking for the results for each expected name from probers 11/12/22 00:08:10.878
    Nov 12 00:08:10.923: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:10.958: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:10.977: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:10.996: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.015: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.033: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.052: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.073: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.175: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.197: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.226: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.244: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.263: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.282: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.301: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.319: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:11.404: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:16.428: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.447: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.467: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.485: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.505: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.523: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.543: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.568: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.680: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.698: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.715: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.769: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.788: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.806: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.825: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:16.916: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:21.428: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.446: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.464: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.484: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.502: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.520: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.540: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.559: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.665: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.684: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.702: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.754: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.772: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.790: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.809: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:21.883: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:26.435: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.461: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.479: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.498: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.517: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.535: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.553: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.571: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.688: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.708: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.735: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.754: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.771: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.790: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.810: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.828: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:26.903: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:31.426: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.447: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.466: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.486: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.506: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.525: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.545: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.565: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.660: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.679: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.698: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.737: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.755: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.775: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.795: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:31.869: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:36.425: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.445: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.464: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.481: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.521: INFO: Unable to read wheezy_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.545: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.564: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.673: INFO: Unable to read jessie_udp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.694: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.715: INFO: Unable to read jessie_udp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.735: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880 from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.760: INFO: Unable to read jessie_udp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.779: INFO: Unable to read jessie_tcp@dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.799: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.824: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc from pod dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea: the server could not find the requested resource (get pods dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea)
    Nov 12 00:08:36.904: INFO: Lookups using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-6880 wheezy_tcp@dns-test-service.dns-6880 wheezy_udp@dns-test-service.dns-6880.svc wheezy_tcp@dns-test-service.dns-6880.svc wheezy_udp@_http._tcp.dns-test-service.dns-6880.svc wheezy_tcp@_http._tcp.dns-test-service.dns-6880.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6880 jessie_tcp@dns-test-service.dns-6880 jessie_udp@dns-test-service.dns-6880.svc jessie_tcp@dns-test-service.dns-6880.svc jessie_udp@_http._tcp.dns-test-service.dns-6880.svc jessie_tcp@_http._tcp.dns-test-service.dns-6880.svc]

    Nov 12 00:08:41.948: INFO: DNS probes using dns-6880/dns-test-900d4860-dbaa-4926-9a07-43f5264dd3ea succeeded

    STEP: deleting the pod 11/12/22 00:08:41.948
    STEP: deleting the test service 11/12/22 00:08:42.02
    STEP: deleting the test headless service 11/12/22 00:08:42.084
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:08:42.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6880" for this suite. 11/12/22 00:08:42.181
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:08:42.213
Nov 12 00:08:42.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:08:42.216
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:42.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:42.313
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-8d20cd35-0d60-43d3-b477-38407b8e28b7 11/12/22 00:08:42.335
STEP: Creating a pod to test consume secrets 11/12/22 00:08:42.357
Nov 12 00:08:42.393: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d" in namespace "projected-279" to be "Succeeded or Failed"
Nov 12 00:08:42.408: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.501459ms
Nov 12 00:08:44.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Running", Reason="", readiness=true. Elapsed: 2.030642206s
Nov 12 00:08:46.427: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Running", Reason="", readiness=false. Elapsed: 4.033448726s
Nov 12 00:08:48.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03039592s
STEP: Saw pod success 11/12/22 00:08:48.424
Nov 12 00:08:48.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d" satisfied condition "Succeeded or Failed"
Nov 12 00:08:48.439: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:08:48.471
Nov 12 00:08:48.513: INFO: Waiting for pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d to disappear
Nov 12 00:08:48.572: INFO: Pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 00:08:48.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-279" for this suite. 11/12/22 00:08:48.603
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":203,"skipped":3880,"failed":0}
------------------------------
• [SLOW TEST] [6.428 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:08:42.213
    Nov 12 00:08:42.213: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:08:42.216
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:42.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:42.313
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-8d20cd35-0d60-43d3-b477-38407b8e28b7 11/12/22 00:08:42.335
    STEP: Creating a pod to test consume secrets 11/12/22 00:08:42.357
    Nov 12 00:08:42.393: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d" in namespace "projected-279" to be "Succeeded or Failed"
    Nov 12 00:08:42.408: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.501459ms
    Nov 12 00:08:44.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Running", Reason="", readiness=true. Elapsed: 2.030642206s
    Nov 12 00:08:46.427: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Running", Reason="", readiness=false. Elapsed: 4.033448726s
    Nov 12 00:08:48.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03039592s
    STEP: Saw pod success 11/12/22 00:08:48.424
    Nov 12 00:08:48.424: INFO: Pod "pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d" satisfied condition "Succeeded or Failed"
    Nov 12 00:08:48.439: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:08:48.471
    Nov 12 00:08:48.513: INFO: Waiting for pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d to disappear
    Nov 12 00:08:48.572: INFO: Pod pod-projected-secrets-4ae7573c-ff3f-40da-9cc5-a7d8d4b5a24d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 00:08:48.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-279" for this suite. 11/12/22 00:08:48.603
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:08:48.644
Nov 12 00:08:48.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/12/22 00:08:48.645
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:48.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:48.708
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 11/12/22 00:08:48.724
Nov 12 00:08:48.762: INFO: Waiting up to 5m0s for pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718" in namespace "var-expansion-6031" to be "Succeeded or Failed"
Nov 12 00:08:48.776: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 13.855561ms
Nov 12 00:08:50.789: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027077359s
Nov 12 00:08:52.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028936069s
Nov 12 00:08:54.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028644855s
STEP: Saw pod success 11/12/22 00:08:54.791
Nov 12 00:08:54.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718" satisfied condition "Succeeded or Failed"
Nov 12 00:08:54.806: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 container dapi-container: <nil>
STEP: delete the pod 11/12/22 00:08:54.838
Nov 12 00:08:54.875: INFO: Waiting for pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 to disappear
Nov 12 00:08:54.889: INFO: Pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 00:08:54.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6031" for this suite. 11/12/22 00:08:54.918
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":204,"skipped":3910,"failed":0}
------------------------------
• [SLOW TEST] [6.300 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:08:48.644
    Nov 12 00:08:48.644: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/12/22 00:08:48.645
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:48.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:48.708
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 11/12/22 00:08:48.724
    Nov 12 00:08:48.762: INFO: Waiting up to 5m0s for pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718" in namespace "var-expansion-6031" to be "Succeeded or Failed"
    Nov 12 00:08:48.776: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 13.855561ms
    Nov 12 00:08:50.789: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027077359s
    Nov 12 00:08:52.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028936069s
    Nov 12 00:08:54.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028644855s
    STEP: Saw pod success 11/12/22 00:08:54.791
    Nov 12 00:08:54.791: INFO: Pod "var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718" satisfied condition "Succeeded or Failed"
    Nov 12 00:08:54.806: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 00:08:54.838
    Nov 12 00:08:54.875: INFO: Waiting for pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 to disappear
    Nov 12 00:08:54.889: INFO: Pod var-expansion-6c0289c6-fc65-42ca-898f-c2bc99dc7718 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 00:08:54.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6031" for this suite. 11/12/22 00:08:54.918
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:08:54.945
Nov 12 00:08:54.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:08:54.948
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:54.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:55.013
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 11/12/22 00:08:55.03
Nov 12 00:08:55.073: INFO: created test-pod-1
Nov 12 00:08:55.090: INFO: created test-pod-2
Nov 12 00:08:55.107: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 11/12/22 00:08:55.107
Nov 12 00:08:55.107: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6777' to be running and ready
Nov 12 00:08:55.151: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:55.151: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:55.151: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:55.151: INFO: 0 / 3 pods in namespace 'pods-6777' are running and ready (0 seconds elapsed)
Nov 12 00:08:55.151: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
Nov 12 00:08:55.151: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
Nov 12 00:08:55.151: INFO: test-pod-1  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:55.151: INFO: test-pod-2  10.184.98.55  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:55.151: INFO: test-pod-3  10.184.98.55  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:55.151: INFO: 
Nov 12 00:08:57.195: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:57.195: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:57.195: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 00:08:57.195: INFO: 0 / 3 pods in namespace 'pods-6777' are running and ready (2 seconds elapsed)
Nov 12 00:08:57.196: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
Nov 12 00:08:57.196: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
Nov 12 00:08:57.196: INFO: test-pod-1  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:57.196: INFO: test-pod-2  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:57.196: INFO: test-pod-3  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
Nov 12 00:08:57.196: INFO: 
Nov 12 00:08:59.195: INFO: 3 / 3 pods in namespace 'pods-6777' are running and ready (4 seconds elapsed)
Nov 12 00:08:59.195: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 11/12/22 00:08:59.285
Nov 12 00:08:59.298: INFO: Pod quantity 3 is different from expected quantity 0
Nov 12 00:09:00.314: INFO: Pod quantity 3 is different from expected quantity 0
Nov 12 00:09:01.315: INFO: Pod quantity 3 is different from expected quantity 0
Nov 12 00:09:02.324: INFO: Pod quantity 2 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:09:03.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6777" for this suite. 11/12/22 00:09:03.35
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":205,"skipped":3920,"failed":0}
------------------------------
• [SLOW TEST] [8.438 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:08:54.945
    Nov 12 00:08:54.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:08:54.948
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:08:54.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:08:55.013
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 11/12/22 00:08:55.03
    Nov 12 00:08:55.073: INFO: created test-pod-1
    Nov 12 00:08:55.090: INFO: created test-pod-2
    Nov 12 00:08:55.107: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 11/12/22 00:08:55.107
    Nov 12 00:08:55.107: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-6777' to be running and ready
    Nov 12 00:08:55.151: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:55.151: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:55.151: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:55.151: INFO: 0 / 3 pods in namespace 'pods-6777' are running and ready (0 seconds elapsed)
    Nov 12 00:08:55.151: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
    Nov 12 00:08:55.151: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
    Nov 12 00:08:55.151: INFO: test-pod-1  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:55.151: INFO: test-pod-2  10.184.98.55  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:55.151: INFO: test-pod-3  10.184.98.55  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:55.151: INFO: 
    Nov 12 00:08:57.195: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:57.195: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:57.195: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 00:08:57.195: INFO: 0 / 3 pods in namespace 'pods-6777' are running and ready (2 seconds elapsed)
    Nov 12 00:08:57.196: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
    Nov 12 00:08:57.196: INFO: POD         NODE          PHASE    GRACE  CONDITIONS
    Nov 12 00:08:57.196: INFO: test-pod-1  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:57.196: INFO: test-pod-2  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:57.196: INFO: test-pod-3  10.184.98.55  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 00:08:55 +0000 UTC  }]
    Nov 12 00:08:57.196: INFO: 
    Nov 12 00:08:59.195: INFO: 3 / 3 pods in namespace 'pods-6777' are running and ready (4 seconds elapsed)
    Nov 12 00:08:59.195: INFO: expected 0 pod replicas in namespace 'pods-6777', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 11/12/22 00:08:59.285
    Nov 12 00:08:59.298: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 12 00:09:00.314: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 12 00:09:01.315: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 12 00:09:02.324: INFO: Pod quantity 2 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:09:03.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6777" for this suite. 11/12/22 00:09:03.35
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:09:03.387
Nov 12 00:09:03.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:09:03.389
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:03.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:03.466
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Nov 12 00:09:03.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: creating the pod 11/12/22 00:09:03.487
STEP: submitting the pod to kubernetes 11/12/22 00:09:03.488
Nov 12 00:09:03.519: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9" in namespace "pods-7259" to be "running and ready"
Nov 12 00:09:03.533: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.065566ms
Nov 12 00:09:03.534: INFO: The phase of Pod pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:09:05.549: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.029581555s
Nov 12 00:09:05.549: INFO: The phase of Pod pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9 is Running (Ready = true)
Nov 12 00:09:05.549: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:09:05.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7259" for this suite. 11/12/22 00:09:05.655
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":206,"skipped":3935,"failed":0}
------------------------------
• [2.333 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:09:03.387
    Nov 12 00:09:03.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:09:03.389
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:03.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:03.466
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Nov 12 00:09:03.485: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: creating the pod 11/12/22 00:09:03.487
    STEP: submitting the pod to kubernetes 11/12/22 00:09:03.488
    Nov 12 00:09:03.519: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9" in namespace "pods-7259" to be "running and ready"
    Nov 12 00:09:03.533: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.065566ms
    Nov 12 00:09:03.534: INFO: The phase of Pod pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:09:05.549: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.029581555s
    Nov 12 00:09:05.549: INFO: The phase of Pod pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9 is Running (Ready = true)
    Nov 12 00:09:05.549: INFO: Pod "pod-logs-websocket-1771b7c2-623b-4286-94e9-371a99a408b9" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:09:05.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7259" for this suite. 11/12/22 00:09:05.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:09:05.723
Nov 12 00:09:05.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:09:05.724
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:05.779
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:05.795
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 11/12/22 00:09:05.817
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_tcp@PTR;sleep 1; done
 11/12/22 00:09:05.876
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_tcp@PTR;sleep 1; done
 11/12/22 00:09:05.876
STEP: creating a pod to probe DNS 11/12/22 00:09:05.877
STEP: submitting the pod to kubernetes 11/12/22 00:09:05.877
Nov 12 00:09:05.928: INFO: Waiting up to 15m0s for pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f" in namespace "dns-5220" to be "running"
Nov 12 00:09:05.956: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.268839ms
Nov 12 00:09:07.972: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044422804s
Nov 12 00:09:09.979: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Running", Reason="", readiness=true. Elapsed: 4.050915017s
Nov 12 00:09:09.979: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f" satisfied condition "running"
STEP: retrieving the pod 11/12/22 00:09:09.979
STEP: looking for the results for each expected name from probers 11/12/22 00:09:09.997
Nov 12 00:09:10.098: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.140: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.269: INFO: Unable to read jessie_udp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.296: INFO: Unable to read jessie_tcp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.316: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.336: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:10.412: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@dns-test-service.dns-5220.svc.cluster.local jessie_tcp@dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:15.471: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:15.491: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:15.636: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:15.655: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:15.745: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:20.473: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:20.494: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:20.631: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:20.651: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:20.753: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:25.474: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:25.491: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:25.638: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:25.658: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:25.744: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:30.474: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:30.495: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:30.684: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:30.703: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:30.792: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:35.471: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:35.490: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:35.630: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:35.649: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
Nov 12 00:09:35.724: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

Nov 12 00:09:40.720: INFO: DNS probes using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f succeeded

STEP: deleting the pod 11/12/22 00:09:40.72
STEP: deleting the test service 11/12/22 00:09:40.766
STEP: deleting the test headless service 11/12/22 00:09:40.862
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:09:40.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5220" for this suite. 11/12/22 00:09:40.987
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":207,"skipped":3957,"failed":0}
------------------------------
• [SLOW TEST] [35.318 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:09:05.723
    Nov 12 00:09:05.724: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:09:05.724
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:05.779
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:05.795
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 11/12/22 00:09:05.817
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_tcp@PTR;sleep 1; done
     11/12/22 00:09:05.876
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5220.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5220.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5220.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_udp@PTR;check="$$(dig +tcp +noall +answer +search 177.207.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.207.177_tcp@PTR;sleep 1; done
     11/12/22 00:09:05.876
    STEP: creating a pod to probe DNS 11/12/22 00:09:05.877
    STEP: submitting the pod to kubernetes 11/12/22 00:09:05.877
    Nov 12 00:09:05.928: INFO: Waiting up to 15m0s for pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f" in namespace "dns-5220" to be "running"
    Nov 12 00:09:05.956: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.268839ms
    Nov 12 00:09:07.972: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044422804s
    Nov 12 00:09:09.979: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f": Phase="Running", Reason="", readiness=true. Elapsed: 4.050915017s
    Nov 12 00:09:09.979: INFO: Pod "dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 00:09:09.979
    STEP: looking for the results for each expected name from probers 11/12/22 00:09:09.997
    Nov 12 00:09:10.098: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.140: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.269: INFO: Unable to read jessie_udp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.296: INFO: Unable to read jessie_tcp@dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.316: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.336: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:10.412: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_tcp@dns-test-service.dns-5220.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@dns-test-service.dns-5220.svc.cluster.local jessie_tcp@dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:15.471: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:15.491: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:15.636: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:15.655: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:15.745: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:20.473: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:20.494: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:20.631: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:20.651: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:20.753: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:25.474: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:25.491: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:25.638: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:25.658: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:25.744: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:30.474: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:30.495: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:30.684: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:30.703: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:30.792: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:35.471: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:35.490: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:35.630: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:35.649: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local from pod dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f: the server could not find the requested resource (get pods dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f)
    Nov 12 00:09:35.724: INFO: Lookups using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5220.svc.cluster.local]

    Nov 12 00:09:40.720: INFO: DNS probes using dns-5220/dns-test-73baea79-6e22-4c71-8af6-9c75de4f251f succeeded

    STEP: deleting the pod 11/12/22 00:09:40.72
    STEP: deleting the test service 11/12/22 00:09:40.766
    STEP: deleting the test headless service 11/12/22 00:09:40.862
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:09:40.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5220" for this suite. 11/12/22 00:09:40.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:09:41.043
Nov 12 00:09:41.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:09:41.045
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:41.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:41.137
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:09:41.178
Nov 12 00:09:41.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707" in namespace "projected-4175" to be "Succeeded or Failed"
Nov 12 00:09:41.233: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 17.570367ms
Nov 12 00:09:43.248: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032567862s
Nov 12 00:09:45.246: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02988306s
Nov 12 00:09:47.248: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032438207s
STEP: Saw pod success 11/12/22 00:09:47.248
Nov 12 00:09:47.249: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707" satisfied condition "Succeeded or Failed"
Nov 12 00:09:47.264: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 container client-container: <nil>
STEP: delete the pod 11/12/22 00:09:47.296
Nov 12 00:09:47.338: INFO: Waiting for pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 to disappear
Nov 12 00:09:47.352: INFO: Pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:09:47.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4175" for this suite. 11/12/22 00:09:47.399
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":208,"skipped":3969,"failed":0}
------------------------------
• [SLOW TEST] [6.384 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:09:41.043
    Nov 12 00:09:41.044: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:09:41.045
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:41.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:41.137
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:09:41.178
    Nov 12 00:09:41.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707" in namespace "projected-4175" to be "Succeeded or Failed"
    Nov 12 00:09:41.233: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 17.570367ms
    Nov 12 00:09:43.248: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032567862s
    Nov 12 00:09:45.246: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02988306s
    Nov 12 00:09:47.248: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032438207s
    STEP: Saw pod success 11/12/22 00:09:47.248
    Nov 12 00:09:47.249: INFO: Pod "downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707" satisfied condition "Succeeded or Failed"
    Nov 12 00:09:47.264: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 container client-container: <nil>
    STEP: delete the pod 11/12/22 00:09:47.296
    Nov 12 00:09:47.338: INFO: Waiting for pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 to disappear
    Nov 12 00:09:47.352: INFO: Pod downwardapi-volume-0fd85336-03fd-4c9f-8a8b-5f00ec91a707 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:09:47.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4175" for this suite. 11/12/22 00:09:47.399
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:09:47.428
Nov 12 00:09:47.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:09:47.436
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:47.56
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:47.578
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 00:09:47.599
Nov 12 00:09:47.628: INFO: Waiting up to 5m0s for pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c" in namespace "emptydir-7561" to be "Succeeded or Failed"
Nov 12 00:09:47.643: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.293657ms
Nov 12 00:09:49.661: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032636447s
Nov 12 00:09:51.658: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029481018s
Nov 12 00:09:53.659: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030511852s
STEP: Saw pod success 11/12/22 00:09:53.659
Nov 12 00:09:53.659: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c" satisfied condition "Succeeded or Failed"
Nov 12 00:09:53.675: INFO: Trying to get logs from node 10.184.98.55 pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c container test-container: <nil>
STEP: delete the pod 11/12/22 00:09:53.705
Nov 12 00:09:53.748: INFO: Waiting for pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c to disappear
Nov 12 00:09:53.761: INFO: Pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:09:53.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7561" for this suite. 11/12/22 00:09:53.8
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":209,"skipped":3973,"failed":0}
------------------------------
• [SLOW TEST] [6.399 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:09:47.428
    Nov 12 00:09:47.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:09:47.436
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:47.56
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:47.578
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 00:09:47.599
    Nov 12 00:09:47.628: INFO: Waiting up to 5m0s for pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c" in namespace "emptydir-7561" to be "Succeeded or Failed"
    Nov 12 00:09:47.643: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.293657ms
    Nov 12 00:09:49.661: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032636447s
    Nov 12 00:09:51.658: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029481018s
    Nov 12 00:09:53.659: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030511852s
    STEP: Saw pod success 11/12/22 00:09:53.659
    Nov 12 00:09:53.659: INFO: Pod "pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c" satisfied condition "Succeeded or Failed"
    Nov 12 00:09:53.675: INFO: Trying to get logs from node 10.184.98.55 pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c container test-container: <nil>
    STEP: delete the pod 11/12/22 00:09:53.705
    Nov 12 00:09:53.748: INFO: Waiting for pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c to disappear
    Nov 12 00:09:53.761: INFO: Pod pod-e4e28ea9-c0ad-4e43-af4e-661f94d1166c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:09:53.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7561" for this suite. 11/12/22 00:09:53.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:09:53.839
Nov 12 00:09:53.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/12/22 00:09:53.841
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:53.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:53.935
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7194 11/12/22 00:09:53.948
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-7194 11/12/22 00:09:54.01
Nov 12 00:09:54.046: INFO: Found 0 stateful pods, waiting for 1
Nov 12 00:10:04.062: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 11/12/22 00:10:04.09
STEP: Getting /status 11/12/22 00:10:04.112
Nov 12 00:10:04.128: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 11/12/22 00:10:04.128
Nov 12 00:10:04.171: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 11/12/22 00:10:04.171
Nov 12 00:10:04.191: INFO: Observed &StatefulSet event: ADDED
Nov 12 00:10:04.191: INFO: Found Statefulset ss in namespace statefulset-7194 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 00:10:04.191: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 11/12/22 00:10:04.191
Nov 12 00:10:04.191: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 12 00:10:04.268: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 11/12/22 00:10:04.268
Nov 12 00:10:04.277: INFO: Observed &StatefulSet event: ADDED
Nov 12 00:10:04.277: INFO: Observed Statefulset ss in namespace statefulset-7194 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 00:10:04.278: INFO: Observed &StatefulSet event: MODIFIED
Nov 12 00:10:04.278: INFO: Found Statefulset ss in namespace statefulset-7194 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 00:10:04.279: INFO: Deleting all statefulset in ns statefulset-7194
Nov 12 00:10:04.292: INFO: Scaling statefulset ss to 0
Nov 12 00:10:14.355: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 00:10:14.368: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 00:10:14.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7194" for this suite. 11/12/22 00:10:14.454
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":210,"skipped":3988,"failed":0}
------------------------------
• [SLOW TEST] [20.641 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:09:53.839
    Nov 12 00:09:53.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/12/22 00:09:53.841
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:09:53.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:09:53.935
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7194 11/12/22 00:09:53.948
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-7194 11/12/22 00:09:54.01
    Nov 12 00:09:54.046: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 00:10:04.062: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 11/12/22 00:10:04.09
    STEP: Getting /status 11/12/22 00:10:04.112
    Nov 12 00:10:04.128: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 11/12/22 00:10:04.128
    Nov 12 00:10:04.171: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 11/12/22 00:10:04.171
    Nov 12 00:10:04.191: INFO: Observed &StatefulSet event: ADDED
    Nov 12 00:10:04.191: INFO: Found Statefulset ss in namespace statefulset-7194 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 00:10:04.191: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 11/12/22 00:10:04.191
    Nov 12 00:10:04.191: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 12 00:10:04.268: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 11/12/22 00:10:04.268
    Nov 12 00:10:04.277: INFO: Observed &StatefulSet event: ADDED
    Nov 12 00:10:04.277: INFO: Observed Statefulset ss in namespace statefulset-7194 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 00:10:04.278: INFO: Observed &StatefulSet event: MODIFIED
    Nov 12 00:10:04.278: INFO: Found Statefulset ss in namespace statefulset-7194 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 00:10:04.279: INFO: Deleting all statefulset in ns statefulset-7194
    Nov 12 00:10:04.292: INFO: Scaling statefulset ss to 0
    Nov 12 00:10:14.355: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 00:10:14.368: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 00:10:14.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7194" for this suite. 11/12/22 00:10:14.454
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:10:14.482
Nov 12 00:10:14.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename subpath 11/12/22 00:10:14.483
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:14.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:14.56
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 00:10:14.576
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-rfts 11/12/22 00:10:14.611
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:10:14.611
Nov 12 00:10:14.643: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rfts" in namespace "subpath-4802" to be "Succeeded or Failed"
Nov 12 00:10:14.657: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Pending", Reason="", readiness=false. Elapsed: 14.163388ms
Nov 12 00:10:16.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029971396s
Nov 12 00:10:18.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 4.031043538s
Nov 12 00:10:20.672: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 6.029516153s
Nov 12 00:10:22.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 8.030773833s
Nov 12 00:10:24.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 10.030939582s
Nov 12 00:10:26.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 12.03074178s
Nov 12 00:10:28.672: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 14.029245196s
Nov 12 00:10:30.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 16.0297087s
Nov 12 00:10:32.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 18.030400146s
Nov 12 00:10:34.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 20.029649681s
Nov 12 00:10:36.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 22.030608892s
Nov 12 00:10:38.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=false. Elapsed: 24.030377171s
Nov 12 00:10:40.670: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.027420683s
STEP: Saw pod success 11/12/22 00:10:40.671
Nov 12 00:10:40.671: INFO: Pod "pod-subpath-test-configmap-rfts" satisfied condition "Succeeded or Failed"
Nov 12 00:10:40.687: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-configmap-rfts container test-container-subpath-configmap-rfts: <nil>
STEP: delete the pod 11/12/22 00:10:40.723
Nov 12 00:10:40.787: INFO: Waiting for pod pod-subpath-test-configmap-rfts to disappear
Nov 12 00:10:40.802: INFO: Pod pod-subpath-test-configmap-rfts no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rfts 11/12/22 00:10:40.802
Nov 12 00:10:40.802: INFO: Deleting pod "pod-subpath-test-configmap-rfts" in namespace "subpath-4802"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 00:10:40.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4802" for this suite. 11/12/22 00:10:40.843
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":211,"skipped":4015,"failed":0}
------------------------------
• [SLOW TEST] [26.399 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:10:14.482
    Nov 12 00:10:14.482: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename subpath 11/12/22 00:10:14.483
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:14.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:14.56
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 00:10:14.576
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-rfts 11/12/22 00:10:14.611
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:10:14.611
    Nov 12 00:10:14.643: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rfts" in namespace "subpath-4802" to be "Succeeded or Failed"
    Nov 12 00:10:14.657: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Pending", Reason="", readiness=false. Elapsed: 14.163388ms
    Nov 12 00:10:16.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029971396s
    Nov 12 00:10:18.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 4.031043538s
    Nov 12 00:10:20.672: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 6.029516153s
    Nov 12 00:10:22.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 8.030773833s
    Nov 12 00:10:24.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 10.030939582s
    Nov 12 00:10:26.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 12.03074178s
    Nov 12 00:10:28.672: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 14.029245196s
    Nov 12 00:10:30.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 16.0297087s
    Nov 12 00:10:32.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 18.030400146s
    Nov 12 00:10:34.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 20.029649681s
    Nov 12 00:10:36.674: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=true. Elapsed: 22.030608892s
    Nov 12 00:10:38.673: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Running", Reason="", readiness=false. Elapsed: 24.030377171s
    Nov 12 00:10:40.670: INFO: Pod "pod-subpath-test-configmap-rfts": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.027420683s
    STEP: Saw pod success 11/12/22 00:10:40.671
    Nov 12 00:10:40.671: INFO: Pod "pod-subpath-test-configmap-rfts" satisfied condition "Succeeded or Failed"
    Nov 12 00:10:40.687: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-configmap-rfts container test-container-subpath-configmap-rfts: <nil>
    STEP: delete the pod 11/12/22 00:10:40.723
    Nov 12 00:10:40.787: INFO: Waiting for pod pod-subpath-test-configmap-rfts to disappear
    Nov 12 00:10:40.802: INFO: Pod pod-subpath-test-configmap-rfts no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-rfts 11/12/22 00:10:40.802
    Nov 12 00:10:40.802: INFO: Deleting pod "pod-subpath-test-configmap-rfts" in namespace "subpath-4802"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 00:10:40.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4802" for this suite. 11/12/22 00:10:40.843
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:10:40.889
Nov 12 00:10:40.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:10:40.891
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:40.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:40.996
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 11/12/22 00:10:41.014
STEP: submitting the pod to kubernetes 11/12/22 00:10:41.014
Nov 12 00:10:41.050: INFO: Waiting up to 5m0s for pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" in namespace "pods-7923" to be "running and ready"
Nov 12 00:10:41.067: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.028447ms
Nov 12 00:10:41.067: INFO: The phase of Pod pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:10:43.097: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Running", Reason="", readiness=true. Elapsed: 2.047115891s
Nov 12 00:10:43.097: INFO: The phase of Pod pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0 is Running (Ready = true)
Nov 12 00:10:43.097: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/12/22 00:10:43.11
STEP: updating the pod 11/12/22 00:10:43.124
Nov 12 00:10:43.661: INFO: Successfully updated pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0"
Nov 12 00:10:43.661: INFO: Waiting up to 5m0s for pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" in namespace "pods-7923" to be "running"
Nov 12 00:10:43.675: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Running", Reason="", readiness=true. Elapsed: 14.365723ms
Nov 12 00:10:43.675: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 11/12/22 00:10:43.675
Nov 12 00:10:43.689: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:10:43.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7923" for this suite. 11/12/22 00:10:43.719
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":212,"skipped":4044,"failed":0}
------------------------------
• [2.858 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:10:40.889
    Nov 12 00:10:40.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:10:40.891
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:40.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:40.996
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 11/12/22 00:10:41.014
    STEP: submitting the pod to kubernetes 11/12/22 00:10:41.014
    Nov 12 00:10:41.050: INFO: Waiting up to 5m0s for pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" in namespace "pods-7923" to be "running and ready"
    Nov 12 00:10:41.067: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.028447ms
    Nov 12 00:10:41.067: INFO: The phase of Pod pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:10:43.097: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Running", Reason="", readiness=true. Elapsed: 2.047115891s
    Nov 12 00:10:43.097: INFO: The phase of Pod pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0 is Running (Ready = true)
    Nov 12 00:10:43.097: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/12/22 00:10:43.11
    STEP: updating the pod 11/12/22 00:10:43.124
    Nov 12 00:10:43.661: INFO: Successfully updated pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0"
    Nov 12 00:10:43.661: INFO: Waiting up to 5m0s for pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" in namespace "pods-7923" to be "running"
    Nov 12 00:10:43.675: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0": Phase="Running", Reason="", readiness=true. Elapsed: 14.365723ms
    Nov 12 00:10:43.675: INFO: Pod "pod-update-0659cb12-c07d-4926-82a4-cab3d627dde0" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 11/12/22 00:10:43.675
    Nov 12 00:10:43.689: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:10:43.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7923" for this suite. 11/12/22 00:10:43.719
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:10:43.751
Nov 12 00:10:43.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename job 11/12/22 00:10:43.753
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:43.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:43.833
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 11/12/22 00:10:43.867
STEP: Patching the Job 11/12/22 00:10:43.887
STEP: Watching for Job to be patched 11/12/22 00:10:43.929
Nov 12 00:10:43.939: INFO: Event ADDED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 12 00:10:43.939: INFO: Event MODIFIED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 11/12/22 00:10:43.939
STEP: Watching for Job to be updated 11/12/22 00:10:44.056
Nov 12 00:10:44.065: INFO: Event MODIFIED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:44.065: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 11/12/22 00:10:44.066
Nov 12 00:10:44.083: INFO: Job: e2e-vhxjj as labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched]
STEP: Waiting for job to complete 11/12/22 00:10:44.083
STEP: Delete a job collection with a labelselector 11/12/22 00:10:56.101
STEP: Watching for Job to be deleted 11/12/22 00:10:56.135
Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.145: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.148: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.149: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.149: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 00:10:56.149: INFO: Event DELETED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 11/12/22 00:10:56.15
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 00:10:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8616" for this suite. 11/12/22 00:10:56.198
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":213,"skipped":4079,"failed":0}
------------------------------
• [SLOW TEST] [12.475 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:10:43.751
    Nov 12 00:10:43.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename job 11/12/22 00:10:43.753
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:43.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:43.833
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 11/12/22 00:10:43.867
    STEP: Patching the Job 11/12/22 00:10:43.887
    STEP: Watching for Job to be patched 11/12/22 00:10:43.929
    Nov 12 00:10:43.939: INFO: Event ADDED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 12 00:10:43.939: INFO: Event MODIFIED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 11/12/22 00:10:43.939
    STEP: Watching for Job to be updated 11/12/22 00:10:44.056
    Nov 12 00:10:44.065: INFO: Event MODIFIED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:44.065: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 11/12/22 00:10:44.066
    Nov 12 00:10:44.083: INFO: Job: e2e-vhxjj as labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched]
    STEP: Waiting for job to complete 11/12/22 00:10:44.083
    STEP: Delete a job collection with a labelselector 11/12/22 00:10:56.101
    STEP: Watching for Job to be deleted 11/12/22 00:10:56.135
    Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.144: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.145: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.148: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.149: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.149: INFO: Event MODIFIED observed for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 00:10:56.149: INFO: Event DELETED found for Job e2e-vhxjj in namespace job-8616 with labels: map[e2e-job-label:e2e-vhxjj e2e-vhxjj:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 11/12/22 00:10:56.15
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 00:10:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8616" for this suite. 11/12/22 00:10:56.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:10:56.229
Nov 12 00:10:56.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/12/22 00:10:56.232
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:56.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:56.327
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 11/12/22 00:10:56.464
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:10:56.484
Nov 12 00:10:56.527: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:10:56.527: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:10:57.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:10:57.571: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:10:58.573: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:10:58.574: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:10:59.578: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 00:10:59.578: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 11/12/22 00:10:59.591
Nov 12 00:10:59.610: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 11/12/22 00:10:59.61
Nov 12 00:10:59.643: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 11/12/22 00:10:59.643
Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: ADDED
Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.654: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.654: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.655: INFO: Found daemon set daemon-set in namespace daemonsets-5451 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 00:10:59.655: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 11/12/22 00:10:59.655
STEP: watching for the daemon set status to be patched 11/12/22 00:10:59.676
Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: ADDED
Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.686: INFO: Observed daemon set daemon-set in namespace daemonsets-5451 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 00:10:59.686: INFO: Found daemon set daemon-set in namespace daemonsets-5451 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Nov 12 00:10:59.686: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 00:10:59.701
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5451, will wait for the garbage collector to delete the pods 11/12/22 00:10:59.701
Nov 12 00:10:59.792: INFO: Deleting DaemonSet.extensions daemon-set took: 26.499892ms
Nov 12 00:10:59.893: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.969002ms
Nov 12 00:11:03.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:11:03.407: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 00:11:03.422: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"37611"},"items":null}

Nov 12 00:11:03.435: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"37611"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:11:03.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5451" for this suite. 11/12/22 00:11:03.542
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":214,"skipped":4097,"failed":0}
------------------------------
• [SLOW TEST] [7.341 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:10:56.229
    Nov 12 00:10:56.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/12/22 00:10:56.232
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:10:56.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:10:56.327
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 11/12/22 00:10:56.464
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:10:56.484
    Nov 12 00:10:56.527: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:10:56.527: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:10:57.571: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:10:57.571: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:10:58.573: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:10:58.574: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:10:59.578: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 00:10:59.578: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 11/12/22 00:10:59.591
    Nov 12 00:10:59.610: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 11/12/22 00:10:59.61
    Nov 12 00:10:59.643: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 11/12/22 00:10:59.643
    Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: ADDED
    Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.653: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.654: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.654: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.655: INFO: Found daemon set daemon-set in namespace daemonsets-5451 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 00:10:59.655: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 11/12/22 00:10:59.655
    STEP: watching for the daemon set status to be patched 11/12/22 00:10:59.676
    Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: ADDED
    Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.685: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.686: INFO: Observed daemon set daemon-set in namespace daemonsets-5451 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 00:10:59.686: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 00:10:59.686: INFO: Found daemon set daemon-set in namespace daemonsets-5451 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Nov 12 00:10:59.686: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 00:10:59.701
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5451, will wait for the garbage collector to delete the pods 11/12/22 00:10:59.701
    Nov 12 00:10:59.792: INFO: Deleting DaemonSet.extensions daemon-set took: 26.499892ms
    Nov 12 00:10:59.893: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.969002ms
    Nov 12 00:11:03.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:11:03.407: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 00:11:03.422: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"37611"},"items":null}

    Nov 12 00:11:03.435: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"37611"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:11:03.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5451" for this suite. 11/12/22 00:11:03.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:03.581
Nov 12 00:11:03.581: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:11:03.582
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:03.637
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:03.655
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2759 11/12/22 00:11:03.672
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 00:11:03.77
STEP: creating service externalsvc in namespace services-2759 11/12/22 00:11:03.771
STEP: creating replication controller externalsvc in namespace services-2759 11/12/22 00:11:03.813
I1112 00:11:03.835105      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2759, replica count: 2
I1112 00:11:06.886567      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 11/12/22 00:11:06.904
Nov 12 00:11:06.956: INFO: Creating new exec pod
Nov 12 00:11:06.987: INFO: Waiting up to 5m0s for pod "execpodzxfg7" in namespace "services-2759" to be "running"
Nov 12 00:11:07.001: INFO: Pod "execpodzxfg7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.090767ms
Nov 12 00:11:09.019: INFO: Pod "execpodzxfg7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03236472s
Nov 12 00:11:11.016: INFO: Pod "execpodzxfg7": Phase="Running", Reason="", readiness=true. Elapsed: 4.029042056s
Nov 12 00:11:11.016: INFO: Pod "execpodzxfg7" satisfied condition "running"
Nov 12 00:11:11.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2759 exec execpodzxfg7 -- /bin/sh -x -c nslookup clusterip-service.services-2759.svc.cluster.local'
Nov 12 00:11:11.412: INFO: stderr: "+ nslookup clusterip-service.services-2759.svc.cluster.local\n"
Nov 12 00:11:11.413: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-2759.svc.cluster.local\tcanonical name = externalsvc.services-2759.svc.cluster.local.\nName:\texternalsvc.services-2759.svc.cluster.local\nAddress: 172.21.218.63\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2759, will wait for the garbage collector to delete the pods 11/12/22 00:11:11.413
Nov 12 00:11:11.504: INFO: Deleting ReplicationController externalsvc took: 22.188625ms
Nov 12 00:11:11.805: INFO: Terminating ReplicationController externalsvc pods took: 300.950137ms
Nov 12 00:11:14.767: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:11:14.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2759" for this suite. 11/12/22 00:11:14.841
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":215,"skipped":4139,"failed":0}
------------------------------
• [SLOW TEST] [11.326 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:03.581
    Nov 12 00:11:03.581: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:11:03.582
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:03.637
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:03.655
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2759 11/12/22 00:11:03.672
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 00:11:03.77
    STEP: creating service externalsvc in namespace services-2759 11/12/22 00:11:03.771
    STEP: creating replication controller externalsvc in namespace services-2759 11/12/22 00:11:03.813
    I1112 00:11:03.835105      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2759, replica count: 2
    I1112 00:11:06.886567      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 11/12/22 00:11:06.904
    Nov 12 00:11:06.956: INFO: Creating new exec pod
    Nov 12 00:11:06.987: INFO: Waiting up to 5m0s for pod "execpodzxfg7" in namespace "services-2759" to be "running"
    Nov 12 00:11:07.001: INFO: Pod "execpodzxfg7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.090767ms
    Nov 12 00:11:09.019: INFO: Pod "execpodzxfg7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03236472s
    Nov 12 00:11:11.016: INFO: Pod "execpodzxfg7": Phase="Running", Reason="", readiness=true. Elapsed: 4.029042056s
    Nov 12 00:11:11.016: INFO: Pod "execpodzxfg7" satisfied condition "running"
    Nov 12 00:11:11.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2759 exec execpodzxfg7 -- /bin/sh -x -c nslookup clusterip-service.services-2759.svc.cluster.local'
    Nov 12 00:11:11.412: INFO: stderr: "+ nslookup clusterip-service.services-2759.svc.cluster.local\n"
    Nov 12 00:11:11.413: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-2759.svc.cluster.local\tcanonical name = externalsvc.services-2759.svc.cluster.local.\nName:\texternalsvc.services-2759.svc.cluster.local\nAddress: 172.21.218.63\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2759, will wait for the garbage collector to delete the pods 11/12/22 00:11:11.413
    Nov 12 00:11:11.504: INFO: Deleting ReplicationController externalsvc took: 22.188625ms
    Nov 12 00:11:11.805: INFO: Terminating ReplicationController externalsvc pods took: 300.950137ms
    Nov 12 00:11:14.767: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:11:14.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2759" for this suite. 11/12/22 00:11:14.841
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:14.919
Nov 12 00:11:14.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:11:14.921
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:14.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:15.012
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 00:11:15.029
Nov 12 00:11:15.062: INFO: Waiting up to 5m0s for pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be" in namespace "emptydir-7111" to be "Succeeded or Failed"
Nov 12 00:11:15.076: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 13.938868ms
Nov 12 00:11:17.091: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02890332s
Nov 12 00:11:19.093: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031017832s
Nov 12 00:11:21.090: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028199691s
STEP: Saw pod success 11/12/22 00:11:21.09
Nov 12 00:11:21.091: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be" satisfied condition "Succeeded or Failed"
Nov 12 00:11:21.104: INFO: Trying to get logs from node 10.184.98.55 pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be container test-container: <nil>
STEP: delete the pod 11/12/22 00:11:21.138
Nov 12 00:11:21.177: INFO: Waiting for pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be to disappear
Nov 12 00:11:21.190: INFO: Pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:11:21.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7111" for this suite. 11/12/22 00:11:21.212
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":216,"skipped":4173,"failed":0}
------------------------------
• [SLOW TEST] [6.325 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:14.919
    Nov 12 00:11:14.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:11:14.921
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:14.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:15.012
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 00:11:15.029
    Nov 12 00:11:15.062: INFO: Waiting up to 5m0s for pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be" in namespace "emptydir-7111" to be "Succeeded or Failed"
    Nov 12 00:11:15.076: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 13.938868ms
    Nov 12 00:11:17.091: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02890332s
    Nov 12 00:11:19.093: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031017832s
    Nov 12 00:11:21.090: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028199691s
    STEP: Saw pod success 11/12/22 00:11:21.09
    Nov 12 00:11:21.091: INFO: Pod "pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be" satisfied condition "Succeeded or Failed"
    Nov 12 00:11:21.104: INFO: Trying to get logs from node 10.184.98.55 pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be container test-container: <nil>
    STEP: delete the pod 11/12/22 00:11:21.138
    Nov 12 00:11:21.177: INFO: Waiting for pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be to disappear
    Nov 12 00:11:21.190: INFO: Pod pod-2ca631b3-71f5-4a24-b1e6-9c0304fd25be no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:11:21.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7111" for this suite. 11/12/22 00:11:21.212
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:21.249
Nov 12 00:11:21.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:11:21.25
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:21.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:21.353
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Nov 12 00:11:21.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 create -f -'
Nov 12 00:11:21.854: INFO: stderr: ""
Nov 12 00:11:21.854: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Nov 12 00:11:21.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 create -f -'
Nov 12 00:11:22.478: INFO: stderr: ""
Nov 12 00:11:22.478: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 00:11:22.478
Nov 12 00:11:23.493: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:11:23.493: INFO: Found 0 / 1
Nov 12 00:11:24.494: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:11:24.495: INFO: Found 1 / 1
Nov 12 00:11:24.495: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 12 00:11:24.511: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:11:24.511: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 00:11:24.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe pod agnhost-primary-fkp8h'
Nov 12 00:11:24.703: INFO: stderr: ""
Nov 12 00:11:24.703: INFO: stdout: "Name:             agnhost-primary-fkp8h\nNamespace:        kubectl-7371\nPriority:         0\nService Account:  default\nNode:             10.184.98.55/10.184.98.55\nStart Time:       Sat, 12 Nov 2022 00:11:21 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 229826aec06fbe27ac56a3de22f3cf66c3989aa73628f192ae7c3243be24b799\n                  cni.projectcalico.org/podIP: 172.30.146.50/32\n                  cni.projectcalico.org/podIPs: 172.30.146.50/32\nStatus:           Running\nIP:               172.30.146.50\nIPs:\n  IP:           172.30.146.50\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://863d9654a97f10206053738993edba0823c0d629428b02fe3889aa6bc72c3cc5\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 12 Nov 2022 00:11:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wscbx (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-wscbx:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-7371/agnhost-primary-fkp8h to 10.184.98.55\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Nov 12 00:11:24.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe rc agnhost-primary'
Nov 12 00:11:24.920: INFO: stderr: ""
Nov 12 00:11:24.920: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7371\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-fkp8h\n"
Nov 12 00:11:24.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe service agnhost-primary'
Nov 12 00:11:25.153: INFO: stderr: ""
Nov 12 00:11:25.153: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7371\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.42.75\nIPs:               172.21.42.75\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.146.50:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 12 00:11:25.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe node 10.184.98.55'
Nov 12 00:11:25.528: INFO: stderr: ""
Nov 12 00:11:25.528: INFO: stdout: "Name:               10.184.98.55\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal12\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.59.216.80\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.184.98.55\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=test-cdnb84020fhsh0fv6jt0-kubee2epvgx-default-000003c5\n                    ibm-cloud.kubernetes.io/worker-pool-id=cdnb84020fhsh0fv6jt0-30aeadb\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.3_1521\n                    ibm-cloud.kubernetes.io/zone=dal12\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.184.98.55\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2747436\n                    publicVLAN=2747434\n                    topology.kubernetes.io/region=us-south\n                    topology.kubernetes.io/zone=dal12\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.184.98.55/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.146.0\nCreationTimestamp:  Fri, 11 Nov 2022 21:00:38 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.184.98.55\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 12 Nov 2022 00:11:25 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 11 Nov 2022 21:01:28 +0000   Fri, 11 Nov 2022 21:01:28 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:59 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.184.98.55\n  ExternalIP:  169.59.216.80\n  Hostname:    10.184.98.55\nCapacity:\n  cpu:                  4\n  ephemeral-storage:    102624184Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               16212384Ki\n  pods:                 110\nAllocatable:\n  cpu:                  3910m\n  ephemeral-storage:    93927226085\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               13440416Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 f89f3c02b0454ff480617cc24bbe5b1d\n  System UUID:                1A5C3630-6DC9-8830-7B46-B9B6B81818B4\n  Boot ID:                    b1ff6818-cf58-4a7a-9ea7-e9f071b1adc7\n  Kernel Version:             4.15.0-194-generic\n  OS Image:                   Ubuntu 18.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.3+IKS\n  Kube-Proxy Version:         v1.25.3+IKS\nProviderID:                   ibm://856f38977b8848e0a6a67f09be3e597c///cdnb84020fhsh0fv6jt0/test-cdnb84020fhsh0fv6jt0-kubee2epvgx-default-000003c5\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-jr9ch                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h10m\n  kube-system                 calico-typha-69875cbbb9-r29rt                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3m52s\n  kube-system                 ibm-keepalived-watcher-8s5vg                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h10m\n  kube-system                 ibm-master-proxy-static-10.184.98.55                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h9m\n  kube-system                 ibmcloud-block-storage-driver-c2stl                        50m (1%)      300m (7%)   100Mi (0%)       300Mi (2%)     3h10m\n  kube-system                 konnectivity-agent-58g6r                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h3m\n  kubectl-7371                agnhost-primary-fkp8h                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         62m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         62m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests       Limits\n  --------             --------       ------\n  cpu                  590m (15%)     600m (15%)\n  memory               328210Ki (2%)  1350860800 (9%)\n  ephemeral-storage    0 (0%)         0 (0%)\n  hugepages-1Gi        0 (0%)         0 (0%)\n  hugepages-2Mi        0 (0%)         0 (0%)\n  example.com/fakecpu  0              0\nEvents:                <none>\n"
Nov 12 00:11:25.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe namespace kubectl-7371'
Nov 12 00:11:25.746: INFO: stderr: ""
Nov 12 00:11:25.746: INFO: stdout: "Name:         kubectl-7371\nLabels:       e2e-framework=kubectl\n              e2e-run=0cbcaf67-ec2b-40e5-9cf1-f211c8b02420\n              kubernetes.io/metadata.name=kubectl-7371\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:11:25.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7371" for this suite. 11/12/22 00:11:25.776
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":217,"skipped":4193,"failed":0}
------------------------------
• [4.580 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:21.249
    Nov 12 00:11:21.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:11:21.25
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:21.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:21.353
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Nov 12 00:11:21.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 create -f -'
    Nov 12 00:11:21.854: INFO: stderr: ""
    Nov 12 00:11:21.854: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Nov 12 00:11:21.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 create -f -'
    Nov 12 00:11:22.478: INFO: stderr: ""
    Nov 12 00:11:22.478: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 00:11:22.478
    Nov 12 00:11:23.493: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:11:23.493: INFO: Found 0 / 1
    Nov 12 00:11:24.494: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:11:24.495: INFO: Found 1 / 1
    Nov 12 00:11:24.495: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 12 00:11:24.511: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:11:24.511: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 00:11:24.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe pod agnhost-primary-fkp8h'
    Nov 12 00:11:24.703: INFO: stderr: ""
    Nov 12 00:11:24.703: INFO: stdout: "Name:             agnhost-primary-fkp8h\nNamespace:        kubectl-7371\nPriority:         0\nService Account:  default\nNode:             10.184.98.55/10.184.98.55\nStart Time:       Sat, 12 Nov 2022 00:11:21 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 229826aec06fbe27ac56a3de22f3cf66c3989aa73628f192ae7c3243be24b799\n                  cni.projectcalico.org/podIP: 172.30.146.50/32\n                  cni.projectcalico.org/podIPs: 172.30.146.50/32\nStatus:           Running\nIP:               172.30.146.50\nIPs:\n  IP:           172.30.146.50\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://863d9654a97f10206053738993edba0823c0d629428b02fe3889aa6bc72c3cc5\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 12 Nov 2022 00:11:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wscbx (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-wscbx:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 600s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 600s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-7371/agnhost-primary-fkp8h to 10.184.98.55\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Nov 12 00:11:24.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe rc agnhost-primary'
    Nov 12 00:11:24.920: INFO: stderr: ""
    Nov 12 00:11:24.920: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-7371\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-fkp8h\n"
    Nov 12 00:11:24.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe service agnhost-primary'
    Nov 12 00:11:25.153: INFO: stderr: ""
    Nov 12 00:11:25.153: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-7371\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                172.21.42.75\nIPs:               172.21.42.75\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.30.146.50:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Nov 12 00:11:25.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe node 10.184.98.55'
    Nov 12 00:11:25.528: INFO: stderr: ""
    Nov 12 00:11:25.528: INFO: stdout: "Name:               10.184.98.55\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal12\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.59.216.80\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.184.98.55\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=test-cdnb84020fhsh0fv6jt0-kubee2epvgx-default-000003c5\n                    ibm-cloud.kubernetes.io/worker-pool-id=cdnb84020fhsh0fv6jt0-30aeadb\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.25.3_1521\n                    ibm-cloud.kubernetes.io/zone=dal12\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.184.98.55\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    privateVLAN=2747436\n                    publicVLAN=2747434\n                    topology.kubernetes.io/region=us-south\n                    topology.kubernetes.io/zone=dal12\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.184.98.55/26\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.30.146.0\nCreationTimestamp:  Fri, 11 Nov 2022 21:00:38 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  10.184.98.55\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 12 Nov 2022 00:11:25 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 11 Nov 2022 21:01:28 +0000   Fri, 11 Nov 2022 21:01:28 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:38 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 12 Nov 2022 00:06:58 +0000   Fri, 11 Nov 2022 21:00:59 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.184.98.55\n  ExternalIP:  169.59.216.80\n  Hostname:    10.184.98.55\nCapacity:\n  cpu:                  4\n  ephemeral-storage:    102624184Ki\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               16212384Ki\n  pods:                 110\nAllocatable:\n  cpu:                  3910m\n  ephemeral-storage:    93927226085\n  example.com/fakecpu:  1k\n  hugepages-1Gi:        0\n  hugepages-2Mi:        0\n  memory:               13440416Ki\n  pods:                 110\nSystem Info:\n  Machine ID:                 f89f3c02b0454ff480617cc24bbe5b1d\n  System UUID:                1A5C3630-6DC9-8830-7B46-B9B6B81818B4\n  Boot ID:                    b1ff6818-cf58-4a7a-9ea7-e9f071b1adc7\n  Kernel Version:             4.15.0-194-generic\n  OS Image:                   Ubuntu 18.04.6 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.25.3+IKS\n  Kube-Proxy Version:         v1.25.3+IKS\nProviderID:                   ibm://856f38977b8848e0a6a67f09be3e597c///cdnb84020fhsh0fv6jt0/test-cdnb84020fhsh0fv6jt0-kubee2epvgx-default-000003c5\nNon-terminated Pods:          (9 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-jr9ch                                          250m (6%)     0 (0%)      90Mi (0%)        0 (0%)         3h10m\n  kube-system                 calico-typha-69875cbbb9-r29rt                              250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         3m52s\n  kube-system                 ibm-keepalived-watcher-8s5vg                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         3h10m\n  kube-system                 ibm-master-proxy-static-10.184.98.55                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      3h9m\n  kube-system                 ibmcloud-block-storage-driver-c2stl                        50m (1%)      300m (7%)   100Mi (0%)       300Mi (2%)     3h10m\n  kube-system                 konnectivity-agent-58g6r                                   10m (0%)      0 (0%)      10Mi (0%)        500Mi (3%)     3h3m\n  kubectl-7371                agnhost-primary-fkp8h                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         62m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2    0 (0%)        0 (0%)      0 (0%)           0 (0%)         62m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource             Requests       Limits\n  --------             --------       ------\n  cpu                  590m (15%)     600m (15%)\n  memory               328210Ki (2%)  1350860800 (9%)\n  ephemeral-storage    0 (0%)         0 (0%)\n  hugepages-1Gi        0 (0%)         0 (0%)\n  hugepages-2Mi        0 (0%)         0 (0%)\n  example.com/fakecpu  0              0\nEvents:                <none>\n"
    Nov 12 00:11:25.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-7371 describe namespace kubectl-7371'
    Nov 12 00:11:25.746: INFO: stderr: ""
    Nov 12 00:11:25.746: INFO: stdout: "Name:         kubectl-7371\nLabels:       e2e-framework=kubectl\n              e2e-run=0cbcaf67-ec2b-40e5-9cf1-f211c8b02420\n              kubernetes.io/metadata.name=kubectl-7371\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:11:25.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7371" for this suite. 11/12/22 00:11:25.776
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:25.842
Nov 12 00:11:25.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:11:25.843
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:25.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:25.921
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-d62eb28a-e06d-4380-bca1-e3ea42b887f9 11/12/22 00:11:25.937
STEP: Creating a pod to test consume secrets 11/12/22 00:11:25.953
Nov 12 00:11:25.988: INFO: Waiting up to 5m0s for pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612" in namespace "secrets-5417" to be "Succeeded or Failed"
Nov 12 00:11:26.003: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 13.849689ms
Nov 12 00:11:28.018: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02922873s
Nov 12 00:11:30.024: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034925271s
Nov 12 00:11:32.021: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031848989s
STEP: Saw pod success 11/12/22 00:11:32.021
Nov 12 00:11:32.021: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612" satisfied condition "Succeeded or Failed"
Nov 12 00:11:32.040: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:11:32.098
Nov 12 00:11:32.158: INFO: Waiting for pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 to disappear
Nov 12 00:11:32.190: INFO: Pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:11:32.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5417" for this suite. 11/12/22 00:11:32.219
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":218,"skipped":4238,"failed":0}
------------------------------
• [SLOW TEST] [6.420 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:25.842
    Nov 12 00:11:25.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:11:25.843
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:25.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:25.921
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-d62eb28a-e06d-4380-bca1-e3ea42b887f9 11/12/22 00:11:25.937
    STEP: Creating a pod to test consume secrets 11/12/22 00:11:25.953
    Nov 12 00:11:25.988: INFO: Waiting up to 5m0s for pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612" in namespace "secrets-5417" to be "Succeeded or Failed"
    Nov 12 00:11:26.003: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 13.849689ms
    Nov 12 00:11:28.018: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02922873s
    Nov 12 00:11:30.024: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034925271s
    Nov 12 00:11:32.021: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031848989s
    STEP: Saw pod success 11/12/22 00:11:32.021
    Nov 12 00:11:32.021: INFO: Pod "pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612" satisfied condition "Succeeded or Failed"
    Nov 12 00:11:32.040: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:11:32.098
    Nov 12 00:11:32.158: INFO: Waiting for pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 to disappear
    Nov 12 00:11:32.190: INFO: Pod pod-secrets-99c5eba8-91c0-426e-878d-f3486054e612 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:11:32.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5417" for this suite. 11/12/22 00:11:32.219
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:32.262
Nov 12 00:11:32.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 00:11:32.264
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:32.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:32.421
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 00:11:32.49
Nov 12 00:11:32.545: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6824" to be "running and ready"
Nov 12 00:11:32.580: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 35.071813ms
Nov 12 00:11:32.580: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:11:34.596: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050915839s
Nov 12 00:11:34.596: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:11:36.598: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.052227972s
Nov 12 00:11:36.598: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 00:11:36.598: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 11/12/22 00:11:36.613
Nov 12 00:11:36.631: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6824" to be "running and ready"
Nov 12 00:11:36.644: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.323106ms
Nov 12 00:11:36.644: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:11:38.659: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028661493s
Nov 12 00:11:38.660: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:11:40.663: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.032403817s
Nov 12 00:11:40.663: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Nov 12 00:11:40.664: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/12/22 00:11:40.679
STEP: delete the pod with lifecycle hook 11/12/22 00:11:40.77
Nov 12 00:11:40.800: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 12 00:11:40.814: INFO: Pod pod-with-poststart-http-hook still exists
Nov 12 00:11:42.815: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 12 00:11:42.830: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 00:11:42.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6824" for this suite. 11/12/22 00:11:42.868
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":219,"skipped":4239,"failed":0}
------------------------------
• [SLOW TEST] [10.639 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:32.262
    Nov 12 00:11:32.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 00:11:32.264
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:32.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:32.421
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 00:11:32.49
    Nov 12 00:11:32.545: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-6824" to be "running and ready"
    Nov 12 00:11:32.580: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 35.071813ms
    Nov 12 00:11:32.580: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:11:34.596: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050915839s
    Nov 12 00:11:34.596: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:11:36.598: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.052227972s
    Nov 12 00:11:36.598: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 00:11:36.598: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 11/12/22 00:11:36.613
    Nov 12 00:11:36.631: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-6824" to be "running and ready"
    Nov 12 00:11:36.644: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 13.323106ms
    Nov 12 00:11:36.644: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:11:38.659: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028661493s
    Nov 12 00:11:38.660: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:11:40.663: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.032403817s
    Nov 12 00:11:40.663: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Nov 12 00:11:40.664: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/12/22 00:11:40.679
    STEP: delete the pod with lifecycle hook 11/12/22 00:11:40.77
    Nov 12 00:11:40.800: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 12 00:11:40.814: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 12 00:11:42.815: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 12 00:11:42.830: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 00:11:42.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-6824" for this suite. 11/12/22 00:11:42.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:42.902
Nov 12 00:11:42.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:11:42.904
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:43.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:43.062
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-a5f904fc-0db8-4538-b38b-4dcb9df9963c 11/12/22 00:11:43.081
STEP: Creating secret with name secret-projected-all-test-volume-faef7a2f-e632-4ddd-8429-72478dc9a7cf 11/12/22 00:11:43.111
STEP: Creating a pod to test Check all projections for projected volume plugin 11/12/22 00:11:43.126
Nov 12 00:11:43.191: INFO: Waiting up to 5m0s for pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52" in namespace "projected-1444" to be "Succeeded or Failed"
Nov 12 00:11:43.215: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 23.368234ms
Nov 12 00:11:45.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037507543s
Nov 12 00:11:47.228: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037233709s
Nov 12 00:11:49.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037499384s
STEP: Saw pod success 11/12/22 00:11:49.229
Nov 12 00:11:49.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52" satisfied condition "Succeeded or Failed"
Nov 12 00:11:49.244: INFO: Trying to get logs from node 10.184.98.55 pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 container projected-all-volume-test: <nil>
STEP: delete the pod 11/12/22 00:11:49.275
Nov 12 00:11:49.304: INFO: Waiting for pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 to disappear
Nov 12 00:11:49.316: INFO: Pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Nov 12 00:11:49.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1444" for this suite. 11/12/22 00:11:49.346
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":220,"skipped":4249,"failed":0}
------------------------------
• [SLOW TEST] [6.474 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:42.902
    Nov 12 00:11:42.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:11:42.904
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:43.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:43.062
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-a5f904fc-0db8-4538-b38b-4dcb9df9963c 11/12/22 00:11:43.081
    STEP: Creating secret with name secret-projected-all-test-volume-faef7a2f-e632-4ddd-8429-72478dc9a7cf 11/12/22 00:11:43.111
    STEP: Creating a pod to test Check all projections for projected volume plugin 11/12/22 00:11:43.126
    Nov 12 00:11:43.191: INFO: Waiting up to 5m0s for pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52" in namespace "projected-1444" to be "Succeeded or Failed"
    Nov 12 00:11:43.215: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 23.368234ms
    Nov 12 00:11:45.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037507543s
    Nov 12 00:11:47.228: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037233709s
    Nov 12 00:11:49.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037499384s
    STEP: Saw pod success 11/12/22 00:11:49.229
    Nov 12 00:11:49.229: INFO: Pod "projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52" satisfied condition "Succeeded or Failed"
    Nov 12 00:11:49.244: INFO: Trying to get logs from node 10.184.98.55 pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 container projected-all-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:11:49.275
    Nov 12 00:11:49.304: INFO: Waiting for pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 to disappear
    Nov 12 00:11:49.316: INFO: Pod projected-volume-9fa156b2-556d-4b1c-881e-523352cf8b52 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Nov 12 00:11:49.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1444" for this suite. 11/12/22 00:11:49.346
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:11:49.377
Nov 12 00:11:49.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename taint-single-pod 11/12/22 00:11:49.38
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:49.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:49.447
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Nov 12 00:11:49.463: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 00:12:49.624: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Nov 12 00:12:49.642: INFO: Starting informer...
STEP: Starting pod... 11/12/22 00:12:49.643
Nov 12 00:12:49.911: INFO: Pod is running on 10.184.98.55. Tainting Node
STEP: Trying to apply a taint on the Node 11/12/22 00:12:49.911
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:12:49.966
STEP: Waiting short time to make sure Pod is queued for deletion 11/12/22 00:12:49.988
Nov 12 00:12:49.989: INFO: Pod wasn't evicted. Proceeding
Nov 12 00:12:49.989: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:12:50.089
STEP: Waiting some time to make sure that toleration time passed. 11/12/22 00:12:50.121
Nov 12 00:14:05.122: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:14:05.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2103" for this suite. 11/12/22 00:14:05.147
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":221,"skipped":4249,"failed":0}
------------------------------
• [SLOW TEST] [135.797 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:11:49.377
    Nov 12 00:11:49.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename taint-single-pod 11/12/22 00:11:49.38
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:11:49.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:11:49.447
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Nov 12 00:11:49.463: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 00:12:49.624: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Nov 12 00:12:49.642: INFO: Starting informer...
    STEP: Starting pod... 11/12/22 00:12:49.643
    Nov 12 00:12:49.911: INFO: Pod is running on 10.184.98.55. Tainting Node
    STEP: Trying to apply a taint on the Node 11/12/22 00:12:49.911
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:12:49.966
    STEP: Waiting short time to make sure Pod is queued for deletion 11/12/22 00:12:49.988
    Nov 12 00:12:49.989: INFO: Pod wasn't evicted. Proceeding
    Nov 12 00:12:49.989: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 00:12:50.089
    STEP: Waiting some time to make sure that toleration time passed. 11/12/22 00:12:50.121
    Nov 12 00:14:05.122: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:14:05.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-2103" for this suite. 11/12/22 00:14:05.147
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:14:05.174
Nov 12 00:14:05.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:14:05.176
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:14:05.234
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:14:05.251
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-44f50709-8ae9-4286-a7fa-b89a6bf337bd 11/12/22 00:14:05.292
STEP: Creating configMap with name cm-test-opt-upd-a4f2a94b-3041-4c0d-8b91-a4d8aa36cc43 11/12/22 00:14:05.313
STEP: Creating the pod 11/12/22 00:14:05.335
Nov 12 00:14:05.395: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482" in namespace "configmap-410" to be "running and ready"
Nov 12 00:14:05.409: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Pending", Reason="", readiness=false. Elapsed: 13.738698ms
Nov 12 00:14:05.409: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:14:07.426: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030602361s
Nov 12 00:14:07.426: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:14:09.424: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Running", Reason="", readiness=true. Elapsed: 4.02871361s
Nov 12 00:14:09.425: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Running (Ready = true)
Nov 12 00:14:09.425: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-44f50709-8ae9-4286-a7fa-b89a6bf337bd 11/12/22 00:14:09.588
STEP: Updating configmap cm-test-opt-upd-a4f2a94b-3041-4c0d-8b91-a4d8aa36cc43 11/12/22 00:14:09.618
STEP: Creating configMap with name cm-test-opt-create-b31c594e-6a4f-4d43-ab2e-0f42f042591c 11/12/22 00:14:09.664
STEP: waiting to observe update in volume 11/12/22 00:14:09.695
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:15:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-410" for this suite. 11/12/22 00:15:23.195
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":222,"skipped":4250,"failed":0}
------------------------------
• [SLOW TEST] [78.049 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:14:05.174
    Nov 12 00:14:05.175: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:14:05.176
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:14:05.234
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:14:05.251
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-44f50709-8ae9-4286-a7fa-b89a6bf337bd 11/12/22 00:14:05.292
    STEP: Creating configMap with name cm-test-opt-upd-a4f2a94b-3041-4c0d-8b91-a4d8aa36cc43 11/12/22 00:14:05.313
    STEP: Creating the pod 11/12/22 00:14:05.335
    Nov 12 00:14:05.395: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482" in namespace "configmap-410" to be "running and ready"
    Nov 12 00:14:05.409: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Pending", Reason="", readiness=false. Elapsed: 13.738698ms
    Nov 12 00:14:05.409: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:14:07.426: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030602361s
    Nov 12 00:14:07.426: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:14:09.424: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482": Phase="Running", Reason="", readiness=true. Elapsed: 4.02871361s
    Nov 12 00:14:09.425: INFO: The phase of Pod pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482 is Running (Ready = true)
    Nov 12 00:14:09.425: INFO: Pod "pod-configmaps-5e6d547b-6679-4fdd-86ec-0b35c866f482" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-44f50709-8ae9-4286-a7fa-b89a6bf337bd 11/12/22 00:14:09.588
    STEP: Updating configmap cm-test-opt-upd-a4f2a94b-3041-4c0d-8b91-a4d8aa36cc43 11/12/22 00:14:09.618
    STEP: Creating configMap with name cm-test-opt-create-b31c594e-6a4f-4d43-ab2e-0f42f042591c 11/12/22 00:14:09.664
    STEP: waiting to observe update in volume 11/12/22 00:14:09.695
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:15:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-410" for this suite. 11/12/22 00:15:23.195
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:23.225
Nov 12 00:15:23.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename watch 11/12/22 00:15:23.227
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:23.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:23.303
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 11/12/22 00:15:23.321
STEP: starting a background goroutine to produce watch events 11/12/22 00:15:23.339
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/12/22 00:15:23.339
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 00:15:26.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5163" for this suite. 11/12/22 00:15:26.187
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":223,"skipped":4261,"failed":0}
------------------------------
• [2.995 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:23.225
    Nov 12 00:15:23.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename watch 11/12/22 00:15:23.227
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:23.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:23.303
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 11/12/22 00:15:23.321
    STEP: starting a background goroutine to produce watch events 11/12/22 00:15:23.339
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/12/22 00:15:23.339
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 00:15:26.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5163" for this suite. 11/12/22 00:15:26.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:26.223
Nov 12 00:15:26.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename proxy 11/12/22 00:15:26.225
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:26.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:26.299
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Nov 12 00:15:26.317: INFO: Creating pod...
Nov 12 00:15:26.352: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9990" to be "running"
Nov 12 00:15:26.365: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 12.237218ms
Nov 12 00:15:28.382: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029769729s
Nov 12 00:15:30.382: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.029237449s
Nov 12 00:15:30.382: INFO: Pod "agnhost" satisfied condition "running"
Nov 12 00:15:30.382: INFO: Creating service...
Nov 12 00:15:30.421: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/DELETE
Nov 12 00:15:30.477: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 00:15:30.477: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/GET
Nov 12 00:15:30.498: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 12 00:15:30.499: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/HEAD
Nov 12 00:15:30.520: INFO: http.Client request:HEAD | StatusCode:200
Nov 12 00:15:30.520: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/OPTIONS
Nov 12 00:15:30.540: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 00:15:30.540: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/PATCH
Nov 12 00:15:30.561: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 00:15:30.562: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/POST
Nov 12 00:15:30.581: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 00:15:30.581: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/PUT
Nov 12 00:15:30.601: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 00:15:30.601: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/DELETE
Nov 12 00:15:30.630: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 00:15:30.630: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/GET
Nov 12 00:15:30.661: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 12 00:15:30.661: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/HEAD
Nov 12 00:15:30.692: INFO: http.Client request:HEAD | StatusCode:200
Nov 12 00:15:30.693: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/OPTIONS
Nov 12 00:15:30.742: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 00:15:30.743: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/PATCH
Nov 12 00:15:30.775: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 00:15:30.775: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/POST
Nov 12 00:15:30.833: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 00:15:30.833: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/PUT
Nov 12 00:15:30.878: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 00:15:30.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9990" for this suite. 11/12/22 00:15:30.903
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":224,"skipped":4269,"failed":0}
------------------------------
• [4.729 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:26.223
    Nov 12 00:15:26.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename proxy 11/12/22 00:15:26.225
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:26.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:26.299
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Nov 12 00:15:26.317: INFO: Creating pod...
    Nov 12 00:15:26.352: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-9990" to be "running"
    Nov 12 00:15:26.365: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 12.237218ms
    Nov 12 00:15:28.382: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029769729s
    Nov 12 00:15:30.382: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.029237449s
    Nov 12 00:15:30.382: INFO: Pod "agnhost" satisfied condition "running"
    Nov 12 00:15:30.382: INFO: Creating service...
    Nov 12 00:15:30.421: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/DELETE
    Nov 12 00:15:30.477: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 00:15:30.477: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/GET
    Nov 12 00:15:30.498: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 12 00:15:30.499: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/HEAD
    Nov 12 00:15:30.520: INFO: http.Client request:HEAD | StatusCode:200
    Nov 12 00:15:30.520: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/OPTIONS
    Nov 12 00:15:30.540: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 00:15:30.540: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/PATCH
    Nov 12 00:15:30.561: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 00:15:30.562: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/POST
    Nov 12 00:15:30.581: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 00:15:30.581: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/pods/agnhost/proxy/some/path/with/PUT
    Nov 12 00:15:30.601: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 00:15:30.601: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/DELETE
    Nov 12 00:15:30.630: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 00:15:30.630: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/GET
    Nov 12 00:15:30.661: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 12 00:15:30.661: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/HEAD
    Nov 12 00:15:30.692: INFO: http.Client request:HEAD | StatusCode:200
    Nov 12 00:15:30.693: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/OPTIONS
    Nov 12 00:15:30.742: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 00:15:30.743: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/PATCH
    Nov 12 00:15:30.775: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 00:15:30.775: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/POST
    Nov 12 00:15:30.833: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 00:15:30.833: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-9990/services/test-service/proxy/some/path/with/PUT
    Nov 12 00:15:30.878: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 00:15:30.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9990" for this suite. 11/12/22 00:15:30.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:30.962
Nov 12 00:15:30.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replication-controller 11/12/22 00:15:30.964
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:31.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:31.059
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Nov 12 00:15:31.077: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/12/22 00:15:31.115
STEP: Checking rc "condition-test" has the desired failure condition set 11/12/22 00:15:31.133
STEP: Scaling down rc "condition-test" to satisfy pod quota 11/12/22 00:15:32.165
Nov 12 00:15:32.210: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 11/12/22 00:15:32.211
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 00:15:32.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-381" for this suite. 11/12/22 00:15:32.257
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":225,"skipped":4281,"failed":0}
------------------------------
• [1.357 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:30.962
    Nov 12 00:15:30.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replication-controller 11/12/22 00:15:30.964
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:31.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:31.059
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Nov 12 00:15:31.077: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/12/22 00:15:31.115
    STEP: Checking rc "condition-test" has the desired failure condition set 11/12/22 00:15:31.133
    STEP: Scaling down rc "condition-test" to satisfy pod quota 11/12/22 00:15:32.165
    Nov 12 00:15:32.210: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 11/12/22 00:15:32.211
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 00:15:32.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-381" for this suite. 11/12/22 00:15:32.257
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:32.326
Nov 12 00:15:32.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:15:32.338
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:32.407
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:32.424
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:15:32.519
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:15:33.572
STEP: Deploying the webhook pod 11/12/22 00:15:33.606
STEP: Wait for the deployment to be ready 11/12/22 00:15:33.65
Nov 12 00:15:33.730: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/12/22 00:15:35.784
STEP: Verifying the service has paired with the endpoint 11/12/22 00:15:35.82
Nov 12 00:15:36.822: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Nov 12 00:15:36.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/12/22 00:15:37.387
STEP: Creating a custom resource that should be denied by the webhook 11/12/22 00:15:37.492
STEP: Creating a custom resource whose deletion would be denied by the webhook 11/12/22 00:15:39.602
STEP: Updating the custom resource with disallowed data should be denied 11/12/22 00:15:39.645
STEP: Deleting the custom resource should be denied 11/12/22 00:15:39.693
STEP: Remove the offending key and value from the custom resource data 11/12/22 00:15:39.737
STEP: Deleting the updated custom resource should be successful 11/12/22 00:15:39.819
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:15:40.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1479" for this suite. 11/12/22 00:15:40.484
STEP: Destroying namespace "webhook-1479-markers" for this suite. 11/12/22 00:15:40.513
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":226,"skipped":4291,"failed":0}
------------------------------
• [SLOW TEST] [8.423 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:32.326
    Nov 12 00:15:32.334: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:15:32.338
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:32.407
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:32.424
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:15:32.519
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:15:33.572
    STEP: Deploying the webhook pod 11/12/22 00:15:33.606
    STEP: Wait for the deployment to be ready 11/12/22 00:15:33.65
    Nov 12 00:15:33.730: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/12/22 00:15:35.784
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:15:35.82
    Nov 12 00:15:36.822: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Nov 12 00:15:36.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/12/22 00:15:37.387
    STEP: Creating a custom resource that should be denied by the webhook 11/12/22 00:15:37.492
    STEP: Creating a custom resource whose deletion would be denied by the webhook 11/12/22 00:15:39.602
    STEP: Updating the custom resource with disallowed data should be denied 11/12/22 00:15:39.645
    STEP: Deleting the custom resource should be denied 11/12/22 00:15:39.693
    STEP: Remove the offending key and value from the custom resource data 11/12/22 00:15:39.737
    STEP: Deleting the updated custom resource should be successful 11/12/22 00:15:39.819
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:15:40.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1479" for this suite. 11/12/22 00:15:40.484
    STEP: Destroying namespace "webhook-1479-markers" for this suite. 11/12/22 00:15:40.513
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:40.752
Nov 12 00:15:40.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:15:40.753
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:40.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:40.844
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 00:15:40.893
Nov 12 00:15:40.926: INFO: Waiting up to 5m0s for pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736" in namespace "emptydir-4915" to be "Succeeded or Failed"
Nov 12 00:15:40.940: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Pending", Reason="", readiness=false. Elapsed: 14.311299ms
Nov 12 00:15:42.955: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Running", Reason="", readiness=true. Elapsed: 2.029255744s
Nov 12 00:15:44.958: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Running", Reason="", readiness=false. Elapsed: 4.032247507s
Nov 12 00:15:46.955: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029279729s
STEP: Saw pod success 11/12/22 00:15:46.955
Nov 12 00:15:46.956: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736" satisfied condition "Succeeded or Failed"
Nov 12 00:15:46.971: INFO: Trying to get logs from node 10.184.98.55 pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 container test-container: <nil>
STEP: delete the pod 11/12/22 00:15:47.003
Nov 12 00:15:47.040: INFO: Waiting for pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 to disappear
Nov 12 00:15:47.054: INFO: Pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:15:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4915" for this suite. 11/12/22 00:15:47.103
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":227,"skipped":4304,"failed":0}
------------------------------
• [SLOW TEST] [6.409 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:40.752
    Nov 12 00:15:40.752: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:15:40.753
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:40.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:40.844
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 00:15:40.893
    Nov 12 00:15:40.926: INFO: Waiting up to 5m0s for pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736" in namespace "emptydir-4915" to be "Succeeded or Failed"
    Nov 12 00:15:40.940: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Pending", Reason="", readiness=false. Elapsed: 14.311299ms
    Nov 12 00:15:42.955: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Running", Reason="", readiness=true. Elapsed: 2.029255744s
    Nov 12 00:15:44.958: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Running", Reason="", readiness=false. Elapsed: 4.032247507s
    Nov 12 00:15:46.955: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029279729s
    STEP: Saw pod success 11/12/22 00:15:46.955
    Nov 12 00:15:46.956: INFO: Pod "pod-71a54d6f-53e8-478d-8baa-eeafcafb3736" satisfied condition "Succeeded or Failed"
    Nov 12 00:15:46.971: INFO: Trying to get logs from node 10.184.98.55 pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 container test-container: <nil>
    STEP: delete the pod 11/12/22 00:15:47.003
    Nov 12 00:15:47.040: INFO: Waiting for pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 to disappear
    Nov 12 00:15:47.054: INFO: Pod pod-71a54d6f-53e8-478d-8baa-eeafcafb3736 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:15:47.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4915" for this suite. 11/12/22 00:15:47.103
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:47.163
Nov 12 00:15:47.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/12/22 00:15:47.164
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:47.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:47.229
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Nov 12 00:15:47.302: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 00:15:52.322: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 00:15:52.322
STEP: Scaling up "test-rs" replicaset  11/12/22 00:15:52.322
Nov 12 00:15:52.379: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 11/12/22 00:15:52.379
W1112 00:15:52.436186      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 12 00:15:52.444: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 00:15:52.462: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 00:15:52.476: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 00:15:54.532: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 2, AvailableReplicas 2
Nov 12 00:15:55.077: INFO: observed Replicaset test-rs in namespace replicaset-2961 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 00:15:55.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2961" for this suite. 11/12/22 00:15:55.112
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":228,"skipped":4308,"failed":0}
------------------------------
• [SLOW TEST] [8.022 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:47.163
    Nov 12 00:15:47.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/12/22 00:15:47.164
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:47.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:47.229
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Nov 12 00:15:47.302: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 00:15:52.322: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 00:15:52.322
    STEP: Scaling up "test-rs" replicaset  11/12/22 00:15:52.322
    Nov 12 00:15:52.379: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 11/12/22 00:15:52.379
    W1112 00:15:52.436186      21 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 12 00:15:52.444: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 00:15:52.462: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 00:15:52.476: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 00:15:54.532: INFO: observed ReplicaSet test-rs in namespace replicaset-2961 with ReadyReplicas 2, AvailableReplicas 2
    Nov 12 00:15:55.077: INFO: observed Replicaset test-rs in namespace replicaset-2961 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 00:15:55.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2961" for this suite. 11/12/22 00:15:55.112
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:15:55.19
Nov 12 00:15:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:15:55.192
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:55.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:55.275
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-3be0bef1-115b-409a-aace-3bff82aada29 11/12/22 00:15:55.321
STEP: Creating the pod 11/12/22 00:15:55.355
Nov 12 00:15:55.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd" in namespace "configmap-30" to be "running and ready"
Nov 12 00:15:55.404: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.279359ms
Nov 12 00:15:55.404: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:15:57.420: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031393677s
Nov 12 00:15:57.420: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:15:59.418: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Running", Reason="", readiness=true. Elapsed: 4.029466736s
Nov 12 00:15:59.418: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Running (Ready = true)
Nov 12 00:15:59.419: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-3be0bef1-115b-409a-aace-3bff82aada29 11/12/22 00:15:59.463
STEP: waiting to observe update in volume 11/12/22 00:15:59.484
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:17:08.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-30" for this suite. 11/12/22 00:17:08.812
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":229,"skipped":4317,"failed":0}
------------------------------
• [SLOW TEST] [73.650 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:15:55.19
    Nov 12 00:15:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:15:55.192
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:15:55.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:15:55.275
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-3be0bef1-115b-409a-aace-3bff82aada29 11/12/22 00:15:55.321
    STEP: Creating the pod 11/12/22 00:15:55.355
    Nov 12 00:15:55.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd" in namespace "configmap-30" to be "running and ready"
    Nov 12 00:15:55.404: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.279359ms
    Nov 12 00:15:55.404: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:15:57.420: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031393677s
    Nov 12 00:15:57.420: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:15:59.418: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd": Phase="Running", Reason="", readiness=true. Elapsed: 4.029466736s
    Nov 12 00:15:59.418: INFO: The phase of Pod pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd is Running (Ready = true)
    Nov 12 00:15:59.419: INFO: Pod "pod-configmaps-bc5eba22-6915-4265-a175-524ed418d5cd" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-3be0bef1-115b-409a-aace-3bff82aada29 11/12/22 00:15:59.463
    STEP: waiting to observe update in volume 11/12/22 00:15:59.484
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:17:08.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-30" for this suite. 11/12/22 00:17:08.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:17:08.842
Nov 12 00:17:08.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:17:08.843
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:08.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:08.916
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-6677 11/12/22 00:17:08.936
STEP: creating a selector 11/12/22 00:17:08.937
STEP: Creating the service pods in kubernetes 11/12/22 00:17:08.937
Nov 12 00:17:08.938: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 00:17:09.057: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6677" to be "running and ready"
Nov 12 00:17:09.069: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.201616ms
Nov 12 00:17:09.069: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:17:11.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.027576899s
Nov 12 00:17:11.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:13.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.027185872s
Nov 12 00:17:13.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:15.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028409907s
Nov 12 00:17:15.085: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:17.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027573698s
Nov 12 00:17:17.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:19.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.028150885s
Nov 12 00:17:19.085: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:21.082: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.025522649s
Nov 12 00:17:21.082: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:23.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.027157933s
Nov 12 00:17:23.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:25.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.026978066s
Nov 12 00:17:25.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:27.087: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.029753111s
Nov 12 00:17:27.087: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:29.086: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.029007089s
Nov 12 00:17:29.086: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:17:31.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.028140939s
Nov 12 00:17:31.085: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 00:17:31.085: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 00:17:31.099: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6677" to be "running and ready"
Nov 12 00:17:31.114: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 15.138968ms
Nov 12 00:17:31.114: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 00:17:31.114: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 00:17:31.133: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6677" to be "running and ready"
Nov 12 00:17:31.149: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.031145ms
Nov 12 00:17:31.149: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 00:17:31.149: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 00:17:31.162
Nov 12 00:17:31.200: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6677" to be "running"
Nov 12 00:17:31.212: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.113004ms
Nov 12 00:17:33.226: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025927555s
Nov 12 00:17:35.228: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.027989016s
Nov 12 00:17:35.228: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 00:17:35.243: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6677" to be "running"
Nov 12 00:17:35.259: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 15.969979ms
Nov 12 00:17:35.259: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 12 00:17:35.274: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 00:17:35.275: INFO: Going to poll 172.30.146.17 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:17:35.291: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.146.17:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:17:35.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:17:35.293: INFO: ExecWithOptions: Clientset creation
Nov 12 00:17:35.293: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.146.17%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:17:35.542: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 12 00:17:35.542: INFO: Going to poll 172.30.188.209 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:17:35.557: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.188.209:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:17:35.557: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:17:35.559: INFO: ExecWithOptions: Clientset creation
Nov 12 00:17:35.559: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.188.209%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:17:35.897: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 12 00:17:35.897: INFO: Going to poll 172.30.194.108 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:17:35.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.194.108:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:17:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:17:35.913: INFO: ExecWithOptions: Clientset creation
Nov 12 00:17:35.913: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.194.108%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:17:36.141: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 00:17:36.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6677" for this suite. 11/12/22 00:17:36.167
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":230,"skipped":4331,"failed":0}
------------------------------
• [SLOW TEST] [27.351 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:17:08.842
    Nov 12 00:17:08.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:17:08.843
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:08.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:08.916
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-6677 11/12/22 00:17:08.936
    STEP: creating a selector 11/12/22 00:17:08.937
    STEP: Creating the service pods in kubernetes 11/12/22 00:17:08.937
    Nov 12 00:17:08.938: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 00:17:09.057: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6677" to be "running and ready"
    Nov 12 00:17:09.069: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.201616ms
    Nov 12 00:17:09.069: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:17:11.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.027576899s
    Nov 12 00:17:11.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:13.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.027185872s
    Nov 12 00:17:13.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:15.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.028409907s
    Nov 12 00:17:15.085: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:17.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.027573698s
    Nov 12 00:17:17.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:19.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.028150885s
    Nov 12 00:17:19.085: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:21.082: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.025522649s
    Nov 12 00:17:21.082: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:23.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.027157933s
    Nov 12 00:17:23.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:25.084: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.026978066s
    Nov 12 00:17:25.084: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:27.087: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.029753111s
    Nov 12 00:17:27.087: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:29.086: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.029007089s
    Nov 12 00:17:29.086: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:17:31.085: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.028140939s
    Nov 12 00:17:31.085: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 00:17:31.085: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 00:17:31.099: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6677" to be "running and ready"
    Nov 12 00:17:31.114: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 15.138968ms
    Nov 12 00:17:31.114: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 00:17:31.114: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 00:17:31.133: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6677" to be "running and ready"
    Nov 12 00:17:31.149: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.031145ms
    Nov 12 00:17:31.149: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 00:17:31.149: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 00:17:31.162
    Nov 12 00:17:31.200: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6677" to be "running"
    Nov 12 00:17:31.212: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.113004ms
    Nov 12 00:17:33.226: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025927555s
    Nov 12 00:17:35.228: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.027989016s
    Nov 12 00:17:35.228: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 00:17:35.243: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6677" to be "running"
    Nov 12 00:17:35.259: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 15.969979ms
    Nov 12 00:17:35.259: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 12 00:17:35.274: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 00:17:35.275: INFO: Going to poll 172.30.146.17 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:17:35.291: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.146.17:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:17:35.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:17:35.293: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:17:35.293: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.146.17%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:17:35.542: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 12 00:17:35.542: INFO: Going to poll 172.30.188.209 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:17:35.557: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.188.209:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:17:35.557: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:17:35.559: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:17:35.559: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.188.209%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:17:35.897: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 12 00:17:35.897: INFO: Going to poll 172.30.194.108 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:17:35.912: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.194.108:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6677 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:17:35.912: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:17:35.913: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:17:35.913: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-6677/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.30.194.108%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:17:36.141: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 00:17:36.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6677" for this suite. 11/12/22 00:17:36.167
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:17:36.195
Nov 12 00:17:36.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:17:36.199
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:36.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:36.268
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 11/12/22 00:17:36.284
Nov 12 00:17:36.316: INFO: Waiting up to 5m0s for pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0" in namespace "emptydir-7874" to be "Succeeded or Failed"
Nov 12 00:17:36.329: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.612546ms
Nov 12 00:17:38.347: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030887262s
Nov 12 00:17:40.347: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031072523s
Nov 12 00:17:42.344: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028664025s
STEP: Saw pod success 11/12/22 00:17:42.345
Nov 12 00:17:42.345: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0" satisfied condition "Succeeded or Failed"
Nov 12 00:17:42.359: INFO: Trying to get logs from node 10.184.98.55 pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 container test-container: <nil>
STEP: delete the pod 11/12/22 00:17:42.392
Nov 12 00:17:42.433: INFO: Waiting for pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 to disappear
Nov 12 00:17:42.449: INFO: Pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:17:42.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7874" for this suite. 11/12/22 00:17:42.473
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":231,"skipped":4331,"failed":0}
------------------------------
• [SLOW TEST] [6.304 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:17:36.195
    Nov 12 00:17:36.196: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:17:36.199
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:36.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:36.268
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 11/12/22 00:17:36.284
    Nov 12 00:17:36.316: INFO: Waiting up to 5m0s for pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0" in namespace "emptydir-7874" to be "Succeeded or Failed"
    Nov 12 00:17:36.329: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.612546ms
    Nov 12 00:17:38.347: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030887262s
    Nov 12 00:17:40.347: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031072523s
    Nov 12 00:17:42.344: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028664025s
    STEP: Saw pod success 11/12/22 00:17:42.345
    Nov 12 00:17:42.345: INFO: Pod "pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0" satisfied condition "Succeeded or Failed"
    Nov 12 00:17:42.359: INFO: Trying to get logs from node 10.184.98.55 pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 container test-container: <nil>
    STEP: delete the pod 11/12/22 00:17:42.392
    Nov 12 00:17:42.433: INFO: Waiting for pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 to disappear
    Nov 12 00:17:42.449: INFO: Pod pod-6242bd72-c51a-4b9a-84fa-227a63a5d3a0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:17:42.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7874" for this suite. 11/12/22 00:17:42.473
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:17:42.504
Nov 12 00:17:42.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:17:42.506
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:42.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:42.574
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Nov 12 00:17:42.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 00:17:49.946
Nov 12 00:17:49.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 create -f -'
Nov 12 00:17:51.305: INFO: stderr: ""
Nov 12 00:17:51.305: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 12 00:17:51.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 delete e2e-test-crd-publish-openapi-7966-crds test-cr'
Nov 12 00:17:51.483: INFO: stderr: ""
Nov 12 00:17:51.483: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 12 00:17:51.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 apply -f -'
Nov 12 00:17:51.999: INFO: stderr: ""
Nov 12 00:17:51.999: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 12 00:17:51.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 delete e2e-test-crd-publish-openapi-7966-crds test-cr'
Nov 12 00:17:52.282: INFO: stderr: ""
Nov 12 00:17:52.282: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/12/22 00:17:52.282
Nov 12 00:17:52.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 explain e2e-test-crd-publish-openapi-7966-crds'
Nov 12 00:17:53.139: INFO: stderr: ""
Nov 12 00:17:53.139: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7966-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:17:57.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-843" for this suite. 11/12/22 00:17:57.568
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":232,"skipped":4350,"failed":0}
------------------------------
• [SLOW TEST] [15.092 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:17:42.504
    Nov 12 00:17:42.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:17:42.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:42.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:42.574
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Nov 12 00:17:42.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 00:17:49.946
    Nov 12 00:17:49.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 create -f -'
    Nov 12 00:17:51.305: INFO: stderr: ""
    Nov 12 00:17:51.305: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 12 00:17:51.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 delete e2e-test-crd-publish-openapi-7966-crds test-cr'
    Nov 12 00:17:51.483: INFO: stderr: ""
    Nov 12 00:17:51.483: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Nov 12 00:17:51.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 apply -f -'
    Nov 12 00:17:51.999: INFO: stderr: ""
    Nov 12 00:17:51.999: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 12 00:17:51.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 --namespace=crd-publish-openapi-843 delete e2e-test-crd-publish-openapi-7966-crds test-cr'
    Nov 12 00:17:52.282: INFO: stderr: ""
    Nov 12 00:17:52.282: INFO: stdout: "e2e-test-crd-publish-openapi-7966-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/12/22 00:17:52.282
    Nov 12 00:17:52.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-843 explain e2e-test-crd-publish-openapi-7966-crds'
    Nov 12 00:17:53.139: INFO: stderr: ""
    Nov 12 00:17:53.139: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7966-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:17:57.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-843" for this suite. 11/12/22 00:17:57.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:17:57.6
Nov 12 00:17:57.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename events 11/12/22 00:17:57.602
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:57.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:57.663
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 11/12/22 00:17:57.672
STEP: listing all events in all namespaces 11/12/22 00:17:57.702
STEP: patching the test event 11/12/22 00:17:57.734
STEP: fetching the test event 11/12/22 00:17:57.761
STEP: updating the test event 11/12/22 00:17:57.776
STEP: getting the test event 11/12/22 00:17:57.817
STEP: deleting the test event 11/12/22 00:17:57.832
STEP: listing all events in all namespaces 11/12/22 00:17:57.87
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 12 00:17:57.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1638" for this suite. 11/12/22 00:17:57.913
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":233,"skipped":4356,"failed":0}
------------------------------
• [0.340 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:17:57.6
    Nov 12 00:17:57.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename events 11/12/22 00:17:57.602
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:57.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:57.663
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 11/12/22 00:17:57.672
    STEP: listing all events in all namespaces 11/12/22 00:17:57.702
    STEP: patching the test event 11/12/22 00:17:57.734
    STEP: fetching the test event 11/12/22 00:17:57.761
    STEP: updating the test event 11/12/22 00:17:57.776
    STEP: getting the test event 11/12/22 00:17:57.817
    STEP: deleting the test event 11/12/22 00:17:57.832
    STEP: listing all events in all namespaces 11/12/22 00:17:57.87
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 12 00:17:57.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1638" for this suite. 11/12/22 00:17:57.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:17:57.942
Nov 12 00:17:57.943: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:17:57.945
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:57.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:57.992
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-b0bcc188-214c-4a8a-8a4a-88a68a9c0743 11/12/22 00:17:58
STEP: Creating a pod to test consume secrets 11/12/22 00:17:58.01
Nov 12 00:17:58.038: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b" in namespace "projected-3232" to be "Succeeded or Failed"
Nov 12 00:17:58.054: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.80536ms
Nov 12 00:18:00.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032805885s
Nov 12 00:18:02.070: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031860323s
Nov 12 00:18:04.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032153451s
STEP: Saw pod success 11/12/22 00:18:04.071
Nov 12 00:18:04.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b" satisfied condition "Succeeded or Failed"
Nov 12 00:18:04.087: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:18:04.198
Nov 12 00:18:04.239: INFO: Waiting for pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b to disappear
Nov 12 00:18:04.256: INFO: Pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 00:18:04.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3232" for this suite. 11/12/22 00:18:04.269
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":234,"skipped":4371,"failed":0}
------------------------------
• [SLOW TEST] [6.352 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:17:57.942
    Nov 12 00:17:57.943: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:17:57.945
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:17:57.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:17:57.992
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-b0bcc188-214c-4a8a-8a4a-88a68a9c0743 11/12/22 00:17:58
    STEP: Creating a pod to test consume secrets 11/12/22 00:17:58.01
    Nov 12 00:17:58.038: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b" in namespace "projected-3232" to be "Succeeded or Failed"
    Nov 12 00:17:58.054: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.80536ms
    Nov 12 00:18:00.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032805885s
    Nov 12 00:18:02.070: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031860323s
    Nov 12 00:18:04.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032153451s
    STEP: Saw pod success 11/12/22 00:18:04.071
    Nov 12 00:18:04.071: INFO: Pod "pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b" satisfied condition "Succeeded or Failed"
    Nov 12 00:18:04.087: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:18:04.198
    Nov 12 00:18:04.239: INFO: Waiting for pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b to disappear
    Nov 12 00:18:04.256: INFO: Pod pod-projected-secrets-fa07835a-ebab-4f57-8d43-4eedc6b9dc5b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 00:18:04.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3232" for this suite. 11/12/22 00:18:04.269
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:18:04.296
Nov 12 00:18:04.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/12/22 00:18:04.298
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:18:04.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:18:04.339
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d in namespace container-probe-1064 11/12/22 00:18:04.35
Nov 12 00:18:04.385: INFO: Waiting up to 5m0s for pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d" in namespace "container-probe-1064" to be "not pending"
Nov 12 00:18:04.399: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.818649ms
Nov 12 00:18:06.414: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d": Phase="Running", Reason="", readiness=true. Elapsed: 2.028733378s
Nov 12 00:18:06.414: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d" satisfied condition "not pending"
Nov 12 00:18:06.414: INFO: Started pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d in namespace container-probe-1064
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:18:06.414
Nov 12 00:18:06.430: INFO: Initial restart count of pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d is 0
STEP: deleting the pod 11/12/22 00:22:06.622
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 00:22:06.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1064" for this suite. 11/12/22 00:22:06.687
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":235,"skipped":4372,"failed":0}
------------------------------
• [SLOW TEST] [242.416 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:18:04.296
    Nov 12 00:18:04.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/12/22 00:18:04.298
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:18:04.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:18:04.339
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d in namespace container-probe-1064 11/12/22 00:18:04.35
    Nov 12 00:18:04.385: INFO: Waiting up to 5m0s for pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d" in namespace "container-probe-1064" to be "not pending"
    Nov 12 00:18:04.399: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.818649ms
    Nov 12 00:18:06.414: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d": Phase="Running", Reason="", readiness=true. Elapsed: 2.028733378s
    Nov 12 00:18:06.414: INFO: Pod "test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d" satisfied condition "not pending"
    Nov 12 00:18:06.414: INFO: Started pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d in namespace container-probe-1064
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:18:06.414
    Nov 12 00:18:06.430: INFO: Initial restart count of pod test-webserver-6e62f873-0299-4cff-97ce-aa7cfd1e372d is 0
    STEP: deleting the pod 11/12/22 00:22:06.622
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 00:22:06.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1064" for this suite. 11/12/22 00:22:06.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:22:06.726
Nov 12 00:22:06.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename ephemeral-containers-test 11/12/22 00:22:06.728
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:06.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:06.77
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 11/12/22 00:22:06.779
Nov 12 00:22:06.808: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3503" to be "running and ready"
Nov 12 00:22:06.822: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.54657ms
Nov 12 00:22:06.822: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:22:08.839: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030356565s
Nov 12 00:22:08.839: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:22:10.837: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028991055s
Nov 12 00:22:10.838: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Nov 12 00:22:10.838: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 11/12/22 00:22:10.852
Nov 12 00:22:10.875: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3503" to be "container debugger running"
Nov 12 00:22:10.889: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.533624ms
Nov 12 00:22:12.905: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03039009s
Nov 12 00:22:14.905: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03016273s
Nov 12 00:22:14.905: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 11/12/22 00:22:14.905
Nov 12 00:22:14.906: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3503 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:22:14.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:22:14.906: INFO: ExecWithOptions: Clientset creation
Nov 12 00:22:14.907: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-3503/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Nov 12 00:22:15.158: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 00:22:15.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-3503" for this suite. 11/12/22 00:22:15.255
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":236,"skipped":4391,"failed":0}
------------------------------
• [SLOW TEST] [8.556 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:22:06.726
    Nov 12 00:22:06.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename ephemeral-containers-test 11/12/22 00:22:06.728
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:06.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:06.77
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 11/12/22 00:22:06.779
    Nov 12 00:22:06.808: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3503" to be "running and ready"
    Nov 12 00:22:06.822: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.54657ms
    Nov 12 00:22:06.822: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:22:08.839: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030356565s
    Nov 12 00:22:08.839: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:22:10.837: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028991055s
    Nov 12 00:22:10.838: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Nov 12 00:22:10.838: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 11/12/22 00:22:10.852
    Nov 12 00:22:10.875: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3503" to be "container debugger running"
    Nov 12 00:22:10.889: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.533624ms
    Nov 12 00:22:12.905: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.03039009s
    Nov 12 00:22:14.905: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.03016273s
    Nov 12 00:22:14.905: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 11/12/22 00:22:14.905
    Nov 12 00:22:14.906: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3503 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:22:14.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:22:14.906: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:22:14.907: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/ephemeral-containers-test-3503/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Nov 12 00:22:15.158: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 00:22:15.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-3503" for this suite. 11/12/22 00:22:15.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:22:15.285
Nov 12 00:22:15.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 00:22:15.287
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:15.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:15.335
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 11/12/22 00:22:15.343
STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:16.132
Nov 12 00:22:16.179: INFO: Pod name wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18: Found 0 pods out of 5
Nov 12 00:22:21.211: INFO: Pod name wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 00:22:21.211
Nov 12 00:22:21.211: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:21.229: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr": Phase="Running", Reason="", readiness=true. Elapsed: 17.399802ms
Nov 12 00:22:21.229: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr" satisfied condition "running"
Nov 12 00:22:21.229: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:21.243: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm": Phase="Running", Reason="", readiness=true. Elapsed: 14.198739ms
Nov 12 00:22:21.243: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm" satisfied condition "running"
Nov 12 00:22:21.243: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:21.260: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm": Phase="Pending", Reason="", readiness=false. Elapsed: 16.664713ms
Nov 12 00:22:23.287: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm": Phase="Running", Reason="", readiness=true. Elapsed: 2.044135958s
Nov 12 00:22:23.287: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm" satisfied condition "running"
Nov 12 00:22:23.287: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:23.305: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk": Phase="Running", Reason="", readiness=true. Elapsed: 17.631486ms
Nov 12 00:22:23.305: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk" satisfied condition "running"
Nov 12 00:22:23.305: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:23.320: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv": Phase="Running", Reason="", readiness=true. Elapsed: 14.960984ms
Nov 12 00:22:23.320: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:23.32
Nov 12 00:22:23.414: INFO: Deleting ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 took: 27.543622ms
Nov 12 00:22:23.615: INFO: Terminating ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 pods took: 201.355819ms
STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:27.032
Nov 12 00:22:27.147: INFO: Pod name wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba: Found 1 pods out of 5
Nov 12 00:22:32.191: INFO: Pod name wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 00:22:32.191
Nov 12 00:22:32.191: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:32.207: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf": Phase="Running", Reason="", readiness=true. Elapsed: 16.332617ms
Nov 12 00:22:32.207: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf" satisfied condition "running"
Nov 12 00:22:32.207: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:32.223: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx": Phase="Running", Reason="", readiness=true. Elapsed: 15.948664ms
Nov 12 00:22:32.223: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx" satisfied condition "running"
Nov 12 00:22:32.223: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:32.243: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5": Phase="Running", Reason="", readiness=true. Elapsed: 19.395924ms
Nov 12 00:22:32.243: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5" satisfied condition "running"
Nov 12 00:22:32.243: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:32.259: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg": Phase="Running", Reason="", readiness=true. Elapsed: 16.358564ms
Nov 12 00:22:32.259: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg" satisfied condition "running"
Nov 12 00:22:32.259: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:32.277: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r": Phase="Running", Reason="", readiness=true. Elapsed: 17.491536ms
Nov 12 00:22:32.277: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:32.278
Nov 12 00:22:32.373: INFO: Deleting ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba took: 28.375754ms
Nov 12 00:22:32.473: INFO: Terminating ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba pods took: 100.423597ms
STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:36.986
Nov 12 00:22:37.031: INFO: Pod name wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765: Found 0 pods out of 5
Nov 12 00:22:42.069: INFO: Pod name wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 00:22:42.069
Nov 12 00:22:42.069: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:42.103: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49": Phase="Running", Reason="", readiness=true. Elapsed: 33.765746ms
Nov 12 00:22:42.103: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49" satisfied condition "running"
Nov 12 00:22:42.103: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:42.118: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76": Phase="Running", Reason="", readiness=true. Elapsed: 15.335038ms
Nov 12 00:22:42.118: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76" satisfied condition "running"
Nov 12 00:22:42.118: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:42.137: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv": Phase="Running", Reason="", readiness=true. Elapsed: 18.027172ms
Nov 12 00:22:42.137: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv" satisfied condition "running"
Nov 12 00:22:42.137: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:42.154: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b": Phase="Running", Reason="", readiness=true. Elapsed: 16.765661ms
Nov 12 00:22:42.154: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b" satisfied condition "running"
Nov 12 00:22:42.154: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb" in namespace "emptydir-wrapper-981" to be "running"
Nov 12 00:22:42.170: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb": Phase="Running", Reason="", readiness=true. Elapsed: 15.901148ms
Nov 12 00:22:42.170: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:42.17
Nov 12 00:22:42.267: INFO: Deleting ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 took: 26.824924ms
Nov 12 00:22:42.368: INFO: Terminating ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 pods took: 100.386772ms
STEP: Cleaning up the configMaps 11/12/22 00:22:46.369
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 12 00:22:47.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-981" for this suite. 11/12/22 00:22:47.766
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":237,"skipped":4428,"failed":0}
------------------------------
• [SLOW TEST] [32.530 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:22:15.285
    Nov 12 00:22:15.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 00:22:15.287
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:15.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:15.335
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 11/12/22 00:22:15.343
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:16.132
    Nov 12 00:22:16.179: INFO: Pod name wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18: Found 0 pods out of 5
    Nov 12 00:22:21.211: INFO: Pod name wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 00:22:21.211
    Nov 12 00:22:21.211: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:21.229: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr": Phase="Running", Reason="", readiness=true. Elapsed: 17.399802ms
    Nov 12 00:22:21.229: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-8xfsr" satisfied condition "running"
    Nov 12 00:22:21.229: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:21.243: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm": Phase="Running", Reason="", readiness=true. Elapsed: 14.198739ms
    Nov 12 00:22:21.243: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-99fsm" satisfied condition "running"
    Nov 12 00:22:21.243: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:21.260: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm": Phase="Pending", Reason="", readiness=false. Elapsed: 16.664713ms
    Nov 12 00:22:23.287: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm": Phase="Running", Reason="", readiness=true. Elapsed: 2.044135958s
    Nov 12 00:22:23.287: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-mmcjm" satisfied condition "running"
    Nov 12 00:22:23.287: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:23.305: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk": Phase="Running", Reason="", readiness=true. Elapsed: 17.631486ms
    Nov 12 00:22:23.305: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-xtjvk" satisfied condition "running"
    Nov 12 00:22:23.305: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:23.320: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv": Phase="Running", Reason="", readiness=true. Elapsed: 14.960984ms
    Nov 12 00:22:23.320: INFO: Pod "wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18-z94nv" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:23.32
    Nov 12 00:22:23.414: INFO: Deleting ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 took: 27.543622ms
    Nov 12 00:22:23.615: INFO: Terminating ReplicationController wrapped-volume-race-ea80dbe9-3dc3-403f-82e9-6f0623b2bb18 pods took: 201.355819ms
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:27.032
    Nov 12 00:22:27.147: INFO: Pod name wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba: Found 1 pods out of 5
    Nov 12 00:22:32.191: INFO: Pod name wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 00:22:32.191
    Nov 12 00:22:32.191: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:32.207: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf": Phase="Running", Reason="", readiness=true. Elapsed: 16.332617ms
    Nov 12 00:22:32.207: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-2ntvf" satisfied condition "running"
    Nov 12 00:22:32.207: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:32.223: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx": Phase="Running", Reason="", readiness=true. Elapsed: 15.948664ms
    Nov 12 00:22:32.223: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-dnpwx" satisfied condition "running"
    Nov 12 00:22:32.223: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:32.243: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5": Phase="Running", Reason="", readiness=true. Elapsed: 19.395924ms
    Nov 12 00:22:32.243: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-k4gw5" satisfied condition "running"
    Nov 12 00:22:32.243: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:32.259: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg": Phase="Running", Reason="", readiness=true. Elapsed: 16.358564ms
    Nov 12 00:22:32.259: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-mbxcg" satisfied condition "running"
    Nov 12 00:22:32.259: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:32.277: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r": Phase="Running", Reason="", readiness=true. Elapsed: 17.491536ms
    Nov 12 00:22:32.277: INFO: Pod "wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba-x8p7r" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:32.278
    Nov 12 00:22:32.373: INFO: Deleting ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba took: 28.375754ms
    Nov 12 00:22:32.473: INFO: Terminating ReplicationController wrapped-volume-race-209c3e82-21a4-40fe-be60-c6717830d1ba pods took: 100.423597ms
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 00:22:36.986
    Nov 12 00:22:37.031: INFO: Pod name wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765: Found 0 pods out of 5
    Nov 12 00:22:42.069: INFO: Pod name wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 00:22:42.069
    Nov 12 00:22:42.069: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:42.103: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49": Phase="Running", Reason="", readiness=true. Elapsed: 33.765746ms
    Nov 12 00:22:42.103: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-25s49" satisfied condition "running"
    Nov 12 00:22:42.103: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:42.118: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76": Phase="Running", Reason="", readiness=true. Elapsed: 15.335038ms
    Nov 12 00:22:42.118: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-26c76" satisfied condition "running"
    Nov 12 00:22:42.118: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:42.137: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv": Phase="Running", Reason="", readiness=true. Elapsed: 18.027172ms
    Nov 12 00:22:42.137: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-5bzsv" satisfied condition "running"
    Nov 12 00:22:42.137: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:42.154: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b": Phase="Running", Reason="", readiness=true. Elapsed: 16.765661ms
    Nov 12 00:22:42.154: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-phw8b" satisfied condition "running"
    Nov 12 00:22:42.154: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb" in namespace "emptydir-wrapper-981" to be "running"
    Nov 12 00:22:42.170: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb": Phase="Running", Reason="", readiness=true. Elapsed: 15.901148ms
    Nov 12 00:22:42.170: INFO: Pod "wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765-xmzvb" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 in namespace emptydir-wrapper-981, will wait for the garbage collector to delete the pods 11/12/22 00:22:42.17
    Nov 12 00:22:42.267: INFO: Deleting ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 took: 26.824924ms
    Nov 12 00:22:42.368: INFO: Terminating ReplicationController wrapped-volume-race-52012502-e873-47be-b9d1-ae877c235765 pods took: 100.386772ms
    STEP: Cleaning up the configMaps 11/12/22 00:22:46.369
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:22:47.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-981" for this suite. 11/12/22 00:22:47.766
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:22:47.817
Nov 12 00:22:47.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:22:47.819
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:47.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:47.864
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 11/12/22 00:22:47.901
Nov 12 00:22:47.902: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30" in namespace "kubelet-test-8942" to be "completed"
Nov 12 00:22:47.920: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 18.165903ms
Nov 12 00:22:49.937: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035109971s
Nov 12 00:22:51.940: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038062915s
Nov 12 00:22:53.936: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034380409s
Nov 12 00:22:53.936: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 00:22:53.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8942" for this suite. 11/12/22 00:22:53.979
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":238,"skipped":4435,"failed":0}
------------------------------
• [SLOW TEST] [6.194 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:22:47.817
    Nov 12 00:22:47.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:22:47.819
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:47.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:47.864
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 11/12/22 00:22:47.901
    Nov 12 00:22:47.902: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30" in namespace "kubelet-test-8942" to be "completed"
    Nov 12 00:22:47.920: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 18.165903ms
    Nov 12 00:22:49.937: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035109971s
    Nov 12 00:22:51.940: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038062915s
    Nov 12 00:22:53.936: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034380409s
    Nov 12 00:22:53.936: INFO: Pod "agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 00:22:53.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8942" for this suite. 11/12/22 00:22:53.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:22:54.018
Nov 12 00:22:54.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-pred 11/12/22 00:22:54.02
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:54.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:54.066
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 12 00:22:54.075: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 12 00:22:54.095: INFO: Waiting for terminating namespaces to be deleted...
Nov 12 00:22:54.112: INFO: 
Logging pods the apiserver thinks is on node 10.184.98.55 before test
Nov 12 00:22:54.144: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container calico-node ready: true, restart count 0
Nov 12 00:22:54.144: INFO: calico-typha-69875cbbb9-9vt9g from kube-system started at 2022-11-12 00:12:51 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container calico-typha ready: true, restart count 0
Nov 12 00:22:54.144: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 12 00:22:54.144: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 12 00:22:54.144: INFO: 	Container pause ready: true, restart count 0
Nov 12 00:22:54.144: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 12 00:22:54.144: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 12 00:22:54.144: INFO: agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30 from kubelet-test-8942 started at 2022-11-12 00:22:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.144: INFO: 	Container agnhost-container ready: false, restart count 0
Nov 12 00:22:54.145: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.145: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 12 00:22:54.145: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 00:22:54.145: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 00:22:54.145: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.113 before test
Nov 12 00:22:54.215: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-hmd68 from ibm-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.218: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 12 00:22:54.218: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.218: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 12 00:22:54.218: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.218: INFO: 	Container calico-node ready: true, restart count 0
Nov 12 00:22:54.219: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.219: INFO: 	Container calico-typha ready: true, restart count 0
Nov 12 00:22:54.219: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.220: INFO: 	Container autoscaler ready: true, restart count 0
Nov 12 00:22:54.220: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.220: INFO: 	Container coredns ready: true, restart count 0
Nov 12 00:22:54.220: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.220: INFO: 	Container coredns ready: true, restart count 0
Nov 12 00:22:54.221: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.221: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 12 00:22:54.221: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.221: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 12 00:22:54.221: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.221: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 12 00:22:54.221: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.221: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 12 00:22:54.222: INFO: 	Container pause ready: true, restart count 0
Nov 12 00:22:54.222: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.222: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 12 00:22:54.222: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.222: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 12 00:22:54.222: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.224: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
Nov 12 00:22:54.225: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.225: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 12 00:22:54.225: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.225: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 12 00:22:54.225: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
Nov 12 00:22:54.225: INFO: 	Container config-watcher ready: true, restart count 0
Nov 12 00:22:54.225: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 00:22:54.226: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 00:22:54.226: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xv7fm from kube-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.226: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 12 00:22:54.226: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.226: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 12 00:22:54.226: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.227: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 12 00:22:54.227: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.227: INFO: 	Container snapshot-controller ready: true, restart count 0
Nov 12 00:22:54.227: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.227: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 00:22:54.227: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 00:22:54.227: INFO: 
Logging pods the apiserver thinks is on node 10.241.148.26 before test
Nov 12 00:22:54.262: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.262: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov 12 00:22:54.262: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.263: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
Nov 12 00:22:54.263: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.263: INFO: 	Container calico-node ready: true, restart count 0
Nov 12 00:22:54.263: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.263: INFO: 	Container calico-typha ready: true, restart count 0
Nov 12 00:22:54.263: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.263: INFO: 	Container coredns ready: true, restart count 0
Nov 12 00:22:54.263: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.264: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 12 00:22:54.264: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.264: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 12 00:22:54.264: INFO: 	Container pause ready: true, restart count 0
Nov 12 00:22:54.264: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.264: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
Nov 12 00:22:54.264: INFO: ingress-cluster-healthcheck-5fc9658887-4wmm6 from kube-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.264: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
Nov 12 00:22:54.264: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.265: INFO: 	Container konnectivity-agent ready: true, restart count 0
Nov 12 00:22:54.265: INFO: metrics-server-6f6df44444-28rrf from kube-system started at 2022-11-12 00:07:33 +0000 UTC (3 container statuses recorded)
Nov 12 00:22:54.265: INFO: 	Container config-watcher ready: true, restart count 0
Nov 12 00:22:54.265: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 00:22:54.265: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 00:22:54.265: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
Nov 12 00:22:54.265: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov 12 00:22:54.265: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.265: INFO: 	Container e2e ready: true, restart count 0
Nov 12 00:22:54.265: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 00:22:54.266: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
Nov 12 00:22:54.266: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 00:22:54.266: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 00:22:54.266
Nov 12 00:22:54.298: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4623" to be "running"
Nov 12 00:22:54.317: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.713747ms
Nov 12 00:22:56.333: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034874126s
Nov 12 00:22:58.335: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.036612483s
Nov 12 00:22:58.335: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 00:22:58.35
STEP: Trying to apply a random label on the found node. 11/12/22 00:22:58.423
STEP: verifying the node has the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 95 11/12/22 00:22:58.456
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/12/22 00:22:58.473
Nov 12 00:22:58.494: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-4623" to be "not pending"
Nov 12 00:22:58.513: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.841992ms
Nov 12 00:23:00.529: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035544848s
Nov 12 00:23:02.529: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.035111842s
Nov 12 00:23:02.529: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.184.98.55 on the node which pod4 resides and expect not scheduled 11/12/22 00:23:02.529
Nov 12 00:23:02.546: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-4623" to be "not pending"
Nov 12 00:23:02.561: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.879875ms
Nov 12 00:23:04.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031037253s
Nov 12 00:23:06.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035350528s
Nov 12 00:23:08.584: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037635202s
Nov 12 00:23:10.599: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052390999s
Nov 12 00:23:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031494916s
Nov 12 00:23:14.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031100509s
Nov 12 00:23:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031401722s
Nov 12 00:23:18.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.030665234s
Nov 12 00:23:20.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.030574058s
Nov 12 00:23:22.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.03098039s
Nov 12 00:23:24.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.0318645s
Nov 12 00:23:26.581: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.034992803s
Nov 12 00:23:28.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.030229152s
Nov 12 00:23:30.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.031506483s
Nov 12 00:23:32.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.033329757s
Nov 12 00:23:34.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.033407056s
Nov 12 00:23:36.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.032632884s
Nov 12 00:23:38.597: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.05035245s
Nov 12 00:23:40.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.032593453s
Nov 12 00:23:42.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.033244284s
Nov 12 00:23:44.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.032268004s
Nov 12 00:23:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.031090939s
Nov 12 00:23:48.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.031298894s
Nov 12 00:23:50.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.032206556s
Nov 12 00:23:52.584: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.03717469s
Nov 12 00:23:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.030941594s
Nov 12 00:23:56.592: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.045647256s
Nov 12 00:23:58.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.030534121s
Nov 12 00:24:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.029124456s
Nov 12 00:24:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.031465805s
Nov 12 00:24:04.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.030471916s
Nov 12 00:24:06.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.030055545s
Nov 12 00:24:08.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.02947788s
Nov 12 00:24:10.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.030870233s
Nov 12 00:24:12.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.030996587s
Nov 12 00:24:14.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.031085014s
Nov 12 00:24:16.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.030760109s
Nov 12 00:24:18.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.031810982s
Nov 12 00:24:20.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.031211478s
Nov 12 00:24:22.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.039707354s
Nov 12 00:24:24.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.02975999s
Nov 12 00:24:26.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.030399209s
Nov 12 00:24:28.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.029322624s
Nov 12 00:24:30.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.031308855s
Nov 12 00:24:32.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.062556422s
Nov 12 00:24:34.583: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.036204258s
Nov 12 00:24:36.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.031076147s
Nov 12 00:24:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.030357824s
Nov 12 00:24:40.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.030532526s
Nov 12 00:24:42.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.033266406s
Nov 12 00:24:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.03155523s
Nov 12 00:24:46.585: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.038217716s
Nov 12 00:24:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.030524927s
Nov 12 00:24:50.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.031101597s
Nov 12 00:24:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.031563815s
Nov 12 00:24:54.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.031200131s
Nov 12 00:24:56.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.030407615s
Nov 12 00:24:58.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.032336252s
Nov 12 00:25:00.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.030477283s
Nov 12 00:25:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.031877634s
Nov 12 00:25:04.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.03224012s
Nov 12 00:25:06.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.031582606s
Nov 12 00:25:08.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.032225467s
Nov 12 00:25:10.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.031876153s
Nov 12 00:25:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.03205176s
Nov 12 00:25:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.031609635s
Nov 12 00:25:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.031271229s
Nov 12 00:25:18.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.030050413s
Nov 12 00:25:20.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.03300402s
Nov 12 00:25:22.588: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.041725493s
Nov 12 00:25:24.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.031631534s
Nov 12 00:25:26.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.031379553s
Nov 12 00:25:28.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.03315811s
Nov 12 00:25:30.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.031077897s
Nov 12 00:25:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.059275709s
Nov 12 00:25:34.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.03123204s
Nov 12 00:25:36.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.031251634s
Nov 12 00:25:38.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.032676414s
Nov 12 00:25:40.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.03107592s
Nov 12 00:25:42.581: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.034521636s
Nov 12 00:25:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.031798961s
Nov 12 00:25:46.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.031498783s
Nov 12 00:25:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.030108077s
Nov 12 00:25:50.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.058678422s
Nov 12 00:25:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.031505029s
Nov 12 00:25:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.030543208s
Nov 12 00:25:56.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.039556304s
Nov 12 00:25:58.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.032171329s
Nov 12 00:26:00.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.030640637s
Nov 12 00:26:02.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.029725574s
Nov 12 00:26:04.587: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.040788522s
Nov 12 00:26:06.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032117034s
Nov 12 00:26:08.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.029609073s
Nov 12 00:26:10.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.032238334s
Nov 12 00:26:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.03164555s
Nov 12 00:26:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.031213909s
Nov 12 00:26:16.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.030284947s
Nov 12 00:26:18.575: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.02854045s
Nov 12 00:26:20.583: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.036209464s
Nov 12 00:26:22.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.058256943s
Nov 12 00:26:24.611: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.065067411s
Nov 12 00:26:26.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.035274346s
Nov 12 00:26:28.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.030246128s
Nov 12 00:26:30.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.029756814s
Nov 12 00:26:32.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.03087023s
Nov 12 00:26:34.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.031269847s
Nov 12 00:26:36.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.030509064s
Nov 12 00:26:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.030656059s
Nov 12 00:26:40.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.032358686s
Nov 12 00:26:42.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.031585881s
Nov 12 00:26:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.031901018s
Nov 12 00:26:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.030500052s
Nov 12 00:26:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.030790768s
Nov 12 00:26:50.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.033328954s
Nov 12 00:26:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.031577732s
Nov 12 00:26:54.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.031358039s
Nov 12 00:26:56.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.030935959s
Nov 12 00:26:58.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.031380391s
Nov 12 00:27:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.029830014s
Nov 12 00:27:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.032051108s
Nov 12 00:27:04.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.03272375s
Nov 12 00:27:06.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.030941906s
Nov 12 00:27:08.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.031055317s
Nov 12 00:27:10.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.029687115s
Nov 12 00:27:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.031226235s
Nov 12 00:27:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.032091249s
Nov 12 00:27:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.032069432s
Nov 12 00:27:18.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.030492392s
Nov 12 00:27:20.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.031897268s
Nov 12 00:27:22.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.03152963s
Nov 12 00:27:24.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.030420055s
Nov 12 00:27:26.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.031159582s
Nov 12 00:27:28.596: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.049383678s
Nov 12 00:27:30.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.030162826s
Nov 12 00:27:32.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.030553667s
Nov 12 00:27:34.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.03219683s
Nov 12 00:27:36.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.03156564s
Nov 12 00:27:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.030365161s
Nov 12 00:27:40.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.031434479s
Nov 12 00:27:42.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.031633396s
Nov 12 00:27:44.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.030215214s
Nov 12 00:27:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.030704205s
Nov 12 00:27:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.030906226s
Nov 12 00:27:50.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.030887183s
Nov 12 00:27:52.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.029749183s
Nov 12 00:27:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.03104701s
Nov 12 00:27:56.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.032000451s
Nov 12 00:27:58.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.030025185s
Nov 12 00:28:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.029168819s
Nov 12 00:28:02.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.030342241s
Nov 12 00:28:02.593: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.046403053s
STEP: removing the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 off the node 10.184.98.55 11/12/22 00:28:02.593
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 11/12/22 00:28:02.625
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:28:02.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4623" for this suite. 11/12/22 00:28:02.649
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":239,"skipped":4457,"failed":0}
------------------------------
• [SLOW TEST] [308.659 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:22:54.018
    Nov 12 00:22:54.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-pred 11/12/22 00:22:54.02
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:22:54.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:22:54.066
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 12 00:22:54.075: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 12 00:22:54.095: INFO: Waiting for terminating namespaces to be deleted...
    Nov 12 00:22:54.112: INFO: 
    Logging pods the apiserver thinks is on node 10.184.98.55 before test
    Nov 12 00:22:54.144: INFO: calico-node-jr9ch from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container calico-node ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: calico-typha-69875cbbb9-9vt9g from kube-system started at 2022-11-12 00:12:51 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: ibm-keepalived-watcher-8s5vg from kube-system started at 2022-11-11 21:00:38 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: ibm-master-proxy-static-10.184.98.55 from kube-system started at 2022-11-11 21:00:26 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: 	Container pause ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: ibmcloud-block-storage-driver-c2stl from kube-system started at 2022-11-11 21:00:52 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: konnectivity-agent-58g6r from kube-system started at 2022-11-11 21:07:52 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 12 00:22:54.144: INFO: agnhost-host-aliases9197d4fe-c4db-4cc9-b25d-06cdb4748d30 from kubelet-test-8942 started at 2022-11-12 00:22:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.144: INFO: 	Container agnhost-container ready: false, restart count 0
    Nov 12 00:22:54.145: INFO: sonobuoy from sonobuoy started at 2022-11-11 23:08:38 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.145: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 12 00:22:54.145: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-hd7c2 from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 00:22:54.145: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 00:22:54.145: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.113 before test
    Nov 12 00:22:54.215: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-hmd68 from ibm-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.218: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 12 00:22:54.218: INFO: calico-kube-controllers-69d96775d-x5dzw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.218: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 12 00:22:54.218: INFO: calico-node-4pllg from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.218: INFO: 	Container calico-node ready: true, restart count 0
    Nov 12 00:22:54.219: INFO: calico-typha-69875cbbb9-6hz97 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.219: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 12 00:22:54.219: INFO: coredns-autoscaler-78b44f5654-q5xkl from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.220: INFO: 	Container autoscaler ready: true, restart count 0
    Nov 12 00:22:54.220: INFO: coredns-f7664d677-7d4gj from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.220: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 00:22:54.220: INFO: coredns-f7664d677-ww5mz from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.220: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 00:22:54.221: INFO: dashboard-metrics-scraper-98b99ddbd-qs8t7 from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.221: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 12 00:22:54.221: INFO: ibm-file-plugin-766c57449-rm8fx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.221: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
    Nov 12 00:22:54.221: INFO: ibm-keepalived-watcher-xsshm from kube-system started at 2022-11-11 20:59:27 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.221: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 12 00:22:54.221: INFO: ibm-master-proxy-static-10.241.148.113 from kube-system started at 2022-11-11 20:59:15 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.221: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 12 00:22:54.222: INFO: 	Container pause ready: true, restart count 0
    Nov 12 00:22:54.222: INFO: ibm-storage-watcher-56b46bbdcf-hnrzg from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.222: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
    Nov 12 00:22:54.222: INFO: ibmcloud-block-storage-driver-ks5rd from kube-system started at 2022-11-11 20:59:36 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.222: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 12 00:22:54.222: INFO: ibmcloud-block-storage-plugin-77d7bb5c7b-4d8xd from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.224: INFO: 	Container ibmcloud-block-storage-plugin-container ready: true, restart count 0
    Nov 12 00:22:54.225: INFO: konnectivity-agent-kvttr from kube-system started at 2022-11-11 21:07:48 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.225: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 12 00:22:54.225: INFO: kubernetes-dashboard-65969f7576-7w24f from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.225: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 12 00:22:54.225: INFO: metrics-server-6f6df44444-686d8 from kube-system started at 2022-11-11 21:47:12 +0000 UTC (3 container statuses recorded)
    Nov 12 00:22:54.225: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 12 00:22:54.225: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 00:22:54.226: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 00:22:54.226: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-xv7fm from kube-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.226: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 12 00:22:54.226: INFO: snapshot-controller-66bd5d44d9-hcrtw from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.226: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 12 00:22:54.226: INFO: snapshot-controller-66bd5d44d9-k7jgh from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.227: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 12 00:22:54.227: INFO: snapshot-controller-66bd5d44d9-th9dx from kube-system started at 2022-11-11 20:59:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.227: INFO: 	Container snapshot-controller ready: true, restart count 0
    Nov 12 00:22:54.227: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-cgqch from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.227: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 00:22:54.227: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 00:22:54.227: INFO: 
    Logging pods the apiserver thinks is on node 10.241.148.26 before test
    Nov 12 00:22:54.262: INFO: test-k8s-e2e-pvg-master-verification from default started at 2022-11-11 21:02:45 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.262: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
    Nov 12 00:22:54.262: INFO: ibm-cloud-provider-ip-169-47-65-82-d6cc5789-58bln from ibm-system started at 2022-11-11 21:06:39 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.263: INFO: 	Container ibm-cloud-provider-ip-169-47-65-82 ready: true, restart count 0
    Nov 12 00:22:54.263: INFO: calico-node-j9dvb from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.263: INFO: 	Container calico-node ready: true, restart count 0
    Nov 12 00:22:54.263: INFO: calico-typha-69875cbbb9-c44sg from kube-system started at 2022-11-11 21:00:47 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.263: INFO: 	Container calico-typha ready: true, restart count 0
    Nov 12 00:22:54.263: INFO: coredns-f7664d677-vrmsd from kube-system started at 2022-11-11 21:08:21 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.263: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 00:22:54.263: INFO: ibm-keepalived-watcher-rvvrm from kube-system started at 2022-11-11 21:00:27 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.264: INFO: 	Container keepalived-watcher ready: true, restart count 0
    Nov 12 00:22:54.264: INFO: ibm-master-proxy-static-10.241.148.26 from kube-system started at 2022-11-11 21:00:24 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.264: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
    Nov 12 00:22:54.264: INFO: 	Container pause ready: true, restart count 0
    Nov 12 00:22:54.264: INFO: ibmcloud-block-storage-driver-ljthd from kube-system started at 2022-11-11 21:00:40 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.264: INFO: 	Container ibmcloud-block-storage-driver-container ready: true, restart count 0
    Nov 12 00:22:54.264: INFO: ingress-cluster-healthcheck-5fc9658887-4wmm6 from kube-system started at 2022-11-12 00:07:33 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.264: INFO: 	Container ingress-cluster-healthcheck ready: true, restart count 0
    Nov 12 00:22:54.264: INFO: konnectivity-agent-wrcmz from kube-system started at 2022-11-11 21:07:55 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.265: INFO: 	Container konnectivity-agent ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: metrics-server-6f6df44444-28rrf from kube-system started at 2022-11-12 00:07:33 +0000 UTC (3 container statuses recorded)
    Nov 12 00:22:54.265: INFO: 	Container config-watcher ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: public-crcdnb84020fhsh0fv6jt0-alb1-7db4c989f7-nhzwc from kube-system started at 2022-11-11 21:04:03 +0000 UTC (1 container statuses recorded)
    Nov 12 00:22:54.265: INFO: 	Container nginx-ingress ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: sonobuoy-e2e-job-2a0ed9b558a64b7e from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.265: INFO: 	Container e2e ready: true, restart count 0
    Nov 12 00:22:54.265: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 00:22:54.266: INFO: sonobuoy-systemd-logs-daemon-set-8ae4f76783ae43b3-25cvk from sonobuoy started at 2022-11-11 23:08:43 +0000 UTC (2 container statuses recorded)
    Nov 12 00:22:54.266: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 00:22:54.266: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 00:22:54.266
    Nov 12 00:22:54.298: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-4623" to be "running"
    Nov 12 00:22:54.317: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 18.713747ms
    Nov 12 00:22:56.333: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034874126s
    Nov 12 00:22:58.335: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.036612483s
    Nov 12 00:22:58.335: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 00:22:58.35
    STEP: Trying to apply a random label on the found node. 11/12/22 00:22:58.423
    STEP: verifying the node has the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 95 11/12/22 00:22:58.456
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/12/22 00:22:58.473
    Nov 12 00:22:58.494: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-4623" to be "not pending"
    Nov 12 00:22:58.513: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.841992ms
    Nov 12 00:23:00.529: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035544848s
    Nov 12 00:23:02.529: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 4.035111842s
    Nov 12 00:23:02.529: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.184.98.55 on the node which pod4 resides and expect not scheduled 11/12/22 00:23:02.529
    Nov 12 00:23:02.546: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-4623" to be "not pending"
    Nov 12 00:23:02.561: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.879875ms
    Nov 12 00:23:04.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031037253s
    Nov 12 00:23:06.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035350528s
    Nov 12 00:23:08.584: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037635202s
    Nov 12 00:23:10.599: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052390999s
    Nov 12 00:23:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031494916s
    Nov 12 00:23:14.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.031100509s
    Nov 12 00:23:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031401722s
    Nov 12 00:23:18.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.030665234s
    Nov 12 00:23:20.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.030574058s
    Nov 12 00:23:22.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.03098039s
    Nov 12 00:23:24.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.0318645s
    Nov 12 00:23:26.581: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.034992803s
    Nov 12 00:23:28.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.030229152s
    Nov 12 00:23:30.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.031506483s
    Nov 12 00:23:32.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.033329757s
    Nov 12 00:23:34.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.033407056s
    Nov 12 00:23:36.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.032632884s
    Nov 12 00:23:38.597: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.05035245s
    Nov 12 00:23:40.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.032593453s
    Nov 12 00:23:42.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.033244284s
    Nov 12 00:23:44.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.032268004s
    Nov 12 00:23:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.031090939s
    Nov 12 00:23:48.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.031298894s
    Nov 12 00:23:50.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.032206556s
    Nov 12 00:23:52.584: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.03717469s
    Nov 12 00:23:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.030941594s
    Nov 12 00:23:56.592: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.045647256s
    Nov 12 00:23:58.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.030534121s
    Nov 12 00:24:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.029124456s
    Nov 12 00:24:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.031465805s
    Nov 12 00:24:04.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.030471916s
    Nov 12 00:24:06.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.030055545s
    Nov 12 00:24:08.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.02947788s
    Nov 12 00:24:10.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.030870233s
    Nov 12 00:24:12.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.030996587s
    Nov 12 00:24:14.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.031085014s
    Nov 12 00:24:16.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.030760109s
    Nov 12 00:24:18.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.031810982s
    Nov 12 00:24:20.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.031211478s
    Nov 12 00:24:22.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.039707354s
    Nov 12 00:24:24.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.02975999s
    Nov 12 00:24:26.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.030399209s
    Nov 12 00:24:28.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.029322624s
    Nov 12 00:24:30.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.031308855s
    Nov 12 00:24:32.609: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.062556422s
    Nov 12 00:24:34.583: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.036204258s
    Nov 12 00:24:36.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.031076147s
    Nov 12 00:24:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.030357824s
    Nov 12 00:24:40.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.030532526s
    Nov 12 00:24:42.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.033266406s
    Nov 12 00:24:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.03155523s
    Nov 12 00:24:46.585: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.038217716s
    Nov 12 00:24:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.030524927s
    Nov 12 00:24:50.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.031101597s
    Nov 12 00:24:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.031563815s
    Nov 12 00:24:54.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.031200131s
    Nov 12 00:24:56.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.030407615s
    Nov 12 00:24:58.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.032336252s
    Nov 12 00:25:00.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.030477283s
    Nov 12 00:25:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.031877634s
    Nov 12 00:25:04.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.03224012s
    Nov 12 00:25:06.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.031582606s
    Nov 12 00:25:08.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.032225467s
    Nov 12 00:25:10.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.031876153s
    Nov 12 00:25:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.03205176s
    Nov 12 00:25:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.031609635s
    Nov 12 00:25:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.031271229s
    Nov 12 00:25:18.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.030050413s
    Nov 12 00:25:20.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.03300402s
    Nov 12 00:25:22.588: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.041725493s
    Nov 12 00:25:24.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.031631534s
    Nov 12 00:25:26.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.031379553s
    Nov 12 00:25:28.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.03315811s
    Nov 12 00:25:30.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.031077897s
    Nov 12 00:25:32.606: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.059275709s
    Nov 12 00:25:34.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.03123204s
    Nov 12 00:25:36.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.031251634s
    Nov 12 00:25:38.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.032676414s
    Nov 12 00:25:40.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.03107592s
    Nov 12 00:25:42.581: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.034521636s
    Nov 12 00:25:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.031798961s
    Nov 12 00:25:46.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.031498783s
    Nov 12 00:25:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.030108077s
    Nov 12 00:25:50.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.058678422s
    Nov 12 00:25:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.031505029s
    Nov 12 00:25:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.030543208s
    Nov 12 00:25:56.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.039556304s
    Nov 12 00:25:58.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.032171329s
    Nov 12 00:26:00.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.030640637s
    Nov 12 00:26:02.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.029725574s
    Nov 12 00:26:04.587: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.040788522s
    Nov 12 00:26:06.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.032117034s
    Nov 12 00:26:08.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.029609073s
    Nov 12 00:26:10.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.032238334s
    Nov 12 00:26:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.03164555s
    Nov 12 00:26:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.031213909s
    Nov 12 00:26:16.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.030284947s
    Nov 12 00:26:18.575: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.02854045s
    Nov 12 00:26:20.583: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.036209464s
    Nov 12 00:26:22.605: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.058256943s
    Nov 12 00:26:24.611: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.065067411s
    Nov 12 00:26:26.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.035274346s
    Nov 12 00:26:28.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.030246128s
    Nov 12 00:26:30.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.029756814s
    Nov 12 00:26:32.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.03087023s
    Nov 12 00:26:34.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.031269847s
    Nov 12 00:26:36.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.030509064s
    Nov 12 00:26:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.030656059s
    Nov 12 00:26:40.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.032358686s
    Nov 12 00:26:42.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.031585881s
    Nov 12 00:26:44.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.031901018s
    Nov 12 00:26:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.030500052s
    Nov 12 00:26:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.030790768s
    Nov 12 00:26:50.580: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.033328954s
    Nov 12 00:26:52.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.031577732s
    Nov 12 00:26:54.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.031358039s
    Nov 12 00:26:56.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.030935959s
    Nov 12 00:26:58.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.031380391s
    Nov 12 00:27:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.029830014s
    Nov 12 00:27:02.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.032051108s
    Nov 12 00:27:04.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.03272375s
    Nov 12 00:27:06.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.030941906s
    Nov 12 00:27:08.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.031055317s
    Nov 12 00:27:10.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.029687115s
    Nov 12 00:27:12.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.031226235s
    Nov 12 00:27:14.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.032091249s
    Nov 12 00:27:16.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.032069432s
    Nov 12 00:27:18.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.030492392s
    Nov 12 00:27:20.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.031897268s
    Nov 12 00:27:22.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.03152963s
    Nov 12 00:27:24.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.030420055s
    Nov 12 00:27:26.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.031159582s
    Nov 12 00:27:28.596: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.049383678s
    Nov 12 00:27:30.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.030162826s
    Nov 12 00:27:32.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.030553667s
    Nov 12 00:27:34.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.03219683s
    Nov 12 00:27:36.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.03156564s
    Nov 12 00:27:38.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.030365161s
    Nov 12 00:27:40.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.031434479s
    Nov 12 00:27:42.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.031633396s
    Nov 12 00:27:44.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.030215214s
    Nov 12 00:27:46.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.030704205s
    Nov 12 00:27:48.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.030906226s
    Nov 12 00:27:50.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.030887183s
    Nov 12 00:27:52.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.029749183s
    Nov 12 00:27:54.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.03104701s
    Nov 12 00:27:56.578: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.032000451s
    Nov 12 00:27:58.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.030025185s
    Nov 12 00:28:00.576: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.029168819s
    Nov 12 00:28:02.577: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.030342241s
    Nov 12 00:28:02.593: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.046403053s
    STEP: removing the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 off the node 10.184.98.55 11/12/22 00:28:02.593
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-b6e3501b-dcf8-4be2-8301-e6fb3af265c5 11/12/22 00:28:02.625
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:28:02.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4623" for this suite. 11/12/22 00:28:02.649
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:02.682
Nov 12 00:28:02.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:28:02.686
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:02.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:02.772
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 11/12/22 00:28:02.789
STEP: watching for the Service to be added 11/12/22 00:28:02.828
Nov 12 00:28:02.838: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Nov 12 00:28:02.838: INFO: Service test-service-p4fhg created
STEP: Getting /status 11/12/22 00:28:02.838
Nov 12 00:28:02.849: INFO: Service test-service-p4fhg has LoadBalancer: {[]}
STEP: patching the ServiceStatus 11/12/22 00:28:02.849
STEP: watching for the Service to be patched 11/12/22 00:28:02.862
Nov 12 00:28:02.868: INFO: observed Service test-service-p4fhg in namespace services-5934 with annotations: map[] & LoadBalancer: {[]}
Nov 12 00:28:02.868: INFO: Found Service test-service-p4fhg in namespace services-5934 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Nov 12 00:28:02.868: INFO: Service test-service-p4fhg has service status patched
STEP: updating the ServiceStatus 11/12/22 00:28:02.868
Nov 12 00:28:02.890: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 11/12/22 00:28:02.89
Nov 12 00:28:02.897: INFO: Observed Service test-service-p4fhg in namespace services-5934 with annotations: map[] & Conditions: {[]}
Nov 12 00:28:02.897: INFO: Observed event: &Service{ObjectMeta:{test-service-p4fhg  services-5934  743d9467-7789-42ae-b8e1-154b298fb219 40500 0 2022-11-12 00:28:02 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-12 00:28:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-12 00:28:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.99.38,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.99.38],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Nov 12 00:28:02.898: INFO: Found Service test-service-p4fhg in namespace services-5934 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 00:28:02.898: INFO: Service test-service-p4fhg has service status updated
STEP: patching the service 11/12/22 00:28:02.898
STEP: watching for the Service to be patched 11/12/22 00:28:02.914
Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
Nov 12 00:28:02.922: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service:patched test-service-static:true]
Nov 12 00:28:02.922: INFO: Service test-service-p4fhg patched
STEP: deleting the service 11/12/22 00:28:02.922
STEP: watching for the Service to be deleted 11/12/22 00:28:02.962
Nov 12 00:28:02.967: INFO: Observed event: ADDED
Nov 12 00:28:02.967: INFO: Observed event: MODIFIED
Nov 12 00:28:02.967: INFO: Observed event: MODIFIED
Nov 12 00:28:02.968: INFO: Observed event: MODIFIED
Nov 12 00:28:02.968: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Nov 12 00:28:02.968: INFO: Service test-service-p4fhg deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:28:02.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5934" for this suite. 11/12/22 00:28:02.979
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":240,"skipped":4464,"failed":0}
------------------------------
• [0.332 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:02.682
    Nov 12 00:28:02.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:28:02.686
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:02.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:02.772
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 11/12/22 00:28:02.789
    STEP: watching for the Service to be added 11/12/22 00:28:02.828
    Nov 12 00:28:02.838: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Nov 12 00:28:02.838: INFO: Service test-service-p4fhg created
    STEP: Getting /status 11/12/22 00:28:02.838
    Nov 12 00:28:02.849: INFO: Service test-service-p4fhg has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 11/12/22 00:28:02.849
    STEP: watching for the Service to be patched 11/12/22 00:28:02.862
    Nov 12 00:28:02.868: INFO: observed Service test-service-p4fhg in namespace services-5934 with annotations: map[] & LoadBalancer: {[]}
    Nov 12 00:28:02.868: INFO: Found Service test-service-p4fhg in namespace services-5934 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Nov 12 00:28:02.868: INFO: Service test-service-p4fhg has service status patched
    STEP: updating the ServiceStatus 11/12/22 00:28:02.868
    Nov 12 00:28:02.890: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 11/12/22 00:28:02.89
    Nov 12 00:28:02.897: INFO: Observed Service test-service-p4fhg in namespace services-5934 with annotations: map[] & Conditions: {[]}
    Nov 12 00:28:02.897: INFO: Observed event: &Service{ObjectMeta:{test-service-p4fhg  services-5934  743d9467-7789-42ae-b8e1-154b298fb219 40500 0 2022-11-12 00:28:02 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-12 00:28:02 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-12 00:28:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:172.21.99.38,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[172.21.99.38],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Nov 12 00:28:02.898: INFO: Found Service test-service-p4fhg in namespace services-5934 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 00:28:02.898: INFO: Service test-service-p4fhg has service status updated
    STEP: patching the service 11/12/22 00:28:02.898
    STEP: watching for the Service to be patched 11/12/22 00:28:02.914
    Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
    Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
    Nov 12 00:28:02.921: INFO: observed Service test-service-p4fhg in namespace services-5934 with labels: map[test-service-static:true]
    Nov 12 00:28:02.922: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service:patched test-service-static:true]
    Nov 12 00:28:02.922: INFO: Service test-service-p4fhg patched
    STEP: deleting the service 11/12/22 00:28:02.922
    STEP: watching for the Service to be deleted 11/12/22 00:28:02.962
    Nov 12 00:28:02.967: INFO: Observed event: ADDED
    Nov 12 00:28:02.967: INFO: Observed event: MODIFIED
    Nov 12 00:28:02.967: INFO: Observed event: MODIFIED
    Nov 12 00:28:02.968: INFO: Observed event: MODIFIED
    Nov 12 00:28:02.968: INFO: Found Service test-service-p4fhg in namespace services-5934 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Nov 12 00:28:02.968: INFO: Service test-service-p4fhg deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:28:02.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5934" for this suite. 11/12/22 00:28:02.979
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:03.037
Nov 12 00:28:03.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 00:28:03.039
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:03.071
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:03.084
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 00:28:03.114
Nov 12 00:28:03.143: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9529" to be "running and ready"
Nov 12 00:28:03.157: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.164162ms
Nov 12 00:28:03.157: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:28:05.174: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031323761s
Nov 12 00:28:05.175: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:28:07.173: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.029896342s
Nov 12 00:28:07.173: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 00:28:07.173: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 11/12/22 00:28:07.189
Nov 12 00:28:07.210: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9529" to be "running and ready"
Nov 12 00:28:07.226: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.716389ms
Nov 12 00:28:07.226: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:28:09.241: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030471597s
Nov 12 00:28:09.241: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:28:11.242: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.031666514s
Nov 12 00:28:11.242: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Nov 12 00:28:11.242: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/12/22 00:28:11.259
STEP: delete the pod with lifecycle hook 11/12/22 00:28:11.34
Nov 12 00:28:11.392: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 12 00:28:11.411: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 12 00:28:13.412: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 12 00:28:13.427: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 00:28:13.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9529" for this suite. 11/12/22 00:28:13.438
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":241,"skipped":4525,"failed":0}
------------------------------
• [SLOW TEST] [10.428 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:03.037
    Nov 12 00:28:03.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 00:28:03.039
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:03.071
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:03.084
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 00:28:03.114
    Nov 12 00:28:03.143: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9529" to be "running and ready"
    Nov 12 00:28:03.157: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 14.164162ms
    Nov 12 00:28:03.157: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:28:05.174: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031323761s
    Nov 12 00:28:05.175: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:28:07.173: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.029896342s
    Nov 12 00:28:07.173: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 00:28:07.173: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 11/12/22 00:28:07.189
    Nov 12 00:28:07.210: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-9529" to be "running and ready"
    Nov 12 00:28:07.226: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.716389ms
    Nov 12 00:28:07.226: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:28:09.241: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030471597s
    Nov 12 00:28:09.241: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:28:11.242: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.031666514s
    Nov 12 00:28:11.242: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Nov 12 00:28:11.242: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/12/22 00:28:11.259
    STEP: delete the pod with lifecycle hook 11/12/22 00:28:11.34
    Nov 12 00:28:11.392: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 12 00:28:11.411: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 12 00:28:13.412: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 12 00:28:13.427: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 00:28:13.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9529" for this suite. 11/12/22 00:28:13.438
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:13.475
Nov 12 00:28:13.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/12/22 00:28:13.478
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:13.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:13.522
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/12/22 00:28:13.532
Nov 12 00:28:13.565: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 00:28:18.580: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 00:28:18.58
STEP: getting scale subresource 11/12/22 00:28:18.58
STEP: updating a scale subresource 11/12/22 00:28:18.593
STEP: verifying the replicaset Spec.Replicas was modified 11/12/22 00:28:18.611
STEP: Patch a scale subresource 11/12/22 00:28:18.626
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 00:28:18.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5434" for this suite. 11/12/22 00:28:18.733
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":242,"skipped":4535,"failed":0}
------------------------------
• [SLOW TEST] [5.290 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:13.475
    Nov 12 00:28:13.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/12/22 00:28:13.478
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:13.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:13.522
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/12/22 00:28:13.532
    Nov 12 00:28:13.565: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 00:28:18.580: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 00:28:18.58
    STEP: getting scale subresource 11/12/22 00:28:18.58
    STEP: updating a scale subresource 11/12/22 00:28:18.593
    STEP: verifying the replicaset Spec.Replicas was modified 11/12/22 00:28:18.611
    STEP: Patch a scale subresource 11/12/22 00:28:18.626
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 00:28:18.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5434" for this suite. 11/12/22 00:28:18.733
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:18.8
Nov 12 00:28:18.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:28:18.802
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:18.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:18.847
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-66f6d48b-c40b-471f-a764-e66492b4a4a0 11/12/22 00:28:18.874
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:28:18.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9759" for this suite. 11/12/22 00:28:18.89
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":243,"skipped":4642,"failed":0}
------------------------------
• [0.118 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:18.8
    Nov 12 00:28:18.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:28:18.802
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:18.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:18.847
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-66f6d48b-c40b-471f-a764-e66492b4a4a0 11/12/22 00:28:18.874
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:28:18.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9759" for this suite. 11/12/22 00:28:18.89
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:18.92
Nov 12 00:28:18.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename containers 11/12/22 00:28:18.922
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:19.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:19.012
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 11/12/22 00:28:19.022
Nov 12 00:28:19.052: INFO: Waiting up to 5m0s for pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74" in namespace "containers-8283" to be "Succeeded or Failed"
Nov 12 00:28:19.066: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 13.782009ms
Nov 12 00:28:21.082: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029657487s
Nov 12 00:28:23.083: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030342354s
Nov 12 00:28:25.082: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030074917s
STEP: Saw pod success 11/12/22 00:28:25.082
Nov 12 00:28:25.083: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74" satisfied condition "Succeeded or Failed"
Nov 12 00:28:25.098: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:28:25.128
Nov 12 00:28:25.243: INFO: Waiting for pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 to disappear
Nov 12 00:28:25.259: INFO: Pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 00:28:25.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8283" for this suite. 11/12/22 00:28:25.273
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":244,"skipped":4648,"failed":0}
------------------------------
• [SLOW TEST] [6.382 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:18.92
    Nov 12 00:28:18.921: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename containers 11/12/22 00:28:18.922
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:19.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:19.012
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 11/12/22 00:28:19.022
    Nov 12 00:28:19.052: INFO: Waiting up to 5m0s for pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74" in namespace "containers-8283" to be "Succeeded or Failed"
    Nov 12 00:28:19.066: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 13.782009ms
    Nov 12 00:28:21.082: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029657487s
    Nov 12 00:28:23.083: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030342354s
    Nov 12 00:28:25.082: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030074917s
    STEP: Saw pod success 11/12/22 00:28:25.082
    Nov 12 00:28:25.083: INFO: Pod "client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74" satisfied condition "Succeeded or Failed"
    Nov 12 00:28:25.098: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:28:25.128
    Nov 12 00:28:25.243: INFO: Waiting for pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 to disappear
    Nov 12 00:28:25.259: INFO: Pod client-containers-5a3fc4bd-fe70-430f-9382-ac77c776de74 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 00:28:25.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8283" for this suite. 11/12/22 00:28:25.273
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:25.308
Nov 12 00:28:25.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:28:25.31
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:25.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:25.357
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 00:28:25.367
Nov 12 00:28:25.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 12 00:28:25.551: INFO: stderr: ""
Nov 12 00:28:25.551: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 11/12/22 00:28:25.551
STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 00:28:30.603
Nov 12 00:28:30.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 get pod e2e-test-httpd-pod -o json'
Nov 12 00:28:30.796: INFO: stderr: ""
Nov 12 00:28:30.796: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"216da9a5460b625ee9cf69ecf7f46c4d659ef28b3b8794961e93bf0b20d42fff\",\n            \"cni.projectcalico.org/podIP\": \"172.30.146.46/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.146.46/32\"\n        },\n        \"creationTimestamp\": \"2022-11-12T00:28:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8202\",\n        \"resourceVersion\": \"40736\",\n        \"uid\": \"35cf4d32-202f-4717-a81c-3aab475da503\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-4tf9k\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.184.98.55\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-4tf9k\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://d2d1e0dc9a3e138e8573d97154af15ed661935398b56e59507d17c8d6176299c\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-12T00:28:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.184.98.55\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.146.46\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.146.46\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-12T00:28:25Z\"\n    }\n}\n"
STEP: replace the image in the pod 11/12/22 00:28:30.796
Nov 12 00:28:30.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 replace -f -'
Nov 12 00:28:31.502: INFO: stderr: ""
Nov 12 00:28:31.502: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/12/22 00:28:31.502
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Nov 12 00:28:31.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 delete pods e2e-test-httpd-pod'
Nov 12 00:28:33.562: INFO: stderr: ""
Nov 12 00:28:33.562: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:28:33.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8202" for this suite. 11/12/22 00:28:33.58
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":245,"skipped":4656,"failed":0}
------------------------------
• [SLOW TEST] [8.298 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:25.308
    Nov 12 00:28:25.308: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:28:25.31
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:25.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:25.357
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 00:28:25.367
    Nov 12 00:28:25.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 12 00:28:25.551: INFO: stderr: ""
    Nov 12 00:28:25.551: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 11/12/22 00:28:25.551
    STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 00:28:30.603
    Nov 12 00:28:30.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 get pod e2e-test-httpd-pod -o json'
    Nov 12 00:28:30.796: INFO: stderr: ""
    Nov 12 00:28:30.796: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"216da9a5460b625ee9cf69ecf7f46c4d659ef28b3b8794961e93bf0b20d42fff\",\n            \"cni.projectcalico.org/podIP\": \"172.30.146.46/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.30.146.46/32\"\n        },\n        \"creationTimestamp\": \"2022-11-12T00:28:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8202\",\n        \"resourceVersion\": \"40736\",\n        \"uid\": \"35cf4d32-202f-4717-a81c-3aab475da503\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-4tf9k\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.184.98.55\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-4tf9k\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T00:28:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://d2d1e0dc9a3e138e8573d97154af15ed661935398b56e59507d17c8d6176299c\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-12T00:28:27Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.184.98.55\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.146.46\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.146.46\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-12T00:28:25Z\"\n    }\n}\n"
    STEP: replace the image in the pod 11/12/22 00:28:30.796
    Nov 12 00:28:30.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 replace -f -'
    Nov 12 00:28:31.502: INFO: stderr: ""
    Nov 12 00:28:31.502: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/12/22 00:28:31.502
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Nov 12 00:28:31.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8202 delete pods e2e-test-httpd-pod'
    Nov 12 00:28:33.562: INFO: stderr: ""
    Nov 12 00:28:33.562: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:28:33.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8202" for this suite. 11/12/22 00:28:33.58
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:33.609
Nov 12 00:28:33.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:28:33.612
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:33.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:33.656
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-32ae4c61-cb31-4b52-b185-81114957c01d 11/12/22 00:28:33.664
STEP: Creating a pod to test consume configMaps 11/12/22 00:28:33.682
Nov 12 00:28:33.713: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1" in namespace "projected-5150" to be "Succeeded or Failed"
Nov 12 00:28:33.728: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297537ms
Nov 12 00:28:35.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03186154s
Nov 12 00:28:37.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031286242s
STEP: Saw pod success 11/12/22 00:28:37.745
Nov 12 00:28:37.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1" satisfied condition "Succeeded or Failed"
Nov 12 00:28:37.760: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:28:37.803
Nov 12 00:28:37.890: INFO: Waiting for pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 to disappear
Nov 12 00:28:37.905: INFO: Pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 00:28:37.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5150" for this suite. 11/12/22 00:28:37.933
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":246,"skipped":4657,"failed":0}
------------------------------
• [4.352 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:33.609
    Nov 12 00:28:33.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:28:33.612
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:33.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:33.656
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-32ae4c61-cb31-4b52-b185-81114957c01d 11/12/22 00:28:33.664
    STEP: Creating a pod to test consume configMaps 11/12/22 00:28:33.682
    Nov 12 00:28:33.713: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1" in namespace "projected-5150" to be "Succeeded or Failed"
    Nov 12 00:28:33.728: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297537ms
    Nov 12 00:28:35.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03186154s
    Nov 12 00:28:37.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031286242s
    STEP: Saw pod success 11/12/22 00:28:37.745
    Nov 12 00:28:37.745: INFO: Pod "pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1" satisfied condition "Succeeded or Failed"
    Nov 12 00:28:37.760: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:28:37.803
    Nov 12 00:28:37.890: INFO: Waiting for pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 to disappear
    Nov 12 00:28:37.905: INFO: Pod pod-projected-configmaps-9ed69fbc-e3ff-4343-99e6-ff6ef8e284d1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 00:28:37.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5150" for this suite. 11/12/22 00:28:37.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:37.964
Nov 12 00:28:37.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:28:37.967
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:38.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:38.042
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 11/12/22 00:28:38.051
STEP: Creating a ResourceQuota 11/12/22 00:28:43.061
STEP: Ensuring resource quota status is calculated 11/12/22 00:28:43.07
STEP: Creating a ReplicaSet 11/12/22 00:28:45.079
STEP: Ensuring resource quota status captures replicaset creation 11/12/22 00:28:45.105
STEP: Deleting a ReplicaSet 11/12/22 00:28:47.116
STEP: Ensuring resource quota status released usage 11/12/22 00:28:47.149
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:28:49.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1336" for this suite. 11/12/22 00:28:49.172
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":247,"skipped":4668,"failed":0}
------------------------------
• [SLOW TEST] [11.266 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:37.964
    Nov 12 00:28:37.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:28:37.967
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:38.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:38.042
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 11/12/22 00:28:38.051
    STEP: Creating a ResourceQuota 11/12/22 00:28:43.061
    STEP: Ensuring resource quota status is calculated 11/12/22 00:28:43.07
    STEP: Creating a ReplicaSet 11/12/22 00:28:45.079
    STEP: Ensuring resource quota status captures replicaset creation 11/12/22 00:28:45.105
    STEP: Deleting a ReplicaSet 11/12/22 00:28:47.116
    STEP: Ensuring resource quota status released usage 11/12/22 00:28:47.149
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:28:49.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1336" for this suite. 11/12/22 00:28:49.172
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:49.238
Nov 12 00:28:49.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename endpointslice 11/12/22 00:28:49.24
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:49.275
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:49.284
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Nov 12 00:28:49.315: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
Nov 12 00:28:49.315: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 12 00:28:49.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3097" for this suite. 11/12/22 00:28:49.325
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":248,"skipped":4739,"failed":0}
------------------------------
• [0.115 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:49.238
    Nov 12 00:28:49.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename endpointslice 11/12/22 00:28:49.24
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:49.275
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:49.284
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Nov 12 00:28:49.315: INFO: Endpoints addresses: [172.20.0.1] , ports: [2040]
    Nov 12 00:28:49.315: INFO: EndpointSlices addresses: [172.20.0.1] , ports: [2040]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 12 00:28:49.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-3097" for this suite. 11/12/22 00:28:49.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:49.372
Nov 12 00:28:49.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 00:28:49.374
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:49.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:49.418
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 11/12/22 00:28:49.455
Nov 12 00:28:49.455: INFO: Creating simple deployment test-deployment-4p7zb
Nov 12 00:28:49.501: INFO: deployment "test-deployment-4p7zb" doesn't have the required revision set
Nov 12 00:28:51.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-4p7zb-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 11/12/22 00:28:53.572
Nov 12 00:28:53.588: INFO: Deployment test-deployment-4p7zb has Conditions: [{Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 11/12/22 00:28:53.588
Nov 12 00:28:53.625: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4p7zb-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 11/12/22 00:28:53.625
Nov 12 00:28:53.631: INFO: Observed &Deployment event: ADDED
Nov 12 00:28:53.632: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
Nov 12 00:28:53.633: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.633: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
Nov 12 00:28:53.633: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 00:28:53.634: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.635: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 00:28:53.635: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4p7zb-777898ffcc" is progressing.}
Nov 12 00:28:53.636: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.636: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 00:28:53.636: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
Nov 12 00:28:53.637: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.637: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 00:28:53.637: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
Nov 12 00:28:53.637: INFO: Found Deployment test-deployment-4p7zb in namespace deployment-9097 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 00:28:53.637: INFO: Deployment test-deployment-4p7zb has an updated status
STEP: patching the Statefulset Status 11/12/22 00:28:53.637
Nov 12 00:28:53.638: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 12 00:28:53.656: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 11/12/22 00:28:53.656
Nov 12 00:28:53.667: INFO: Observed &Deployment event: ADDED
Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
Nov 12 00:28:53.667: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 00:28:53.667: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4p7zb-777898ffcc" is progressing.}
Nov 12 00:28:53.668: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
Nov 12 00:28:53.669: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 00:28:53.670: INFO: Observed &Deployment event: MODIFIED
Nov 12 00:28:53.671: INFO: Found deployment test-deployment-4p7zb in namespace deployment-9097 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Nov 12 00:28:53.671: INFO: Deployment test-deployment-4p7zb has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 00:28:53.690: INFO: Deployment "test-deployment-4p7zb":
&Deployment{ObjectMeta:{test-deployment-4p7zb  deployment-9097  0805e8a5-3a71-4818-8d78-a0ae60a04fc8 40875 1 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-12 00:28:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-12 00:28:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004902f98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-4p7zb-777898ffcc",LastUpdateTime:2022-11-12 00:28:53 +0000 UTC,LastTransitionTime:2022-11-12 00:28:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 00:28:53.720: INFO: New ReplicaSet "test-deployment-4p7zb-777898ffcc" of Deployment "test-deployment-4p7zb":
&ReplicaSet{ObjectMeta:{test-deployment-4p7zb-777898ffcc  deployment-9097  ac6fa96c-593b-454d-87b8-6b3ce377a7ad 40868 1 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-4p7zb 0805e8a5-3a71-4818-8d78-a0ae60a04fc8 0xc0049033e0 0xc0049033e1}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0805e8a5-3a71-4818-8d78-a0ae60a04fc8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:28:51 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004903488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:28:53.735: INFO: Pod "test-deployment-4p7zb-777898ffcc-kz6bx" is available:
&Pod{ObjectMeta:{test-deployment-4p7zb-777898ffcc-kz6bx test-deployment-4p7zb-777898ffcc- deployment-9097  cdbf9462-b0ec-47a2-a74f-15982fba1cf7 40867 0 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:4a59ce616c8383477c4b7a2a848050be6a033fbaf10b5bb4a23eebe2746a7a39 cni.projectcalico.org/podIP:172.30.146.48/32 cni.projectcalico.org/podIPs:172.30.146.48/32] [{apps/v1 ReplicaSet test-deployment-4p7zb-777898ffcc ac6fa96c-593b-454d-87b8-6b3ce377a7ad 0xc0049038a0 0xc0049038a1}] [] [{kube-controller-manager Update v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6fa96c-593b-454d-87b8-6b3ce377a7ad\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:28:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:28:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j8z62,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j8z62,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.48,StartTime:2022-11-12 00:28:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:28:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f99ac70c45f675d235b5d09b9358e062afef2c3399c4f198422ba1270ee32e6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 00:28:53.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9097" for this suite. 11/12/22 00:28:53.747
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":249,"skipped":4759,"failed":0}
------------------------------
• [4.404 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:49.372
    Nov 12 00:28:49.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 00:28:49.374
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:49.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:49.418
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 11/12/22 00:28:49.455
    Nov 12 00:28:49.455: INFO: Creating simple deployment test-deployment-4p7zb
    Nov 12 00:28:49.501: INFO: deployment "test-deployment-4p7zb" doesn't have the required revision set
    Nov 12 00:28:51.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-4p7zb-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 11/12/22 00:28:53.572
    Nov 12 00:28:53.588: INFO: Deployment test-deployment-4p7zb has Conditions: [{Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 11/12/22 00:28:53.588
    Nov 12 00:28:53.625: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 51, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 49, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4p7zb-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 11/12/22 00:28:53.625
    Nov 12 00:28:53.631: INFO: Observed &Deployment event: ADDED
    Nov 12 00:28:53.632: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
    Nov 12 00:28:53.633: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.633: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
    Nov 12 00:28:53.633: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 00:28:53.634: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.635: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 00:28:53.635: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4p7zb-777898ffcc" is progressing.}
    Nov 12 00:28:53.636: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.636: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 00:28:53.636: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
    Nov 12 00:28:53.637: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.637: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 00:28:53.637: INFO: Observed Deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
    Nov 12 00:28:53.637: INFO: Found Deployment test-deployment-4p7zb in namespace deployment-9097 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 00:28:53.637: INFO: Deployment test-deployment-4p7zb has an updated status
    STEP: patching the Statefulset Status 11/12/22 00:28:53.637
    Nov 12 00:28:53.638: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 12 00:28:53.656: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 11/12/22 00:28:53.656
    Nov 12 00:28:53.667: INFO: Observed &Deployment event: ADDED
    Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
    Nov 12 00:28:53.667: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4p7zb-777898ffcc"}
    Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 00:28:53.667: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.667: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:49 +0000 UTC 2022-11-12 00:28:49 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4p7zb-777898ffcc" is progressing.}
    Nov 12 00:28:53.668: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 00:28:53.668: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
    Nov 12 00:28:53.669: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 00:28:51 +0000 UTC 2022-11-12 00:28:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4p7zb-777898ffcc" has successfully progressed.}
    Nov 12 00:28:53.670: INFO: Observed deployment test-deployment-4p7zb in namespace deployment-9097 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 00:28:53.670: INFO: Observed &Deployment event: MODIFIED
    Nov 12 00:28:53.671: INFO: Found deployment test-deployment-4p7zb in namespace deployment-9097 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Nov 12 00:28:53.671: INFO: Deployment test-deployment-4p7zb has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 00:28:53.690: INFO: Deployment "test-deployment-4p7zb":
    &Deployment{ObjectMeta:{test-deployment-4p7zb  deployment-9097  0805e8a5-3a71-4818-8d78-a0ae60a04fc8 40875 1 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-12 00:28:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-12 00:28:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004902f98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-4p7zb-777898ffcc",LastUpdateTime:2022-11-12 00:28:53 +0000 UTC,LastTransitionTime:2022-11-12 00:28:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 00:28:53.720: INFO: New ReplicaSet "test-deployment-4p7zb-777898ffcc" of Deployment "test-deployment-4p7zb":
    &ReplicaSet{ObjectMeta:{test-deployment-4p7zb-777898ffcc  deployment-9097  ac6fa96c-593b-454d-87b8-6b3ce377a7ad 40868 1 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-4p7zb 0805e8a5-3a71-4818-8d78-a0ae60a04fc8 0xc0049033e0 0xc0049033e1}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0805e8a5-3a71-4818-8d78-a0ae60a04fc8\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:28:51 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004903488 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:28:53.735: INFO: Pod "test-deployment-4p7zb-777898ffcc-kz6bx" is available:
    &Pod{ObjectMeta:{test-deployment-4p7zb-777898ffcc-kz6bx test-deployment-4p7zb-777898ffcc- deployment-9097  cdbf9462-b0ec-47a2-a74f-15982fba1cf7 40867 0 2022-11-12 00:28:49 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:4a59ce616c8383477c4b7a2a848050be6a033fbaf10b5bb4a23eebe2746a7a39 cni.projectcalico.org/podIP:172.30.146.48/32 cni.projectcalico.org/podIPs:172.30.146.48/32] [{apps/v1 ReplicaSet test-deployment-4p7zb-777898ffcc ac6fa96c-593b-454d-87b8-6b3ce377a7ad 0xc0049038a0 0xc0049038a1}] [] [{kube-controller-manager Update v1 2022-11-12 00:28:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ac6fa96c-593b-454d-87b8-6b3ce377a7ad\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:28:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:28:51 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-j8z62,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-j8z62,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:28:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.48,StartTime:2022-11-12 00:28:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:28:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f99ac70c45f675d235b5d09b9358e062afef2c3399c4f198422ba1270ee32e6f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 00:28:53.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9097" for this suite. 11/12/22 00:28:53.747
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:28:53.784
Nov 12 00:28:53.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-webhook 11/12/22 00:28:53.786
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:53.824
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:53.833
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/12/22 00:28:53.843
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 00:28:54.983
STEP: Deploying the custom resource conversion webhook pod 11/12/22 00:28:55.006
STEP: Wait for the deployment to be ready 11/12/22 00:28:55.033
Nov 12 00:28:55.066: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov 12 00:28:57.110: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:28:59.124
STEP: Verifying the service has paired with the endpoint 11/12/22 00:28:59.184
Nov 12 00:29:00.185: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Nov 12 00:29:00.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Creating a v1 custom resource 11/12/22 00:29:02.916
STEP: v2 custom resource should be converted 11/12/22 00:29:02.928
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:29:03.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8113" for this suite. 11/12/22 00:29:03.488
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":250,"skipped":4761,"failed":0}
------------------------------
• [SLOW TEST] [9.895 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:28:53.784
    Nov 12 00:28:53.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-webhook 11/12/22 00:28:53.786
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:28:53.824
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:28:53.833
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/12/22 00:28:53.843
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 00:28:54.983
    STEP: Deploying the custom resource conversion webhook pod 11/12/22 00:28:55.006
    STEP: Wait for the deployment to be ready 11/12/22 00:28:55.033
    Nov 12 00:28:55.066: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Nov 12 00:28:57.110: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 28, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:28:59.124
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:28:59.184
    Nov 12 00:29:00.185: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Nov 12 00:29:00.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Creating a v1 custom resource 11/12/22 00:29:02.916
    STEP: v2 custom resource should be converted 11/12/22 00:29:02.928
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:29:03.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-8113" for this suite. 11/12/22 00:29:03.488
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:29:03.689
Nov 12 00:29:03.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context-test 11/12/22 00:29:03.692
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:03.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:03.743
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Nov 12 00:29:03.810: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9" in namespace "security-context-test-6263" to be "Succeeded or Failed"
Nov 12 00:29:03.845: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.903272ms
Nov 12 00:29:05.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051551904s
Nov 12 00:29:07.868: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057248389s
Nov 12 00:29:09.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051410317s
Nov 12 00:29:09.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 00:29:09.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6263" for this suite. 11/12/22 00:29:09.874
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":251,"skipped":4775,"failed":0}
------------------------------
• [SLOW TEST] [6.213 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:29:03.689
    Nov 12 00:29:03.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context-test 11/12/22 00:29:03.692
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:03.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:03.743
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Nov 12 00:29:03.810: INFO: Waiting up to 5m0s for pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9" in namespace "security-context-test-6263" to be "Succeeded or Failed"
    Nov 12 00:29:03.845: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.903272ms
    Nov 12 00:29:05.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051551904s
    Nov 12 00:29:07.868: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057248389s
    Nov 12 00:29:09.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051410317s
    Nov 12 00:29:09.862: INFO: Pod "busybox-user-65534-5d4dbbbc-dfa2-4ff4-acb7-1795a79168a9" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 00:29:09.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6263" for this suite. 11/12/22 00:29:09.874
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:29:09.905
Nov 12 00:29:09.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/12/22 00:29:09.907
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:09.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:09.951
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 11/12/22 00:29:09.959
Nov 12 00:29:09.991: INFO: Waiting up to 5m0s for pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2" in namespace "var-expansion-2757" to be "Succeeded or Failed"
Nov 12 00:29:10.007: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.908314ms
Nov 12 00:29:12.026: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034800785s
Nov 12 00:29:14.024: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032852694s
Nov 12 00:29:16.027: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035589939s
STEP: Saw pod success 11/12/22 00:29:16.027
Nov 12 00:29:16.027: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2" satisfied condition "Succeeded or Failed"
Nov 12 00:29:16.043: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 container dapi-container: <nil>
STEP: delete the pod 11/12/22 00:29:16.071
Nov 12 00:29:16.108: INFO: Waiting for pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 to disappear
Nov 12 00:29:16.123: INFO: Pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 00:29:16.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2757" for this suite. 11/12/22 00:29:16.135
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":252,"skipped":4778,"failed":0}
------------------------------
• [SLOW TEST] [6.258 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:29:09.905
    Nov 12 00:29:09.905: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/12/22 00:29:09.907
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:09.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:09.951
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 11/12/22 00:29:09.959
    Nov 12 00:29:09.991: INFO: Waiting up to 5m0s for pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2" in namespace "var-expansion-2757" to be "Succeeded or Failed"
    Nov 12 00:29:10.007: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.908314ms
    Nov 12 00:29:12.026: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034800785s
    Nov 12 00:29:14.024: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032852694s
    Nov 12 00:29:16.027: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035589939s
    STEP: Saw pod success 11/12/22 00:29:16.027
    Nov 12 00:29:16.027: INFO: Pod "var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2" satisfied condition "Succeeded or Failed"
    Nov 12 00:29:16.043: INFO: Trying to get logs from node 10.184.98.55 pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 00:29:16.071
    Nov 12 00:29:16.108: INFO: Waiting for pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 to disappear
    Nov 12 00:29:16.123: INFO: Pod var-expansion-048318ac-cc9f-4876-bc52-514c2543d5e2 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 00:29:16.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2757" for this suite. 11/12/22 00:29:16.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:29:16.17
Nov 12 00:29:16.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/12/22 00:29:16.173
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:16.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:16.219
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 in namespace container-probe-9997 11/12/22 00:29:16.235
Nov 12 00:29:16.264: INFO: Waiting up to 5m0s for pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5" in namespace "container-probe-9997" to be "not pending"
Nov 12 00:29:16.280: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.039832ms
Nov 12 00:29:18.295: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031269688s
Nov 12 00:29:20.296: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Running", Reason="", readiness=true. Elapsed: 4.031963643s
Nov 12 00:29:20.296: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5" satisfied condition "not pending"
Nov 12 00:29:20.296: INFO: Started pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 in namespace container-probe-9997
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:29:20.296
Nov 12 00:29:20.313: INFO: Initial restart count of pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 is 0
STEP: deleting the pod 11/12/22 00:33:20.406
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 00:33:20.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9997" for this suite. 11/12/22 00:33:20.475
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":253,"skipped":4794,"failed":0}
------------------------------
• [SLOW TEST] [244.333 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:29:16.17
    Nov 12 00:29:16.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/12/22 00:29:16.173
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:29:16.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:29:16.219
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 in namespace container-probe-9997 11/12/22 00:29:16.235
    Nov 12 00:29:16.264: INFO: Waiting up to 5m0s for pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5" in namespace "container-probe-9997" to be "not pending"
    Nov 12 00:29:16.280: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.039832ms
    Nov 12 00:29:18.295: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031269688s
    Nov 12 00:29:20.296: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5": Phase="Running", Reason="", readiness=true. Elapsed: 4.031963643s
    Nov 12 00:29:20.296: INFO: Pod "busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5" satisfied condition "not pending"
    Nov 12 00:29:20.296: INFO: Started pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 in namespace container-probe-9997
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:29:20.296
    Nov 12 00:29:20.313: INFO: Initial restart count of pod busybox-a39f0ae8-bc30-4d53-a6ce-04ed181d59c5 is 0
    STEP: deleting the pod 11/12/22 00:33:20.406
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 00:33:20.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9997" for this suite. 11/12/22 00:33:20.475
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:33:20.51
Nov 12 00:33:20.510: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename watch 11/12/22 00:33:20.511
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:33:20.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:33:20.559
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 11/12/22 00:33:20.569
STEP: creating a new configmap 11/12/22 00:33:20.573
STEP: modifying the configmap once 11/12/22 00:33:20.588
STEP: changing the label value of the configmap 11/12/22 00:33:20.629
STEP: Expecting to observe a delete notification for the watched object 11/12/22 00:33:20.663
Nov 12 00:33:20.663: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41331 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 00:33:20.664: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41332 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 00:33:20.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41333 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 11/12/22 00:33:20.664
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/12/22 00:33:20.706
STEP: changing the label value of the configmap back 11/12/22 00:33:30.707
STEP: modifying the configmap a third time 11/12/22 00:33:30.737
STEP: deleting the configmap 11/12/22 00:33:30.764
STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/12/22 00:33:30.788
Nov 12 00:33:30.788: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41355 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 00:33:30.789: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41356 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 00:33:30.789: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41358 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 00:33:30.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6416" for this suite. 11/12/22 00:33:30.801
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":254,"skipped":4826,"failed":0}
------------------------------
• [SLOW TEST] [10.318 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:33:20.51
    Nov 12 00:33:20.510: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename watch 11/12/22 00:33:20.511
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:33:20.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:33:20.559
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 11/12/22 00:33:20.569
    STEP: creating a new configmap 11/12/22 00:33:20.573
    STEP: modifying the configmap once 11/12/22 00:33:20.588
    STEP: changing the label value of the configmap 11/12/22 00:33:20.629
    STEP: Expecting to observe a delete notification for the watched object 11/12/22 00:33:20.663
    Nov 12 00:33:20.663: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41331 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 00:33:20.664: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41332 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 00:33:20.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41333 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:20 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 11/12/22 00:33:20.664
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/12/22 00:33:20.706
    STEP: changing the label value of the configmap back 11/12/22 00:33:30.707
    STEP: modifying the configmap a third time 11/12/22 00:33:30.737
    STEP: deleting the configmap 11/12/22 00:33:30.764
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/12/22 00:33:30.788
    Nov 12 00:33:30.788: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41355 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 00:33:30.789: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41356 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 00:33:30.789: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6416  0bb429e0-939e-473c-95a4-cd2683b3d292 41358 0 2022-11-12 00:33:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 00:33:30 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 00:33:30.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6416" for this suite. 11/12/22 00:33:30.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:33:30.83
Nov 12 00:33:30.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:33:30.831
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:33:30.864
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:33:30.876
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c6110763-d1b3-486b-ba7c-66e7832c540f 11/12/22 00:33:30.895
STEP: Creating the pod 11/12/22 00:33:30.91
Nov 12 00:33:30.938: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd" in namespace "projected-674" to be "running and ready"
Nov 12 00:33:30.955: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.592591ms
Nov 12 00:33:30.955: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:33:32.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032051572s
Nov 12 00:33:32.970: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:33:34.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Running", Reason="", readiness=true. Elapsed: 4.032141416s
Nov 12 00:33:34.970: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Running (Ready = true)
Nov 12 00:33:34.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-c6110763-d1b3-486b-ba7c-66e7832c540f 11/12/22 00:33:35.062
STEP: waiting to observe update in volume 11/12/22 00:33:35.079
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 00:34:50.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-674" for this suite. 11/12/22 00:34:50.318
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":255,"skipped":4838,"failed":0}
------------------------------
• [SLOW TEST] [79.517 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:33:30.83
    Nov 12 00:33:30.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:33:30.831
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:33:30.864
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:33:30.876
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-c6110763-d1b3-486b-ba7c-66e7832c540f 11/12/22 00:33:30.895
    STEP: Creating the pod 11/12/22 00:33:30.91
    Nov 12 00:33:30.938: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd" in namespace "projected-674" to be "running and ready"
    Nov 12 00:33:30.955: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.592591ms
    Nov 12 00:33:30.955: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:33:32.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032051572s
    Nov 12 00:33:32.970: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:33:34.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd": Phase="Running", Reason="", readiness=true. Elapsed: 4.032141416s
    Nov 12 00:33:34.970: INFO: The phase of Pod pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd is Running (Ready = true)
    Nov 12 00:33:34.970: INFO: Pod "pod-projected-configmaps-48bda05a-4e52-4beb-add3-952b300dcddd" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-c6110763-d1b3-486b-ba7c-66e7832c540f 11/12/22 00:33:35.062
    STEP: waiting to observe update in volume 11/12/22 00:33:35.079
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 00:34:50.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-674" for this suite. 11/12/22 00:34:50.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:34:50.348
Nov 12 00:34:50.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replicaset 11/12/22 00:34:50.35
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:34:50.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:34:50.395
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/12/22 00:34:50.404
Nov 12 00:34:50.430: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8105" to be "running and ready"
Nov 12 00:34:50.444: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 14.555566ms
Nov 12 00:34:50.444: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:34:52.463: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032811646s
Nov 12 00:34:52.463: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:34:54.489: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.059153425s
Nov 12 00:34:54.489: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Nov 12 00:34:54.489: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 11/12/22 00:34:54.508
STEP: Then the orphan pod is adopted 11/12/22 00:34:54.527
STEP: When the matched label of one of its pods change 11/12/22 00:34:55.564
Nov 12 00:34:55.579: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 11/12/22 00:34:55.616
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 00:34:55.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8105" for this suite. 11/12/22 00:34:55.664
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":256,"skipped":4850,"failed":0}
------------------------------
• [SLOW TEST] [5.374 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:34:50.348
    Nov 12 00:34:50.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replicaset 11/12/22 00:34:50.35
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:34:50.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:34:50.395
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/12/22 00:34:50.404
    Nov 12 00:34:50.430: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8105" to be "running and ready"
    Nov 12 00:34:50.444: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 14.555566ms
    Nov 12 00:34:50.444: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:34:52.463: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032811646s
    Nov 12 00:34:52.463: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:34:54.489: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.059153425s
    Nov 12 00:34:54.489: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Nov 12 00:34:54.489: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 11/12/22 00:34:54.508
    STEP: Then the orphan pod is adopted 11/12/22 00:34:54.527
    STEP: When the matched label of one of its pods change 11/12/22 00:34:55.564
    Nov 12 00:34:55.579: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/12/22 00:34:55.616
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 00:34:55.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8105" for this suite. 11/12/22 00:34:55.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:34:55.725
Nov 12 00:34:55.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:34:55.726
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:34:55.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:34:55.825
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:34:55.835
Nov 12 00:34:55.862: INFO: Waiting up to 5m0s for pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8" in namespace "downward-api-8533" to be "Succeeded or Failed"
Nov 12 00:34:55.876: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.050034ms
Nov 12 00:34:57.892: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030403786s
Nov 12 00:34:59.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031605451s
Nov 12 00:35:01.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031283162s
STEP: Saw pod success 11/12/22 00:35:01.893
Nov 12 00:35:01.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8" satisfied condition "Succeeded or Failed"
Nov 12 00:35:01.908: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 container client-container: <nil>
STEP: delete the pod 11/12/22 00:35:01.938
Nov 12 00:35:01.987: INFO: Waiting for pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 to disappear
Nov 12 00:35:02.010: INFO: Pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:35:02.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8533" for this suite. 11/12/22 00:35:02.023
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":257,"skipped":4864,"failed":0}
------------------------------
• [SLOW TEST] [6.327 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:34:55.725
    Nov 12 00:34:55.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:34:55.726
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:34:55.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:34:55.825
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:34:55.835
    Nov 12 00:34:55.862: INFO: Waiting up to 5m0s for pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8" in namespace "downward-api-8533" to be "Succeeded or Failed"
    Nov 12 00:34:55.876: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.050034ms
    Nov 12 00:34:57.892: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030403786s
    Nov 12 00:34:59.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031605451s
    Nov 12 00:35:01.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031283162s
    STEP: Saw pod success 11/12/22 00:35:01.893
    Nov 12 00:35:01.893: INFO: Pod "downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8" satisfied condition "Succeeded or Failed"
    Nov 12 00:35:01.908: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 container client-container: <nil>
    STEP: delete the pod 11/12/22 00:35:01.938
    Nov 12 00:35:01.987: INFO: Waiting for pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 to disappear
    Nov 12 00:35:02.010: INFO: Pod downwardapi-volume-178e7f52-48f2-4bc2-9cdd-534012aab3a8 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:35:02.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8533" for this suite. 11/12/22 00:35:02.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:02.057
Nov 12 00:35:02.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:35:02.06
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:02.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:02.109
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 00:35:02.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3392" for this suite. 11/12/22 00:35:02.193
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":258,"skipped":4871,"failed":0}
------------------------------
• [0.164 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:02.057
    Nov 12 00:35:02.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:35:02.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:02.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:02.109
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 00:35:02.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3392" for this suite. 11/12/22 00:35:02.193
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:02.222
Nov 12 00:35:02.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 00:35:02.225
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:02.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:02.291
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Nov 12 00:35:02.301: INFO: Creating deployment "test-recreate-deployment"
Nov 12 00:35:02.346: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 12 00:35:02.381: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 12 00:35:04.412: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 12 00:35:04.424: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:35:06.439: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 12 00:35:06.471: INFO: Updating deployment test-recreate-deployment
Nov 12 00:35:06.471: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 00:35:06.661: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2582  fbc0431c-90f2-4e15-86aa-4f61578da129 41621 2 2022-11-12 00:35:02 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00483df18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 00:35:06 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-12 00:35:06 +0000 UTC,LastTransitionTime:2022-11-12 00:35:02 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 12 00:35:06.677: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2582  056e4297-dc2a-41fe-9d7d-52aca5568af5 41619 1 2022-11-12 00:35:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fbc0431c-90f2-4e15-86aa-4f61578da129 0xc005a9db40 0xc005a9db41}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbc0431c-90f2-4e15-86aa-4f61578da129\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005a9dbd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:35:06.677: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 12 00:35:06.677: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2582  ac03a656-d423-4b8c-a3c3-75992a6c67f7 41608 2 2022-11-12 00:35:02 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fbc0431c-90f2-4e15-86aa-4f61578da129 0xc005a9da27 0xc005a9da28}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbc0431c-90f2-4e15-86aa-4f61578da129\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005a9dad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:35:06.698: INFO: Pod "test-recreate-deployment-9d58999df-xwm7z" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-xwm7z test-recreate-deployment-9d58999df- deployment-2582  9161f1de-2301-4e9b-a7fc-f75559bd9f2e 41620 0 2022-11-12 00:35:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 056e4297-dc2a-41fe-9d7d-52aca5568af5 0xc004d08040 0xc004d08041}] [] [{kube-controller-manager Update v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"056e4297-dc2a-41fe-9d7d-52aca5568af5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbsrq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbsrq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:35:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 00:35:06.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2582" for this suite. 11/12/22 00:35:06.712
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":259,"skipped":4874,"failed":0}
------------------------------
• [4.517 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:02.222
    Nov 12 00:35:02.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 00:35:02.225
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:02.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:02.291
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Nov 12 00:35:02.301: INFO: Creating deployment "test-recreate-deployment"
    Nov 12 00:35:02.346: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Nov 12 00:35:02.381: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Nov 12 00:35:04.412: INFO: Waiting deployment "test-recreate-deployment" to complete
    Nov 12 00:35:04.424: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 35, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:35:06.439: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Nov 12 00:35:06.471: INFO: Updating deployment test-recreate-deployment
    Nov 12 00:35:06.471: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 00:35:06.661: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-2582  fbc0431c-90f2-4e15-86aa-4f61578da129 41621 2 2022-11-12 00:35:02 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00483df18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 00:35:06 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-12 00:35:06 +0000 UTC,LastTransitionTime:2022-11-12 00:35:02 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 12 00:35:06.677: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-2582  056e4297-dc2a-41fe-9d7d-52aca5568af5 41619 1 2022-11-12 00:35:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment fbc0431c-90f2-4e15-86aa-4f61578da129 0xc005a9db40 0xc005a9db41}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbc0431c-90f2-4e15-86aa-4f61578da129\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005a9dbd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:35:06.677: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Nov 12 00:35:06.677: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-2582  ac03a656-d423-4b8c-a3c3-75992a6c67f7 41608 2 2022-11-12 00:35:02 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment fbc0431c-90f2-4e15-86aa-4f61578da129 0xc005a9da27 0xc005a9da28}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fbc0431c-90f2-4e15-86aa-4f61578da129\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005a9dad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:35:06.698: INFO: Pod "test-recreate-deployment-9d58999df-xwm7z" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-xwm7z test-recreate-deployment-9d58999df- deployment-2582  9161f1de-2301-4e9b-a7fc-f75559bd9f2e 41620 0 2022-11-12 00:35:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 056e4297-dc2a-41fe-9d7d-52aca5568af5 0xc004d08040 0xc004d08041}] [] [{kube-controller-manager Update v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"056e4297-dc2a-41fe-9d7d-52aca5568af5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:35:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbsrq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbsrq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:35:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:35:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 00:35:06.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2582" for this suite. 11/12/22 00:35:06.712
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:06.748
Nov 12 00:35:06.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-runtime 11/12/22 00:35:06.75
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:06.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:06.801
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 11/12/22 00:35:06.81
STEP: wait for the container to reach Succeeded 11/12/22 00:35:06.847
STEP: get the container status 11/12/22 00:35:11.948
STEP: the container should be terminated 11/12/22 00:35:11.965
STEP: the termination message should be set 11/12/22 00:35:11.966
Nov 12 00:35:11.966: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/12/22 00:35:11.966
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 00:35:12.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7668" for this suite. 11/12/22 00:35:12.064
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":260,"skipped":4910,"failed":0}
------------------------------
• [SLOW TEST] [5.344 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:06.748
    Nov 12 00:35:06.748: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-runtime 11/12/22 00:35:06.75
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:06.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:06.801
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 11/12/22 00:35:06.81
    STEP: wait for the container to reach Succeeded 11/12/22 00:35:06.847
    STEP: get the container status 11/12/22 00:35:11.948
    STEP: the container should be terminated 11/12/22 00:35:11.965
    STEP: the termination message should be set 11/12/22 00:35:11.966
    Nov 12 00:35:11.966: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/12/22 00:35:11.966
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 00:35:12.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7668" for this suite. 11/12/22 00:35:12.064
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:12.102
Nov 12 00:35:12.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-runtime 11/12/22 00:35:12.104
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:12.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:12.154
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/12/22 00:35:12.219
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/12/22 00:35:29.52
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/12/22 00:35:29.535
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/12/22 00:35:29.566
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/12/22 00:35:29.566
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/12/22 00:35:29.649
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/12/22 00:35:33.725
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/12/22 00:35:35.78
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/12/22 00:35:35.809
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/12/22 00:35:35.81
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/12/22 00:35:35.897
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/12/22 00:35:36.932
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/12/22 00:35:41.032
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/12/22 00:35:41.061
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/12/22 00:35:41.061
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 00:35:41.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-66" for this suite. 11/12/22 00:35:41.172
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":261,"skipped":4954,"failed":0}
------------------------------
• [SLOW TEST] [29.096 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:12.102
    Nov 12 00:35:12.102: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-runtime 11/12/22 00:35:12.104
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:12.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:12.154
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/12/22 00:35:12.219
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/12/22 00:35:29.52
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/12/22 00:35:29.535
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/12/22 00:35:29.566
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/12/22 00:35:29.566
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/12/22 00:35:29.649
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/12/22 00:35:33.725
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/12/22 00:35:35.78
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/12/22 00:35:35.809
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/12/22 00:35:35.81
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/12/22 00:35:35.897
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/12/22 00:35:36.932
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/12/22 00:35:41.032
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/12/22 00:35:41.061
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/12/22 00:35:41.061
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 00:35:41.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-66" for this suite. 11/12/22 00:35:41.172
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:41.199
Nov 12 00:35:41.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:35:41.201
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:41.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:41.256
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 11/12/22 00:35:41.265
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/12/22 00:35:41.27
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 00:35:41.27
STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/12/22 00:35:41.271
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/12/22 00:35:41.275
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 00:35:41.276
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 00:35:41.281
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:35:41.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1180" for this suite. 11/12/22 00:35:41.292
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":262,"skipped":4955,"failed":0}
------------------------------
• [0.118 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:41.199
    Nov 12 00:35:41.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:35:41.201
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:41.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:41.256
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 11/12/22 00:35:41.265
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/12/22 00:35:41.27
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 00:35:41.27
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/12/22 00:35:41.271
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/12/22 00:35:41.275
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 00:35:41.276
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 00:35:41.281
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:35:41.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1180" for this suite. 11/12/22 00:35:41.292
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:41.318
Nov 12 00:35:41.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:35:41.32
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:41.354
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:41.363
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Nov 12 00:35:41.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 00:35:48.705
Nov 12 00:35:48.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 create -f -'
Nov 12 00:35:49.862: INFO: stderr: ""
Nov 12 00:35:49.862: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 12 00:35:49.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 delete e2e-test-crd-publish-openapi-2780-crds test-cr'
Nov 12 00:35:49.980: INFO: stderr: ""
Nov 12 00:35:49.981: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 12 00:35:49.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 apply -f -'
Nov 12 00:35:51.131: INFO: stderr: ""
Nov 12 00:35:51.131: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 12 00:35:51.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 delete e2e-test-crd-publish-openapi-2780-crds test-cr'
Nov 12 00:35:51.419: INFO: stderr: ""
Nov 12 00:35:51.419: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/12/22 00:35:51.419
Nov 12 00:35:51.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 explain e2e-test-crd-publish-openapi-2780-crds'
Nov 12 00:35:52.440: INFO: stderr: ""
Nov 12 00:35:52.440: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2780-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:35:59.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7952" for this suite. 11/12/22 00:35:59.622
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":263,"skipped":4956,"failed":0}
------------------------------
• [SLOW TEST] [18.331 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:41.318
    Nov 12 00:35:41.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:35:41.32
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:41.354
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:41.363
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Nov 12 00:35:41.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 00:35:48.705
    Nov 12 00:35:48.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 create -f -'
    Nov 12 00:35:49.862: INFO: stderr: ""
    Nov 12 00:35:49.862: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 12 00:35:49.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 delete e2e-test-crd-publish-openapi-2780-crds test-cr'
    Nov 12 00:35:49.980: INFO: stderr: ""
    Nov 12 00:35:49.981: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Nov 12 00:35:49.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 apply -f -'
    Nov 12 00:35:51.131: INFO: stderr: ""
    Nov 12 00:35:51.131: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 12 00:35:51.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 --namespace=crd-publish-openapi-7952 delete e2e-test-crd-publish-openapi-2780-crds test-cr'
    Nov 12 00:35:51.419: INFO: stderr: ""
    Nov 12 00:35:51.419: INFO: stdout: "e2e-test-crd-publish-openapi-2780-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/12/22 00:35:51.419
    Nov 12 00:35:51.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-7952 explain e2e-test-crd-publish-openapi-2780-crds'
    Nov 12 00:35:52.440: INFO: stderr: ""
    Nov 12 00:35:52.440: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2780-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:35:59.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7952" for this suite. 11/12/22 00:35:59.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:35:59.654
Nov 12 00:35:59.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:35:59.657
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:59.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:59.74
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-f65160be-38d4-44cb-8a7f-a00c8eb2fea7 11/12/22 00:35:59.76
STEP: Creating a pod to test consume configMaps 11/12/22 00:35:59.78
Nov 12 00:35:59.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17" in namespace "configmap-8211" to be "Succeeded or Failed"
Nov 12 00:35:59.837: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 17.473314ms
Nov 12 00:36:01.859: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038905979s
Nov 12 00:36:03.858: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038345154s
Nov 12 00:36:05.857: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037160066s
STEP: Saw pod success 11/12/22 00:36:05.857
Nov 12 00:36:05.857: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17" satisfied condition "Succeeded or Failed"
Nov 12 00:36:05.875: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:36:05.997
Nov 12 00:36:06.053: INFO: Waiting for pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 to disappear
Nov 12 00:36:06.071: INFO: Pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:36:06.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8211" for this suite. 11/12/22 00:36:06.092
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":264,"skipped":4967,"failed":0}
------------------------------
• [SLOW TEST] [6.461 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:35:59.654
    Nov 12 00:35:59.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:35:59.657
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:35:59.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:35:59.74
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-f65160be-38d4-44cb-8a7f-a00c8eb2fea7 11/12/22 00:35:59.76
    STEP: Creating a pod to test consume configMaps 11/12/22 00:35:59.78
    Nov 12 00:35:59.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17" in namespace "configmap-8211" to be "Succeeded or Failed"
    Nov 12 00:35:59.837: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 17.473314ms
    Nov 12 00:36:01.859: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038905979s
    Nov 12 00:36:03.858: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038345154s
    Nov 12 00:36:05.857: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037160066s
    STEP: Saw pod success 11/12/22 00:36:05.857
    Nov 12 00:36:05.857: INFO: Pod "pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17" satisfied condition "Succeeded or Failed"
    Nov 12 00:36:05.875: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:36:05.997
    Nov 12 00:36:06.053: INFO: Waiting for pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 to disappear
    Nov 12 00:36:06.071: INFO: Pod pod-configmaps-99f2d8f8-f467-4d33-8bbe-6275c3a73a17 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:36:06.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8211" for this suite. 11/12/22 00:36:06.092
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:36:06.115
Nov 12 00:36:06.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:36:06.118
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:06.189
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:06.208
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Nov 12 00:36:06.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/12/22 00:36:10.992
Nov 12 00:36:10.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
Nov 12 00:36:12.488: INFO: stderr: ""
Nov 12 00:36:12.488: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 12 00:36:12.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 delete e2e-test-crd-publish-openapi-2700-crds test-foo'
Nov 12 00:36:12.655: INFO: stderr: ""
Nov 12 00:36:12.655: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 12 00:36:12.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
Nov 12 00:36:13.591: INFO: stderr: ""
Nov 12 00:36:13.591: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 12 00:36:13.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 delete e2e-test-crd-publish-openapi-2700-crds test-foo'
Nov 12 00:36:13.784: INFO: stderr: ""
Nov 12 00:36:13.784: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/12/22 00:36:13.784
Nov 12 00:36:13.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
Nov 12 00:36:14.630: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/12/22 00:36:14.631
Nov 12 00:36:14.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
Nov 12 00:36:15.138: INFO: rc: 1
Nov 12 00:36:15.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
Nov 12 00:36:15.694: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/12/22 00:36:15.695
Nov 12 00:36:15.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
Nov 12 00:36:16.125: INFO: rc: 1
Nov 12 00:36:16.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
Nov 12 00:36:16.579: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 11/12/22 00:36:16.58
Nov 12 00:36:16.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds'
Nov 12 00:36:17.121: INFO: stderr: ""
Nov 12 00:36:17.121: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 11/12/22 00:36:17.122
Nov 12 00:36:17.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.metadata'
Nov 12 00:36:17.683: INFO: stderr: ""
Nov 12 00:36:17.683: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 12 00:36:17.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec'
Nov 12 00:36:18.193: INFO: stderr: ""
Nov 12 00:36:18.193: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 12 00:36:18.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec.bars'
Nov 12 00:36:18.738: INFO: stderr: ""
Nov 12 00:36:18.738: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/12/22 00:36:18.738
Nov 12 00:36:18.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec.bars2'
Nov 12 00:36:19.239: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:36:26.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3935" for this suite. 11/12/22 00:36:26.481
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":265,"skipped":4970,"failed":0}
------------------------------
• [SLOW TEST] [20.394 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:36:06.115
    Nov 12 00:36:06.116: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 00:36:06.118
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:06.189
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:06.208
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Nov 12 00:36:06.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/12/22 00:36:10.992
    Nov 12 00:36:10.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
    Nov 12 00:36:12.488: INFO: stderr: ""
    Nov 12 00:36:12.488: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 12 00:36:12.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 delete e2e-test-crd-publish-openapi-2700-crds test-foo'
    Nov 12 00:36:12.655: INFO: stderr: ""
    Nov 12 00:36:12.655: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Nov 12 00:36:12.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
    Nov 12 00:36:13.591: INFO: stderr: ""
    Nov 12 00:36:13.591: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 12 00:36:13.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 delete e2e-test-crd-publish-openapi-2700-crds test-foo'
    Nov 12 00:36:13.784: INFO: stderr: ""
    Nov 12 00:36:13.784: INFO: stdout: "e2e-test-crd-publish-openapi-2700-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/12/22 00:36:13.784
    Nov 12 00:36:13.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
    Nov 12 00:36:14.630: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/12/22 00:36:14.631
    Nov 12 00:36:14.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
    Nov 12 00:36:15.138: INFO: rc: 1
    Nov 12 00:36:15.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
    Nov 12 00:36:15.694: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/12/22 00:36:15.695
    Nov 12 00:36:15.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 create -f -'
    Nov 12 00:36:16.125: INFO: rc: 1
    Nov 12 00:36:16.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 --namespace=crd-publish-openapi-3935 apply -f -'
    Nov 12 00:36:16.579: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 11/12/22 00:36:16.58
    Nov 12 00:36:16.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds'
    Nov 12 00:36:17.121: INFO: stderr: ""
    Nov 12 00:36:17.121: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 11/12/22 00:36:17.122
    Nov 12 00:36:17.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.metadata'
    Nov 12 00:36:17.683: INFO: stderr: ""
    Nov 12 00:36:17.683: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Nov 12 00:36:17.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec'
    Nov 12 00:36:18.193: INFO: stderr: ""
    Nov 12 00:36:18.193: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Nov 12 00:36:18.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec.bars'
    Nov 12 00:36:18.738: INFO: stderr: ""
    Nov 12 00:36:18.738: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2700-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/12/22 00:36:18.738
    Nov 12 00:36:18.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=crd-publish-openapi-3935 explain e2e-test-crd-publish-openapi-2700-crds.spec.bars2'
    Nov 12 00:36:19.239: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:36:26.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3935" for this suite. 11/12/22 00:36:26.481
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:36:26.528
Nov 12 00:36:26.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:36:26.531
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:26.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:26.584
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:36:26.597
Nov 12 00:36:26.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd" in namespace "projected-8303" to be "Succeeded or Failed"
Nov 12 00:36:26.643: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.358105ms
Nov 12 00:36:28.660: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032912689s
Nov 12 00:36:30.660: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032956046s
Nov 12 00:36:32.663: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035581616s
STEP: Saw pod success 11/12/22 00:36:32.663
Nov 12 00:36:32.664: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd" satisfied condition "Succeeded or Failed"
Nov 12 00:36:32.684: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd container client-container: <nil>
STEP: delete the pod 11/12/22 00:36:32.766
Nov 12 00:36:32.823: INFO: Waiting for pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd to disappear
Nov 12 00:36:32.839: INFO: Pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:36:32.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8303" for this suite. 11/12/22 00:36:32.86
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":266,"skipped":5018,"failed":0}
------------------------------
• [SLOW TEST] [6.369 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:36:26.528
    Nov 12 00:36:26.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:36:26.531
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:26.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:26.584
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:36:26.597
    Nov 12 00:36:26.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd" in namespace "projected-8303" to be "Succeeded or Failed"
    Nov 12 00:36:26.643: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.358105ms
    Nov 12 00:36:28.660: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032912689s
    Nov 12 00:36:30.660: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032956046s
    Nov 12 00:36:32.663: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035581616s
    STEP: Saw pod success 11/12/22 00:36:32.663
    Nov 12 00:36:32.664: INFO: Pod "downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd" satisfied condition "Succeeded or Failed"
    Nov 12 00:36:32.684: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd container client-container: <nil>
    STEP: delete the pod 11/12/22 00:36:32.766
    Nov 12 00:36:32.823: INFO: Waiting for pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd to disappear
    Nov 12 00:36:32.839: INFO: Pod downwardapi-volume-d76a8b35-bc52-4660-95ce-c68295a2a1bd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:36:32.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8303" for this suite. 11/12/22 00:36:32.86
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:36:32.916
Nov 12 00:36:32.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:36:32.92
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:32.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:32.971
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:36:32.983
Nov 12 00:36:33.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5" in namespace "downward-api-4075" to be "Succeeded or Failed"
Nov 12 00:36:33.032: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.960653ms
Nov 12 00:36:35.048: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033067661s
Nov 12 00:36:37.049: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034255236s
Nov 12 00:36:39.050: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034977797s
STEP: Saw pod success 11/12/22 00:36:39.05
Nov 12 00:36:39.050: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5" satisfied condition "Succeeded or Failed"
Nov 12 00:36:39.067: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 container client-container: <nil>
STEP: delete the pod 11/12/22 00:36:39.103
Nov 12 00:36:39.147: INFO: Waiting for pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 to disappear
Nov 12 00:36:39.163: INFO: Pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:36:39.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4075" for this suite. 11/12/22 00:36:39.179
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":267,"skipped":5047,"failed":0}
------------------------------
• [SLOW TEST] [6.291 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:36:32.916
    Nov 12 00:36:32.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:36:32.92
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:32.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:32.971
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:36:32.983
    Nov 12 00:36:33.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5" in namespace "downward-api-4075" to be "Succeeded or Failed"
    Nov 12 00:36:33.032: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.960653ms
    Nov 12 00:36:35.048: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033067661s
    Nov 12 00:36:37.049: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034255236s
    Nov 12 00:36:39.050: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034977797s
    STEP: Saw pod success 11/12/22 00:36:39.05
    Nov 12 00:36:39.050: INFO: Pod "downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5" satisfied condition "Succeeded or Failed"
    Nov 12 00:36:39.067: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 container client-container: <nil>
    STEP: delete the pod 11/12/22 00:36:39.103
    Nov 12 00:36:39.147: INFO: Waiting for pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 to disappear
    Nov 12 00:36:39.163: INFO: Pod downwardapi-volume-1d3a9284-adbd-4651-b5b0-053d739309d5 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:36:39.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4075" for this suite. 11/12/22 00:36:39.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:36:39.213
Nov 12 00:36:39.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/12/22 00:36:39.216
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:39.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:39.272
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 in namespace container-probe-8993 11/12/22 00:36:39.284
Nov 12 00:36:39.316: INFO: Waiting up to 5m0s for pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3" in namespace "container-probe-8993" to be "not pending"
Nov 12 00:36:39.334: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 17.718032ms
Nov 12 00:36:41.351: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035533009s
Nov 12 00:36:43.357: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Running", Reason="", readiness=true. Elapsed: 4.041166866s
Nov 12 00:36:43.357: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3" satisfied condition "not pending"
Nov 12 00:36:43.357: INFO: Started pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 in namespace container-probe-8993
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:36:43.357
Nov 12 00:36:43.392: INFO: Initial restart count of pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 is 0
STEP: deleting the pod 11/12/22 00:40:43.611
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 00:40:43.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8993" for this suite. 11/12/22 00:40:43.682
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":268,"skipped":5053,"failed":0}
------------------------------
• [SLOW TEST] [244.524 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:36:39.213
    Nov 12 00:36:39.214: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/12/22 00:36:39.216
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:36:39.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:36:39.272
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 in namespace container-probe-8993 11/12/22 00:36:39.284
    Nov 12 00:36:39.316: INFO: Waiting up to 5m0s for pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3" in namespace "container-probe-8993" to be "not pending"
    Nov 12 00:36:39.334: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 17.718032ms
    Nov 12 00:36:41.351: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035533009s
    Nov 12 00:36:43.357: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3": Phase="Running", Reason="", readiness=true. Elapsed: 4.041166866s
    Nov 12 00:36:43.357: INFO: Pod "liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3" satisfied condition "not pending"
    Nov 12 00:36:43.357: INFO: Started pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 in namespace container-probe-8993
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:36:43.357
    Nov 12 00:36:43.392: INFO: Initial restart count of pod liveness-9a07dfc2-0e11-4e5c-a5ee-2ae1b171e2c3 is 0
    STEP: deleting the pod 11/12/22 00:40:43.611
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 00:40:43.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8993" for this suite. 11/12/22 00:40:43.682
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:40:43.749
Nov 12 00:40:43.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption 11/12/22 00:40:43.752
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:40:43.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:40:43.797
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 00:40:43.845: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 00:41:43.949: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 11/12/22 00:41:43.969
Nov 12 00:41:44.035: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 12 00:41:44.055: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 12 00:41:44.097: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 12 00:41:44.119: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 12 00:41:44.158: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 12 00:41:44.182: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/12/22 00:41:44.182
Nov 12 00:41:44.182: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:44.200: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 17.13174ms
Nov 12 00:41:46.219: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037067379s
Nov 12 00:41:48.219: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036616433s
Nov 12 00:41:50.217: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035081567s
Nov 12 00:41:52.220: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037469203s
Nov 12 00:41:54.217: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.034306369s
Nov 12 00:41:56.218: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.035236795s
Nov 12 00:41:56.218: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 12 00:41:56.218: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:56.234: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 15.751203ms
Nov 12 00:41:56.234: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:41:56.234: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:56.251: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.551087ms
Nov 12 00:41:56.251: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:41:56.251: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:56.271: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 20.207041ms
Nov 12 00:41:56.272: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:41:56.272: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:56.290: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.501866ms
Nov 12 00:41:56.290: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:41:56.290: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
Nov 12 00:41:56.307: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.948344ms
Nov 12 00:41:56.307: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 11/12/22 00:41:56.308
Nov 12 00:41:56.346: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Nov 12 00:41:56.363: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 16.900064ms
Nov 12 00:41:58.387: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040704504s
Nov 12 00:42:00.380: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034363425s
Nov 12 00:42:02.379: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033190698s
Nov 12 00:42:04.381: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.034747542s
Nov 12 00:42:04.381: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:42:04.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2052" for this suite. 11/12/22 00:42:04.569
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":269,"skipped":5065,"failed":0}
------------------------------
• [SLOW TEST] [80.947 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:40:43.749
    Nov 12 00:40:43.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 00:40:43.752
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:40:43.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:40:43.797
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 00:40:43.845: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 00:41:43.949: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 11/12/22 00:41:43.969
    Nov 12 00:41:44.035: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 12 00:41:44.055: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 12 00:41:44.097: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 12 00:41:44.119: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 12 00:41:44.158: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 12 00:41:44.182: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/12/22 00:41:44.182
    Nov 12 00:41:44.182: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:44.200: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 17.13174ms
    Nov 12 00:41:46.219: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037067379s
    Nov 12 00:41:48.219: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036616433s
    Nov 12 00:41:50.217: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035081567s
    Nov 12 00:41:52.220: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.037469203s
    Nov 12 00:41:54.217: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.034306369s
    Nov 12 00:41:56.218: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.035236795s
    Nov 12 00:41:56.218: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 12 00:41:56.218: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:56.234: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 15.751203ms
    Nov 12 00:41:56.234: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:41:56.234: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:56.251: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 17.551087ms
    Nov 12 00:41:56.251: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:41:56.251: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:56.271: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 20.207041ms
    Nov 12 00:41:56.272: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:41:56.272: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:56.290: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.501866ms
    Nov 12 00:41:56.290: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:41:56.290: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2052" to be "running"
    Nov 12 00:41:56.307: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.948344ms
    Nov 12 00:41:56.307: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 11/12/22 00:41:56.308
    Nov 12 00:41:56.346: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Nov 12 00:41:56.363: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 16.900064ms
    Nov 12 00:41:58.387: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040704504s
    Nov 12 00:42:00.380: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034363425s
    Nov 12 00:42:02.379: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033190698s
    Nov 12 00:42:04.381: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.034747542s
    Nov 12 00:42:04.381: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:42:04.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2052" for this suite. 11/12/22 00:42:04.569
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:04.702
Nov 12 00:42:04.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption 11/12/22 00:42:04.704
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:04.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:04.773
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:04.785
Nov 12 00:42:04.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption-2 11/12/22 00:42:04.786
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:04.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:04.834
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.858
STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.879
STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.898
STEP: listing a collection of PDBs across all namespaces 11/12/22 00:42:04.907
STEP: listing a collection of PDBs in namespace disruption-2243 11/12/22 00:42:04.917
STEP: deleting a collection of PDBs 11/12/22 00:42:04.926
STEP: Waiting for the PDB collection to be deleted 11/12/22 00:42:04.954
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Nov 12 00:42:04.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-611" for this suite. 11/12/22 00:42:04.975
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 00:42:05.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2243" for this suite. 11/12/22 00:42:05.016
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":270,"skipped":5076,"failed":0}
------------------------------
• [0.344 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:04.702
    Nov 12 00:42:04.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption 11/12/22 00:42:04.704
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:04.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:04.773
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:04.785
    Nov 12 00:42:04.785: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption-2 11/12/22 00:42:04.786
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:04.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:04.834
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.858
    STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.879
    STEP: Waiting for the pdb to be processed 11/12/22 00:42:04.898
    STEP: listing a collection of PDBs across all namespaces 11/12/22 00:42:04.907
    STEP: listing a collection of PDBs in namespace disruption-2243 11/12/22 00:42:04.917
    STEP: deleting a collection of PDBs 11/12/22 00:42:04.926
    STEP: Waiting for the PDB collection to be deleted 11/12/22 00:42:04.954
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Nov 12 00:42:04.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-611" for this suite. 11/12/22 00:42:04.975
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 00:42:05.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2243" for this suite. 11/12/22 00:42:05.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:05.054
Nov 12 00:42:05.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:42:05.056
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:05.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:05.106
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-c0fee8d8-9ef7-43b6-944f-f714429cb0d8 11/12/22 00:42:05.119
STEP: Creating a pod to test consume secrets 11/12/22 00:42:05.131
Nov 12 00:42:05.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5" in namespace "projected-9227" to be "Succeeded or Failed"
Nov 12 00:42:05.181: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.617672ms
Nov 12 00:42:07.198: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037551416s
Nov 12 00:42:09.198: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038223336s
STEP: Saw pod success 11/12/22 00:42:09.199
Nov 12 00:42:09.199: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5" satisfied condition "Succeeded or Failed"
Nov 12 00:42:09.219: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:42:09.298
Nov 12 00:42:09.346: INFO: Waiting for pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 to disappear
Nov 12 00:42:09.362: INFO: Pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 00:42:09.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9227" for this suite. 11/12/22 00:42:09.377
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":271,"skipped":5096,"failed":0}
------------------------------
• [4.351 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:05.054
    Nov 12 00:42:05.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:42:05.056
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:05.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:05.106
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-c0fee8d8-9ef7-43b6-944f-f714429cb0d8 11/12/22 00:42:05.119
    STEP: Creating a pod to test consume secrets 11/12/22 00:42:05.131
    Nov 12 00:42:05.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5" in namespace "projected-9227" to be "Succeeded or Failed"
    Nov 12 00:42:05.181: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.617672ms
    Nov 12 00:42:07.198: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037551416s
    Nov 12 00:42:09.198: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038223336s
    STEP: Saw pod success 11/12/22 00:42:09.199
    Nov 12 00:42:09.199: INFO: Pod "pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5" satisfied condition "Succeeded or Failed"
    Nov 12 00:42:09.219: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:42:09.298
    Nov 12 00:42:09.346: INFO: Waiting for pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 to disappear
    Nov 12 00:42:09.362: INFO: Pod pod-projected-secrets-2ef3c474-1c29-4d17-bd9a-7aaa725beee5 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 00:42:09.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9227" for this suite. 11/12/22 00:42:09.377
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:09.41
Nov 12 00:42:09.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:42:09.415
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:09.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:09.474
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:42:09.527
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:42:10.415
STEP: Deploying the webhook pod 11/12/22 00:42:10.435
STEP: Wait for the deployment to be ready 11/12/22 00:42:10.491
Nov 12 00:42:10.557: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 00:42:12.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:42:14.641
STEP: Verifying the service has paired with the endpoint 11/12/22 00:42:14.676
Nov 12 00:42:15.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Nov 12 00:42:15.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7108-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 00:42:16.22
STEP: Creating a custom resource while v1 is storage version 11/12/22 00:42:16.313
STEP: Patching Custom Resource Definition to set v2 as storage 11/12/22 00:42:18.433
STEP: Patching the custom resource while v2 is storage version 11/12/22 00:42:18.458
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:42:19.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4379" for this suite. 11/12/22 00:42:19.123
STEP: Destroying namespace "webhook-4379-markers" for this suite. 11/12/22 00:42:19.162
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":272,"skipped":5100,"failed":0}
------------------------------
• [SLOW TEST] [9.905 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:09.41
    Nov 12 00:42:09.411: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:42:09.415
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:09.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:09.474
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:42:09.527
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:42:10.415
    STEP: Deploying the webhook pod 11/12/22 00:42:10.435
    STEP: Wait for the deployment to be ready 11/12/22 00:42:10.491
    Nov 12 00:42:10.557: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 00:42:12.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:42:14.641
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:42:14.676
    Nov 12 00:42:15.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Nov 12 00:42:15.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7108-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 00:42:16.22
    STEP: Creating a custom resource while v1 is storage version 11/12/22 00:42:16.313
    STEP: Patching Custom Resource Definition to set v2 as storage 11/12/22 00:42:18.433
    STEP: Patching the custom resource while v2 is storage version 11/12/22 00:42:18.458
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:42:19.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4379" for this suite. 11/12/22 00:42:19.123
    STEP: Destroying namespace "webhook-4379-markers" for this suite. 11/12/22 00:42:19.162
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:19.325
Nov 12 00:42:19.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename var-expansion 11/12/22 00:42:19.328
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:19.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:19.388
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Nov 12 00:42:19.433: INFO: Waiting up to 2m0s for pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" in namespace "var-expansion-3201" to be "container 0 failed with reason CreateContainerConfigError"
Nov 12 00:42:19.452: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39": Phase="Pending", Reason="", readiness=false. Elapsed: 18.717632ms
Nov 12 00:42:21.470: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036585933s
Nov 12 00:42:21.470: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 12 00:42:21.470: INFO: Deleting pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" in namespace "var-expansion-3201"
Nov 12 00:42:21.499: INFO: Wait up to 5m0s for pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 00:42:25.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3201" for this suite. 11/12/22 00:42:25.551
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":273,"skipped":5127,"failed":0}
------------------------------
• [SLOW TEST] [6.255 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:19.325
    Nov 12 00:42:19.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename var-expansion 11/12/22 00:42:19.328
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:19.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:19.388
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Nov 12 00:42:19.433: INFO: Waiting up to 2m0s for pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" in namespace "var-expansion-3201" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 12 00:42:19.452: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39": Phase="Pending", Reason="", readiness=false. Elapsed: 18.717632ms
    Nov 12 00:42:21.470: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036585933s
    Nov 12 00:42:21.470: INFO: Pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 12 00:42:21.470: INFO: Deleting pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" in namespace "var-expansion-3201"
    Nov 12 00:42:21.499: INFO: Wait up to 5m0s for pod "var-expansion-ffac1812-0a79-4768-a548-36f1a242ef39" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 00:42:25.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3201" for this suite. 11/12/22 00:42:25.551
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:25.583
Nov 12 00:42:25.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 00:42:25.584
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:25.627
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:25.64
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Nov 12 00:42:25.685: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 12 00:42:25.720: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 00:42:30.741: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 00:42:30.741
Nov 12 00:42:30.741: INFO: Creating deployment "test-rolling-update-deployment"
Nov 12 00:42:30.758: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 12 00:42:30.792: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 12 00:42:32.825: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 12 00:42:32.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:42:34.859: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 00:42:34.908: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8221  48526b2a-06c3-4649-a429-9d4ccd2708f5 42856 1 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e18eb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 00:42:30 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-12 00:42:33 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 00:42:34.926: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8221  72a3a4ea-edb1-482a-90b1-c1f14891f469 42846 1 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 48526b2a-06c3-4649-a429-9d4ccd2708f5 0xc003e196a7 0xc003e196a8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48526b2a-06c3-4649-a429-9d4ccd2708f5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e19758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:42:34.926: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 12 00:42:34.927: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8221  93f408ed-921c-4a19-867e-8492ce0658fc 42855 2 2022-11-12 00:42:25 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 48526b2a-06c3-4649-a429-9d4ccd2708f5 0xc003e19577 0xc003e19578}] [] [{e2e.test Update apps/v1 2022-11-12 00:42:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48526b2a-06c3-4649-a429-9d4ccd2708f5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003e19638 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:42:34.944: INFO: Pod "test-rolling-update-deployment-78f575d8ff-9ttgj" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-9ttgj test-rolling-update-deployment-78f575d8ff- deployment-8221  af41d27c-f10c-4914-9f3c-fdc8d8684fa2 42845 0 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:2285a2db7f462c0e321763cd11ab3e3a4089ef38189a9e71b9508aaf54ded598 cni.projectcalico.org/podIP:172.30.146.26/32 cni.projectcalico.org/podIPs:172.30.146.26/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 72a3a4ea-edb1-482a-90b1-c1f14891f469 0xc005b165e7 0xc005b165e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a3a4ea-edb1-482a-90b1-c1f14891f469\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:42:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rjlcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rjlcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.26,StartTime:2022-11-12 00:42:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:42:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://18e02cf0a9dec24102302d612fd4e459876f70f8e454465d0c215ad3ff46bc25,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 00:42:34.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8221" for this suite. 11/12/22 00:42:34.961
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":274,"skipped":5174,"failed":0}
------------------------------
• [SLOW TEST] [9.418 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:25.583
    Nov 12 00:42:25.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 00:42:25.584
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:25.627
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:25.64
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Nov 12 00:42:25.685: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Nov 12 00:42:25.720: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 00:42:30.741: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 00:42:30.741
    Nov 12 00:42:30.741: INFO: Creating deployment "test-rolling-update-deployment"
    Nov 12 00:42:30.758: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Nov 12 00:42:30.792: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Nov 12 00:42:32.825: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Nov 12 00:42:32.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 42, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:42:34.859: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 00:42:34.908: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8221  48526b2a-06c3-4649-a429-9d4ccd2708f5 42856 1 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e18eb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 00:42:30 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-12 00:42:33 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 00:42:34.926: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8221  72a3a4ea-edb1-482a-90b1-c1f14891f469 42846 1 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 48526b2a-06c3-4649-a429-9d4ccd2708f5 0xc003e196a7 0xc003e196a8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48526b2a-06c3-4649-a429-9d4ccd2708f5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003e19758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:42:34.926: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Nov 12 00:42:34.927: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8221  93f408ed-921c-4a19-867e-8492ce0658fc 42855 2 2022-11-12 00:42:25 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 48526b2a-06c3-4649-a429-9d4ccd2708f5 0xc003e19577 0xc003e19578}] [] [{e2e.test Update apps/v1 2022-11-12 00:42:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"48526b2a-06c3-4649-a429-9d4ccd2708f5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003e19638 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:42:34.944: INFO: Pod "test-rolling-update-deployment-78f575d8ff-9ttgj" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-9ttgj test-rolling-update-deployment-78f575d8ff- deployment-8221  af41d27c-f10c-4914-9f3c-fdc8d8684fa2 42845 0 2022-11-12 00:42:30 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:2285a2db7f462c0e321763cd11ab3e3a4089ef38189a9e71b9508aaf54ded598 cni.projectcalico.org/podIP:172.30.146.26/32 cni.projectcalico.org/podIPs:172.30.146.26/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 72a3a4ea-edb1-482a-90b1-c1f14891f469 0xc005b165e7 0xc005b165e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:42:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"72a3a4ea-edb1-482a-90b1-c1f14891f469\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:42:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:42:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rjlcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rjlcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:42:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.26,StartTime:2022-11-12 00:42:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:42:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://18e02cf0a9dec24102302d612fd4e459876f70f8e454465d0c215ad3ff46bc25,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 00:42:34.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8221" for this suite. 11/12/22 00:42:34.961
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:35.002
Nov 12 00:42:35.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:42:35.005
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:35.043
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:35.057
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-45180014-eca6-47d9-a57d-1d2eb3bd68f7 11/12/22 00:42:35.07
STEP: Creating a pod to test consume configMaps 11/12/22 00:42:35.088
Nov 12 00:42:35.137: INFO: Waiting up to 5m0s for pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa" in namespace "configmap-2376" to be "Succeeded or Failed"
Nov 12 00:42:35.158: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 20.988395ms
Nov 12 00:42:37.176: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038746401s
Nov 12 00:42:39.176: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038392595s
Nov 12 00:42:41.178: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040415729s
STEP: Saw pod success 11/12/22 00:42:41.178
Nov 12 00:42:41.179: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa" satisfied condition "Succeeded or Failed"
Nov 12 00:42:41.219: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:42:41.249
Nov 12 00:42:41.301: INFO: Waiting for pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa to disappear
Nov 12 00:42:41.320: INFO: Pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:42:41.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2376" for this suite. 11/12/22 00:42:41.336
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":275,"skipped":5176,"failed":0}
------------------------------
• [SLOW TEST] [6.366 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:35.002
    Nov 12 00:42:35.003: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:42:35.005
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:35.043
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:35.057
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-45180014-eca6-47d9-a57d-1d2eb3bd68f7 11/12/22 00:42:35.07
    STEP: Creating a pod to test consume configMaps 11/12/22 00:42:35.088
    Nov 12 00:42:35.137: INFO: Waiting up to 5m0s for pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa" in namespace "configmap-2376" to be "Succeeded or Failed"
    Nov 12 00:42:35.158: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 20.988395ms
    Nov 12 00:42:37.176: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038746401s
    Nov 12 00:42:39.176: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038392595s
    Nov 12 00:42:41.178: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.040415729s
    STEP: Saw pod success 11/12/22 00:42:41.178
    Nov 12 00:42:41.179: INFO: Pod "pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa" satisfied condition "Succeeded or Failed"
    Nov 12 00:42:41.219: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:42:41.249
    Nov 12 00:42:41.301: INFO: Waiting for pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa to disappear
    Nov 12 00:42:41.320: INFO: Pod pod-configmaps-0999bf89-62ea-4c2e-b4ac-1edfbbd100aa no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:42:41.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2376" for this suite. 11/12/22 00:42:41.336
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:42:41.377
Nov 12 00:42:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename statefulset 11/12/22 00:42:41.379
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:41.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:41.432
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4251 11/12/22 00:42:41.446
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 11/12/22 00:42:41.46
Nov 12 00:42:41.490: INFO: Found 0 stateful pods, waiting for 3
Nov 12 00:42:51.510: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:42:51.510: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:42:51.510: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 00:42:51.558
Nov 12 00:42:51.593: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/12/22 00:42:51.593
STEP: Not applying an update when the partition is greater than the number of replicas 11/12/22 00:43:01.65
STEP: Performing a canary update 11/12/22 00:43:01.65
Nov 12 00:43:01.684: INFO: Updating stateful set ss2
Nov 12 00:43:01.743: INFO: Waiting for Pod statefulset-4251/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 11/12/22 00:43:11.796
Nov 12 00:43:11.920: INFO: Found 2 stateful pods, waiting for 3
Nov 12 00:43:21.941: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:43:21.941: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 00:43:21.941: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 11/12/22 00:43:21.971
Nov 12 00:43:22.021: INFO: Updating stateful set ss2
Nov 12 00:43:22.051: INFO: Waiting for Pod statefulset-4251/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 12 00:43:32.117: INFO: Updating stateful set ss2
Nov 12 00:43:32.148: INFO: Waiting for StatefulSet statefulset-4251/ss2 to complete update
Nov 12 00:43:32.148: INFO: Waiting for Pod statefulset-4251/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 00:43:42.177: INFO: Deleting all statefulset in ns statefulset-4251
Nov 12 00:43:42.186: INFO: Scaling statefulset ss2 to 0
Nov 12 00:43:52.252: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 00:43:52.265: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 00:43:52.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4251" for this suite. 11/12/22 00:43:52.326
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":276,"skipped":5203,"failed":0}
------------------------------
• [SLOW TEST] [70.984 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:42:41.377
    Nov 12 00:42:41.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename statefulset 11/12/22 00:42:41.379
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:42:41.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:42:41.432
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4251 11/12/22 00:42:41.446
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 11/12/22 00:42:41.46
    Nov 12 00:42:41.490: INFO: Found 0 stateful pods, waiting for 3
    Nov 12 00:42:51.510: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:42:51.510: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:42:51.510: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 00:42:51.558
    Nov 12 00:42:51.593: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/12/22 00:42:51.593
    STEP: Not applying an update when the partition is greater than the number of replicas 11/12/22 00:43:01.65
    STEP: Performing a canary update 11/12/22 00:43:01.65
    Nov 12 00:43:01.684: INFO: Updating stateful set ss2
    Nov 12 00:43:01.743: INFO: Waiting for Pod statefulset-4251/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 11/12/22 00:43:11.796
    Nov 12 00:43:11.920: INFO: Found 2 stateful pods, waiting for 3
    Nov 12 00:43:21.941: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:43:21.941: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 00:43:21.941: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 11/12/22 00:43:21.971
    Nov 12 00:43:22.021: INFO: Updating stateful set ss2
    Nov 12 00:43:22.051: INFO: Waiting for Pod statefulset-4251/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 12 00:43:32.117: INFO: Updating stateful set ss2
    Nov 12 00:43:32.148: INFO: Waiting for StatefulSet statefulset-4251/ss2 to complete update
    Nov 12 00:43:32.148: INFO: Waiting for Pod statefulset-4251/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 00:43:42.177: INFO: Deleting all statefulset in ns statefulset-4251
    Nov 12 00:43:42.186: INFO: Scaling statefulset ss2 to 0
    Nov 12 00:43:52.252: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 00:43:52.265: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 00:43:52.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4251" for this suite. 11/12/22 00:43:52.326
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:43:52.361
Nov 12 00:43:52.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:43:52.362
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:43:52.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:43:52.425
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:43:52.485
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:43:53.724
STEP: Deploying the webhook pod 11/12/22 00:43:53.747
STEP: Wait for the deployment to be ready 11/12/22 00:43:53.778
Nov 12 00:43:53.815: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 00:43:55.869: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:43:57.907
STEP: Verifying the service has paired with the endpoint 11/12/22 00:43:57.95
Nov 12 00:43:58.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 11/12/22 00:43:58.96
STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/12/22 00:43:59.072
STEP: Creating a configMap that should not be mutated 11/12/22 00:43:59.093
STEP: Patching a mutating webhook configuration's rules to include the create operation 11/12/22 00:43:59.136
STEP: Creating a configMap that should be mutated 11/12/22 00:43:59.158
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:43:59.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5900" for this suite. 11/12/22 00:43:59.287
STEP: Destroying namespace "webhook-5900-markers" for this suite. 11/12/22 00:43:59.315
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":277,"skipped":5205,"failed":0}
------------------------------
• [SLOW TEST] [7.139 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:43:52.361
    Nov 12 00:43:52.361: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:43:52.362
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:43:52.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:43:52.425
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:43:52.485
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:43:53.724
    STEP: Deploying the webhook pod 11/12/22 00:43:53.747
    STEP: Wait for the deployment to be ready 11/12/22 00:43:53.778
    Nov 12 00:43:53.815: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 00:43:55.869: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 43, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:43:57.907
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:43:57.95
    Nov 12 00:43:58.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 11/12/22 00:43:58.96
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/12/22 00:43:59.072
    STEP: Creating a configMap that should not be mutated 11/12/22 00:43:59.093
    STEP: Patching a mutating webhook configuration's rules to include the create operation 11/12/22 00:43:59.136
    STEP: Creating a configMap that should be mutated 11/12/22 00:43:59.158
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:43:59.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5900" for this suite. 11/12/22 00:43:59.287
    STEP: Destroying namespace "webhook-5900-markers" for this suite. 11/12/22 00:43:59.315
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:43:59.502
Nov 12 00:43:59.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:43:59.504
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:43:59.567
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:43:59.58
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 11/12/22 00:43:59.593
STEP: Creating a ResourceQuota 11/12/22 00:44:04.603
STEP: Ensuring resource quota status is calculated 11/12/22 00:44:04.615
STEP: Creating a ReplicationController 11/12/22 00:44:06.627
STEP: Ensuring resource quota status captures replication controller creation 11/12/22 00:44:06.657
STEP: Deleting a ReplicationController 11/12/22 00:44:08.668
STEP: Ensuring resource quota status released usage 11/12/22 00:44:08.697
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:44:10.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8072" for this suite. 11/12/22 00:44:10.724
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":278,"skipped":5220,"failed":0}
------------------------------
• [SLOW TEST] [11.251 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:43:59.502
    Nov 12 00:43:59.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:43:59.504
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:43:59.567
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:43:59.58
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 11/12/22 00:43:59.593
    STEP: Creating a ResourceQuota 11/12/22 00:44:04.603
    STEP: Ensuring resource quota status is calculated 11/12/22 00:44:04.615
    STEP: Creating a ReplicationController 11/12/22 00:44:06.627
    STEP: Ensuring resource quota status captures replication controller creation 11/12/22 00:44:06.657
    STEP: Deleting a ReplicationController 11/12/22 00:44:08.668
    STEP: Ensuring resource quota status released usage 11/12/22 00:44:08.697
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:44:10.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8072" for this suite. 11/12/22 00:44:10.724
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:10.755
Nov 12 00:44:10.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:44:10.758
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:10.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:10.827
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:44:10.84
Nov 12 00:44:10.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b" in namespace "projected-8666" to be "Succeeded or Failed"
Nov 12 00:44:10.889: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.596116ms
Nov 12 00:44:12.907: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034869054s
Nov 12 00:44:14.941: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068708161s
Nov 12 00:44:16.908: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03548032s
STEP: Saw pod success 11/12/22 00:44:16.908
Nov 12 00:44:16.908: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b" satisfied condition "Succeeded or Failed"
Nov 12 00:44:16.926: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b container client-container: <nil>
STEP: delete the pod 11/12/22 00:44:17.002
Nov 12 00:44:17.045: INFO: Waiting for pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b to disappear
Nov 12 00:44:17.062: INFO: Pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:44:17.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8666" for this suite. 11/12/22 00:44:17.078
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":279,"skipped":5226,"failed":0}
------------------------------
• [SLOW TEST] [6.350 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:10.755
    Nov 12 00:44:10.756: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:44:10.758
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:10.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:10.827
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:44:10.84
    Nov 12 00:44:10.872: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b" in namespace "projected-8666" to be "Succeeded or Failed"
    Nov 12 00:44:10.889: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.596116ms
    Nov 12 00:44:12.907: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034869054s
    Nov 12 00:44:14.941: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068708161s
    Nov 12 00:44:16.908: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03548032s
    STEP: Saw pod success 11/12/22 00:44:16.908
    Nov 12 00:44:16.908: INFO: Pod "downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b" satisfied condition "Succeeded or Failed"
    Nov 12 00:44:16.926: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b container client-container: <nil>
    STEP: delete the pod 11/12/22 00:44:17.002
    Nov 12 00:44:17.045: INFO: Waiting for pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b to disappear
    Nov 12 00:44:17.062: INFO: Pod downwardapi-volume-97a4713e-dc1d-4d1a-9aa2-4d43ecc2810b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:44:17.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8666" for this suite. 11/12/22 00:44:17.078
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:17.106
Nov 12 00:44:17.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:44:17.108
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:17.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:17.159
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 11/12/22 00:44:17.171
STEP: Creating a ResourceQuota 11/12/22 00:44:22.184
STEP: Ensuring resource quota status is calculated 11/12/22 00:44:22.195
STEP: Creating a Pod that fits quota 11/12/22 00:44:24.21
STEP: Ensuring ResourceQuota status captures the pod usage 11/12/22 00:44:24.264
STEP: Not allowing a pod to be created that exceeds remaining quota 11/12/22 00:44:26.283
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/12/22 00:44:26.29
STEP: Ensuring a pod cannot update its resource requirements 11/12/22 00:44:26.298
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/12/22 00:44:26.316
STEP: Deleting the pod 11/12/22 00:44:28.327
STEP: Ensuring resource quota status released the pod usage 11/12/22 00:44:28.373
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:44:30.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1582" for this suite. 11/12/22 00:44:30.451
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":280,"skipped":5231,"failed":0}
------------------------------
• [SLOW TEST] [13.379 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:17.106
    Nov 12 00:44:17.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:44:17.108
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:17.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:17.159
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 11/12/22 00:44:17.171
    STEP: Creating a ResourceQuota 11/12/22 00:44:22.184
    STEP: Ensuring resource quota status is calculated 11/12/22 00:44:22.195
    STEP: Creating a Pod that fits quota 11/12/22 00:44:24.21
    STEP: Ensuring ResourceQuota status captures the pod usage 11/12/22 00:44:24.264
    STEP: Not allowing a pod to be created that exceeds remaining quota 11/12/22 00:44:26.283
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/12/22 00:44:26.29
    STEP: Ensuring a pod cannot update its resource requirements 11/12/22 00:44:26.298
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/12/22 00:44:26.316
    STEP: Deleting the pod 11/12/22 00:44:28.327
    STEP: Ensuring resource quota status released the pod usage 11/12/22 00:44:28.373
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:44:30.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1582" for this suite. 11/12/22 00:44:30.451
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:30.504
Nov 12 00:44:30.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:44:30.506
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:30.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:30.559
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 00:44:34.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2571" for this suite. 11/12/22 00:44:34.683
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":281,"skipped":5262,"failed":0}
------------------------------
• [4.207 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:30.504
    Nov 12 00:44:30.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:44:30.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:30.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:30.559
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 00:44:34.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2571" for this suite. 11/12/22 00:44:34.683
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:34.713
Nov 12 00:44:34.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:44:34.715
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:34.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:34.764
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-21211ab7-9e80-477d-afa6-9ea3f01fdc89 11/12/22 00:44:34.777
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:44:34.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6487" for this suite. 11/12/22 00:44:34.796
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":282,"skipped":5274,"failed":0}
------------------------------
• [0.111 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:34.713
    Nov 12 00:44:34.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:44:34.715
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:34.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:34.764
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-21211ab7-9e80-477d-afa6-9ea3f01fdc89 11/12/22 00:44:34.777
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:44:34.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6487" for this suite. 11/12/22 00:44:34.796
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:34.829
Nov 12 00:44:34.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:44:34.831
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:34.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:34.884
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 11/12/22 00:44:34.897
STEP: getting /apis/node.k8s.io 11/12/22 00:44:34.908
STEP: getting /apis/node.k8s.io/v1 11/12/22 00:44:34.915
STEP: creating 11/12/22 00:44:34.921
STEP: watching 11/12/22 00:44:34.984
Nov 12 00:44:34.985: INFO: starting watch
STEP: getting 11/12/22 00:44:35.011
STEP: listing 11/12/22 00:44:35.026
STEP: patching 11/12/22 00:44:35.042
STEP: updating 11/12/22 00:44:35.059
Nov 12 00:44:35.076: INFO: waiting for watch events with expected annotations
STEP: deleting 11/12/22 00:44:35.077
STEP: deleting a collection 11/12/22 00:44:35.133
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 00:44:35.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9262" for this suite. 11/12/22 00:44:35.219
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":283,"skipped":5285,"failed":0}
------------------------------
• [0.421 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:34.829
    Nov 12 00:44:34.830: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:44:34.831
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:34.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:34.884
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 11/12/22 00:44:34.897
    STEP: getting /apis/node.k8s.io 11/12/22 00:44:34.908
    STEP: getting /apis/node.k8s.io/v1 11/12/22 00:44:34.915
    STEP: creating 11/12/22 00:44:34.921
    STEP: watching 11/12/22 00:44:34.984
    Nov 12 00:44:34.985: INFO: starting watch
    STEP: getting 11/12/22 00:44:35.011
    STEP: listing 11/12/22 00:44:35.026
    STEP: patching 11/12/22 00:44:35.042
    STEP: updating 11/12/22 00:44:35.059
    Nov 12 00:44:35.076: INFO: waiting for watch events with expected annotations
    STEP: deleting 11/12/22 00:44:35.077
    STEP: deleting a collection 11/12/22 00:44:35.133
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 00:44:35.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9262" for this suite. 11/12/22 00:44:35.219
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:35.255
Nov 12 00:44:35.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replication-controller 11/12/22 00:44:35.257
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:35.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:35.309
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 11/12/22 00:44:35.338
STEP: waiting for RC to be added 11/12/22 00:44:35.357
STEP: waiting for available Replicas 11/12/22 00:44:35.358
STEP: patching ReplicationController 11/12/22 00:44:38.027
STEP: waiting for RC to be modified 11/12/22 00:44:38.049
STEP: patching ReplicationController status 11/12/22 00:44:38.051
STEP: waiting for RC to be modified 11/12/22 00:44:38.071
STEP: waiting for available Replicas 11/12/22 00:44:38.072
STEP: fetching ReplicationController status 11/12/22 00:44:38.084
STEP: patching ReplicationController scale 11/12/22 00:44:38.101
STEP: waiting for RC to be modified 11/12/22 00:44:38.119
STEP: waiting for ReplicationController's scale to be the max amount 11/12/22 00:44:38.12
STEP: fetching ReplicationController; ensuring that it's patched 11/12/22 00:44:40.311
STEP: updating ReplicationController status 11/12/22 00:44:40.327
STEP: waiting for RC to be modified 11/12/22 00:44:40.346
STEP: listing all ReplicationControllers 11/12/22 00:44:40.348
STEP: checking that ReplicationController has expected values 11/12/22 00:44:40.377
STEP: deleting ReplicationControllers by collection 11/12/22 00:44:40.378
STEP: waiting for ReplicationController to have a DELETED watchEvent 11/12/22 00:44:40.423
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 00:44:40.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5623" for this suite. 11/12/22 00:44:40.574
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":284,"skipped":5296,"failed":0}
------------------------------
• [SLOW TEST] [5.357 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:35.255
    Nov 12 00:44:35.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replication-controller 11/12/22 00:44:35.257
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:35.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:35.309
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 11/12/22 00:44:35.338
    STEP: waiting for RC to be added 11/12/22 00:44:35.357
    STEP: waiting for available Replicas 11/12/22 00:44:35.358
    STEP: patching ReplicationController 11/12/22 00:44:38.027
    STEP: waiting for RC to be modified 11/12/22 00:44:38.049
    STEP: patching ReplicationController status 11/12/22 00:44:38.051
    STEP: waiting for RC to be modified 11/12/22 00:44:38.071
    STEP: waiting for available Replicas 11/12/22 00:44:38.072
    STEP: fetching ReplicationController status 11/12/22 00:44:38.084
    STEP: patching ReplicationController scale 11/12/22 00:44:38.101
    STEP: waiting for RC to be modified 11/12/22 00:44:38.119
    STEP: waiting for ReplicationController's scale to be the max amount 11/12/22 00:44:38.12
    STEP: fetching ReplicationController; ensuring that it's patched 11/12/22 00:44:40.311
    STEP: updating ReplicationController status 11/12/22 00:44:40.327
    STEP: waiting for RC to be modified 11/12/22 00:44:40.346
    STEP: listing all ReplicationControllers 11/12/22 00:44:40.348
    STEP: checking that ReplicationController has expected values 11/12/22 00:44:40.377
    STEP: deleting ReplicationControllers by collection 11/12/22 00:44:40.378
    STEP: waiting for ReplicationController to have a DELETED watchEvent 11/12/22 00:44:40.423
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 00:44:40.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5623" for this suite. 11/12/22 00:44:40.574
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:40.619
Nov 12 00:44:40.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:44:40.62
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:40.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:40.692
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4323 11/12/22 00:44:40.704
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 00:44:40.77
STEP: creating service externalsvc in namespace services-4323 11/12/22 00:44:40.772
STEP: creating replication controller externalsvc in namespace services-4323 11/12/22 00:44:40.821
I1112 00:44:40.841503      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4323, replica count: 2
I1112 00:44:43.892291      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 11/12/22 00:44:43.903
Nov 12 00:44:43.971: INFO: Creating new exec pod
Nov 12 00:44:43.991: INFO: Waiting up to 5m0s for pod "execpodkz4xc" in namespace "services-4323" to be "running"
Nov 12 00:44:44.008: INFO: Pod "execpodkz4xc": Phase="Pending", Reason="", readiness=false. Elapsed: 17.424224ms
Nov 12 00:44:46.025: INFO: Pod "execpodkz4xc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034726147s
Nov 12 00:44:48.025: INFO: Pod "execpodkz4xc": Phase="Running", Reason="", readiness=true. Elapsed: 4.034318726s
Nov 12 00:44:48.025: INFO: Pod "execpodkz4xc" satisfied condition "running"
Nov 12 00:44:48.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4323 exec execpodkz4xc -- /bin/sh -x -c nslookup nodeport-service.services-4323.svc.cluster.local'
Nov 12 00:44:48.441: INFO: stderr: "+ nslookup nodeport-service.services-4323.svc.cluster.local\n"
Nov 12 00:44:48.441: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-4323.svc.cluster.local\tcanonical name = externalsvc.services-4323.svc.cluster.local.\nName:\texternalsvc.services-4323.svc.cluster.local\nAddress: 172.21.180.163\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4323, will wait for the garbage collector to delete the pods 11/12/22 00:44:48.441
Nov 12 00:44:48.537: INFO: Deleting ReplicationController externalsvc took: 28.713821ms
Nov 12 00:44:48.638: INFO: Terminating ReplicationController externalsvc pods took: 101.092318ms
Nov 12 00:44:51.288: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:44:51.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4323" for this suite. 11/12/22 00:44:51.329
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":285,"skipped":5310,"failed":0}
------------------------------
• [SLOW TEST] [10.740 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:40.619
    Nov 12 00:44:40.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:44:40.62
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:40.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:40.692
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-4323 11/12/22 00:44:40.704
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 00:44:40.77
    STEP: creating service externalsvc in namespace services-4323 11/12/22 00:44:40.772
    STEP: creating replication controller externalsvc in namespace services-4323 11/12/22 00:44:40.821
    I1112 00:44:40.841503      21 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4323, replica count: 2
    I1112 00:44:43.892291      21 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 11/12/22 00:44:43.903
    Nov 12 00:44:43.971: INFO: Creating new exec pod
    Nov 12 00:44:43.991: INFO: Waiting up to 5m0s for pod "execpodkz4xc" in namespace "services-4323" to be "running"
    Nov 12 00:44:44.008: INFO: Pod "execpodkz4xc": Phase="Pending", Reason="", readiness=false. Elapsed: 17.424224ms
    Nov 12 00:44:46.025: INFO: Pod "execpodkz4xc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034726147s
    Nov 12 00:44:48.025: INFO: Pod "execpodkz4xc": Phase="Running", Reason="", readiness=true. Elapsed: 4.034318726s
    Nov 12 00:44:48.025: INFO: Pod "execpodkz4xc" satisfied condition "running"
    Nov 12 00:44:48.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-4323 exec execpodkz4xc -- /bin/sh -x -c nslookup nodeport-service.services-4323.svc.cluster.local'
    Nov 12 00:44:48.441: INFO: stderr: "+ nslookup nodeport-service.services-4323.svc.cluster.local\n"
    Nov 12 00:44:48.441: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-4323.svc.cluster.local\tcanonical name = externalsvc.services-4323.svc.cluster.local.\nName:\texternalsvc.services-4323.svc.cluster.local\nAddress: 172.21.180.163\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4323, will wait for the garbage collector to delete the pods 11/12/22 00:44:48.441
    Nov 12 00:44:48.537: INFO: Deleting ReplicationController externalsvc took: 28.713821ms
    Nov 12 00:44:48.638: INFO: Terminating ReplicationController externalsvc pods took: 101.092318ms
    Nov 12 00:44:51.288: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:44:51.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4323" for this suite. 11/12/22 00:44:51.329
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:44:51.374
Nov 12 00:44:51.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename init-container 11/12/22 00:44:51.375
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:51.419
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:51.433
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 11/12/22 00:44:51.445
Nov 12 00:44:51.446: INFO: PodSpec: initContainers in spec.initContainers
Nov 12 00:45:37.342: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4103f0cd-80ab-46c3-a571-97d59debad02", GenerateName:"", Namespace:"init-container-9426", SelfLink:"", UID:"db361e34-9fa5-4e81-8e01-f9c44f9e81a8", ResourceVersion:"43900", Generation:0, CreationTimestamp:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"446439626"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"cadc346667686fce673130e91d51473c58572908b0a76040818a90374cfac5d2", "cni.projectcalico.org/podIP":"172.30.146.63/32", "cni.projectcalico.org/podIPs":"172.30.146.63/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004722378), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 44, 52, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047223a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 45, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047223d8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-pwrtd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0037c52c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004350a88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.184.98.55", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00372e700), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004350b20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004350b40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004350b48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004350b4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00459f850), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.184.98.55", PodIP:"172.30.146.63", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.146.63"}}, StartTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00372e7e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00372e8c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f5de4e064abd5e433dd293c89aa9b890e78fae0a1509e9341723c028a401df60", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037c5340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037c5320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004350bdf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 00:45:37.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9426" for this suite. 11/12/22 00:45:37.359
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":286,"skipped":5350,"failed":0}
------------------------------
• [SLOW TEST] [46.015 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:44:51.374
    Nov 12 00:44:51.374: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename init-container 11/12/22 00:44:51.375
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:44:51.419
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:44:51.433
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 11/12/22 00:44:51.445
    Nov 12 00:44:51.446: INFO: PodSpec: initContainers in spec.initContainers
    Nov 12 00:45:37.342: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4103f0cd-80ab-46c3-a571-97d59debad02", GenerateName:"", Namespace:"init-container-9426", SelfLink:"", UID:"db361e34-9fa5-4e81-8e01-f9c44f9e81a8", ResourceVersion:"43900", Generation:0, CreationTimestamp:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"446439626"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"cadc346667686fce673130e91d51473c58572908b0a76040818a90374cfac5d2", "cni.projectcalico.org/podIP":"172.30.146.63/32", "cni.projectcalico.org/podIPs":"172.30.146.63/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004722378), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 44, 52, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047223a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 0, 45, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0047223d8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-pwrtd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0037c52c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pwrtd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004350a88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.184.98.55", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00372e700), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004350b20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004350b40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004350b48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004350b4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00459f850), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.184.98.55", PodIP:"172.30.146.63", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.146.63"}}, StartTime:time.Date(2022, time.November, 12, 0, 44, 51, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00372e7e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00372e8c0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://f5de4e064abd5e433dd293c89aa9b890e78fae0a1509e9341723c028a401df60", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037c5340), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037c5320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004350bdf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 00:45:37.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9426" for this suite. 11/12/22 00:45:37.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:45:37.4
Nov 12 00:45:37.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:45:37.402
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:45:37.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:45:37.457
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 11/12/22 00:45:37.47
Nov 12 00:45:37.502: INFO: Waiting up to 5m0s for pod "downward-api-8d475726-7187-4541-a87d-04e493f65693" in namespace "downward-api-296" to be "Succeeded or Failed"
Nov 12 00:45:37.523: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 20.411516ms
Nov 12 00:45:39.541: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039032627s
Nov 12 00:45:41.540: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03740955s
Nov 12 00:45:43.541: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038896381s
STEP: Saw pod success 11/12/22 00:45:43.541
Nov 12 00:45:43.542: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693" satisfied condition "Succeeded or Failed"
Nov 12 00:45:43.563: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-8d475726-7187-4541-a87d-04e493f65693 container dapi-container: <nil>
STEP: delete the pod 11/12/22 00:45:43.597
Nov 12 00:45:43.654: INFO: Waiting for pod downward-api-8d475726-7187-4541-a87d-04e493f65693 to disappear
Nov 12 00:45:43.685: INFO: Pod downward-api-8d475726-7187-4541-a87d-04e493f65693 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 00:45:43.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-296" for this suite. 11/12/22 00:45:43.702
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":287,"skipped":5397,"failed":0}
------------------------------
• [SLOW TEST] [6.333 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:45:37.4
    Nov 12 00:45:37.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:45:37.402
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:45:37.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:45:37.457
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 11/12/22 00:45:37.47
    Nov 12 00:45:37.502: INFO: Waiting up to 5m0s for pod "downward-api-8d475726-7187-4541-a87d-04e493f65693" in namespace "downward-api-296" to be "Succeeded or Failed"
    Nov 12 00:45:37.523: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 20.411516ms
    Nov 12 00:45:39.541: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039032627s
    Nov 12 00:45:41.540: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03740955s
    Nov 12 00:45:43.541: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038896381s
    STEP: Saw pod success 11/12/22 00:45:43.541
    Nov 12 00:45:43.542: INFO: Pod "downward-api-8d475726-7187-4541-a87d-04e493f65693" satisfied condition "Succeeded or Failed"
    Nov 12 00:45:43.563: INFO: Trying to get logs from node 10.184.98.55 pod downward-api-8d475726-7187-4541-a87d-04e493f65693 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 00:45:43.597
    Nov 12 00:45:43.654: INFO: Waiting for pod downward-api-8d475726-7187-4541-a87d-04e493f65693 to disappear
    Nov 12 00:45:43.685: INFO: Pod downward-api-8d475726-7187-4541-a87d-04e493f65693 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 00:45:43.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-296" for this suite. 11/12/22 00:45:43.702
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:45:43.752
Nov 12 00:45:43.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:45:43.755
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:45:43.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:45:43.832
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-3968 11/12/22 00:45:43.845
STEP: creating a selector 11/12/22 00:45:43.846
STEP: Creating the service pods in kubernetes 11/12/22 00:45:43.846
Nov 12 00:45:43.847: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 00:45:43.942: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3968" to be "running and ready"
Nov 12 00:45:43.962: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.705161ms
Nov 12 00:45:43.962: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:45:45.979: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037795262s
Nov 12 00:45:45.979: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:45:47.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.03989844s
Nov 12 00:45:47.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:49.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.039454452s
Nov 12 00:45:49.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:51.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.038831455s
Nov 12 00:45:51.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:53.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.038422814s
Nov 12 00:45:53.980: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:55.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.038107737s
Nov 12 00:45:55.980: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:57.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.040216712s
Nov 12 00:45:57.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:45:59.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.040466837s
Nov 12 00:45:59.983: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:46:01.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.040380916s
Nov 12 00:46:01.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:46:03.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.039420669s
Nov 12 00:46:03.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:46:05.979: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.037797628s
Nov 12 00:46:05.979: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 00:46:05.979: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 00:46:05.995: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3968" to be "running and ready"
Nov 12 00:46:06.012: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 16.477435ms
Nov 12 00:46:06.012: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 00:46:06.012: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 00:46:06.029: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3968" to be "running and ready"
Nov 12 00:46:06.045: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.912782ms
Nov 12 00:46:06.045: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 00:46:06.045: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 00:46:06.063
Nov 12 00:46:06.084: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3968" to be "running"
Nov 12 00:46:06.103: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025687ms
Nov 12 00:46:08.120: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035291745s
Nov 12 00:46:10.122: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.037199233s
Nov 12 00:46:10.122: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 00:46:10.139: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 00:46:10.139: INFO: Breadth first check of 172.30.146.19 on host 10.184.98.55...
Nov 12 00:46:10.155: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.146.19&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:46:10.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:46:10.156: INFO: ExecWithOptions: Clientset creation
Nov 12 00:46:10.157: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.146.19%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 00:46:10.432: INFO: Waiting for responses: map[]
Nov 12 00:46:10.432: INFO: reached 172.30.146.19 after 0/1 tries
Nov 12 00:46:10.432: INFO: Breadth first check of 172.30.188.220 on host 10.241.148.113...
Nov 12 00:46:10.448: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.188.220&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:46:10.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:46:10.450: INFO: ExecWithOptions: Clientset creation
Nov 12 00:46:10.450: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.188.220%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 00:46:10.686: INFO: Waiting for responses: map[]
Nov 12 00:46:10.686: INFO: reached 172.30.188.220 after 0/1 tries
Nov 12 00:46:10.686: INFO: Breadth first check of 172.30.194.111 on host 10.241.148.26...
Nov 12 00:46:10.702: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.194.111&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:46:10.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:46:10.704: INFO: ExecWithOptions: Clientset creation
Nov 12 00:46:10.704: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.194.111%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 00:46:10.926: INFO: Waiting for responses: map[]
Nov 12 00:46:10.926: INFO: reached 172.30.194.111 after 0/1 tries
Nov 12 00:46:10.926: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 00:46:10.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3968" for this suite. 11/12/22 00:46:10.942
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":288,"skipped":5450,"failed":0}
------------------------------
• [SLOW TEST] [27.219 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:45:43.752
    Nov 12 00:45:43.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:45:43.755
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:45:43.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:45:43.832
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-3968 11/12/22 00:45:43.845
    STEP: creating a selector 11/12/22 00:45:43.846
    STEP: Creating the service pods in kubernetes 11/12/22 00:45:43.846
    Nov 12 00:45:43.847: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 00:45:43.942: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3968" to be "running and ready"
    Nov 12 00:45:43.962: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.705161ms
    Nov 12 00:45:43.962: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:45:45.979: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037795262s
    Nov 12 00:45:45.979: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:45:47.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.03989844s
    Nov 12 00:45:47.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:49.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.039454452s
    Nov 12 00:45:49.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:51.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.038831455s
    Nov 12 00:45:51.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:53.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.038422814s
    Nov 12 00:45:53.980: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:55.980: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.038107737s
    Nov 12 00:45:55.980: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:57.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.040216712s
    Nov 12 00:45:57.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:45:59.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.040466837s
    Nov 12 00:45:59.983: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:46:01.982: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.040380916s
    Nov 12 00:46:01.982: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:46:03.981: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.039420669s
    Nov 12 00:46:03.981: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:46:05.979: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.037797628s
    Nov 12 00:46:05.979: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 00:46:05.979: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 00:46:05.995: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3968" to be "running and ready"
    Nov 12 00:46:06.012: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 16.477435ms
    Nov 12 00:46:06.012: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 00:46:06.012: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 00:46:06.029: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3968" to be "running and ready"
    Nov 12 00:46:06.045: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 15.912782ms
    Nov 12 00:46:06.045: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 00:46:06.045: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 00:46:06.063
    Nov 12 00:46:06.084: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3968" to be "running"
    Nov 12 00:46:06.103: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025687ms
    Nov 12 00:46:08.120: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035291745s
    Nov 12 00:46:10.122: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.037199233s
    Nov 12 00:46:10.122: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 00:46:10.139: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 00:46:10.139: INFO: Breadth first check of 172.30.146.19 on host 10.184.98.55...
    Nov 12 00:46:10.155: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.146.19&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:46:10.155: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:46:10.156: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:46:10.157: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.146.19%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 00:46:10.432: INFO: Waiting for responses: map[]
    Nov 12 00:46:10.432: INFO: reached 172.30.146.19 after 0/1 tries
    Nov 12 00:46:10.432: INFO: Breadth first check of 172.30.188.220 on host 10.241.148.113...
    Nov 12 00:46:10.448: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.188.220&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:46:10.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:46:10.450: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:46:10.450: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.188.220%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 00:46:10.686: INFO: Waiting for responses: map[]
    Nov 12 00:46:10.686: INFO: reached 172.30.188.220 after 0/1 tries
    Nov 12 00:46:10.686: INFO: Breadth first check of 172.30.194.111 on host 10.241.148.26...
    Nov 12 00:46:10.702: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.146.32:9080/dial?request=hostname&protocol=http&host=172.30.194.111&port=8083&tries=1'] Namespace:pod-network-test-3968 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:46:10.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:46:10.704: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:46:10.704: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-3968/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.30.146.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.30.194.111%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 00:46:10.926: INFO: Waiting for responses: map[]
    Nov 12 00:46:10.926: INFO: reached 172.30.194.111 after 0/1 tries
    Nov 12 00:46:10.926: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 00:46:10.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3968" for this suite. 11/12/22 00:46:10.942
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:46:10.977
Nov 12 00:46:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename subpath 11/12/22 00:46:10.979
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:11.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:11.058
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 00:46:11.071
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-sj2c 11/12/22 00:46:11.099
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:46:11.099
Nov 12 00:46:11.127: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sj2c" in namespace "subpath-6688" to be "Succeeded or Failed"
Nov 12 00:46:11.145: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.523624ms
Nov 12 00:46:13.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035127512s
Nov 12 00:46:15.165: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 4.037559128s
Nov 12 00:46:17.177: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 6.049787199s
Nov 12 00:46:19.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 8.035723198s
Nov 12 00:46:21.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 10.035142379s
Nov 12 00:46:23.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 12.035093623s
Nov 12 00:46:25.164: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 14.036873131s
Nov 12 00:46:27.161: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 16.033277717s
Nov 12 00:46:29.188: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 18.0605977s
Nov 12 00:46:31.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 20.035909561s
Nov 12 00:46:33.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 22.035526291s
Nov 12 00:46:35.165: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=false. Elapsed: 24.03766679s
Nov 12 00:46:37.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.034640149s
STEP: Saw pod success 11/12/22 00:46:37.162
Nov 12 00:46:37.163: INFO: Pod "pod-subpath-test-projected-sj2c" satisfied condition "Succeeded or Failed"
Nov 12 00:46:37.180: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-projected-sj2c container test-container-subpath-projected-sj2c: <nil>
STEP: delete the pod 11/12/22 00:46:37.21
Nov 12 00:46:37.252: INFO: Waiting for pod pod-subpath-test-projected-sj2c to disappear
Nov 12 00:46:37.268: INFO: Pod pod-subpath-test-projected-sj2c no longer exists
STEP: Deleting pod pod-subpath-test-projected-sj2c 11/12/22 00:46:37.268
Nov 12 00:46:37.268: INFO: Deleting pod "pod-subpath-test-projected-sj2c" in namespace "subpath-6688"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 00:46:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6688" for this suite. 11/12/22 00:46:37.301
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":289,"skipped":5451,"failed":0}
------------------------------
• [SLOW TEST] [26.355 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:46:10.977
    Nov 12 00:46:10.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename subpath 11/12/22 00:46:10.979
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:11.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:11.058
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 00:46:11.071
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-sj2c 11/12/22 00:46:11.099
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 00:46:11.099
    Nov 12 00:46:11.127: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-sj2c" in namespace "subpath-6688" to be "Succeeded or Failed"
    Nov 12 00:46:11.145: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Pending", Reason="", readiness=false. Elapsed: 17.523624ms
    Nov 12 00:46:13.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035127512s
    Nov 12 00:46:15.165: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 4.037559128s
    Nov 12 00:46:17.177: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 6.049787199s
    Nov 12 00:46:19.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 8.035723198s
    Nov 12 00:46:21.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 10.035142379s
    Nov 12 00:46:23.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 12.035093623s
    Nov 12 00:46:25.164: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 14.036873131s
    Nov 12 00:46:27.161: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 16.033277717s
    Nov 12 00:46:29.188: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 18.0605977s
    Nov 12 00:46:31.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 20.035909561s
    Nov 12 00:46:33.163: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=true. Elapsed: 22.035526291s
    Nov 12 00:46:35.165: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Running", Reason="", readiness=false. Elapsed: 24.03766679s
    Nov 12 00:46:37.162: INFO: Pod "pod-subpath-test-projected-sj2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.034640149s
    STEP: Saw pod success 11/12/22 00:46:37.162
    Nov 12 00:46:37.163: INFO: Pod "pod-subpath-test-projected-sj2c" satisfied condition "Succeeded or Failed"
    Nov 12 00:46:37.180: INFO: Trying to get logs from node 10.184.98.55 pod pod-subpath-test-projected-sj2c container test-container-subpath-projected-sj2c: <nil>
    STEP: delete the pod 11/12/22 00:46:37.21
    Nov 12 00:46:37.252: INFO: Waiting for pod pod-subpath-test-projected-sj2c to disappear
    Nov 12 00:46:37.268: INFO: Pod pod-subpath-test-projected-sj2c no longer exists
    STEP: Deleting pod pod-subpath-test-projected-sj2c 11/12/22 00:46:37.268
    Nov 12 00:46:37.268: INFO: Deleting pod "pod-subpath-test-projected-sj2c" in namespace "subpath-6688"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 00:46:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6688" for this suite. 11/12/22 00:46:37.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:46:37.336
Nov 12 00:46:37.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:46:37.337
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:37.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:37.394
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Nov 12 00:46:37.476: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8297 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 00:46:37.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8297" for this suite. 11/12/22 00:46:37.532
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":290,"skipped":5482,"failed":0}
------------------------------
• [0.254 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:46:37.336
    Nov 12 00:46:37.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:46:37.337
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:37.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:37.394
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Nov 12 00:46:37.476: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8297 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 00:46:37.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8297" for this suite. 11/12/22 00:46:37.532
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:46:37.59
Nov 12 00:46:37.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:46:37.593
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:37.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:37.645
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 11/12/22 00:46:37.662
STEP: setting up watch 11/12/22 00:46:37.663
STEP: submitting the pod to kubernetes 11/12/22 00:46:37.781
STEP: verifying the pod is in kubernetes 11/12/22 00:46:37.814
STEP: verifying pod creation was observed 11/12/22 00:46:37.831
Nov 12 00:46:37.831: INFO: Waiting up to 5m0s for pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf" in namespace "pods-3718" to be "running"
Nov 12 00:46:37.848: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 17.444233ms
Nov 12 00:46:39.871: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf": Phase="Running", Reason="", readiness=true. Elapsed: 2.039899103s
Nov 12 00:46:39.871: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf" satisfied condition "running"
STEP: deleting the pod gracefully 11/12/22 00:46:39.887
STEP: verifying pod deletion was observed 11/12/22 00:46:39.948
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:46:43.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3718" for this suite. 11/12/22 00:46:43.043
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":291,"skipped":5484,"failed":0}
------------------------------
• [SLOW TEST] [5.485 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:46:37.59
    Nov 12 00:46:37.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:46:37.593
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:37.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:37.645
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 11/12/22 00:46:37.662
    STEP: setting up watch 11/12/22 00:46:37.663
    STEP: submitting the pod to kubernetes 11/12/22 00:46:37.781
    STEP: verifying the pod is in kubernetes 11/12/22 00:46:37.814
    STEP: verifying pod creation was observed 11/12/22 00:46:37.831
    Nov 12 00:46:37.831: INFO: Waiting up to 5m0s for pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf" in namespace "pods-3718" to be "running"
    Nov 12 00:46:37.848: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf": Phase="Pending", Reason="", readiness=false. Elapsed: 17.444233ms
    Nov 12 00:46:39.871: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf": Phase="Running", Reason="", readiness=true. Elapsed: 2.039899103s
    Nov 12 00:46:39.871: INFO: Pod "pod-submit-remove-c89a871b-859a-44a7-bd22-ac29dd5fd7bf" satisfied condition "running"
    STEP: deleting the pod gracefully 11/12/22 00:46:39.887
    STEP: verifying pod deletion was observed 11/12/22 00:46:39.948
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:46:43.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3718" for this suite. 11/12/22 00:46:43.043
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:46:43.078
Nov 12 00:46:43.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename events 11/12/22 00:46:43.08
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:43.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:43.141
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 11/12/22 00:46:43.154
Nov 12 00:46:43.176: INFO: created test-event-1
Nov 12 00:46:43.202: INFO: created test-event-2
Nov 12 00:46:43.222: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 11/12/22 00:46:43.222
STEP: delete collection of events 11/12/22 00:46:43.244
Nov 12 00:46:43.244: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/12/22 00:46:43.382
Nov 12 00:46:43.382: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 12 00:46:43.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9686" for this suite. 11/12/22 00:46:43.435
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":292,"skipped":5504,"failed":0}
------------------------------
• [0.401 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:46:43.078
    Nov 12 00:46:43.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename events 11/12/22 00:46:43.08
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:43.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:43.141
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 11/12/22 00:46:43.154
    Nov 12 00:46:43.176: INFO: created test-event-1
    Nov 12 00:46:43.202: INFO: created test-event-2
    Nov 12 00:46:43.222: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 11/12/22 00:46:43.222
    STEP: delete collection of events 11/12/22 00:46:43.244
    Nov 12 00:46:43.244: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/12/22 00:46:43.382
    Nov 12 00:46:43.382: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 12 00:46:43.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9686" for this suite. 11/12/22 00:46:43.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:46:43.484
Nov 12 00:46:43.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:46:43.485
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:43.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:43.538
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:46:43.592
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:46:45.102
STEP: Deploying the webhook pod 11/12/22 00:46:45.125
STEP: Wait for the deployment to be ready 11/12/22 00:46:45.157
Nov 12 00:46:45.202: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 12 00:46:47.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:46:49.265
STEP: Verifying the service has paired with the endpoint 11/12/22 00:46:49.303
Nov 12 00:46:50.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/12/22 00:46:50.316
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:50.316
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/12/22 00:46:50.394
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/12/22 00:46:51.442
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:51.442
STEP: Having no error when timeout is longer than webhook latency 11/12/22 00:46:52.533
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:52.533
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/12/22 00:46:57.814
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:57.814
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:47:02.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5906" for this suite. 11/12/22 00:47:02.981
STEP: Destroying namespace "webhook-5906-markers" for this suite. 11/12/22 00:47:03.004
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":293,"skipped":5517,"failed":0}
------------------------------
• [SLOW TEST] [19.749 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:46:43.484
    Nov 12 00:46:43.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:46:43.485
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:46:43.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:46:43.538
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:46:43.592
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:46:45.102
    STEP: Deploying the webhook pod 11/12/22 00:46:45.125
    STEP: Wait for the deployment to be ready 11/12/22 00:46:45.157
    Nov 12 00:46:45.202: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Nov 12 00:46:47.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 46, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:46:49.265
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:46:49.303
    Nov 12 00:46:50.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/12/22 00:46:50.316
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:50.316
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/12/22 00:46:50.394
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/12/22 00:46:51.442
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:51.442
    STEP: Having no error when timeout is longer than webhook latency 11/12/22 00:46:52.533
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:52.533
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/12/22 00:46:57.814
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 00:46:57.814
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:47:02.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5906" for this suite. 11/12/22 00:47:02.981
    STEP: Destroying namespace "webhook-5906-markers" for this suite. 11/12/22 00:47:03.004
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:47:03.236
Nov 12 00:47:03.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:47:03.239
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:03.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:03.312
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:47:03.329
Nov 12 00:47:03.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde" in namespace "projected-9959" to be "Succeeded or Failed"
Nov 12 00:47:03.382: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 15.417361ms
Nov 12 00:47:05.397: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03066137s
Nov 12 00:47:07.397: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030105221s
Nov 12 00:47:09.395: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028924112s
STEP: Saw pod success 11/12/22 00:47:09.396
Nov 12 00:47:09.396: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde" satisfied condition "Succeeded or Failed"
Nov 12 00:47:09.409: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde container client-container: <nil>
STEP: delete the pod 11/12/22 00:47:09.511
Nov 12 00:47:09.575: INFO: Waiting for pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde to disappear
Nov 12 00:47:09.605: INFO: Pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 00:47:09.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9959" for this suite. 11/12/22 00:47:09.655
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":294,"skipped":5542,"failed":0}
------------------------------
• [SLOW TEST] [6.448 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:47:03.236
    Nov 12 00:47:03.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:47:03.239
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:03.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:03.312
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:47:03.329
    Nov 12 00:47:03.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde" in namespace "projected-9959" to be "Succeeded or Failed"
    Nov 12 00:47:03.382: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 15.417361ms
    Nov 12 00:47:05.397: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03066137s
    Nov 12 00:47:07.397: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030105221s
    Nov 12 00:47:09.395: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028924112s
    STEP: Saw pod success 11/12/22 00:47:09.396
    Nov 12 00:47:09.396: INFO: Pod "downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde" satisfied condition "Succeeded or Failed"
    Nov 12 00:47:09.409: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde container client-container: <nil>
    STEP: delete the pod 11/12/22 00:47:09.511
    Nov 12 00:47:09.575: INFO: Waiting for pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde to disappear
    Nov 12 00:47:09.605: INFO: Pod downwardapi-volume-45166926-6e98-4af5-a5f4-ffe4fc488cde no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 00:47:09.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9959" for this suite. 11/12/22 00:47:09.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:47:09.687
Nov 12 00:47:09.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context-test 11/12/22 00:47:09.691
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:09.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:09.756
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Nov 12 00:47:09.802: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa" in namespace "security-context-test-7720" to be "Succeeded or Failed"
Nov 12 00:47:09.820: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Pending", Reason="", readiness=false. Elapsed: 17.535635ms
Nov 12 00:47:11.834: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031905824s
Nov 12 00:47:13.835: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Running", Reason="", readiness=true. Elapsed: 4.033469888s
Nov 12 00:47:15.835: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Running", Reason="", readiness=false. Elapsed: 6.033066466s
Nov 12 00:47:17.833: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.03047571s
Nov 12 00:47:17.833: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 00:47:17.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7720" for this suite. 11/12/22 00:47:17.885
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":295,"skipped":5553,"failed":0}
------------------------------
• [SLOW TEST] [8.224 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:47:09.687
    Nov 12 00:47:09.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context-test 11/12/22 00:47:09.691
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:09.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:09.756
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Nov 12 00:47:09.802: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa" in namespace "security-context-test-7720" to be "Succeeded or Failed"
    Nov 12 00:47:09.820: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Pending", Reason="", readiness=false. Elapsed: 17.535635ms
    Nov 12 00:47:11.834: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031905824s
    Nov 12 00:47:13.835: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Running", Reason="", readiness=true. Elapsed: 4.033469888s
    Nov 12 00:47:15.835: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Running", Reason="", readiness=false. Elapsed: 6.033066466s
    Nov 12 00:47:17.833: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.03047571s
    Nov 12 00:47:17.833: INFO: Pod "alpine-nnp-false-54835bb5-68eb-472c-a255-6977744d2baa" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 00:47:17.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7720" for this suite. 11/12/22 00:47:17.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:47:17.912
Nov 12 00:47:17.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename replication-controller 11/12/22 00:47:17.915
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:17.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:17.975
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 11/12/22 00:47:17.991
STEP: When the matched label of one of its pods change 11/12/22 00:47:18.007
Nov 12 00:47:18.020: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 12 00:47:23.035: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 11/12/22 00:47:23.064
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 00:47:24.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2127" for this suite. 11/12/22 00:47:24.121
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":296,"skipped":5566,"failed":0}
------------------------------
• [SLOW TEST] [6.234 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:47:17.912
    Nov 12 00:47:17.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename replication-controller 11/12/22 00:47:17.915
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:17.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:17.975
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 11/12/22 00:47:17.991
    STEP: When the matched label of one of its pods change 11/12/22 00:47:18.007
    Nov 12 00:47:18.020: INFO: Pod name pod-release: Found 0 pods out of 1
    Nov 12 00:47:23.035: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/12/22 00:47:23.064
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 00:47:24.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2127" for this suite. 11/12/22 00:47:24.121
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:47:24.148
Nov 12 00:47:24.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:47:24.15
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:24.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:24.218
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-5777 11/12/22 00:47:24.232
Nov 12 00:47:24.264: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5777" to be "running and ready"
Nov 12 00:47:24.277: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 12.514905ms
Nov 12 00:47:24.277: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:47:26.321: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.056778622s
Nov 12 00:47:26.321: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 12 00:47:26.321: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 12 00:47:26.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 12 00:47:26.716: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 12 00:47:26.716: INFO: stdout: "iptables"
Nov 12 00:47:26.716: INFO: proxyMode: iptables
Nov 12 00:47:26.744: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 12 00:47:26.757: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-5777 11/12/22 00:47:26.757
STEP: creating replication controller affinity-clusterip-timeout in namespace services-5777 11/12/22 00:47:26.8
I1112 00:47:26.819768      21 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5777, replica count: 3
I1112 00:47:29.870771      21 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 00:47:29.898: INFO: Creating new exec pod
Nov 12 00:47:29.915: INFO: Waiting up to 5m0s for pod "execpod-affinityt5bjx" in namespace "services-5777" to be "running"
Nov 12 00:47:29.931: INFO: Pod "execpod-affinityt5bjx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.086674ms
Nov 12 00:47:31.947: INFO: Pod "execpod-affinityt5bjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03183552s
Nov 12 00:47:33.953: INFO: Pod "execpod-affinityt5bjx": Phase="Running", Reason="", readiness=true. Elapsed: 4.037973667s
Nov 12 00:47:33.953: INFO: Pod "execpod-affinityt5bjx" satisfied condition "running"
Nov 12 00:47:34.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov 12 00:47:35.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Nov 12 00:47:35.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:47:35.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.199.245 80'
Nov 12 00:47:35.765: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.199.245 80\nConnection to 172.21.199.245 80 port [tcp/http] succeeded!\n"
Nov 12 00:47:35.765: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:47:35.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.199.245:80/ ; done'
Nov 12 00:47:36.331: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
Nov 12 00:47:36.331: INFO: stdout: "\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx"
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
Nov 12 00:47:36.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.199.245:80/'
Nov 12 00:47:36.759: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
Nov 12 00:47:36.759: INFO: stdout: "affinity-clusterip-timeout-hmqdx"
Nov 12 00:47:56.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.199.245:80/'
Nov 12 00:47:57.190: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
Nov 12 00:47:57.190: INFO: stdout: "affinity-clusterip-timeout-lzpv8"
Nov 12 00:47:57.190: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5777, will wait for the garbage collector to delete the pods 11/12/22 00:47:57.232
Nov 12 00:47:57.319: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 21.354971ms
Nov 12 00:47:57.437: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 118.041741ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:48:00.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5777" for this suite. 11/12/22 00:48:00.548
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":297,"skipped":5572,"failed":0}
------------------------------
• [SLOW TEST] [36.498 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:47:24.148
    Nov 12 00:47:24.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:47:24.15
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:47:24.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:47:24.218
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-5777 11/12/22 00:47:24.232
    Nov 12 00:47:24.264: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-5777" to be "running and ready"
    Nov 12 00:47:24.277: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 12.514905ms
    Nov 12 00:47:24.277: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:47:26.321: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.056778622s
    Nov 12 00:47:26.321: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 12 00:47:26.321: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 12 00:47:26.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 12 00:47:26.716: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 12 00:47:26.716: INFO: stdout: "iptables"
    Nov 12 00:47:26.716: INFO: proxyMode: iptables
    Nov 12 00:47:26.744: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 12 00:47:26.757: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-5777 11/12/22 00:47:26.757
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-5777 11/12/22 00:47:26.8
    I1112 00:47:26.819768      21 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5777, replica count: 3
    I1112 00:47:29.870771      21 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 00:47:29.898: INFO: Creating new exec pod
    Nov 12 00:47:29.915: INFO: Waiting up to 5m0s for pod "execpod-affinityt5bjx" in namespace "services-5777" to be "running"
    Nov 12 00:47:29.931: INFO: Pod "execpod-affinityt5bjx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.086674ms
    Nov 12 00:47:31.947: INFO: Pod "execpod-affinityt5bjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03183552s
    Nov 12 00:47:33.953: INFO: Pod "execpod-affinityt5bjx": Phase="Running", Reason="", readiness=true. Elapsed: 4.037973667s
    Nov 12 00:47:33.953: INFO: Pod "execpod-affinityt5bjx" satisfied condition "running"
    Nov 12 00:47:34.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov 12 00:47:35.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Nov 12 00:47:35.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:47:35.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.199.245 80'
    Nov 12 00:47:35.765: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.199.245 80\nConnection to 172.21.199.245 80 port [tcp/http] succeeded!\n"
    Nov 12 00:47:35.765: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:47:35.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.21.199.245:80/ ; done'
    Nov 12 00:47:36.331: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
    Nov 12 00:47:36.331: INFO: stdout: "\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx\naffinity-clusterip-timeout-hmqdx"
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.331: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Received response from host: affinity-clusterip-timeout-hmqdx
    Nov 12 00:47:36.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.199.245:80/'
    Nov 12 00:47:36.759: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
    Nov 12 00:47:36.759: INFO: stdout: "affinity-clusterip-timeout-hmqdx"
    Nov 12 00:47:56.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5777 exec execpod-affinityt5bjx -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.21.199.245:80/'
    Nov 12 00:47:57.190: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.21.199.245:80/\n"
    Nov 12 00:47:57.190: INFO: stdout: "affinity-clusterip-timeout-lzpv8"
    Nov 12 00:47:57.190: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5777, will wait for the garbage collector to delete the pods 11/12/22 00:47:57.232
    Nov 12 00:47:57.319: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 21.354971ms
    Nov 12 00:47:57.437: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 118.041741ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:48:00.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5777" for this suite. 11/12/22 00:48:00.548
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:00.659
Nov 12 00:48:00.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:48:00.661
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:00.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:00.773
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-2504 11/12/22 00:48:00.79
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[] 11/12/22 00:48:00.826
Nov 12 00:48:00.866: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2504 11/12/22 00:48:00.866
Nov 12 00:48:00.907: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2504" to be "running and ready"
Nov 12 00:48:00.921: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.317942ms
Nov 12 00:48:00.921: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:02.938: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03053392s
Nov 12 00:48:02.938: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:04.937: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.029664253s
Nov 12 00:48:04.937: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 12 00:48:04.937: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod1:[80]] 11/12/22 00:48:04.95
Nov 12 00:48:05.004: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 11/12/22 00:48:05.004
Nov 12 00:48:05.005: INFO: Creating new exec pod
Nov 12 00:48:05.022: INFO: Waiting up to 5m0s for pod "execpodk5zmj" in namespace "services-2504" to be "running"
Nov 12 00:48:05.034: INFO: Pod "execpodk5zmj": Phase="Pending", Reason="", readiness=false. Elapsed: 11.896405ms
Nov 12 00:48:07.048: INFO: Pod "execpodk5zmj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026229448s
Nov 12 00:48:09.051: INFO: Pod "execpodk5zmj": Phase="Running", Reason="", readiness=true. Elapsed: 4.029059959s
Nov 12 00:48:09.051: INFO: Pod "execpodk5zmj" satisfied condition "running"
Nov 12 00:48:10.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 00:48:10.458: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:10.458: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:48:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
Nov 12 00:48:10.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:10.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-2504 11/12/22 00:48:10.897
Nov 12 00:48:10.919: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2504" to be "running and ready"
Nov 12 00:48:10.930: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.282789ms
Nov 12 00:48:10.931: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:12.944: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024515863s
Nov 12 00:48:12.944: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:14.952: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032474656s
Nov 12 00:48:14.952: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 12 00:48:14.952: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod1:[80] pod2:[80]] 11/12/22 00:48:14.965
Nov 12 00:48:15.030: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 11/12/22 00:48:15.03
Nov 12 00:48:16.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 00:48:16.432: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:16.432: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:48:16.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
Nov 12 00:48:16.911: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:16.911: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2504 11/12/22 00:48:16.911
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod2:[80]] 11/12/22 00:48:16.94
Nov 12 00:48:16.997: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 11/12/22 00:48:16.997
Nov 12 00:48:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 00:48:19.482: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:19.482: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:48:19.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
Nov 12 00:48:19.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
Nov 12 00:48:19.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-2504 11/12/22 00:48:19.871
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[] 11/12/22 00:48:19.9
Nov 12 00:48:19.947: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:48:20.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2504" for this suite. 11/12/22 00:48:20.071
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":298,"skipped":5595,"failed":0}
------------------------------
• [SLOW TEST] [19.469 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:00.659
    Nov 12 00:48:00.660: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:48:00.661
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:00.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:00.773
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-2504 11/12/22 00:48:00.79
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[] 11/12/22 00:48:00.826
    Nov 12 00:48:00.866: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2504 11/12/22 00:48:00.866
    Nov 12 00:48:00.907: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2504" to be "running and ready"
    Nov 12 00:48:00.921: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.317942ms
    Nov 12 00:48:00.921: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:02.938: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03053392s
    Nov 12 00:48:02.938: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:04.937: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.029664253s
    Nov 12 00:48:04.937: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 12 00:48:04.937: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod1:[80]] 11/12/22 00:48:04.95
    Nov 12 00:48:05.004: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 11/12/22 00:48:05.004
    Nov 12 00:48:05.005: INFO: Creating new exec pod
    Nov 12 00:48:05.022: INFO: Waiting up to 5m0s for pod "execpodk5zmj" in namespace "services-2504" to be "running"
    Nov 12 00:48:05.034: INFO: Pod "execpodk5zmj": Phase="Pending", Reason="", readiness=false. Elapsed: 11.896405ms
    Nov 12 00:48:07.048: INFO: Pod "execpodk5zmj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026229448s
    Nov 12 00:48:09.051: INFO: Pod "execpodk5zmj": Phase="Running", Reason="", readiness=true. Elapsed: 4.029059959s
    Nov 12 00:48:09.051: INFO: Pod "execpodk5zmj" satisfied condition "running"
    Nov 12 00:48:10.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 00:48:10.458: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:10.458: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:48:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
    Nov 12 00:48:10.897: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:10.897: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-2504 11/12/22 00:48:10.897
    Nov 12 00:48:10.919: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2504" to be "running and ready"
    Nov 12 00:48:10.930: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.282789ms
    Nov 12 00:48:10.931: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:12.944: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024515863s
    Nov 12 00:48:12.944: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:14.952: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032474656s
    Nov 12 00:48:14.952: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 12 00:48:14.952: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod1:[80] pod2:[80]] 11/12/22 00:48:14.965
    Nov 12 00:48:15.030: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 11/12/22 00:48:15.03
    Nov 12 00:48:16.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 00:48:16.432: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:16.432: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:48:16.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
    Nov 12 00:48:16.911: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:16.911: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2504 11/12/22 00:48:16.911
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[pod2:[80]] 11/12/22 00:48:16.94
    Nov 12 00:48:16.997: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 11/12/22 00:48:16.997
    Nov 12 00:48:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 00:48:19.482: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:19.482: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:48:19.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-2504 exec execpodk5zmj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.200.153 80'
    Nov 12 00:48:19.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.200.153 80\nConnection to 172.21.200.153 80 port [tcp/http] succeeded!\n"
    Nov 12 00:48:19.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-2504 11/12/22 00:48:19.871
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2504 to expose endpoints map[] 11/12/22 00:48:19.9
    Nov 12 00:48:19.947: INFO: successfully validated that service endpoint-test2 in namespace services-2504 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:48:20.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2504" for this suite. 11/12/22 00:48:20.071
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:20.131
Nov 12 00:48:20.131: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:48:20.133
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:20.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:20.206
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 00:48:20.222
Nov 12 00:48:20.252: INFO: Waiting up to 5m0s for pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588" in namespace "emptydir-459" to be "Succeeded or Failed"
Nov 12 00:48:20.264: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 12.575802ms
Nov 12 00:48:22.292: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040137523s
Nov 12 00:48:24.279: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027734102s
Nov 12 00:48:26.277: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02520115s
STEP: Saw pod success 11/12/22 00:48:26.277
Nov 12 00:48:26.277: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588" satisfied condition "Succeeded or Failed"
Nov 12 00:48:26.290: INFO: Trying to get logs from node 10.184.98.55 pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 container test-container: <nil>
STEP: delete the pod 11/12/22 00:48:26.32
Nov 12 00:48:26.378: INFO: Waiting for pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 to disappear
Nov 12 00:48:26.392: INFO: Pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:48:26.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-459" for this suite. 11/12/22 00:48:26.419
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":299,"skipped":5618,"failed":0}
------------------------------
• [SLOW TEST] [6.314 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:20.131
    Nov 12 00:48:20.131: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:48:20.133
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:20.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:20.206
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 00:48:20.222
    Nov 12 00:48:20.252: INFO: Waiting up to 5m0s for pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588" in namespace "emptydir-459" to be "Succeeded or Failed"
    Nov 12 00:48:20.264: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 12.575802ms
    Nov 12 00:48:22.292: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040137523s
    Nov 12 00:48:24.279: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027734102s
    Nov 12 00:48:26.277: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02520115s
    STEP: Saw pod success 11/12/22 00:48:26.277
    Nov 12 00:48:26.277: INFO: Pod "pod-e169a886-4f07-4e08-9896-3e6eb4c79588" satisfied condition "Succeeded or Failed"
    Nov 12 00:48:26.290: INFO: Trying to get logs from node 10.184.98.55 pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 container test-container: <nil>
    STEP: delete the pod 11/12/22 00:48:26.32
    Nov 12 00:48:26.378: INFO: Waiting for pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 to disappear
    Nov 12 00:48:26.392: INFO: Pod pod-e169a886-4f07-4e08-9896-3e6eb4c79588 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:48:26.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-459" for this suite. 11/12/22 00:48:26.419
  << End Captured GinkgoWriter Output
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:26.447
Nov 12 00:48:26.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename conformance-tests 11/12/22 00:48:26.45
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:26.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:26.61
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 11/12/22 00:48:26.626
Nov 12 00:48:26.627: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Nov 12 00:48:26.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-7054" for this suite. 11/12/22 00:48:26.704
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":300,"skipped":5618,"failed":0}
------------------------------
• [0.284 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:26.447
    Nov 12 00:48:26.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename conformance-tests 11/12/22 00:48:26.45
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:26.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:26.61
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 11/12/22 00:48:26.626
    Nov 12 00:48:26.627: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Nov 12 00:48:26.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-7054" for this suite. 11/12/22 00:48:26.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:26.743
Nov 12 00:48:26.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename watch 11/12/22 00:48:26.745
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:26.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:26.839
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 11/12/22 00:48:26.853
STEP: modifying the configmap once 11/12/22 00:48:26.877
STEP: modifying the configmap a second time 11/12/22 00:48:26.92
STEP: deleting the configmap 11/12/22 00:48:26.958
STEP: creating a watch on configmaps from the resource version returned by the first update 11/12/22 00:48:26.987
STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/12/22 00:48:26.993
Nov 12 00:48:26.993: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6071  799c6daf-1483-474d-8cee-e736ed24e74f 44823 0 2022-11-12 00:48:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 00:48:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 00:48:26.994: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6071  799c6daf-1483-474d-8cee-e736ed24e74f 44824 0 2022-11-12 00:48:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 00:48:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 00:48:26.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6071" for this suite. 11/12/22 00:48:27.019
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":301,"skipped":5678,"failed":0}
------------------------------
• [0.335 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:26.743
    Nov 12 00:48:26.743: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename watch 11/12/22 00:48:26.745
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:26.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:26.839
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 11/12/22 00:48:26.853
    STEP: modifying the configmap once 11/12/22 00:48:26.877
    STEP: modifying the configmap a second time 11/12/22 00:48:26.92
    STEP: deleting the configmap 11/12/22 00:48:26.958
    STEP: creating a watch on configmaps from the resource version returned by the first update 11/12/22 00:48:26.987
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/12/22 00:48:26.993
    Nov 12 00:48:26.993: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6071  799c6daf-1483-474d-8cee-e736ed24e74f 44823 0 2022-11-12 00:48:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 00:48:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 00:48:26.994: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6071  799c6daf-1483-474d-8cee-e736ed24e74f 44824 0 2022-11-12 00:48:26 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 00:48:26 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 00:48:26.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6071" for this suite. 11/12/22 00:48:27.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:27.101
Nov 12 00:48:27.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename proxy 11/12/22 00:48:27.103
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:27.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:27.263
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 11/12/22 00:48:27.32
STEP: creating replication controller proxy-service-7x9tk in namespace proxy-2016 11/12/22 00:48:27.329
I1112 00:48:27.351632      21 runners.go:193] Created replication controller with name: proxy-service-7x9tk, namespace: proxy-2016, replica count: 1
I1112 00:48:28.402496      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1112 00:48:29.402823      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1112 00:48:30.403969      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 00:48:30.422: INFO: setup took 3.144294543s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/12/22 00:48:30.422
Nov 12 00:48:30.516: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 91.702673ms)
Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 102.240336ms)
Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 104.036923ms)
Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 105.858944ms)
Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 103.922619ms)
Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 103.198028ms)
Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 105.006692ms)
Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 105.533621ms)
Nov 12 00:48:30.543: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 119.836718ms)
Nov 12 00:48:30.574: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 147.194465ms)
Nov 12 00:48:30.574: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 148.672305ms)
Nov 12 00:48:30.585: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 159.887798ms)
Nov 12 00:48:30.586: INFO: (0) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 163.633819ms)
Nov 12 00:48:30.586: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 162.289586ms)
Nov 12 00:48:30.587: INFO: (0) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 161.956712ms)
Nov 12 00:48:30.588: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 162.567277ms)
Nov 12 00:48:30.615: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 25.428771ms)
Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 38.677836ms)
Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 38.398891ms)
Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 38.838228ms)
Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 39.074608ms)
Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 59.447098ms)
Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 60.064903ms)
Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 59.395424ms)
Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 60.260818ms)
Nov 12 00:48:30.650: INFO: (1) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 61.390314ms)
Nov 12 00:48:30.655: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 66.306749ms)
Nov 12 00:48:30.667: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 78.047014ms)
Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 79.190926ms)
Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 79.742181ms)
Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 79.029006ms)
Nov 12 00:48:30.670: INFO: (1) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 80.625252ms)
Nov 12 00:48:30.708: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 37.406623ms)
Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 52.461254ms)
Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 51.812142ms)
Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 51.970294ms)
Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 52.02391ms)
Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 52.759791ms)
Nov 12 00:48:30.724: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 52.458188ms)
Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 57.738316ms)
Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 57.873631ms)
Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 57.583662ms)
Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 58.049797ms)
Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 57.90176ms)
Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 58.562927ms)
Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 59.087618ms)
Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 59.604976ms)
Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 59.684847ms)
Nov 12 00:48:30.753: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.942304ms)
Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.592921ms)
Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 23.073142ms)
Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.935214ms)
Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.308681ms)
Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.591849ms)
Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 24.558181ms)
Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.870343ms)
Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 25.679626ms)
Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 26.816246ms)
Nov 12 00:48:30.764: INFO: (3) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.911324ms)
Nov 12 00:48:30.769: INFO: (3) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.256821ms)
Nov 12 00:48:30.771: INFO: (3) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 39.397104ms)
Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 39.717116ms)
Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 40.925586ms)
Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 40.635476ms)
Nov 12 00:48:30.804: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 31.77396ms)
Nov 12 00:48:30.815: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 41.882931ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 42.032654ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 41.976145ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 42.637199ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 42.36297ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 42.40125ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 42.55542ms)
Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 42.804825ms)
Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 46.05375ms)
Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 45.203749ms)
Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 45.4077ms)
Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 46.082093ms)
Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 45.932394ms)
Nov 12 00:48:30.820: INFO: (4) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 46.501742ms)
Nov 12 00:48:30.820: INFO: (4) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 47.114791ms)
Nov 12 00:48:30.838: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 16.790664ms)
Nov 12 00:48:30.842: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.450364ms)
Nov 12 00:48:30.842: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.446345ms)
Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.908844ms)
Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.735347ms)
Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.666744ms)
Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.927027ms)
Nov 12 00:48:30.844: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.038076ms)
Nov 12 00:48:30.845: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.047177ms)
Nov 12 00:48:30.846: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 24.874554ms)
Nov 12 00:48:30.848: INFO: (5) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 27.284976ms)
Nov 12 00:48:30.854: INFO: (5) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 33.224797ms)
Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 37.307455ms)
Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.369154ms)
Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 37.985092ms)
Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 38.22233ms)
Nov 12 00:48:30.877: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 17.674877ms)
Nov 12 00:48:30.879: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 19.451301ms)
Nov 12 00:48:30.882: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.691557ms)
Nov 12 00:48:30.883: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.247709ms)
Nov 12 00:48:30.885: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 25.288446ms)
Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.534678ms)
Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.148236ms)
Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 26.056017ms)
Nov 12 00:48:30.887: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 26.544155ms)
Nov 12 00:48:30.887: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 27.155116ms)
Nov 12 00:48:30.888: INFO: (6) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 28.643331ms)
Nov 12 00:48:30.892: INFO: (6) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 32.353109ms)
Nov 12 00:48:30.900: INFO: (6) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 39.297751ms)
Nov 12 00:48:30.903: INFO: (6) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 43.702143ms)
Nov 12 00:48:30.904: INFO: (6) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 44.330235ms)
Nov 12 00:48:30.904: INFO: (6) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 44.584767ms)
Nov 12 00:48:30.924: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 18.916929ms)
Nov 12 00:48:30.924: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 18.404021ms)
Nov 12 00:48:30.926: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 19.239836ms)
Nov 12 00:48:30.926: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.188986ms)
Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 20.79448ms)
Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.354865ms)
Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.179523ms)
Nov 12 00:48:30.928: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.858527ms)
Nov 12 00:48:30.928: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.746267ms)
Nov 12 00:48:30.930: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.460344ms)
Nov 12 00:48:30.931: INFO: (7) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 26.690478ms)
Nov 12 00:48:30.938: INFO: (7) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.792111ms)
Nov 12 00:48:30.939: INFO: (7) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 33.873891ms)
Nov 12 00:48:30.939: INFO: (7) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 33.69947ms)
Nov 12 00:48:30.942: INFO: (7) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 36.062674ms)
Nov 12 00:48:30.943: INFO: (7) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.415797ms)
Nov 12 00:48:30.963: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.123496ms)
Nov 12 00:48:30.964: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 19.809465ms)
Nov 12 00:48:30.964: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.349248ms)
Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.800964ms)
Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.654521ms)
Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 23.698467ms)
Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 26.150537ms)
Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 26.457881ms)
Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 26.378882ms)
Nov 12 00:48:30.971: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.746844ms)
Nov 12 00:48:30.975: INFO: (8) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 31.428853ms)
Nov 12 00:48:30.983: INFO: (8) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 39.277809ms)
Nov 12 00:48:30.983: INFO: (8) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 39.055637ms)
Nov 12 00:48:30.985: INFO: (8) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 41.914746ms)
Nov 12 00:48:30.986: INFO: (8) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 42.046499ms)
Nov 12 00:48:30.987: INFO: (8) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 43.693157ms)
Nov 12 00:48:31.004: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.447323ms)
Nov 12 00:48:31.007: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 18.781695ms)
Nov 12 00:48:31.008: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 20.401825ms)
Nov 12 00:48:31.009: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 20.826119ms)
Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.148032ms)
Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.936868ms)
Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.635644ms)
Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.471604ms)
Nov 12 00:48:31.011: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 22.567409ms)
Nov 12 00:48:31.011: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 22.649884ms)
Nov 12 00:48:31.015: INFO: (9) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 26.912468ms)
Nov 12 00:48:31.023: INFO: (9) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 34.963691ms)
Nov 12 00:48:31.024: INFO: (9) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.135937ms)
Nov 12 00:48:31.024: INFO: (9) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 36.473201ms)
Nov 12 00:48:31.026: INFO: (9) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 37.989774ms)
Nov 12 00:48:31.026: INFO: (9) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.710049ms)
Nov 12 00:48:31.043: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 16.507622ms)
Nov 12 00:48:31.047: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.218872ms)
Nov 12 00:48:31.048: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.74261ms)
Nov 12 00:48:31.048: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.607936ms)
Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.982472ms)
Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 22.640203ms)
Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.099446ms)
Nov 12 00:48:31.050: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.039297ms)
Nov 12 00:48:31.051: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 23.891276ms)
Nov 12 00:48:31.051: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 24.663977ms)
Nov 12 00:48:31.053: INFO: (10) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 26.563078ms)
Nov 12 00:48:31.062: INFO: (10) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 35.155846ms)
Nov 12 00:48:31.066: INFO: (10) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.057835ms)
Nov 12 00:48:31.068: INFO: (10) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 42.071555ms)
Nov 12 00:48:31.069: INFO: (10) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 42.009574ms)
Nov 12 00:48:31.069: INFO: (10) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.789054ms)
Nov 12 00:48:31.086: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.557453ms)
Nov 12 00:48:31.091: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.508135ms)
Nov 12 00:48:31.093: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.542411ms)
Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 24.725394ms)
Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 24.834659ms)
Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.041554ms)
Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.099389ms)
Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 25.046396ms)
Nov 12 00:48:31.096: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 25.644831ms)
Nov 12 00:48:31.096: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 25.855368ms)
Nov 12 00:48:31.098: INFO: (11) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 27.694541ms)
Nov 12 00:48:31.101: INFO: (11) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 31.346629ms)
Nov 12 00:48:31.103: INFO: (11) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.949988ms)
Nov 12 00:48:31.105: INFO: (11) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 34.757186ms)
Nov 12 00:48:31.106: INFO: (11) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 35.516033ms)
Nov 12 00:48:31.107: INFO: (11) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 36.542832ms)
Nov 12 00:48:31.124: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.575822ms)
Nov 12 00:48:31.129: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.433005ms)
Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.26296ms)
Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.589554ms)
Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.01561ms)
Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 23.16528ms)
Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 23.308589ms)
Nov 12 00:48:31.133: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.746671ms)
Nov 12 00:48:31.133: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 26.310625ms)
Nov 12 00:48:31.134: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 26.166368ms)
Nov 12 00:48:31.134: INFO: (12) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 27.045894ms)
Nov 12 00:48:31.143: INFO: (12) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 35.238281ms)
Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 38.880891ms)
Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 40.150556ms)
Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.618015ms)
Nov 12 00:48:31.148: INFO: (12) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 40.685759ms)
Nov 12 00:48:31.168: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.007268ms)
Nov 12 00:48:31.168: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 19.120834ms)
Nov 12 00:48:31.169: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.637248ms)
Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.6754ms)
Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.931774ms)
Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.265236ms)
Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.324405ms)
Nov 12 00:48:31.172: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.663605ms)
Nov 12 00:48:31.173: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.019518ms)
Nov 12 00:48:31.173: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.878044ms)
Nov 12 00:48:31.176: INFO: (13) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 26.377627ms)
Nov 12 00:48:31.183: INFO: (13) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 32.768599ms)
Nov 12 00:48:31.185: INFO: (13) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 36.177253ms)
Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 36.393048ms)
Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.676125ms)
Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.260818ms)
Nov 12 00:48:31.203: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 16.667731ms)
Nov 12 00:48:31.207: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.445604ms)
Nov 12 00:48:31.208: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.736045ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.369467ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.786124ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.587938ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.118983ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.529557ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 22.178709ms)
Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.309587ms)
Nov 12 00:48:31.214: INFO: (14) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 27.176142ms)
Nov 12 00:48:31.221: INFO: (14) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 34.440171ms)
Nov 12 00:48:31.224: INFO: (14) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.435113ms)
Nov 12 00:48:31.225: INFO: (14) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 37.979107ms)
Nov 12 00:48:31.225: INFO: (14) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 37.969828ms)
Nov 12 00:48:31.226: INFO: (14) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 39.11399ms)
Nov 12 00:48:31.245: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 18.962784ms)
Nov 12 00:48:31.248: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 22.424935ms)
Nov 12 00:48:31.248: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.08379ms)
Nov 12 00:48:31.249: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.645549ms)
Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.071214ms)
Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.821054ms)
Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.166884ms)
Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 24.142547ms)
Nov 12 00:48:31.252: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.75275ms)
Nov 12 00:48:31.252: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 24.72784ms)
Nov 12 00:48:31.255: INFO: (15) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 29.225106ms)
Nov 12 00:48:31.262: INFO: (15) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 35.424175ms)
Nov 12 00:48:31.265: INFO: (15) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 38.488328ms)
Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.038467ms)
Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 39.330744ms)
Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.751635ms)
Nov 12 00:48:31.284: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 18.56835ms)
Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 20.605386ms)
Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.53895ms)
Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.76192ms)
Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.348852ms)
Nov 12 00:48:31.289: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.776842ms)
Nov 12 00:48:31.289: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.980867ms)
Nov 12 00:48:31.290: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.802235ms)
Nov 12 00:48:31.291: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 24.351928ms)
Nov 12 00:48:31.292: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.367955ms)
Nov 12 00:48:31.294: INFO: (16) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 26.958228ms)
Nov 12 00:48:31.301: INFO: (16) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 33.648824ms)
Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.472855ms)
Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 37.557501ms)
Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 38.042667ms)
Nov 12 00:48:31.306: INFO: (16) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 38.446298ms)
Nov 12 00:48:31.323: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 16.219297ms)
Nov 12 00:48:31.327: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.012455ms)
Nov 12 00:48:31.327: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.517696ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.689249ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.879674ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 21.48104ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.100548ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.128347ms)
Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.453839ms)
Nov 12 00:48:31.329: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.819669ms)
Nov 12 00:48:31.337: INFO: (17) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 30.41069ms)
Nov 12 00:48:31.342: INFO: (17) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 34.526052ms)
Nov 12 00:48:31.347: INFO: (17) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.213348ms)
Nov 12 00:48:31.347: INFO: (17) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.988131ms)
Nov 12 00:48:31.348: INFO: (17) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 40.500253ms)
Nov 12 00:48:31.348: INFO: (17) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 40.445354ms)
Nov 12 00:48:31.366: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 17.076848ms)
Nov 12 00:48:31.369: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.084003ms)
Nov 12 00:48:31.370: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.119479ms)
Nov 12 00:48:31.370: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.082303ms)
Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.374776ms)
Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.794534ms)
Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.522071ms)
Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.378418ms)
Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.721147ms)
Nov 12 00:48:31.372: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.659118ms)
Nov 12 00:48:31.379: INFO: (18) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 30.651995ms)
Nov 12 00:48:31.388: INFO: (18) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 38.885279ms)
Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 41.961709ms)
Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.664216ms)
Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 41.834513ms)
Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 42.399934ms)
Nov 12 00:48:31.411: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 18.393883ms)
Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 25.003867ms)
Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 24.668701ms)
Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.272262ms)
Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.335904ms)
Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.990228ms)
Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 26.117949ms)
Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 26.52067ms)
Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 26.100225ms)
Nov 12 00:48:31.428: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 35.080367ms)
Nov 12 00:48:31.435: INFO: (19) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 42.313827ms)
Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.631253ms)
Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 42.953362ms)
Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 43.156414ms)
Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 43.212369ms)
Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 42.655613ms)
STEP: deleting ReplicationController proxy-service-7x9tk in namespace proxy-2016, will wait for the garbage collector to delete the pods 11/12/22 00:48:31.436
Nov 12 00:48:31.523: INFO: Deleting ReplicationController proxy-service-7x9tk took: 22.452453ms
Nov 12 00:48:31.623: INFO: Terminating ReplicationController proxy-service-7x9tk pods took: 100.369017ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 00:48:33.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2016" for this suite. 11/12/22 00:48:33.751
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":302,"skipped":5718,"failed":0}
------------------------------
• [SLOW TEST] [6.674 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:27.101
    Nov 12 00:48:27.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename proxy 11/12/22 00:48:27.103
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:27.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:27.263
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 11/12/22 00:48:27.32
    STEP: creating replication controller proxy-service-7x9tk in namespace proxy-2016 11/12/22 00:48:27.329
    I1112 00:48:27.351632      21 runners.go:193] Created replication controller with name: proxy-service-7x9tk, namespace: proxy-2016, replica count: 1
    I1112 00:48:28.402496      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1112 00:48:29.402823      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I1112 00:48:30.403969      21 runners.go:193] proxy-service-7x9tk Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 00:48:30.422: INFO: setup took 3.144294543s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/12/22 00:48:30.422
    Nov 12 00:48:30.516: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 91.702673ms)
    Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 102.240336ms)
    Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 104.036923ms)
    Nov 12 00:48:30.528: INFO: (0) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 105.858944ms)
    Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 103.922619ms)
    Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 103.198028ms)
    Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 105.006692ms)
    Nov 12 00:48:30.529: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 105.533621ms)
    Nov 12 00:48:30.543: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 119.836718ms)
    Nov 12 00:48:30.574: INFO: (0) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 147.194465ms)
    Nov 12 00:48:30.574: INFO: (0) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 148.672305ms)
    Nov 12 00:48:30.585: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 159.887798ms)
    Nov 12 00:48:30.586: INFO: (0) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 163.633819ms)
    Nov 12 00:48:30.586: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 162.289586ms)
    Nov 12 00:48:30.587: INFO: (0) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 161.956712ms)
    Nov 12 00:48:30.588: INFO: (0) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 162.567277ms)
    Nov 12 00:48:30.615: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 25.428771ms)
    Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 38.677836ms)
    Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 38.398891ms)
    Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 38.838228ms)
    Nov 12 00:48:30.628: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 39.074608ms)
    Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 59.447098ms)
    Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 60.064903ms)
    Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 59.395424ms)
    Nov 12 00:48:30.649: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 60.260818ms)
    Nov 12 00:48:30.650: INFO: (1) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 61.390314ms)
    Nov 12 00:48:30.655: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 66.306749ms)
    Nov 12 00:48:30.667: INFO: (1) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 78.047014ms)
    Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 79.190926ms)
    Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 79.742181ms)
    Nov 12 00:48:30.668: INFO: (1) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 79.029006ms)
    Nov 12 00:48:30.670: INFO: (1) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 80.625252ms)
    Nov 12 00:48:30.708: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 37.406623ms)
    Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 52.461254ms)
    Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 51.812142ms)
    Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 51.970294ms)
    Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 52.02391ms)
    Nov 12 00:48:30.723: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 52.759791ms)
    Nov 12 00:48:30.724: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 52.458188ms)
    Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 57.738316ms)
    Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 57.873631ms)
    Nov 12 00:48:30.728: INFO: (2) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 57.583662ms)
    Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 58.049797ms)
    Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 57.90176ms)
    Nov 12 00:48:30.729: INFO: (2) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 58.562927ms)
    Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 59.087618ms)
    Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 59.604976ms)
    Nov 12 00:48:30.730: INFO: (2) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 59.684847ms)
    Nov 12 00:48:30.753: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.942304ms)
    Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.592921ms)
    Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 23.073142ms)
    Nov 12 00:48:30.754: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.935214ms)
    Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.308681ms)
    Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.591849ms)
    Nov 12 00:48:30.756: INFO: (3) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 24.558181ms)
    Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.870343ms)
    Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 25.679626ms)
    Nov 12 00:48:30.757: INFO: (3) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 26.816246ms)
    Nov 12 00:48:30.764: INFO: (3) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.911324ms)
    Nov 12 00:48:30.769: INFO: (3) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.256821ms)
    Nov 12 00:48:30.771: INFO: (3) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 39.397104ms)
    Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 39.717116ms)
    Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 40.925586ms)
    Nov 12 00:48:30.772: INFO: (3) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 40.635476ms)
    Nov 12 00:48:30.804: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 31.77396ms)
    Nov 12 00:48:30.815: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 41.882931ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 42.032654ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 41.976145ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 42.637199ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 42.36297ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 42.40125ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 42.55542ms)
    Nov 12 00:48:30.816: INFO: (4) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 42.804825ms)
    Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 46.05375ms)
    Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 45.203749ms)
    Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 45.4077ms)
    Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 46.082093ms)
    Nov 12 00:48:30.819: INFO: (4) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 45.932394ms)
    Nov 12 00:48:30.820: INFO: (4) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 46.501742ms)
    Nov 12 00:48:30.820: INFO: (4) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 47.114791ms)
    Nov 12 00:48:30.838: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 16.790664ms)
    Nov 12 00:48:30.842: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.450364ms)
    Nov 12 00:48:30.842: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.446345ms)
    Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.908844ms)
    Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.735347ms)
    Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.666744ms)
    Nov 12 00:48:30.843: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.927027ms)
    Nov 12 00:48:30.844: INFO: (5) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.038076ms)
    Nov 12 00:48:30.845: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.047177ms)
    Nov 12 00:48:30.846: INFO: (5) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 24.874554ms)
    Nov 12 00:48:30.848: INFO: (5) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 27.284976ms)
    Nov 12 00:48:30.854: INFO: (5) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 33.224797ms)
    Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 37.307455ms)
    Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.369154ms)
    Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 37.985092ms)
    Nov 12 00:48:30.859: INFO: (5) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 38.22233ms)
    Nov 12 00:48:30.877: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 17.674877ms)
    Nov 12 00:48:30.879: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 19.451301ms)
    Nov 12 00:48:30.882: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.691557ms)
    Nov 12 00:48:30.883: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.247709ms)
    Nov 12 00:48:30.885: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 25.288446ms)
    Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.534678ms)
    Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.148236ms)
    Nov 12 00:48:30.886: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 26.056017ms)
    Nov 12 00:48:30.887: INFO: (6) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 26.544155ms)
    Nov 12 00:48:30.887: INFO: (6) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 27.155116ms)
    Nov 12 00:48:30.888: INFO: (6) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 28.643331ms)
    Nov 12 00:48:30.892: INFO: (6) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 32.353109ms)
    Nov 12 00:48:30.900: INFO: (6) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 39.297751ms)
    Nov 12 00:48:30.903: INFO: (6) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 43.702143ms)
    Nov 12 00:48:30.904: INFO: (6) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 44.330235ms)
    Nov 12 00:48:30.904: INFO: (6) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 44.584767ms)
    Nov 12 00:48:30.924: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 18.916929ms)
    Nov 12 00:48:30.924: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 18.404021ms)
    Nov 12 00:48:30.926: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 19.239836ms)
    Nov 12 00:48:30.926: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.188986ms)
    Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 20.79448ms)
    Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.354865ms)
    Nov 12 00:48:30.927: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.179523ms)
    Nov 12 00:48:30.928: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.858527ms)
    Nov 12 00:48:30.928: INFO: (7) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.746267ms)
    Nov 12 00:48:30.930: INFO: (7) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.460344ms)
    Nov 12 00:48:30.931: INFO: (7) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 26.690478ms)
    Nov 12 00:48:30.938: INFO: (7) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.792111ms)
    Nov 12 00:48:30.939: INFO: (7) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 33.873891ms)
    Nov 12 00:48:30.939: INFO: (7) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 33.69947ms)
    Nov 12 00:48:30.942: INFO: (7) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 36.062674ms)
    Nov 12 00:48:30.943: INFO: (7) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.415797ms)
    Nov 12 00:48:30.963: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.123496ms)
    Nov 12 00:48:30.964: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 19.809465ms)
    Nov 12 00:48:30.964: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.349248ms)
    Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.800964ms)
    Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.654521ms)
    Nov 12 00:48:30.967: INFO: (8) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 23.698467ms)
    Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 26.150537ms)
    Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 26.457881ms)
    Nov 12 00:48:30.970: INFO: (8) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 26.378882ms)
    Nov 12 00:48:30.971: INFO: (8) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.746844ms)
    Nov 12 00:48:30.975: INFO: (8) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 31.428853ms)
    Nov 12 00:48:30.983: INFO: (8) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 39.277809ms)
    Nov 12 00:48:30.983: INFO: (8) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 39.055637ms)
    Nov 12 00:48:30.985: INFO: (8) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 41.914746ms)
    Nov 12 00:48:30.986: INFO: (8) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 42.046499ms)
    Nov 12 00:48:30.987: INFO: (8) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 43.693157ms)
    Nov 12 00:48:31.004: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.447323ms)
    Nov 12 00:48:31.007: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 18.781695ms)
    Nov 12 00:48:31.008: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 20.401825ms)
    Nov 12 00:48:31.009: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 20.826119ms)
    Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.148032ms)
    Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.936868ms)
    Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.635644ms)
    Nov 12 00:48:31.010: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.471604ms)
    Nov 12 00:48:31.011: INFO: (9) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 22.567409ms)
    Nov 12 00:48:31.011: INFO: (9) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 22.649884ms)
    Nov 12 00:48:31.015: INFO: (9) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 26.912468ms)
    Nov 12 00:48:31.023: INFO: (9) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 34.963691ms)
    Nov 12 00:48:31.024: INFO: (9) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.135937ms)
    Nov 12 00:48:31.024: INFO: (9) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 36.473201ms)
    Nov 12 00:48:31.026: INFO: (9) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 37.989774ms)
    Nov 12 00:48:31.026: INFO: (9) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.710049ms)
    Nov 12 00:48:31.043: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 16.507622ms)
    Nov 12 00:48:31.047: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.218872ms)
    Nov 12 00:48:31.048: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.74261ms)
    Nov 12 00:48:31.048: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.607936ms)
    Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.982472ms)
    Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 22.640203ms)
    Nov 12 00:48:31.049: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.099446ms)
    Nov 12 00:48:31.050: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.039297ms)
    Nov 12 00:48:31.051: INFO: (10) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 23.891276ms)
    Nov 12 00:48:31.051: INFO: (10) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 24.663977ms)
    Nov 12 00:48:31.053: INFO: (10) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 26.563078ms)
    Nov 12 00:48:31.062: INFO: (10) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 35.155846ms)
    Nov 12 00:48:31.066: INFO: (10) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.057835ms)
    Nov 12 00:48:31.068: INFO: (10) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 42.071555ms)
    Nov 12 00:48:31.069: INFO: (10) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 42.009574ms)
    Nov 12 00:48:31.069: INFO: (10) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.789054ms)
    Nov 12 00:48:31.086: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.557453ms)
    Nov 12 00:48:31.091: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.508135ms)
    Nov 12 00:48:31.093: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.542411ms)
    Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 24.725394ms)
    Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 24.834659ms)
    Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.041554ms)
    Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.099389ms)
    Nov 12 00:48:31.095: INFO: (11) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 25.046396ms)
    Nov 12 00:48:31.096: INFO: (11) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 25.644831ms)
    Nov 12 00:48:31.096: INFO: (11) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 25.855368ms)
    Nov 12 00:48:31.098: INFO: (11) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 27.694541ms)
    Nov 12 00:48:31.101: INFO: (11) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 31.346629ms)
    Nov 12 00:48:31.103: INFO: (11) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 31.949988ms)
    Nov 12 00:48:31.105: INFO: (11) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 34.757186ms)
    Nov 12 00:48:31.106: INFO: (11) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 35.516033ms)
    Nov 12 00:48:31.107: INFO: (11) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 36.542832ms)
    Nov 12 00:48:31.124: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 16.575822ms)
    Nov 12 00:48:31.129: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.433005ms)
    Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 23.26296ms)
    Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.589554ms)
    Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.01561ms)
    Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 23.16528ms)
    Nov 12 00:48:31.131: INFO: (12) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 23.308589ms)
    Nov 12 00:48:31.133: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.746671ms)
    Nov 12 00:48:31.133: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 26.310625ms)
    Nov 12 00:48:31.134: INFO: (12) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 26.166368ms)
    Nov 12 00:48:31.134: INFO: (12) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 27.045894ms)
    Nov 12 00:48:31.143: INFO: (12) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 35.238281ms)
    Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 38.880891ms)
    Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 40.150556ms)
    Nov 12 00:48:31.147: INFO: (12) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.618015ms)
    Nov 12 00:48:31.148: INFO: (12) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 40.685759ms)
    Nov 12 00:48:31.168: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.007268ms)
    Nov 12 00:48:31.168: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 19.120834ms)
    Nov 12 00:48:31.169: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.637248ms)
    Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.6754ms)
    Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.931774ms)
    Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.265236ms)
    Nov 12 00:48:31.171: INFO: (13) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.324405ms)
    Nov 12 00:48:31.172: INFO: (13) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.663605ms)
    Nov 12 00:48:31.173: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.019518ms)
    Nov 12 00:48:31.173: INFO: (13) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 22.878044ms)
    Nov 12 00:48:31.176: INFO: (13) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 26.377627ms)
    Nov 12 00:48:31.183: INFO: (13) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 32.768599ms)
    Nov 12 00:48:31.185: INFO: (13) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 36.177253ms)
    Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 36.393048ms)
    Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 36.676125ms)
    Nov 12 00:48:31.186: INFO: (13) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.260818ms)
    Nov 12 00:48:31.203: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 16.667731ms)
    Nov 12 00:48:31.207: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.445604ms)
    Nov 12 00:48:31.208: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.736045ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.369467ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.786124ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.587938ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.118983ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.529557ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 22.178709ms)
    Nov 12 00:48:31.209: INFO: (14) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.309587ms)
    Nov 12 00:48:31.214: INFO: (14) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 27.176142ms)
    Nov 12 00:48:31.221: INFO: (14) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 34.440171ms)
    Nov 12 00:48:31.224: INFO: (14) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 37.435113ms)
    Nov 12 00:48:31.225: INFO: (14) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 37.979107ms)
    Nov 12 00:48:31.225: INFO: (14) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 37.969828ms)
    Nov 12 00:48:31.226: INFO: (14) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 39.11399ms)
    Nov 12 00:48:31.245: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 18.962784ms)
    Nov 12 00:48:31.248: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 22.424935ms)
    Nov 12 00:48:31.248: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.08379ms)
    Nov 12 00:48:31.249: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 22.645549ms)
    Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 23.071214ms)
    Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.821054ms)
    Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 23.166884ms)
    Nov 12 00:48:31.250: INFO: (15) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 24.142547ms)
    Nov 12 00:48:31.252: INFO: (15) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 24.75275ms)
    Nov 12 00:48:31.252: INFO: (15) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 24.72784ms)
    Nov 12 00:48:31.255: INFO: (15) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 29.225106ms)
    Nov 12 00:48:31.262: INFO: (15) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 35.424175ms)
    Nov 12 00:48:31.265: INFO: (15) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 38.488328ms)
    Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.038467ms)
    Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 39.330744ms)
    Nov 12 00:48:31.266: INFO: (15) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.751635ms)
    Nov 12 00:48:31.284: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 18.56835ms)
    Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 20.605386ms)
    Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 20.53895ms)
    Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.76192ms)
    Nov 12 00:48:31.288: INFO: (16) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.348852ms)
    Nov 12 00:48:31.289: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.776842ms)
    Nov 12 00:48:31.289: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.980867ms)
    Nov 12 00:48:31.290: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 23.802235ms)
    Nov 12 00:48:31.291: INFO: (16) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 24.351928ms)
    Nov 12 00:48:31.292: INFO: (16) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.367955ms)
    Nov 12 00:48:31.294: INFO: (16) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 26.958228ms)
    Nov 12 00:48:31.301: INFO: (16) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 33.648824ms)
    Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 37.472855ms)
    Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 37.557501ms)
    Nov 12 00:48:31.305: INFO: (16) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 38.042667ms)
    Nov 12 00:48:31.306: INFO: (16) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 38.446298ms)
    Nov 12 00:48:31.323: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 16.219297ms)
    Nov 12 00:48:31.327: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 19.012455ms)
    Nov 12 00:48:31.327: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 20.517696ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 20.689249ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.879674ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 21.48104ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.100548ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 21.128347ms)
    Nov 12 00:48:31.328: INFO: (17) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.453839ms)
    Nov 12 00:48:31.329: INFO: (17) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.819669ms)
    Nov 12 00:48:31.337: INFO: (17) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 30.41069ms)
    Nov 12 00:48:31.342: INFO: (17) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 34.526052ms)
    Nov 12 00:48:31.347: INFO: (17) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 39.213348ms)
    Nov 12 00:48:31.347: INFO: (17) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 39.988131ms)
    Nov 12 00:48:31.348: INFO: (17) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 40.500253ms)
    Nov 12 00:48:31.348: INFO: (17) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 40.445354ms)
    Nov 12 00:48:31.366: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 17.076848ms)
    Nov 12 00:48:31.369: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.084003ms)
    Nov 12 00:48:31.370: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 21.119479ms)
    Nov 12 00:48:31.370: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 21.082303ms)
    Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 21.374776ms)
    Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.794534ms)
    Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 21.522071ms)
    Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 21.378418ms)
    Nov 12 00:48:31.371: INFO: (18) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 21.721147ms)
    Nov 12 00:48:31.372: INFO: (18) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 22.659118ms)
    Nov 12 00:48:31.379: INFO: (18) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 30.651995ms)
    Nov 12 00:48:31.388: INFO: (18) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 38.885279ms)
    Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 41.961709ms)
    Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.664216ms)
    Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 41.834513ms)
    Nov 12 00:48:31.391: INFO: (18) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 42.399934ms)
    Nov 12 00:48:31.411: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 18.393883ms)
    Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:443/proxy/tlsrewritem... (200; 25.003867ms)
    Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:160/proxy/: foo (200; 24.668701ms)
    Nov 12 00:48:31.418: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8/proxy/rewriteme">test</a> (200; 25.272262ms)
    Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:462/proxy/: tls qux (200; 26.335904ms)
    Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 25.990228ms)
    Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/https:proxy-service-7x9tk-kd2n8:460/proxy/: tls baz (200; 26.117949ms)
    Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:162/proxy/: bar (200; 26.52067ms)
    Nov 12 00:48:31.419: INFO: (19) /api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">test<... (200; 26.100225ms)
    Nov 12 00:48:31.428: INFO: (19) /api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/: <a href="/api/v1/namespaces/proxy-2016/pods/http:proxy-service-7x9tk-kd2n8:1080/proxy/rewriteme">... (200; 35.080367ms)
    Nov 12 00:48:31.435: INFO: (19) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname1/proxy/: foo (200; 42.313827ms)
    Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/proxy-service-7x9tk:portname2/proxy/: bar (200; 42.631253ms)
    Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname1/proxy/: foo (200; 42.953362ms)
    Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname1/proxy/: tls baz (200; 43.156414ms)
    Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/https:proxy-service-7x9tk:tlsportname2/proxy/: tls qux (200; 43.212369ms)
    Nov 12 00:48:31.436: INFO: (19) /api/v1/namespaces/proxy-2016/services/http:proxy-service-7x9tk:portname2/proxy/: bar (200; 42.655613ms)
    STEP: deleting ReplicationController proxy-service-7x9tk in namespace proxy-2016, will wait for the garbage collector to delete the pods 11/12/22 00:48:31.436
    Nov 12 00:48:31.523: INFO: Deleting ReplicationController proxy-service-7x9tk took: 22.452453ms
    Nov 12 00:48:31.623: INFO: Terminating ReplicationController proxy-service-7x9tk pods took: 100.369017ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 00:48:33.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-2016" for this suite. 11/12/22 00:48:33.751
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:33.779
Nov 12 00:48:33.780: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:48:33.78
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:33.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:33.844
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 00:48:33.857
Nov 12 00:48:33.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-1411 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Nov 12 00:48:34.039: INFO: stderr: ""
Nov 12 00:48:34.039: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 00:48:34.039
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Nov 12 00:48:34.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-1411 delete pods e2e-test-httpd-pod'
Nov 12 00:48:37.729: INFO: stderr: ""
Nov 12 00:48:37.729: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:48:37.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1411" for this suite. 11/12/22 00:48:37.755
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":303,"skipped":5723,"failed":0}
------------------------------
• [4.002 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:33.779
    Nov 12 00:48:33.780: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:48:33.78
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:33.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:33.844
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 00:48:33.857
    Nov 12 00:48:33.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-1411 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Nov 12 00:48:34.039: INFO: stderr: ""
    Nov 12 00:48:34.039: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 00:48:34.039
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Nov 12 00:48:34.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-1411 delete pods e2e-test-httpd-pod'
    Nov 12 00:48:37.729: INFO: stderr: ""
    Nov 12 00:48:37.729: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:48:37.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1411" for this suite. 11/12/22 00:48:37.755
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:37.783
Nov 12 00:48:37.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/12/22 00:48:37.786
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:37.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:37.85
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 11/12/22 00:48:37.86
STEP: Creating hostNetwork=false pod 11/12/22 00:48:37.861
Nov 12 00:48:37.892: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5175" to be "running and ready"
Nov 12 00:48:37.913: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.405267ms
Nov 12 00:48:37.914: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:39.933: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041166391s
Nov 12 00:48:39.933: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:41.939: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.046786213s
Nov 12 00:48:41.939: INFO: The phase of Pod test-pod is Running (Ready = true)
Nov 12 00:48:41.940: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 11/12/22 00:48:41.956
Nov 12 00:48:41.975: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5175" to be "running and ready"
Nov 12 00:48:41.991: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.958387ms
Nov 12 00:48:41.992: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:44.007: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.031636546s
Nov 12 00:48:44.007: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Nov 12 00:48:44.007: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 11/12/22 00:48:44.022
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/12/22 00:48:44.023
Nov 12 00:48:44.023: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:44.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:44.024: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:44.025: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 00:48:44.316: INFO: Exec stderr: ""
Nov 12 00:48:44.317: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:44.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:44.319: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:44.320: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 00:48:44.578: INFO: Exec stderr: ""
Nov 12 00:48:44.578: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:44.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:44.579: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:44.579: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 00:48:44.799: INFO: Exec stderr: ""
Nov 12 00:48:44.799: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:44.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:44.800: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:44.801: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 00:48:44.995: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/12/22 00:48:44.995
Nov 12 00:48:44.996: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:44.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:44.997: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:44.997: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 12 00:48:45.249: INFO: Exec stderr: ""
Nov 12 00:48:45.249: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:45.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:45.252: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:45.252: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 12 00:48:45.468: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/12/22 00:48:45.468
Nov 12 00:48:45.468: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:45.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:45.471: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:45.471: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 00:48:45.687: INFO: Exec stderr: ""
Nov 12 00:48:45.687: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:45.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:45.690: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:45.691: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 00:48:45.940: INFO: Exec stderr: ""
Nov 12 00:48:45.940: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:45.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:45.942: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:45.942: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 00:48:46.147: INFO: Exec stderr: ""
Nov 12 00:48:46.147: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:48:46.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:48:46.149: INFO: ExecWithOptions: Clientset creation
Nov 12 00:48:46.149: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 00:48:46.399: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Nov 12 00:48:46.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5175" for this suite. 11/12/22 00:48:46.412
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":304,"skipped":5728,"failed":0}
------------------------------
• [SLOW TEST] [8.655 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:37.783
    Nov 12 00:48:37.784: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/12/22 00:48:37.786
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:37.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:37.85
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 11/12/22 00:48:37.86
    STEP: Creating hostNetwork=false pod 11/12/22 00:48:37.861
    Nov 12 00:48:37.892: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-5175" to be "running and ready"
    Nov 12 00:48:37.913: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 21.405267ms
    Nov 12 00:48:37.914: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:39.933: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041166391s
    Nov 12 00:48:39.933: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:41.939: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.046786213s
    Nov 12 00:48:41.939: INFO: The phase of Pod test-pod is Running (Ready = true)
    Nov 12 00:48:41.940: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 11/12/22 00:48:41.956
    Nov 12 00:48:41.975: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-5175" to be "running and ready"
    Nov 12 00:48:41.991: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 15.958387ms
    Nov 12 00:48:41.992: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:44.007: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.031636546s
    Nov 12 00:48:44.007: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Nov 12 00:48:44.007: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 11/12/22 00:48:44.022
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/12/22 00:48:44.023
    Nov 12 00:48:44.023: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:44.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:44.024: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:44.025: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 00:48:44.316: INFO: Exec stderr: ""
    Nov 12 00:48:44.317: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:44.317: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:44.319: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:44.320: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 00:48:44.578: INFO: Exec stderr: ""
    Nov 12 00:48:44.578: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:44.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:44.579: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:44.579: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 00:48:44.799: INFO: Exec stderr: ""
    Nov 12 00:48:44.799: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:44.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:44.800: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:44.801: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 00:48:44.995: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/12/22 00:48:44.995
    Nov 12 00:48:44.996: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:44.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:44.997: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:44.997: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 12 00:48:45.249: INFO: Exec stderr: ""
    Nov 12 00:48:45.249: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:45.249: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:45.252: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:45.252: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 12 00:48:45.468: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/12/22 00:48:45.468
    Nov 12 00:48:45.468: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:45.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:45.471: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:45.471: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 00:48:45.687: INFO: Exec stderr: ""
    Nov 12 00:48:45.687: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:45.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:45.690: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:45.691: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 00:48:45.940: INFO: Exec stderr: ""
    Nov 12 00:48:45.940: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:45.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:45.942: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:45.942: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 00:48:46.147: INFO: Exec stderr: ""
    Nov 12 00:48:46.147: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5175 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:48:46.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:48:46.149: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:48:46.149: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-5175/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 00:48:46.399: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Nov 12 00:48:46.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-5175" for this suite. 11/12/22 00:48:46.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:46.462
Nov 12 00:48:46.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:48:46.464
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:46.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:46.521
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 11/12/22 00:48:46.531
Nov 12 00:48:46.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 12 00:48:46.739: INFO: stderr: ""
Nov 12 00:48:46.739: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 11/12/22 00:48:46.739
Nov 12 00:48:46.739: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 12 00:48:46.739: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8454" to be "running and ready, or succeeded"
Nov 12 00:48:46.755: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 15.684477ms
Nov 12 00:48:46.755: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.184.98.55' to be 'Running' but was 'Pending'
Nov 12 00:48:48.771: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031308796s
Nov 12 00:48:48.771: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.184.98.55' to be 'Running' but was 'Pending'
Nov 12 00:48:50.770: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.031068612s
Nov 12 00:48:50.771: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 12 00:48:50.771: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 11/12/22 00:48:50.771
Nov 12 00:48:50.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator'
Nov 12 00:48:51.011: INFO: stderr: ""
Nov 12 00:48:51.011: INFO: stdout: "I1112 00:48:48.446994       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/ch8 510\nI1112 00:48:48.647248       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/xmzl 451\nI1112 00:48:48.856322       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/sp6 428\nI1112 00:48:49.048430       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/lnk 381\nI1112 00:48:49.247698       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/vb2g 532\nI1112 00:48:49.447059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/qcm 231\nI1112 00:48:49.647700       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/469 397\nI1112 00:48:49.848080       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm2t 528\nI1112 00:48:50.047559       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/mvx8 417\nI1112 00:48:50.248052       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/m45 555\nI1112 00:48:50.447538       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fnc 226\nI1112 00:48:50.648051       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/gl5g 454\nI1112 00:48:50.847520       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/2rh 439\n"
STEP: limiting log lines 11/12/22 00:48:51.011
Nov 12 00:48:51.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --tail=1'
Nov 12 00:48:51.205: INFO: stderr: ""
Nov 12 00:48:51.205: INFO: stdout: "I1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\n"
Nov 12 00:48:51.205: INFO: got output "I1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\n"
STEP: limiting log bytes 11/12/22 00:48:51.205
Nov 12 00:48:51.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --limit-bytes=1'
Nov 12 00:48:51.394: INFO: stderr: ""
Nov 12 00:48:51.394: INFO: stdout: "I"
Nov 12 00:48:51.394: INFO: got output "I"
STEP: exposing timestamps 11/12/22 00:48:51.394
Nov 12 00:48:51.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --tail=1 --timestamps'
Nov 12 00:48:51.587: INFO: stderr: ""
Nov 12 00:48:51.587: INFO: stdout: "2022-11-12T00:48:51.448444940Z I1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\n"
Nov 12 00:48:51.587: INFO: got output "2022-11-12T00:48:51.448444940Z I1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\n"
STEP: restricting to a time range 11/12/22 00:48:51.587
Nov 12 00:48:54.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --since=1s'
Nov 12 00:48:54.258: INFO: stderr: ""
Nov 12 00:48:54.258: INFO: stdout: "I1112 00:48:53.447530       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/bsh 575\nI1112 00:48:53.648041       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/d7h 332\nI1112 00:48:53.847520       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/z4bs 575\nI1112 00:48:54.047998       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/pxx 282\nI1112 00:48:54.247469       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/kc9 526\n"
Nov 12 00:48:54.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --since=24h'
Nov 12 00:48:54.476: INFO: stderr: ""
Nov 12 00:48:54.476: INFO: stdout: "I1112 00:48:48.446994       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/ch8 510\nI1112 00:48:48.647248       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/xmzl 451\nI1112 00:48:48.856322       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/sp6 428\nI1112 00:48:49.048430       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/lnk 381\nI1112 00:48:49.247698       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/vb2g 532\nI1112 00:48:49.447059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/qcm 231\nI1112 00:48:49.647700       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/469 397\nI1112 00:48:49.848080       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm2t 528\nI1112 00:48:50.047559       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/mvx8 417\nI1112 00:48:50.248052       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/m45 555\nI1112 00:48:50.447538       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fnc 226\nI1112 00:48:50.648051       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/gl5g 454\nI1112 00:48:50.847520       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/2rh 439\nI1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\nI1112 00:48:51.247533       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/bq5 439\nI1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\nI1112 00:48:51.647599       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/fds5 479\nI1112 00:48:51.850956       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/dzcs 293\nI1112 00:48:52.050930       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/n2p 468\nI1112 00:48:52.247298       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/94p 416\nI1112 00:48:52.448339       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/djr9 273\nI1112 00:48:52.652416       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/696d 387\nI1112 00:48:52.848040       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/cs5w 480\nI1112 00:48:53.047544       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/4wl 591\nI1112 00:48:53.247993       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/c52p 296\nI1112 00:48:53.447530       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/bsh 575\nI1112 00:48:53.648041       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/d7h 332\nI1112 00:48:53.847520       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/z4bs 575\nI1112 00:48:54.047998       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/pxx 282\nI1112 00:48:54.247469       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/kc9 526\nI1112 00:48:54.447973       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/ns/pods/wrq 265\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Nov 12 00:48:54.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 delete pod logs-generator'
Nov 12 00:48:56.596: INFO: stderr: ""
Nov 12 00:48:56.596: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:48:56.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8454" for this suite. 11/12/22 00:48:56.609
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":305,"skipped":5798,"failed":0}
------------------------------
• [SLOW TEST] [10.174 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:46.462
    Nov 12 00:48:46.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:48:46.464
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:46.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:46.521
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 11/12/22 00:48:46.531
    Nov 12 00:48:46.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Nov 12 00:48:46.739: INFO: stderr: ""
    Nov 12 00:48:46.739: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 11/12/22 00:48:46.739
    Nov 12 00:48:46.739: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Nov 12 00:48:46.739: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8454" to be "running and ready, or succeeded"
    Nov 12 00:48:46.755: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 15.684477ms
    Nov 12 00:48:46.755: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.184.98.55' to be 'Running' but was 'Pending'
    Nov 12 00:48:48.771: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031308796s
    Nov 12 00:48:48.771: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on '10.184.98.55' to be 'Running' but was 'Pending'
    Nov 12 00:48:50.770: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.031068612s
    Nov 12 00:48:50.771: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Nov 12 00:48:50.771: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 11/12/22 00:48:50.771
    Nov 12 00:48:50.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator'
    Nov 12 00:48:51.011: INFO: stderr: ""
    Nov 12 00:48:51.011: INFO: stdout: "I1112 00:48:48.446994       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/ch8 510\nI1112 00:48:48.647248       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/xmzl 451\nI1112 00:48:48.856322       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/sp6 428\nI1112 00:48:49.048430       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/lnk 381\nI1112 00:48:49.247698       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/vb2g 532\nI1112 00:48:49.447059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/qcm 231\nI1112 00:48:49.647700       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/469 397\nI1112 00:48:49.848080       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm2t 528\nI1112 00:48:50.047559       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/mvx8 417\nI1112 00:48:50.248052       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/m45 555\nI1112 00:48:50.447538       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fnc 226\nI1112 00:48:50.648051       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/gl5g 454\nI1112 00:48:50.847520       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/2rh 439\n"
    STEP: limiting log lines 11/12/22 00:48:51.011
    Nov 12 00:48:51.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --tail=1'
    Nov 12 00:48:51.205: INFO: stderr: ""
    Nov 12 00:48:51.205: INFO: stdout: "I1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\n"
    Nov 12 00:48:51.205: INFO: got output "I1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\n"
    STEP: limiting log bytes 11/12/22 00:48:51.205
    Nov 12 00:48:51.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --limit-bytes=1'
    Nov 12 00:48:51.394: INFO: stderr: ""
    Nov 12 00:48:51.394: INFO: stdout: "I"
    Nov 12 00:48:51.394: INFO: got output "I"
    STEP: exposing timestamps 11/12/22 00:48:51.394
    Nov 12 00:48:51.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --tail=1 --timestamps'
    Nov 12 00:48:51.587: INFO: stderr: ""
    Nov 12 00:48:51.587: INFO: stdout: "2022-11-12T00:48:51.448444940Z I1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\n"
    Nov 12 00:48:51.587: INFO: got output "2022-11-12T00:48:51.448444940Z I1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\n"
    STEP: restricting to a time range 11/12/22 00:48:51.587
    Nov 12 00:48:54.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --since=1s'
    Nov 12 00:48:54.258: INFO: stderr: ""
    Nov 12 00:48:54.258: INFO: stdout: "I1112 00:48:53.447530       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/bsh 575\nI1112 00:48:53.648041       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/d7h 332\nI1112 00:48:53.847520       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/z4bs 575\nI1112 00:48:54.047998       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/pxx 282\nI1112 00:48:54.247469       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/kc9 526\n"
    Nov 12 00:48:54.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 logs logs-generator logs-generator --since=24h'
    Nov 12 00:48:54.476: INFO: stderr: ""
    Nov 12 00:48:54.476: INFO: stdout: "I1112 00:48:48.446994       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/ch8 510\nI1112 00:48:48.647248       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/xmzl 451\nI1112 00:48:48.856322       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/sp6 428\nI1112 00:48:49.048430       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/lnk 381\nI1112 00:48:49.247698       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/vb2g 532\nI1112 00:48:49.447059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/qcm 231\nI1112 00:48:49.647700       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/469 397\nI1112 00:48:49.848080       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/lm2t 528\nI1112 00:48:50.047559       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/mvx8 417\nI1112 00:48:50.248052       1 logs_generator.go:76] 9 GET /api/v1/namespaces/default/pods/m45 555\nI1112 00:48:50.447538       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/fnc 226\nI1112 00:48:50.648051       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/gl5g 454\nI1112 00:48:50.847520       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/2rh 439\nI1112 00:48:51.048035       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/dc9c 339\nI1112 00:48:51.247533       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/bq5 439\nI1112 00:48:51.448092       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6qvc 500\nI1112 00:48:51.647599       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/fds5 479\nI1112 00:48:51.850956       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/dzcs 293\nI1112 00:48:52.050930       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/n2p 468\nI1112 00:48:52.247298       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/94p 416\nI1112 00:48:52.448339       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/djr9 273\nI1112 00:48:52.652416       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/696d 387\nI1112 00:48:52.848040       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/cs5w 480\nI1112 00:48:53.047544       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/4wl 591\nI1112 00:48:53.247993       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/c52p 296\nI1112 00:48:53.447530       1 logs_generator.go:76] 25 GET /api/v1/namespaces/default/pods/bsh 575\nI1112 00:48:53.648041       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/d7h 332\nI1112 00:48:53.847520       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/z4bs 575\nI1112 00:48:54.047998       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/pxx 282\nI1112 00:48:54.247469       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/kc9 526\nI1112 00:48:54.447973       1 logs_generator.go:76] 30 PUT /api/v1/namespaces/ns/pods/wrq 265\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Nov 12 00:48:54.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8454 delete pod logs-generator'
    Nov 12 00:48:56.596: INFO: stderr: ""
    Nov 12 00:48:56.596: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:48:56.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8454" for this suite. 11/12/22 00:48:56.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:48:56.639
Nov 12 00:48:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:48:56.644
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:56.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:56.691
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Nov 12 00:48:56.738: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af" in namespace "kubelet-test-3877" to be "running and ready"
Nov 12 00:48:56.754: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Pending", Reason="", readiness=false. Elapsed: 15.570311ms
Nov 12 00:48:56.754: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:48:58.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03288772s
Nov 12 00:48:58.771: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:49:00.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Running", Reason="", readiness=true. Elapsed: 4.03239139s
Nov 12 00:49:00.771: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Running (Ready = true)
Nov 12 00:49:00.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 00:49:00.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3877" for this suite. 11/12/22 00:49:00.83
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":306,"skipped":5810,"failed":0}
------------------------------
• [4.216 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:48:56.639
    Nov 12 00:48:56.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:48:56.644
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:48:56.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:48:56.691
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Nov 12 00:48:56.738: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af" in namespace "kubelet-test-3877" to be "running and ready"
    Nov 12 00:48:56.754: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Pending", Reason="", readiness=false. Elapsed: 15.570311ms
    Nov 12 00:48:56.754: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:48:58.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03288772s
    Nov 12 00:48:58.771: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:49:00.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af": Phase="Running", Reason="", readiness=true. Elapsed: 4.03239139s
    Nov 12 00:49:00.771: INFO: The phase of Pod busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af is Running (Ready = true)
    Nov 12 00:49:00.771: INFO: Pod "busybox-readonly-fsb7d6957b-25ec-416e-ab6d-572d1ef7d1af" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 00:49:00.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3877" for this suite. 11/12/22 00:49:00.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:00.859
Nov 12 00:49:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:49:00.861
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:00.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:00.907
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 11/12/22 00:49:00.919
STEP: submitting the pod to kubernetes 11/12/22 00:49:00.92
Nov 12 00:49:00.948: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" in namespace "pods-6196" to be "running and ready"
Nov 12 00:49:00.961: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Pending", Reason="", readiness=false. Elapsed: 13.661726ms
Nov 12 00:49:00.961: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:49:02.978: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030330712s
Nov 12 00:49:02.978: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:49:04.979: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=true. Elapsed: 4.031409016s
Nov 12 00:49:04.979: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Running (Ready = true)
Nov 12 00:49:04.979: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/12/22 00:49:04.994
STEP: updating the pod 11/12/22 00:49:05.009
Nov 12 00:49:05.545: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691"
Nov 12 00:49:05.545: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" in namespace "pods-6196" to be "terminated with reason DeadlineExceeded"
Nov 12 00:49:05.560: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=true. Elapsed: 14.251117ms
Nov 12 00:49:07.578: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=false. Elapsed: 2.032383217s
Nov 12 00:49:09.576: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.031087252s
Nov 12 00:49:09.576: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:49:09.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6196" for this suite. 11/12/22 00:49:09.59
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":307,"skipped":5830,"failed":0}
------------------------------
• [SLOW TEST] [8.758 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:00.859
    Nov 12 00:49:00.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:49:00.861
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:00.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:00.907
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 11/12/22 00:49:00.919
    STEP: submitting the pod to kubernetes 11/12/22 00:49:00.92
    Nov 12 00:49:00.948: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" in namespace "pods-6196" to be "running and ready"
    Nov 12 00:49:00.961: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Pending", Reason="", readiness=false. Elapsed: 13.661726ms
    Nov 12 00:49:00.961: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:49:02.978: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030330712s
    Nov 12 00:49:02.978: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:49:04.979: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=true. Elapsed: 4.031409016s
    Nov 12 00:49:04.979: INFO: The phase of Pod pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691 is Running (Ready = true)
    Nov 12 00:49:04.979: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/12/22 00:49:04.994
    STEP: updating the pod 11/12/22 00:49:05.009
    Nov 12 00:49:05.545: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691"
    Nov 12 00:49:05.545: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" in namespace "pods-6196" to be "terminated with reason DeadlineExceeded"
    Nov 12 00:49:05.560: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=true. Elapsed: 14.251117ms
    Nov 12 00:49:07.578: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Running", Reason="", readiness=false. Elapsed: 2.032383217s
    Nov 12 00:49:09.576: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.031087252s
    Nov 12 00:49:09.576: INFO: Pod "pod-update-activedeadlineseconds-4598cc40-efa5-4212-b56a-3f21da24e691" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:49:09.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6196" for this suite. 11/12/22 00:49:09.59
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:09.622
Nov 12 00:49:09.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:49:09.623
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:09.663
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:09.672
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 11/12/22 00:49:09.682
Nov 12 00:49:09.710: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f" in namespace "downward-api-8914" to be "Succeeded or Failed"
Nov 12 00:49:09.724: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.861479ms
Nov 12 00:49:11.744: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033023365s
Nov 12 00:49:13.740: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029407266s
STEP: Saw pod success 11/12/22 00:49:13.741
Nov 12 00:49:13.741: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f" satisfied condition "Succeeded or Failed"
Nov 12 00:49:13.756: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f container client-container: <nil>
STEP: delete the pod 11/12/22 00:49:13.784
Nov 12 00:49:13.831: INFO: Waiting for pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f to disappear
Nov 12 00:49:13.845: INFO: Pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:49:13.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8914" for this suite. 11/12/22 00:49:13.86
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":308,"skipped":5885,"failed":0}
------------------------------
• [4.268 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:09.622
    Nov 12 00:49:09.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:49:09.623
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:09.663
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:09.672
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 11/12/22 00:49:09.682
    Nov 12 00:49:09.710: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f" in namespace "downward-api-8914" to be "Succeeded or Failed"
    Nov 12 00:49:09.724: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.861479ms
    Nov 12 00:49:11.744: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033023365s
    Nov 12 00:49:13.740: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029407266s
    STEP: Saw pod success 11/12/22 00:49:13.741
    Nov 12 00:49:13.741: INFO: Pod "downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f" satisfied condition "Succeeded or Failed"
    Nov 12 00:49:13.756: INFO: Trying to get logs from node 10.184.98.55 pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f container client-container: <nil>
    STEP: delete the pod 11/12/22 00:49:13.784
    Nov 12 00:49:13.831: INFO: Waiting for pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f to disappear
    Nov 12 00:49:13.845: INFO: Pod downwardapi-volume-66eb9e4e-2f41-40bc-9748-321538c0938f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:49:13.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8914" for this suite. 11/12/22 00:49:13.86
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:13.894
Nov 12 00:49:13.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:49:13.895
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:13.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:13.936
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 00:49:13.945
Nov 12 00:49:13.974: INFO: Waiting up to 5m0s for pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b" in namespace "emptydir-266" to be "Succeeded or Failed"
Nov 12 00:49:13.989: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.198796ms
Nov 12 00:49:16.008: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034194467s
Nov 12 00:49:18.005: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031738626s
Nov 12 00:49:20.007: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03351041s
STEP: Saw pod success 11/12/22 00:49:20.007
Nov 12 00:49:20.008: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b" satisfied condition "Succeeded or Failed"
Nov 12 00:49:20.025: INFO: Trying to get logs from node 10.184.98.55 pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b container test-container: <nil>
STEP: delete the pod 11/12/22 00:49:20.055
Nov 12 00:49:20.103: INFO: Waiting for pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b to disappear
Nov 12 00:49:20.131: INFO: Pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:49:20.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-266" for this suite. 11/12/22 00:49:20.146
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":309,"skipped":5894,"failed":0}
------------------------------
• [SLOW TEST] [6.280 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:13.894
    Nov 12 00:49:13.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:49:13.895
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:13.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:13.936
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 00:49:13.945
    Nov 12 00:49:13.974: INFO: Waiting up to 5m0s for pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b" in namespace "emptydir-266" to be "Succeeded or Failed"
    Nov 12 00:49:13.989: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.198796ms
    Nov 12 00:49:16.008: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034194467s
    Nov 12 00:49:18.005: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031738626s
    Nov 12 00:49:20.007: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03351041s
    STEP: Saw pod success 11/12/22 00:49:20.007
    Nov 12 00:49:20.008: INFO: Pod "pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b" satisfied condition "Succeeded or Failed"
    Nov 12 00:49:20.025: INFO: Trying to get logs from node 10.184.98.55 pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b container test-container: <nil>
    STEP: delete the pod 11/12/22 00:49:20.055
    Nov 12 00:49:20.103: INFO: Waiting for pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b to disappear
    Nov 12 00:49:20.131: INFO: Pod pod-95203125-7e64-4b7c-8aed-b2ef1b7ae66b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:49:20.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-266" for this suite. 11/12/22 00:49:20.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:20.18
Nov 12 00:49:20.180: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:49:20.183
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:20.221
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:20.259
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Nov 12 00:49:20.301: INFO: Waiting up to 5m0s for pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa" in namespace "kubelet-test-7224" to be "running and ready"
Nov 12 00:49:20.316: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 14.241395ms
Nov 12 00:49:20.316: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:49:22.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032421946s
Nov 12 00:49:22.334: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:49:24.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Running", Reason="", readiness=true. Elapsed: 4.032741619s
Nov 12 00:49:24.334: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Running (Ready = true)
Nov 12 00:49:24.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 00:49:24.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7224" for this suite. 11/12/22 00:49:24.403
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":310,"skipped":5909,"failed":0}
------------------------------
• [4.252 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:20.18
    Nov 12 00:49:20.180: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 00:49:20.183
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:20.221
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:20.259
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Nov 12 00:49:20.301: INFO: Waiting up to 5m0s for pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa" in namespace "kubelet-test-7224" to be "running and ready"
    Nov 12 00:49:20.316: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 14.241395ms
    Nov 12 00:49:20.316: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:49:22.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032421946s
    Nov 12 00:49:22.334: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:49:24.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa": Phase="Running", Reason="", readiness=true. Elapsed: 4.032741619s
    Nov 12 00:49:24.334: INFO: The phase of Pod busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa is Running (Ready = true)
    Nov 12 00:49:24.334: INFO: Pod "busybox-scheduling-08f29f44-4f5e-4c45-b3d9-0d589a3ca4fa" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 00:49:24.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7224" for this suite. 11/12/22 00:49:24.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:24.435
Nov 12 00:49:24.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:49:24.437
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:24.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:24.485
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 00:49:24.495
Nov 12 00:49:24.526: INFO: Waiting up to 5m0s for pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6" in namespace "emptydir-5107" to be "Succeeded or Failed"
Nov 12 00:49:24.541: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.408683ms
Nov 12 00:49:26.576: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049498892s
Nov 12 00:49:28.558: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03160619s
Nov 12 00:49:30.555: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028769706s
STEP: Saw pod success 11/12/22 00:49:30.556
Nov 12 00:49:30.556: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6" satisfied condition "Succeeded or Failed"
Nov 12 00:49:30.572: INFO: Trying to get logs from node 10.184.98.55 pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 container test-container: <nil>
STEP: delete the pod 11/12/22 00:49:30.603
Nov 12 00:49:30.657: INFO: Waiting for pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 to disappear
Nov 12 00:49:30.672: INFO: Pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:49:30.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5107" for this suite. 11/12/22 00:49:30.686
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":311,"skipped":5916,"failed":0}
------------------------------
• [SLOW TEST] [6.280 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:24.435
    Nov 12 00:49:24.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:49:24.437
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:24.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:24.485
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 00:49:24.495
    Nov 12 00:49:24.526: INFO: Waiting up to 5m0s for pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6" in namespace "emptydir-5107" to be "Succeeded or Failed"
    Nov 12 00:49:24.541: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.408683ms
    Nov 12 00:49:26.576: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049498892s
    Nov 12 00:49:28.558: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03160619s
    Nov 12 00:49:30.555: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028769706s
    STEP: Saw pod success 11/12/22 00:49:30.556
    Nov 12 00:49:30.556: INFO: Pod "pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6" satisfied condition "Succeeded or Failed"
    Nov 12 00:49:30.572: INFO: Trying to get logs from node 10.184.98.55 pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 container test-container: <nil>
    STEP: delete the pod 11/12/22 00:49:30.603
    Nov 12 00:49:30.657: INFO: Waiting for pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 to disappear
    Nov 12 00:49:30.672: INFO: Pod pod-55f93cdf-edb2-45a6-9f6d-9a39798e25b6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:49:30.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5107" for this suite. 11/12/22 00:49:30.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:30.726
Nov 12 00:49:30.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:49:30.728
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:30.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:30.779
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 11/12/22 00:49:30.788
STEP: Creating a ResourceQuota 11/12/22 00:49:35.799
STEP: Ensuring resource quota status is calculated 11/12/22 00:49:35.81
STEP: Creating a Service 11/12/22 00:49:37.82
STEP: Creating a NodePort Service 11/12/22 00:49:37.88
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/12/22 00:49:37.947
STEP: Ensuring resource quota status captures service creation 11/12/22 00:49:38.039
STEP: Deleting Services 11/12/22 00:49:40.05
STEP: Ensuring resource quota status released usage 11/12/22 00:49:40.151
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:49:42.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1996" for this suite. 11/12/22 00:49:42.258
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":312,"skipped":5959,"failed":0}
------------------------------
• [SLOW TEST] [11.560 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:30.726
    Nov 12 00:49:30.727: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:49:30.728
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:30.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:30.779
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 11/12/22 00:49:30.788
    STEP: Creating a ResourceQuota 11/12/22 00:49:35.799
    STEP: Ensuring resource quota status is calculated 11/12/22 00:49:35.81
    STEP: Creating a Service 11/12/22 00:49:37.82
    STEP: Creating a NodePort Service 11/12/22 00:49:37.88
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/12/22 00:49:37.947
    STEP: Ensuring resource quota status captures service creation 11/12/22 00:49:38.039
    STEP: Deleting Services 11/12/22 00:49:40.05
    STEP: Ensuring resource quota status released usage 11/12/22 00:49:40.151
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:49:42.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1996" for this suite. 11/12/22 00:49:42.258
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:42.292
Nov 12 00:49:42.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:49:42.295
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:42.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:42.354
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 11/12/22 00:49:42.367
Nov 12 00:49:42.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 create -f -'
Nov 12 00:49:42.946: INFO: stderr: ""
Nov 12 00:49:42.946: INFO: stdout: "pod/pause created\n"
Nov 12 00:49:42.946: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 12 00:49:42.947: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3287" to be "running and ready"
Nov 12 00:49:42.962: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.895812ms
Nov 12 00:49:42.962: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.184.98.55' to be 'Running' but was 'Pending'
Nov 12 00:49:44.977: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.029737223s
Nov 12 00:49:44.977: INFO: Pod "pause" satisfied condition "running and ready"
Nov 12 00:49:44.977: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 11/12/22 00:49:44.977
Nov 12 00:49:44.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 label pods pause testing-label=testing-label-value'
Nov 12 00:49:45.115: INFO: stderr: ""
Nov 12 00:49:45.115: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 11/12/22 00:49:45.115
Nov 12 00:49:45.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pod pause -L testing-label'
Nov 12 00:49:45.216: INFO: stderr: ""
Nov 12 00:49:45.216: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod 11/12/22 00:49:45.216
Nov 12 00:49:45.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 label pods pause testing-label-'
Nov 12 00:49:45.376: INFO: stderr: ""
Nov 12 00:49:45.376: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 11/12/22 00:49:45.376
Nov 12 00:49:45.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pod pause -L testing-label'
Nov 12 00:49:45.553: INFO: stderr: ""
Nov 12 00:49:45.553: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 11/12/22 00:49:45.553
Nov 12 00:49:45.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 delete --grace-period=0 --force -f -'
Nov 12 00:49:45.765: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 00:49:45.765: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 12 00:49:45.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get rc,svc -l name=pause --no-headers'
Nov 12 00:49:45.995: INFO: stderr: "No resources found in kubectl-3287 namespace.\n"
Nov 12 00:49:45.995: INFO: stdout: ""
Nov 12 00:49:45.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 12 00:49:46.196: INFO: stderr: ""
Nov 12 00:49:46.196: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:49:46.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3287" for this suite. 11/12/22 00:49:46.217
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":313,"skipped":5974,"failed":0}
------------------------------
• [3.943 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:42.292
    Nov 12 00:49:42.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:49:42.295
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:42.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:42.354
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 11/12/22 00:49:42.367
    Nov 12 00:49:42.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 create -f -'
    Nov 12 00:49:42.946: INFO: stderr: ""
    Nov 12 00:49:42.946: INFO: stdout: "pod/pause created\n"
    Nov 12 00:49:42.946: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Nov 12 00:49:42.947: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3287" to be "running and ready"
    Nov 12 00:49:42.962: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.895812ms
    Nov 12 00:49:42.962: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '10.184.98.55' to be 'Running' but was 'Pending'
    Nov 12 00:49:44.977: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.029737223s
    Nov 12 00:49:44.977: INFO: Pod "pause" satisfied condition "running and ready"
    Nov 12 00:49:44.977: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 11/12/22 00:49:44.977
    Nov 12 00:49:44.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 label pods pause testing-label=testing-label-value'
    Nov 12 00:49:45.115: INFO: stderr: ""
    Nov 12 00:49:45.115: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 11/12/22 00:49:45.115
    Nov 12 00:49:45.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pod pause -L testing-label'
    Nov 12 00:49:45.216: INFO: stderr: ""
    Nov 12 00:49:45.216: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 11/12/22 00:49:45.216
    Nov 12 00:49:45.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 label pods pause testing-label-'
    Nov 12 00:49:45.376: INFO: stderr: ""
    Nov 12 00:49:45.376: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 11/12/22 00:49:45.376
    Nov 12 00:49:45.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pod pause -L testing-label'
    Nov 12 00:49:45.553: INFO: stderr: ""
    Nov 12 00:49:45.553: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 11/12/22 00:49:45.553
    Nov 12 00:49:45.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 delete --grace-period=0 --force -f -'
    Nov 12 00:49:45.765: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 00:49:45.765: INFO: stdout: "pod \"pause\" force deleted\n"
    Nov 12 00:49:45.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get rc,svc -l name=pause --no-headers'
    Nov 12 00:49:45.995: INFO: stderr: "No resources found in kubectl-3287 namespace.\n"
    Nov 12 00:49:45.995: INFO: stdout: ""
    Nov 12 00:49:45.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3287 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 12 00:49:46.196: INFO: stderr: ""
    Nov 12 00:49:46.196: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:49:46.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3287" for this suite. 11/12/22 00:49:46.217
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:46.238
Nov 12 00:49:46.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename init-container 11/12/22 00:49:46.239
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:46.318
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:46.328
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 11/12/22 00:49:46.341
Nov 12 00:49:46.341: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 00:49:52.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1492" for this suite. 11/12/22 00:49:52.948
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":314,"skipped":5994,"failed":0}
------------------------------
• [SLOW TEST] [6.734 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:46.238
    Nov 12 00:49:46.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename init-container 11/12/22 00:49:46.239
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:46.318
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:46.328
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 11/12/22 00:49:46.341
    Nov 12 00:49:46.341: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 00:49:52.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1492" for this suite. 11/12/22 00:49:52.948
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:52.977
Nov 12 00:49:52.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename discovery 11/12/22 00:49:52.979
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:53.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:53.047
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 11/12/22 00:49:53.063
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Nov 12 00:49:53.863: INFO: Checking APIGroup: apiregistration.k8s.io
Nov 12 00:49:53.868: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Nov 12 00:49:53.868: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Nov 12 00:49:53.868: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Nov 12 00:49:53.868: INFO: Checking APIGroup: apps
Nov 12 00:49:53.874: INFO: PreferredVersion.GroupVersion: apps/v1
Nov 12 00:49:53.874: INFO: Versions found [{apps/v1 v1}]
Nov 12 00:49:53.874: INFO: apps/v1 matches apps/v1
Nov 12 00:49:53.874: INFO: Checking APIGroup: events.k8s.io
Nov 12 00:49:53.878: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Nov 12 00:49:53.878: INFO: Versions found [{events.k8s.io/v1 v1}]
Nov 12 00:49:53.878: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Nov 12 00:49:53.878: INFO: Checking APIGroup: authentication.k8s.io
Nov 12 00:49:53.882: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Nov 12 00:49:53.882: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Nov 12 00:49:53.882: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Nov 12 00:49:53.882: INFO: Checking APIGroup: authorization.k8s.io
Nov 12 00:49:53.887: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Nov 12 00:49:53.887: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Nov 12 00:49:53.887: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Nov 12 00:49:53.887: INFO: Checking APIGroup: autoscaling
Nov 12 00:49:53.891: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Nov 12 00:49:53.891: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Nov 12 00:49:53.891: INFO: autoscaling/v2 matches autoscaling/v2
Nov 12 00:49:53.891: INFO: Checking APIGroup: batch
Nov 12 00:49:53.896: INFO: PreferredVersion.GroupVersion: batch/v1
Nov 12 00:49:53.896: INFO: Versions found [{batch/v1 v1}]
Nov 12 00:49:53.897: INFO: batch/v1 matches batch/v1
Nov 12 00:49:53.897: INFO: Checking APIGroup: certificates.k8s.io
Nov 12 00:49:53.901: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Nov 12 00:49:53.901: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Nov 12 00:49:53.901: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Nov 12 00:49:53.901: INFO: Checking APIGroup: networking.k8s.io
Nov 12 00:49:53.905: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Nov 12 00:49:53.905: INFO: Versions found [{networking.k8s.io/v1 v1}]
Nov 12 00:49:53.905: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Nov 12 00:49:53.905: INFO: Checking APIGroup: policy
Nov 12 00:49:53.908: INFO: PreferredVersion.GroupVersion: policy/v1
Nov 12 00:49:53.908: INFO: Versions found [{policy/v1 v1}]
Nov 12 00:49:53.908: INFO: policy/v1 matches policy/v1
Nov 12 00:49:53.908: INFO: Checking APIGroup: rbac.authorization.k8s.io
Nov 12 00:49:53.911: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Nov 12 00:49:53.911: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Nov 12 00:49:53.911: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Nov 12 00:49:53.911: INFO: Checking APIGroup: storage.k8s.io
Nov 12 00:49:53.917: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Nov 12 00:49:53.917: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Nov 12 00:49:53.917: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Nov 12 00:49:53.917: INFO: Checking APIGroup: admissionregistration.k8s.io
Nov 12 00:49:53.922: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Nov 12 00:49:53.922: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Nov 12 00:49:53.922: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Nov 12 00:49:53.922: INFO: Checking APIGroup: apiextensions.k8s.io
Nov 12 00:49:53.927: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Nov 12 00:49:53.927: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Nov 12 00:49:53.927: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Nov 12 00:49:53.927: INFO: Checking APIGroup: scheduling.k8s.io
Nov 12 00:49:53.933: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Nov 12 00:49:53.933: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Nov 12 00:49:53.933: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Nov 12 00:49:53.933: INFO: Checking APIGroup: coordination.k8s.io
Nov 12 00:49:53.938: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Nov 12 00:49:53.938: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Nov 12 00:49:53.938: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Nov 12 00:49:53.938: INFO: Checking APIGroup: node.k8s.io
Nov 12 00:49:53.943: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Nov 12 00:49:53.943: INFO: Versions found [{node.k8s.io/v1 v1}]
Nov 12 00:49:53.943: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Nov 12 00:49:53.943: INFO: Checking APIGroup: discovery.k8s.io
Nov 12 00:49:53.949: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Nov 12 00:49:53.949: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Nov 12 00:49:53.949: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Nov 12 00:49:53.949: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Nov 12 00:49:53.954: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Nov 12 00:49:53.954: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Nov 12 00:49:53.954: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Nov 12 00:49:53.954: INFO: Checking APIGroup: crd.projectcalico.org
Nov 12 00:49:53.960: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Nov 12 00:49:53.960: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Nov 12 00:49:53.960: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Nov 12 00:49:53.960: INFO: Checking APIGroup: snapshot.storage.k8s.io
Nov 12 00:49:53.968: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Nov 12 00:49:53.968: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
Nov 12 00:49:53.968: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Nov 12 00:49:53.968: INFO: Checking APIGroup: ibm.com
Nov 12 00:49:53.974: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
Nov 12 00:49:53.974: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
Nov 12 00:49:53.974: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
Nov 12 00:49:53.974: INFO: Checking APIGroup: metrics.k8s.io
Nov 12 00:49:53.977: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Nov 12 00:49:53.977: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Nov 12 00:49:53.977: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Nov 12 00:49:53.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-3077" for this suite. 11/12/22 00:49:53.994
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":315,"skipped":6020,"failed":0}
------------------------------
• [1.039 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:52.977
    Nov 12 00:49:52.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename discovery 11/12/22 00:49:52.979
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:53.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:53.047
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 11/12/22 00:49:53.063
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Nov 12 00:49:53.863: INFO: Checking APIGroup: apiregistration.k8s.io
    Nov 12 00:49:53.868: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Nov 12 00:49:53.868: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Nov 12 00:49:53.868: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Nov 12 00:49:53.868: INFO: Checking APIGroup: apps
    Nov 12 00:49:53.874: INFO: PreferredVersion.GroupVersion: apps/v1
    Nov 12 00:49:53.874: INFO: Versions found [{apps/v1 v1}]
    Nov 12 00:49:53.874: INFO: apps/v1 matches apps/v1
    Nov 12 00:49:53.874: INFO: Checking APIGroup: events.k8s.io
    Nov 12 00:49:53.878: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Nov 12 00:49:53.878: INFO: Versions found [{events.k8s.io/v1 v1}]
    Nov 12 00:49:53.878: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Nov 12 00:49:53.878: INFO: Checking APIGroup: authentication.k8s.io
    Nov 12 00:49:53.882: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Nov 12 00:49:53.882: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Nov 12 00:49:53.882: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Nov 12 00:49:53.882: INFO: Checking APIGroup: authorization.k8s.io
    Nov 12 00:49:53.887: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Nov 12 00:49:53.887: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Nov 12 00:49:53.887: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Nov 12 00:49:53.887: INFO: Checking APIGroup: autoscaling
    Nov 12 00:49:53.891: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Nov 12 00:49:53.891: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Nov 12 00:49:53.891: INFO: autoscaling/v2 matches autoscaling/v2
    Nov 12 00:49:53.891: INFO: Checking APIGroup: batch
    Nov 12 00:49:53.896: INFO: PreferredVersion.GroupVersion: batch/v1
    Nov 12 00:49:53.896: INFO: Versions found [{batch/v1 v1}]
    Nov 12 00:49:53.897: INFO: batch/v1 matches batch/v1
    Nov 12 00:49:53.897: INFO: Checking APIGroup: certificates.k8s.io
    Nov 12 00:49:53.901: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Nov 12 00:49:53.901: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Nov 12 00:49:53.901: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Nov 12 00:49:53.901: INFO: Checking APIGroup: networking.k8s.io
    Nov 12 00:49:53.905: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Nov 12 00:49:53.905: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Nov 12 00:49:53.905: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Nov 12 00:49:53.905: INFO: Checking APIGroup: policy
    Nov 12 00:49:53.908: INFO: PreferredVersion.GroupVersion: policy/v1
    Nov 12 00:49:53.908: INFO: Versions found [{policy/v1 v1}]
    Nov 12 00:49:53.908: INFO: policy/v1 matches policy/v1
    Nov 12 00:49:53.908: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Nov 12 00:49:53.911: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Nov 12 00:49:53.911: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Nov 12 00:49:53.911: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Nov 12 00:49:53.911: INFO: Checking APIGroup: storage.k8s.io
    Nov 12 00:49:53.917: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Nov 12 00:49:53.917: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Nov 12 00:49:53.917: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Nov 12 00:49:53.917: INFO: Checking APIGroup: admissionregistration.k8s.io
    Nov 12 00:49:53.922: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Nov 12 00:49:53.922: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Nov 12 00:49:53.922: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Nov 12 00:49:53.922: INFO: Checking APIGroup: apiextensions.k8s.io
    Nov 12 00:49:53.927: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Nov 12 00:49:53.927: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Nov 12 00:49:53.927: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Nov 12 00:49:53.927: INFO: Checking APIGroup: scheduling.k8s.io
    Nov 12 00:49:53.933: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Nov 12 00:49:53.933: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Nov 12 00:49:53.933: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Nov 12 00:49:53.933: INFO: Checking APIGroup: coordination.k8s.io
    Nov 12 00:49:53.938: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Nov 12 00:49:53.938: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Nov 12 00:49:53.938: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Nov 12 00:49:53.938: INFO: Checking APIGroup: node.k8s.io
    Nov 12 00:49:53.943: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Nov 12 00:49:53.943: INFO: Versions found [{node.k8s.io/v1 v1}]
    Nov 12 00:49:53.943: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Nov 12 00:49:53.943: INFO: Checking APIGroup: discovery.k8s.io
    Nov 12 00:49:53.949: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Nov 12 00:49:53.949: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Nov 12 00:49:53.949: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Nov 12 00:49:53.949: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Nov 12 00:49:53.954: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Nov 12 00:49:53.954: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Nov 12 00:49:53.954: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Nov 12 00:49:53.954: INFO: Checking APIGroup: crd.projectcalico.org
    Nov 12 00:49:53.960: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Nov 12 00:49:53.960: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Nov 12 00:49:53.960: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Nov 12 00:49:53.960: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Nov 12 00:49:53.968: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Nov 12 00:49:53.968: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
    Nov 12 00:49:53.968: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Nov 12 00:49:53.968: INFO: Checking APIGroup: ibm.com
    Nov 12 00:49:53.974: INFO: PreferredVersion.GroupVersion: ibm.com/v1alpha1
    Nov 12 00:49:53.974: INFO: Versions found [{ibm.com/v1alpha1 v1alpha1}]
    Nov 12 00:49:53.974: INFO: ibm.com/v1alpha1 matches ibm.com/v1alpha1
    Nov 12 00:49:53.974: INFO: Checking APIGroup: metrics.k8s.io
    Nov 12 00:49:53.977: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Nov 12 00:49:53.977: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Nov 12 00:49:53.977: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Nov 12 00:49:53.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-3077" for this suite. 11/12/22 00:49:53.994
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:49:54.016
Nov 12 00:49:54.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename dns 11/12/22 00:49:54.018
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:54.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:54.078
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 11/12/22 00:49:54.091
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local;sleep 1; done
 11/12/22 00:49:54.109
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local;sleep 1; done
 11/12/22 00:49:54.109
STEP: creating a pod to probe DNS 11/12/22 00:49:54.11
STEP: submitting the pod to kubernetes 11/12/22 00:49:54.11
Nov 12 00:49:54.147: INFO: Waiting up to 15m0s for pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f" in namespace "dns-6217" to be "running"
Nov 12 00:49:54.164: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.757238ms
Nov 12 00:49:56.181: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033938725s
Nov 12 00:49:58.183: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Running", Reason="", readiness=true. Elapsed: 4.035094203s
Nov 12 00:49:58.183: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f" satisfied condition "running"
STEP: retrieving the pod 11/12/22 00:49:58.183
STEP: looking for the results for each expected name from probers 11/12/22 00:49:58.202
Nov 12 00:49:58.280: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.332: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.356: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.377: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.403: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.433: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.458: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:49:58.458: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:03.532: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:03.557: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:03.631: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:03.671: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:03.671: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:08.545: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:08.569: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:08.642: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:08.667: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:08.667: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:13.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:13.562: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:13.635: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:13.658: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:13.658: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:18.539: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:18.570: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:18.641: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:18.664: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:18.664: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:23.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:23.562: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:23.630: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:23.654: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
Nov 12 00:50:23.654: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

Nov 12 00:50:28.671: INFO: DNS probes using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f succeeded

STEP: deleting the pod 11/12/22 00:50:28.671
STEP: deleting the test headless service 11/12/22 00:50:28.774
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 00:50:28.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6217" for this suite. 11/12/22 00:50:28.836
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":316,"skipped":6022,"failed":0}
------------------------------
• [SLOW TEST] [34.843 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:49:54.016
    Nov 12 00:49:54.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename dns 11/12/22 00:49:54.018
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:49:54.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:49:54.078
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 11/12/22 00:49:54.091
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local;sleep 1; done
     11/12/22 00:49:54.109
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6217.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local;sleep 1; done
     11/12/22 00:49:54.109
    STEP: creating a pod to probe DNS 11/12/22 00:49:54.11
    STEP: submitting the pod to kubernetes 11/12/22 00:49:54.11
    Nov 12 00:49:54.147: INFO: Waiting up to 15m0s for pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f" in namespace "dns-6217" to be "running"
    Nov 12 00:49:54.164: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.757238ms
    Nov 12 00:49:56.181: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033938725s
    Nov 12 00:49:58.183: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f": Phase="Running", Reason="", readiness=true. Elapsed: 4.035094203s
    Nov 12 00:49:58.183: INFO: Pod "dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 00:49:58.183
    STEP: looking for the results for each expected name from probers 11/12/22 00:49:58.202
    Nov 12 00:49:58.280: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.332: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.356: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.377: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.403: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.433: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.458: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:49:58.458: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:03.532: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:03.557: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:03.631: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:03.671: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:03.671: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:08.545: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:08.569: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:08.642: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:08.667: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:08.667: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:13.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:13.562: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:13.635: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:13.658: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:13.658: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:18.539: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:18.570: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:18.641: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:18.664: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:18.664: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:23.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:23.562: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:23.630: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:23.654: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local from pod dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f: the server could not find the requested resource (get pods dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f)
    Nov 12 00:50:23.654: INFO: Lookups using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f failed for: [wheezy_udp@dns-test-service-2.dns-6217.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6217.svc.cluster.local jessie_udp@dns-test-service-2.dns-6217.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6217.svc.cluster.local]

    Nov 12 00:50:28.671: INFO: DNS probes using dns-6217/dns-test-ccfd758e-556c-4ac1-a9b4-9ab43aa7b74f succeeded

    STEP: deleting the pod 11/12/22 00:50:28.671
    STEP: deleting the test headless service 11/12/22 00:50:28.774
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 00:50:28.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6217" for this suite. 11/12/22 00:50:28.836
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:50:28.865
Nov 12 00:50:28.867: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:50:28.868
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:28.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:28.931
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-5225/configmap-test-27b0ed6a-61fa-47c9-88c6-6a67cb097644 11/12/22 00:50:28.944
STEP: Creating a pod to test consume configMaps 11/12/22 00:50:28.961
Nov 12 00:50:29.003: INFO: Waiting up to 5m0s for pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d" in namespace "configmap-5225" to be "Succeeded or Failed"
Nov 12 00:50:29.020: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.776395ms
Nov 12 00:50:31.039: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035262044s
Nov 12 00:50:33.037: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033714754s
Nov 12 00:50:35.038: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034939979s
STEP: Saw pod success 11/12/22 00:50:35.038
Nov 12 00:50:35.039: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d" satisfied condition "Succeeded or Failed"
Nov 12 00:50:35.055: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d container env-test: <nil>
STEP: delete the pod 11/12/22 00:50:35.157
Nov 12 00:50:35.201: INFO: Waiting for pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d to disappear
Nov 12 00:50:35.217: INFO: Pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:50:35.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5225" for this suite. 11/12/22 00:50:35.236
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":317,"skipped":6027,"failed":0}
------------------------------
• [SLOW TEST] [6.392 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:50:28.865
    Nov 12 00:50:28.867: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:50:28.868
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:28.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:28.931
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-5225/configmap-test-27b0ed6a-61fa-47c9-88c6-6a67cb097644 11/12/22 00:50:28.944
    STEP: Creating a pod to test consume configMaps 11/12/22 00:50:28.961
    Nov 12 00:50:29.003: INFO: Waiting up to 5m0s for pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d" in namespace "configmap-5225" to be "Succeeded or Failed"
    Nov 12 00:50:29.020: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.776395ms
    Nov 12 00:50:31.039: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035262044s
    Nov 12 00:50:33.037: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033714754s
    Nov 12 00:50:35.038: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034939979s
    STEP: Saw pod success 11/12/22 00:50:35.038
    Nov 12 00:50:35.039: INFO: Pod "pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d" satisfied condition "Succeeded or Failed"
    Nov 12 00:50:35.055: INFO: Trying to get logs from node 10.184.98.55 pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d container env-test: <nil>
    STEP: delete the pod 11/12/22 00:50:35.157
    Nov 12 00:50:35.201: INFO: Waiting for pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d to disappear
    Nov 12 00:50:35.217: INFO: Pod pod-configmaps-635350ce-8cde-4cc7-9851-77b028c5e40d no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:50:35.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5225" for this suite. 11/12/22 00:50:35.236
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:50:35.261
Nov 12 00:50:35.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-probe 11/12/22 00:50:35.263
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:35.313
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:35.327
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 in namespace container-probe-8230 11/12/22 00:50:35.341
Nov 12 00:50:35.378: INFO: Waiting up to 5m0s for pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67" in namespace "container-probe-8230" to be "not pending"
Nov 12 00:50:35.394: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67": Phase="Pending", Reason="", readiness=false. Elapsed: 16.175398ms
Nov 12 00:50:37.411: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67": Phase="Running", Reason="", readiness=true. Elapsed: 2.033191291s
Nov 12 00:50:37.411: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67" satisfied condition "not pending"
Nov 12 00:50:37.412: INFO: Started pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 in namespace container-probe-8230
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:50:37.412
Nov 12 00:50:37.429: INFO: Initial restart count of pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 is 0
Nov 12 00:50:57.649: INFO: Restart count of pod container-probe-8230/liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 is now 1 (20.220407742s elapsed)
STEP: deleting the pod 11/12/22 00:50:57.651
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 00:50:57.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8230" for this suite. 11/12/22 00:50:57.718
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":318,"skipped":6045,"failed":0}
------------------------------
• [SLOW TEST] [22.482 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:50:35.261
    Nov 12 00:50:35.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-probe 11/12/22 00:50:35.263
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:35.313
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:35.327
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 in namespace container-probe-8230 11/12/22 00:50:35.341
    Nov 12 00:50:35.378: INFO: Waiting up to 5m0s for pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67" in namespace "container-probe-8230" to be "not pending"
    Nov 12 00:50:35.394: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67": Phase="Pending", Reason="", readiness=false. Elapsed: 16.175398ms
    Nov 12 00:50:37.411: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67": Phase="Running", Reason="", readiness=true. Elapsed: 2.033191291s
    Nov 12 00:50:37.411: INFO: Pod "liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67" satisfied condition "not pending"
    Nov 12 00:50:37.412: INFO: Started pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 in namespace container-probe-8230
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 00:50:37.412
    Nov 12 00:50:37.429: INFO: Initial restart count of pod liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 is 0
    Nov 12 00:50:57.649: INFO: Restart count of pod container-probe-8230/liveness-0cd4df4f-eda9-4a4d-9ea2-6e48d9ed2c67 is now 1 (20.220407742s elapsed)
    STEP: deleting the pod 11/12/22 00:50:57.651
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 00:50:57.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8230" for this suite. 11/12/22 00:50:57.718
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:50:57.749
Nov 12 00:50:57.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename proxy 11/12/22 00:50:57.751
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:57.798
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:57.819
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Nov 12 00:50:57.830: INFO: Creating pod...
Nov 12 00:50:57.863: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3585" to be "running"
Nov 12 00:50:57.883: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 19.748298ms
Nov 12 00:50:59.910: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046269834s
Nov 12 00:51:01.906: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.042701163s
Nov 12 00:51:01.906: INFO: Pod "agnhost" satisfied condition "running"
Nov 12 00:51:01.906: INFO: Creating service...
Nov 12 00:51:01.944: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=DELETE
Nov 12 00:51:02.024: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 00:51:02.024: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=OPTIONS
Nov 12 00:51:02.055: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 00:51:02.055: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=PATCH
Nov 12 00:51:02.078: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 00:51:02.078: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=POST
Nov 12 00:51:02.102: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 00:51:02.102: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=PUT
Nov 12 00:51:02.126: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 00:51:02.126: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=DELETE
Nov 12 00:51:02.178: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 00:51:02.178: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=OPTIONS
Nov 12 00:51:02.209: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 00:51:02.209: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=PATCH
Nov 12 00:51:02.238: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 00:51:02.238: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=POST
Nov 12 00:51:02.270: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 00:51:02.271: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=PUT
Nov 12 00:51:02.323: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 00:51:02.323: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=GET
Nov 12 00:51:02.339: INFO: http.Client request:GET StatusCode:301
Nov 12 00:51:02.339: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=GET
Nov 12 00:51:02.363: INFO: http.Client request:GET StatusCode:301
Nov 12 00:51:02.363: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=HEAD
Nov 12 00:51:02.377: INFO: http.Client request:HEAD StatusCode:301
Nov 12 00:51:02.377: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=HEAD
Nov 12 00:51:02.396: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 00:51:02.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3585" for this suite. 11/12/22 00:51:02.415
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":319,"skipped":6062,"failed":0}
------------------------------
• [4.688 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:50:57.749
    Nov 12 00:50:57.749: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename proxy 11/12/22 00:50:57.751
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:50:57.798
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:50:57.819
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Nov 12 00:50:57.830: INFO: Creating pod...
    Nov 12 00:50:57.863: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3585" to be "running"
    Nov 12 00:50:57.883: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 19.748298ms
    Nov 12 00:50:59.910: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046269834s
    Nov 12 00:51:01.906: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.042701163s
    Nov 12 00:51:01.906: INFO: Pod "agnhost" satisfied condition "running"
    Nov 12 00:51:01.906: INFO: Creating service...
    Nov 12 00:51:01.944: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=DELETE
    Nov 12 00:51:02.024: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 00:51:02.024: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=OPTIONS
    Nov 12 00:51:02.055: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 00:51:02.055: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=PATCH
    Nov 12 00:51:02.078: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 00:51:02.078: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=POST
    Nov 12 00:51:02.102: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 00:51:02.102: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=PUT
    Nov 12 00:51:02.126: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 00:51:02.126: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=DELETE
    Nov 12 00:51:02.178: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 00:51:02.178: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Nov 12 00:51:02.209: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 00:51:02.209: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=PATCH
    Nov 12 00:51:02.238: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 00:51:02.238: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=POST
    Nov 12 00:51:02.270: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 00:51:02.271: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=PUT
    Nov 12 00:51:02.323: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 00:51:02.323: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=GET
    Nov 12 00:51:02.339: INFO: http.Client request:GET StatusCode:301
    Nov 12 00:51:02.339: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=GET
    Nov 12 00:51:02.363: INFO: http.Client request:GET StatusCode:301
    Nov 12 00:51:02.363: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/pods/agnhost/proxy?method=HEAD
    Nov 12 00:51:02.377: INFO: http.Client request:HEAD StatusCode:301
    Nov 12 00:51:02.377: INFO: Starting http.Client for https://172.21.0.1:443/api/v1/namespaces/proxy-3585/services/e2e-proxy-test-service/proxy?method=HEAD
    Nov 12 00:51:02.396: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 00:51:02.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3585" for this suite. 11/12/22 00:51:02.415
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:02.437
Nov 12 00:51:02.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context-test 11/12/22 00:51:02.439
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:02.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:02.494
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Nov 12 00:51:02.538: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c" in namespace "security-context-test-7686" to be "Succeeded or Failed"
Nov 12 00:51:02.554: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.85331ms
Nov 12 00:51:04.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Running", Reason="", readiness=true. Elapsed: 2.033186238s
Nov 12 00:51:06.570: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Running", Reason="", readiness=false. Elapsed: 4.032452273s
Nov 12 00:51:08.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033199706s
Nov 12 00:51:08.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c" satisfied condition "Succeeded or Failed"
Nov 12 00:51:08.604: INFO: Got logs for pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 00:51:08.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7686" for this suite. 11/12/22 00:51:08.623
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":320,"skipped":6065,"failed":0}
------------------------------
• [SLOW TEST] [6.209 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:02.437
    Nov 12 00:51:02.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context-test 11/12/22 00:51:02.439
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:02.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:02.494
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Nov 12 00:51:02.538: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c" in namespace "security-context-test-7686" to be "Succeeded or Failed"
    Nov 12 00:51:02.554: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.85331ms
    Nov 12 00:51:04.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Running", Reason="", readiness=true. Elapsed: 2.033186238s
    Nov 12 00:51:06.570: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Running", Reason="", readiness=false. Elapsed: 4.032452273s
    Nov 12 00:51:08.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033199706s
    Nov 12 00:51:08.571: INFO: Pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c" satisfied condition "Succeeded or Failed"
    Nov 12 00:51:08.604: INFO: Got logs for pod "busybox-privileged-false-9815b73d-adbf-40a5-b538-ad622914763c": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 00:51:08.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7686" for this suite. 11/12/22 00:51:08.623
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:08.655
Nov 12 00:51:08.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 00:51:08.657
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:08.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:08.715
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Nov 12 00:51:08.726: INFO: Creating deployment "webserver-deployment"
Nov 12 00:51:08.746: INFO: Waiting for observed generation 1
Nov 12 00:51:10.793: INFO: Waiting for all required pods to come up
Nov 12 00:51:10.822: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 11/12/22 00:51:10.822
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-t79td" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-4rndg" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-h2cgf" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7b44m" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2p692" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ghmls" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lqxkq" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jzjrt" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-p85kk" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-smzp8" in namespace "deployment-217" to be "running"
Nov 12 00:51:10.841: INFO: Pod "webserver-deployment-845c8977d9-4rndg": Phase="Pending", Reason="", readiness=false. Elapsed: 18.588186ms
Nov 12 00:51:10.854: INFO: Pod "webserver-deployment-845c8977d9-jzjrt": Phase="Pending", Reason="", readiness=false. Elapsed: 30.572952ms
Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-p85kk": Phase="Pending", Reason="", readiness=false. Elapsed: 30.754922ms
Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-t79td": Phase="Pending", Reason="", readiness=false. Elapsed: 32.215633ms
Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-2p692": Phase="Pending", Reason="", readiness=false. Elapsed: 31.722027ms
Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-smzp8": Phase="Pending", Reason="", readiness=false. Elapsed: 31.133359ms
Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-lqxkq": Phase="Pending", Reason="", readiness=false. Elapsed: 31.827433ms
Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-h2cgf": Phase="Pending", Reason="", readiness=false. Elapsed: 32.745081ms
Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-7b44m": Phase="Pending", Reason="", readiness=false. Elapsed: 32.702914ms
Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-ghmls": Phase="Pending", Reason="", readiness=false. Elapsed: 32.487083ms
Nov 12 00:51:12.862: INFO: Pod "webserver-deployment-845c8977d9-4rndg": Phase="Running", Reason="", readiness=true. Elapsed: 2.039387074s
Nov 12 00:51:12.862: INFO: Pod "webserver-deployment-845c8977d9-4rndg" satisfied condition "running"
Nov 12 00:51:12.871: INFO: Pod "webserver-deployment-845c8977d9-jzjrt": Phase="Running", Reason="", readiness=true. Elapsed: 2.047294592s
Nov 12 00:51:12.871: INFO: Pod "webserver-deployment-845c8977d9-jzjrt" satisfied condition "running"
Nov 12 00:51:12.876: INFO: Pod "webserver-deployment-845c8977d9-2p692": Phase="Running", Reason="", readiness=true. Elapsed: 2.053230007s
Nov 12 00:51:12.876: INFO: Pod "webserver-deployment-845c8977d9-2p692" satisfied condition "running"
Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-ghmls": Phase="Running", Reason="", readiness=true. Elapsed: 2.053344024s
Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-ghmls" satisfied condition "running"
Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-lqxkq": Phase="Running", Reason="", readiness=true. Elapsed: 2.053439401s
Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-lqxkq" satisfied condition "running"
Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-7b44m": Phase="Running", Reason="", readiness=true. Elapsed: 2.055152599s
Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-7b44m" satisfied condition "running"
Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-t79td": Phase="Running", Reason="", readiness=true. Elapsed: 2.055838215s
Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-t79td" satisfied condition "running"
Nov 12 00:51:12.879: INFO: Pod "webserver-deployment-845c8977d9-smzp8": Phase="Running", Reason="", readiness=true. Elapsed: 2.054576812s
Nov 12 00:51:12.879: INFO: Pod "webserver-deployment-845c8977d9-smzp8" satisfied condition "running"
Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-p85kk": Phase="Running", Reason="", readiness=true. Elapsed: 2.058664845s
Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-p85kk" satisfied condition "running"
Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-h2cgf": Phase="Running", Reason="", readiness=true. Elapsed: 2.060342335s
Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-h2cgf" satisfied condition "running"
Nov 12 00:51:12.883: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 12 00:51:12.913: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 12 00:51:12.951: INFO: Updating deployment webserver-deployment
Nov 12 00:51:12.951: INFO: Waiting for observed generation 2
Nov 12 00:51:14.981: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 12 00:51:14.997: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 12 00:51:15.016: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 12 00:51:15.063: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 12 00:51:15.063: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 12 00:51:15.080: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 12 00:51:15.111: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 12 00:51:15.111: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 12 00:51:15.144: INFO: Updating deployment webserver-deployment
Nov 12 00:51:15.144: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 12 00:51:15.181: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 12 00:51:17.289: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 00:51:17.328: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-217  d04939df-0e28-4cd1-8b4b-bc898f828571 46014 3 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003dbaab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 00:51:15 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-12 00:51:15 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 12 00:51:17.356: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-217  7553ab6f-de36-42bd-b602-7241050b4ffb 46008 3 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d04939df-0e28-4cd1-8b4b-bc898f828571 0xc005125957 0xc005125958}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d04939df-0e28-4cd1-8b4b-bc898f828571\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051259f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:51:17.356: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 12 00:51:17.356: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-217  aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 46005 3 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d04939df-0e28-4cd1-8b4b-bc898f828571 0xc005125a57 0xc005125a58}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d04939df-0e28-4cd1-8b4b-bc898f828571\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005125ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:51:17.397: INFO: Pod "webserver-deployment-69b7448995-772p8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-772p8 webserver-deployment-69b7448995- deployment-217  b4bce1e5-c188-4f3e-8e2a-776a9e5f7e82 46082 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:84d35e426b78c12dd9873a53e9d666ceb03635298c9ad963f830a9c1bd009681 cni.projectcalico.org/podIP:172.30.188.198/32 cni.projectcalico.org/podIPs:172.30.188.198/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbaee7 0xc003dbaee8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dzhpr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dzhpr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.398: INFO: Pod "webserver-deployment-69b7448995-7dgcs" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7dgcs webserver-deployment-69b7448995- deployment-217  f1bcf662-3891-4332-9c8b-c29bbebf1098 46016 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbb7b7 0xc003dbb7b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cxr9w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cxr9w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.399: INFO: Pod "webserver-deployment-69b7448995-9pcv6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9pcv6 webserver-deployment-69b7448995- deployment-217  54e34560-7e32-4541-91c4-3bbd9c76e37f 46032 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbbd47 0xc003dbbd48}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29f6z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29f6z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.399: INFO: Pod "webserver-deployment-69b7448995-ddzp9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ddzp9 webserver-deployment-69b7448995- deployment-217  34f4f3fc-4f4b-472b-b322-74d1b1d441de 46019 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c017 0xc00483c018}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jrnv2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jrnv2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.400: INFO: Pod "webserver-deployment-69b7448995-j4j4c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-j4j4c webserver-deployment-69b7448995- deployment-217  574b444c-8b4f-48dc-8024-a4181cc73ea7 46100 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:50356e6e41577a1298eef7326d562ec41cbe847d84d1ebf1988cbf571180364d cni.projectcalico.org/podIP:172.30.194.118/32 cni.projectcalico.org/podIPs:172.30.194.118/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c217 0xc00483c218}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c2nsl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2nsl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.400: INFO: Pod "webserver-deployment-69b7448995-kp4g7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-kp4g7 webserver-deployment-69b7448995- deployment-217  95109332-f83d-498b-b916-7989dcb6cc25 46035 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c427 0xc00483c428}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cqlkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cqlkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.401: INFO: Pod "webserver-deployment-69b7448995-lg6jf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lg6jf webserver-deployment-69b7448995- deployment-217  64fe9682-acf4-453f-8e6d-3d3e9b4faa1f 46048 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c617 0xc00483c618}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qznqv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qznqv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.401: INFO: Pod "webserver-deployment-69b7448995-lzd2h" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lzd2h webserver-deployment-69b7448995- deployment-217  519c20f4-c0a7-418b-bc02-a4a671091da3 45926 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:36f66bd0b6922e07ec80cb26421449caba59c332c4b3aac06a18ed7128a6970f cni.projectcalico.org/podIP:172.30.146.59/32 cni.projectcalico.org/podIPs:172.30.146.59/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c837 0xc00483c838}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q7plv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q7plv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.402: INFO: Pod "webserver-deployment-69b7448995-mpp7n" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mpp7n webserver-deployment-69b7448995- deployment-217  9d938116-8aab-4d98-b318-08f7cc050f38 46080 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:12c3c6f449dff412a0d1c5598bcd5dc88beb32b3de350fd315454c5e90f40361 cni.projectcalico.org/podIP:172.30.194.123/32 cni.projectcalico.org/podIPs:172.30.194.123/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483ca57 0xc00483ca58}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.123\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rkhv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rkhv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.123,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.123,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.402: INFO: Pod "webserver-deployment-69b7448995-n7f8k" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-n7f8k webserver-deployment-69b7448995- deployment-217  5138d836-bceb-4677-97e8-d3a875454417 46086 0 2022-11-12 00:51:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d621da61dbf487b1f47bed96ebb4e2173d501b8fcc2e0ba87b61e8d47a395ead cni.projectcalico.org/podIP:172.30.194.126/32 cni.projectcalico.org/podIPs:172.30.194.126/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483cca7 0xc00483cca8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.126\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7k4jh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7k4jh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.126,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.126,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.403: INFO: Pod "webserver-deployment-69b7448995-qxk45" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qxk45 webserver-deployment-69b7448995- deployment-217  ea14cc40-ae59-4074-975f-35f64ab0714d 46111 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:11a978f753b70d286bbc4fe9241ac1e03190fc461d3c0b6c255b1d2e3a9271c4 cni.projectcalico.org/podIP:172.30.188.228/32 cni.projectcalico.org/podIPs:172.30.188.228/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483cee7 0xc00483cee8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.228\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vh8rg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vh8rg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.228,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.228,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.403: INFO: Pod "webserver-deployment-69b7448995-s4zlv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-s4zlv webserver-deployment-69b7448995- deployment-217  55301cb9-4cf4-494b-a07b-f4df7c674845 45941 0 2022-11-12 00:51:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3f3a45eadcf2d3f06007b67904c88096e4aeb4355a298da2b2a5d2eb055a8a3c cni.projectcalico.org/podIP:172.30.146.14/32 cni.projectcalico.org/podIPs:172.30.146.14/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483d147 0xc00483d148}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhf5m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhf5m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.404: INFO: Pod "webserver-deployment-69b7448995-v54pg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-v54pg webserver-deployment-69b7448995- deployment-217  d5ecd453-b6ec-4eed-bc84-e88ff34e52d8 46101 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:039139c5db6930348d4564fd8f4f9daef0f8f5ab2be048fb28070b205446febf cni.projectcalico.org/podIP:172.30.188.205/32 cni.projectcalico.org/podIPs:172.30.188.205/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483d357 0xc00483d358}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b95mm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b95mm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.404: INFO: Pod "webserver-deployment-845c8977d9-4rndg" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4rndg webserver-deployment-845c8977d9- deployment-217  0a9476dd-9712-4dff-aab5-7142dfe8759e 45823 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b5b686a328ae28cbc7f50d0fe2b7d40baa0451c52da50f04233a08ed018ae8c8 cni.projectcalico.org/podIP:172.30.146.53/32 cni.projectcalico.org/podIPs:172.30.146.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483d5b7 0xc00483d5b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jtslj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jtslj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.53,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6c7085f482a8f016e0f2b15b5ca831b7fc4255f343d7d37f0a7c02c2fe33d44a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.405: INFO: Pod "webserver-deployment-845c8977d9-67nx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-67nx9 webserver-deployment-845c8977d9- deployment-217  46ce87cd-7c11-44fc-91ae-ee96979fe6fc 46124 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fb38f8c44494d3b83121647abeed72cebba91d0faf21b79640f02829b0d7af97 cni.projectcalico.org/podIP:172.30.188.229/32 cni.projectcalico.org/podIPs:172.30.188.229/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483d7e7 0xc00483d7e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p6hpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p6hpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.406: INFO: Pod "webserver-deployment-845c8977d9-6qdl8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6qdl8 webserver-deployment-845c8977d9- deployment-217  6756d0fe-8b0c-40b2-9422-dec931d1ed46 46122 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:00f21d14f969ad811e8e6cbaf063248be52c87f5b15b6466d7626fd82082d7af cni.projectcalico.org/podIP:172.30.146.60/32 cni.projectcalico.org/podIPs:172.30.146.60/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483da57 0xc00483da58}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n7d9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n7d9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.406: INFO: Pod "webserver-deployment-845c8977d9-7b44m" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7b44m webserver-deployment-845c8977d9- deployment-217  de330955-d33f-4f1f-9c37-47af954d3f89 45816 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:debe5b223757bf424c90d24e409544a3b0a58a6d4aa85c5c2471dd771942133b cni.projectcalico.org/podIP:172.30.194.70/32 cni.projectcalico.org/podIPs:172.30.194.70/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483dc77 0xc00483dc78}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.70\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v9tht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v9tht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.70,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b68073e3ff70b0cb6c66de97d45b0fa9beb68428fefc90934c0a5e952ca77b4a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.407: INFO: Pod "webserver-deployment-845c8977d9-dzfh6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dzfh6 webserver-deployment-845c8977d9- deployment-217  6481453a-12d0-4b7d-8345-70775169beb5 46023 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483deb7 0xc00483deb8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nnl5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nnl5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.407: INFO: Pod "webserver-deployment-845c8977d9-ghmls" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ghmls webserver-deployment-845c8977d9- deployment-217  72a970ea-de15-40b5-962b-48eca6257ccc 45838 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:89088403a1642ca110fe617fc5a5fa73a78be77c617b4ad8b50779a5cbdcde68 cni.projectcalico.org/podIP:172.30.188.245/32 cni.projectcalico.org/podIPs:172.30.188.245/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946157 0xc004946158}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.245\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4kcw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4kcw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.245,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1066d6834cfb9e535c3a10dc5d8a6c9c5f27d96025da64c157776d8fa22aa71b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.245,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-h2cgf" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-h2cgf webserver-deployment-845c8977d9- deployment-217  f1607647-541d-4552-8238-72eb6c371c49 45842 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:035ccc4ecf813f3c18a739ee2f167533f3029c9cdfc52ae158242f5c596ca285 cni.projectcalico.org/podIP:172.30.194.69/32 cni.projectcalico.org/podIPs:172.30.194.69/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946387 0xc004946388}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zkchk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zkchk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.69,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7e2f15cb2170ba6b377ba2ee1e6690ba7607c5ea4aa98df6f4f27fbe0dfdd97e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-jzjrt" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jzjrt webserver-deployment-845c8977d9- deployment-217  86f5518d-f993-4950-89a2-9220eedc5a26 45845 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3f5f7267e9768f74bc8d8c5e7b6af7f394f6d35d6159ebfd08a0297597210c4a cni.projectcalico.org/podIP:172.30.194.65/32 cni.projectcalico.org/podIPs:172.30.194.65/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049465b7 0xc0049465b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w5242,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w5242,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.65,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://997407690707f92a3003a3eb41e3055073a59636bcb58e797f5f4386298deeee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-kj4bn" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kj4bn webserver-deployment-845c8977d9- deployment-217  92d5d7c6-194d-4f8b-bba5-ed5b5fe6fa0f 46084 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2d237623199662cc8d29ed9e79001a82e4acda3b236778eac0118c032d377db1 cni.projectcalico.org/podIP:172.30.194.117/32 cni.projectcalico.org/podIPs:172.30.194.117/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049467c7 0xc0049467c8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-58v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-58v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-lqxkq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lqxkq webserver-deployment-845c8977d9- deployment-217  93fb6fdf-cdb3-459c-9312-b8a30a928348 45854 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:42950df373bdd19b53eba8774de7ffe61be17a00aca5e15677f9e4d08366e898 cni.projectcalico.org/podIP:172.30.146.16/32 cni.projectcalico.org/podIPs:172.30.146.16/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049469d7 0xc0049469d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-td94s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-td94s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.16,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://39d65467df872be0b38aba569422df864cbb77e23ee7e09de3cce859478c3609,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-mjbfk" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mjbfk webserver-deployment-845c8977d9- deployment-217  a128b5ba-9b90-4140-8138-0195c691281e 46099 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6b9655af98fbe6db184bfddefd574fa7cf40291f26d6f150d171033d221e80d2 cni.projectcalico.org/podIP:172.30.146.61/32 cni.projectcalico.org/podIPs:172.30.146.61/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946c17 0xc004946c18}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dx2nb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dx2nb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-p85kk" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p85kk webserver-deployment-845c8977d9- deployment-217  46d4b136-f998-480f-8afb-5c01233dd9bc 45804 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:48cb52d29eaafba377e760dbee60c1cf78efc4760652a6356e419657fa8cb24d cni.projectcalico.org/podIP:172.30.188.242/32 cni.projectcalico.org/podIPs:172.30.188.242/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946e07 0xc004946e08}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.242\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtdh7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtdh7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.242,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9a9b8e503021a2d53814771987add89398d0a774f184e9927879e3d9a5c9d420,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-rjq2q" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rjq2q webserver-deployment-845c8977d9- deployment-217  ea1f32bb-d546-4e23-a67e-3ab57ba41807 46087 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e1408c0b76631893fca65e07b2ab8a02eab25f8a01477415d40b0dadc7f0f763 cni.projectcalico.org/podIP:172.30.146.15/32 cni.projectcalico.org/podIPs:172.30.146.15/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947037 0xc004947038}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lbhhp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lbhhp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-sb8wc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sb8wc webserver-deployment-845c8977d9- deployment-217  2c68171b-1d21-44e5-b4ec-9a60b0cfacc7 46040 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947237 0xc004947238}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49hth,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49hth,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.410: INFO: Pod "webserver-deployment-845c8977d9-scfg9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-scfg9 webserver-deployment-845c8977d9- deployment-217  2143c344-f94a-4cd6-bd32-9f32b08035b4 46037 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947407 0xc004947408}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2xql,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2xql,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.410: INFO: Pod "webserver-deployment-845c8977d9-t79td" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-t79td webserver-deployment-845c8977d9- deployment-217  44363071-dd08-4e8f-a361-4178e2dd7cf0 45836 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b96e76ee6b60adcd3f1aa12cd076b180460f21efdb8a69f341d29a20a730f7c5 cni.projectcalico.org/podIP:172.30.188.240/32 cni.projectcalico.org/podIPs:172.30.188.240/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049475d7 0xc0049475d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.240\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7sfp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7sfp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.240,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://15e38d2b966e2f70e878076f2620d7afd47c474f692234c2c3ee0fa86939266c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.240,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.411: INFO: Pod "webserver-deployment-845c8977d9-tqxq8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tqxq8 webserver-deployment-845c8977d9- deployment-217  e7b09d2e-4308-4a7e-ab22-3d15be1f2d3d 46107 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6ac0d160eb40be618b56d082a606faaf8116d3ccef6f301e2946c9c029e57539 cni.projectcalico.org/podIP:172.30.188.246/32 cni.projectcalico.org/podIPs:172.30.188.246/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049477e7 0xc0049477e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hnrmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hnrmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.411: INFO: Pod "webserver-deployment-845c8977d9-v9bx6" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-v9bx6 webserver-deployment-845c8977d9- deployment-217  e360e4a8-ef82-44a6-8f01-f0b5fc151829 46001 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049479d7 0xc0049479d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5cdpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5cdpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.412: INFO: Pod "webserver-deployment-845c8977d9-xtkcp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xtkcp webserver-deployment-845c8977d9- deployment-217  36a884cd-9104-4f60-80b5-ad989ee50be5 46053 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947ba7 0xc004947ba8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vwpff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vwpff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 00:51:17.412: INFO: Pod "webserver-deployment-845c8977d9-zcc6x" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zcc6x webserver-deployment-845c8977d9- deployment-217  72958420-88e4-4b41-8dd4-61cde616d665 46116 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:afe6c84793605c1465efd7ddfadee757927e9aff6138258454377552bfcc685e cni.projectcalico.org/podIP:172.30.194.119/32 cni.projectcalico.org/podIPs:172.30.194.119/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947d77 0xc004947d78}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4w5sd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4w5sd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 00:51:17.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-217" for this suite. 11/12/22 00:51:17.435
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":321,"skipped":6099,"failed":0}
------------------------------
• [SLOW TEST] [8.806 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:08.655
    Nov 12 00:51:08.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 00:51:08.657
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:08.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:08.715
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Nov 12 00:51:08.726: INFO: Creating deployment "webserver-deployment"
    Nov 12 00:51:08.746: INFO: Waiting for observed generation 1
    Nov 12 00:51:10.793: INFO: Waiting for all required pods to come up
    Nov 12 00:51:10.822: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 11/12/22 00:51:10.822
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-t79td" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-4rndg" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-h2cgf" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-7b44m" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2p692" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.823: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ghmls" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lqxkq" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-jzjrt" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-p85kk" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.824: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-smzp8" in namespace "deployment-217" to be "running"
    Nov 12 00:51:10.841: INFO: Pod "webserver-deployment-845c8977d9-4rndg": Phase="Pending", Reason="", readiness=false. Elapsed: 18.588186ms
    Nov 12 00:51:10.854: INFO: Pod "webserver-deployment-845c8977d9-jzjrt": Phase="Pending", Reason="", readiness=false. Elapsed: 30.572952ms
    Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-p85kk": Phase="Pending", Reason="", readiness=false. Elapsed: 30.754922ms
    Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-t79td": Phase="Pending", Reason="", readiness=false. Elapsed: 32.215633ms
    Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-2p692": Phase="Pending", Reason="", readiness=false. Elapsed: 31.722027ms
    Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-smzp8": Phase="Pending", Reason="", readiness=false. Elapsed: 31.133359ms
    Nov 12 00:51:10.855: INFO: Pod "webserver-deployment-845c8977d9-lqxkq": Phase="Pending", Reason="", readiness=false. Elapsed: 31.827433ms
    Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-h2cgf": Phase="Pending", Reason="", readiness=false. Elapsed: 32.745081ms
    Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-7b44m": Phase="Pending", Reason="", readiness=false. Elapsed: 32.702914ms
    Nov 12 00:51:10.856: INFO: Pod "webserver-deployment-845c8977d9-ghmls": Phase="Pending", Reason="", readiness=false. Elapsed: 32.487083ms
    Nov 12 00:51:12.862: INFO: Pod "webserver-deployment-845c8977d9-4rndg": Phase="Running", Reason="", readiness=true. Elapsed: 2.039387074s
    Nov 12 00:51:12.862: INFO: Pod "webserver-deployment-845c8977d9-4rndg" satisfied condition "running"
    Nov 12 00:51:12.871: INFO: Pod "webserver-deployment-845c8977d9-jzjrt": Phase="Running", Reason="", readiness=true. Elapsed: 2.047294592s
    Nov 12 00:51:12.871: INFO: Pod "webserver-deployment-845c8977d9-jzjrt" satisfied condition "running"
    Nov 12 00:51:12.876: INFO: Pod "webserver-deployment-845c8977d9-2p692": Phase="Running", Reason="", readiness=true. Elapsed: 2.053230007s
    Nov 12 00:51:12.876: INFO: Pod "webserver-deployment-845c8977d9-2p692" satisfied condition "running"
    Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-ghmls": Phase="Running", Reason="", readiness=true. Elapsed: 2.053344024s
    Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-ghmls" satisfied condition "running"
    Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-lqxkq": Phase="Running", Reason="", readiness=true. Elapsed: 2.053439401s
    Nov 12 00:51:12.877: INFO: Pod "webserver-deployment-845c8977d9-lqxkq" satisfied condition "running"
    Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-7b44m": Phase="Running", Reason="", readiness=true. Elapsed: 2.055152599s
    Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-7b44m" satisfied condition "running"
    Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-t79td": Phase="Running", Reason="", readiness=true. Elapsed: 2.055838215s
    Nov 12 00:51:12.878: INFO: Pod "webserver-deployment-845c8977d9-t79td" satisfied condition "running"
    Nov 12 00:51:12.879: INFO: Pod "webserver-deployment-845c8977d9-smzp8": Phase="Running", Reason="", readiness=true. Elapsed: 2.054576812s
    Nov 12 00:51:12.879: INFO: Pod "webserver-deployment-845c8977d9-smzp8" satisfied condition "running"
    Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-p85kk": Phase="Running", Reason="", readiness=true. Elapsed: 2.058664845s
    Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-p85kk" satisfied condition "running"
    Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-h2cgf": Phase="Running", Reason="", readiness=true. Elapsed: 2.060342335s
    Nov 12 00:51:12.883: INFO: Pod "webserver-deployment-845c8977d9-h2cgf" satisfied condition "running"
    Nov 12 00:51:12.883: INFO: Waiting for deployment "webserver-deployment" to complete
    Nov 12 00:51:12.913: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Nov 12 00:51:12.951: INFO: Updating deployment webserver-deployment
    Nov 12 00:51:12.951: INFO: Waiting for observed generation 2
    Nov 12 00:51:14.981: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Nov 12 00:51:14.997: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Nov 12 00:51:15.016: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 00:51:15.063: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Nov 12 00:51:15.063: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Nov 12 00:51:15.080: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 00:51:15.111: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Nov 12 00:51:15.111: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Nov 12 00:51:15.144: INFO: Updating deployment webserver-deployment
    Nov 12 00:51:15.144: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 00:51:15.181: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Nov 12 00:51:17.289: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 00:51:17.328: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-217  d04939df-0e28-4cd1-8b4b-bc898f828571 46014 3 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003dbaab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 00:51:15 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-12 00:51:15 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Nov 12 00:51:17.356: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-217  7553ab6f-de36-42bd-b602-7241050b4ffb 46008 3 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d04939df-0e28-4cd1-8b4b-bc898f828571 0xc005125957 0xc005125958}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d04939df-0e28-4cd1-8b4b-bc898f828571\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0051259f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:51:17.356: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Nov 12 00:51:17.356: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-217  aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 46005 3 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d04939df-0e28-4cd1-8b4b-bc898f828571 0xc005125a57 0xc005125a58}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d04939df-0e28-4cd1-8b4b-bc898f828571\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005125ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:51:17.397: INFO: Pod "webserver-deployment-69b7448995-772p8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-772p8 webserver-deployment-69b7448995- deployment-217  b4bce1e5-c188-4f3e-8e2a-776a9e5f7e82 46082 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:84d35e426b78c12dd9873a53e9d666ceb03635298c9ad963f830a9c1bd009681 cni.projectcalico.org/podIP:172.30.188.198/32 cni.projectcalico.org/podIPs:172.30.188.198/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbaee7 0xc003dbaee8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dzhpr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dzhpr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.398: INFO: Pod "webserver-deployment-69b7448995-7dgcs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7dgcs webserver-deployment-69b7448995- deployment-217  f1bcf662-3891-4332-9c8b-c29bbebf1098 46016 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbb7b7 0xc003dbb7b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cxr9w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cxr9w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.399: INFO: Pod "webserver-deployment-69b7448995-9pcv6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9pcv6 webserver-deployment-69b7448995- deployment-217  54e34560-7e32-4541-91c4-3bbd9c76e37f 46032 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc003dbbd47 0xc003dbbd48}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-29f6z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-29f6z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.399: INFO: Pod "webserver-deployment-69b7448995-ddzp9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ddzp9 webserver-deployment-69b7448995- deployment-217  34f4f3fc-4f4b-472b-b322-74d1b1d441de 46019 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c017 0xc00483c018}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jrnv2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jrnv2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.400: INFO: Pod "webserver-deployment-69b7448995-j4j4c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-j4j4c webserver-deployment-69b7448995- deployment-217  574b444c-8b4f-48dc-8024-a4181cc73ea7 46100 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:50356e6e41577a1298eef7326d562ec41cbe847d84d1ebf1988cbf571180364d cni.projectcalico.org/podIP:172.30.194.118/32 cni.projectcalico.org/podIPs:172.30.194.118/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c217 0xc00483c218}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c2nsl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2nsl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.400: INFO: Pod "webserver-deployment-69b7448995-kp4g7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-kp4g7 webserver-deployment-69b7448995- deployment-217  95109332-f83d-498b-b916-7989dcb6cc25 46035 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c427 0xc00483c428}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cqlkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cqlkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.401: INFO: Pod "webserver-deployment-69b7448995-lg6jf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lg6jf webserver-deployment-69b7448995- deployment-217  64fe9682-acf4-453f-8e6d-3d3e9b4faa1f 46048 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c617 0xc00483c618}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qznqv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qznqv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.401: INFO: Pod "webserver-deployment-69b7448995-lzd2h" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lzd2h webserver-deployment-69b7448995- deployment-217  519c20f4-c0a7-418b-bc02-a4a671091da3 45926 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:36f66bd0b6922e07ec80cb26421449caba59c332c4b3aac06a18ed7128a6970f cni.projectcalico.org/podIP:172.30.146.59/32 cni.projectcalico.org/podIPs:172.30.146.59/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483c837 0xc00483c838}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q7plv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q7plv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.402: INFO: Pod "webserver-deployment-69b7448995-mpp7n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mpp7n webserver-deployment-69b7448995- deployment-217  9d938116-8aab-4d98-b318-08f7cc050f38 46080 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:12c3c6f449dff412a0d1c5598bcd5dc88beb32b3de350fd315454c5e90f40361 cni.projectcalico.org/podIP:172.30.194.123/32 cni.projectcalico.org/podIPs:172.30.194.123/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483ca57 0xc00483ca58}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.123\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rkhv5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rkhv5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.123,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.123,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.402: INFO: Pod "webserver-deployment-69b7448995-n7f8k" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-n7f8k webserver-deployment-69b7448995- deployment-217  5138d836-bceb-4677-97e8-d3a875454417 46086 0 2022-11-12 00:51:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d621da61dbf487b1f47bed96ebb4e2173d501b8fcc2e0ba87b61e8d47a395ead cni.projectcalico.org/podIP:172.30.194.126/32 cni.projectcalico.org/podIPs:172.30.194.126/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483cca7 0xc00483cca8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.126\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7k4jh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7k4jh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.126,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.126,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.403: INFO: Pod "webserver-deployment-69b7448995-qxk45" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qxk45 webserver-deployment-69b7448995- deployment-217  ea14cc40-ae59-4074-975f-35f64ab0714d 46111 0 2022-11-12 00:51:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:11a978f753b70d286bbc4fe9241ac1e03190fc461d3c0b6c255b1d2e3a9271c4 cni.projectcalico.org/podIP:172.30.188.228/32 cni.projectcalico.org/podIPs:172.30.188.228/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483cee7 0xc00483cee8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.228\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vh8rg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vh8rg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.228,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to unpack image on snapshotter overlayfs: unexpected media type text/html for sha256:d3db295fa28276785a6ae443241e4f527b103321204cd7be9b10d9ccbe40b68b: not found,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.228,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.403: INFO: Pod "webserver-deployment-69b7448995-s4zlv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-s4zlv webserver-deployment-69b7448995- deployment-217  55301cb9-4cf4-494b-a07b-f4df7c674845 45941 0 2022-11-12 00:51:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3f3a45eadcf2d3f06007b67904c88096e4aeb4355a298da2b2a5d2eb055a8a3c cni.projectcalico.org/podIP:172.30.146.14/32 cni.projectcalico.org/podIPs:172.30.146.14/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483d147 0xc00483d148}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhf5m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhf5m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.404: INFO: Pod "webserver-deployment-69b7448995-v54pg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-v54pg webserver-deployment-69b7448995- deployment-217  d5ecd453-b6ec-4eed-bc84-e88ff34e52d8 46101 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:039139c5db6930348d4564fd8f4f9daef0f8f5ab2be048fb28070b205446febf cni.projectcalico.org/podIP:172.30.188.205/32 cni.projectcalico.org/podIPs:172.30.188.205/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 7553ab6f-de36-42bd-b602-7241050b4ffb 0xc00483d357 0xc00483d358}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7553ab6f-de36-42bd-b602-7241050b4ffb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b95mm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b95mm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.404: INFO: Pod "webserver-deployment-845c8977d9-4rndg" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4rndg webserver-deployment-845c8977d9- deployment-217  0a9476dd-9712-4dff-aab5-7142dfe8759e 45823 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b5b686a328ae28cbc7f50d0fe2b7d40baa0451c52da50f04233a08ed018ae8c8 cni.projectcalico.org/podIP:172.30.146.53/32 cni.projectcalico.org/podIPs:172.30.146.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483d5b7 0xc00483d5b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jtslj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jtslj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.53,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6c7085f482a8f016e0f2b15b5ca831b7fc4255f343d7d37f0a7c02c2fe33d44a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.405: INFO: Pod "webserver-deployment-845c8977d9-67nx9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-67nx9 webserver-deployment-845c8977d9- deployment-217  46ce87cd-7c11-44fc-91ae-ee96979fe6fc 46124 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:fb38f8c44494d3b83121647abeed72cebba91d0faf21b79640f02829b0d7af97 cni.projectcalico.org/podIP:172.30.188.229/32 cni.projectcalico.org/podIPs:172.30.188.229/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483d7e7 0xc00483d7e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p6hpv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p6hpv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.406: INFO: Pod "webserver-deployment-845c8977d9-6qdl8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6qdl8 webserver-deployment-845c8977d9- deployment-217  6756d0fe-8b0c-40b2-9422-dec931d1ed46 46122 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:00f21d14f969ad811e8e6cbaf063248be52c87f5b15b6466d7626fd82082d7af cni.projectcalico.org/podIP:172.30.146.60/32 cni.projectcalico.org/podIPs:172.30.146.60/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483da57 0xc00483da58}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n7d9m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n7d9m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.406: INFO: Pod "webserver-deployment-845c8977d9-7b44m" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7b44m webserver-deployment-845c8977d9- deployment-217  de330955-d33f-4f1f-9c37-47af954d3f89 45816 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:debe5b223757bf424c90d24e409544a3b0a58a6d4aa85c5c2471dd771942133b cni.projectcalico.org/podIP:172.30.194.70/32 cni.projectcalico.org/podIPs:172.30.194.70/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483dc77 0xc00483dc78}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.70\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v9tht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v9tht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.70,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b68073e3ff70b0cb6c66de97d45b0fa9beb68428fefc90934c0a5e952ca77b4a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.407: INFO: Pod "webserver-deployment-845c8977d9-dzfh6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dzfh6 webserver-deployment-845c8977d9- deployment-217  6481453a-12d0-4b7d-8345-70775169beb5 46023 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc00483deb7 0xc00483deb8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nnl5d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nnl5d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.407: INFO: Pod "webserver-deployment-845c8977d9-ghmls" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ghmls webserver-deployment-845c8977d9- deployment-217  72a970ea-de15-40b5-962b-48eca6257ccc 45838 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:89088403a1642ca110fe617fc5a5fa73a78be77c617b4ad8b50779a5cbdcde68 cni.projectcalico.org/podIP:172.30.188.245/32 cni.projectcalico.org/podIPs:172.30.188.245/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946157 0xc004946158}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.245\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4kcw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4kcw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.245,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1066d6834cfb9e535c3a10dc5d8a6c9c5f27d96025da64c157776d8fa22aa71b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.245,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-h2cgf" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-h2cgf webserver-deployment-845c8977d9- deployment-217  f1607647-541d-4552-8238-72eb6c371c49 45842 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:035ccc4ecf813f3c18a739ee2f167533f3029c9cdfc52ae158242f5c596ca285 cni.projectcalico.org/podIP:172.30.194.69/32 cni.projectcalico.org/podIPs:172.30.194.69/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946387 0xc004946388}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zkchk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zkchk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.69,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7e2f15cb2170ba6b377ba2ee1e6690ba7607c5ea4aa98df6f4f27fbe0dfdd97e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-jzjrt" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jzjrt webserver-deployment-845c8977d9- deployment-217  86f5518d-f993-4950-89a2-9220eedc5a26 45845 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:3f5f7267e9768f74bc8d8c5e7b6af7f394f6d35d6159ebfd08a0297597210c4a cni.projectcalico.org/podIP:172.30.194.65/32 cni.projectcalico.org/podIPs:172.30.194.65/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049465b7 0xc0049465b8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w5242,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w5242,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:172.30.194.65,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://997407690707f92a3003a3eb41e3055073a59636bcb58e797f5f4386298deeee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.194.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-kj4bn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kj4bn webserver-deployment-845c8977d9- deployment-217  92d5d7c6-194d-4f8b-bba5-ed5b5fe6fa0f 46084 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:2d237623199662cc8d29ed9e79001a82e4acda3b236778eac0118c032d377db1 cni.projectcalico.org/podIP:172.30.194.117/32 cni.projectcalico.org/podIPs:172.30.194.117/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049467c7 0xc0049467c8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-58v49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-58v49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.408: INFO: Pod "webserver-deployment-845c8977d9-lqxkq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lqxkq webserver-deployment-845c8977d9- deployment-217  93fb6fdf-cdb3-459c-9312-b8a30a928348 45854 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:42950df373bdd19b53eba8774de7ffe61be17a00aca5e15677f9e4d08366e898 cni.projectcalico.org/podIP:172.30.146.16/32 cni.projectcalico.org/podIPs:172.30.146.16/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049469d7 0xc0049469d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.16\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-td94s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-td94s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.16,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://39d65467df872be0b38aba569422df864cbb77e23ee7e09de3cce859478c3609,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-mjbfk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mjbfk webserver-deployment-845c8977d9- deployment-217  a128b5ba-9b90-4140-8138-0195c691281e 46099 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6b9655af98fbe6db184bfddefd574fa7cf40291f26d6f150d171033d221e80d2 cni.projectcalico.org/podIP:172.30.146.61/32 cni.projectcalico.org/podIPs:172.30.146.61/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946c17 0xc004946c18}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dx2nb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dx2nb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-p85kk" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p85kk webserver-deployment-845c8977d9- deployment-217  46d4b136-f998-480f-8afb-5c01233dd9bc 45804 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:48cb52d29eaafba377e760dbee60c1cf78efc4760652a6356e419657fa8cb24d cni.projectcalico.org/podIP:172.30.188.242/32 cni.projectcalico.org/podIPs:172.30.188.242/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004946e07 0xc004946e08}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.242\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rtdh7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rtdh7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.242,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9a9b8e503021a2d53814771987add89398d0a774f184e9927879e3d9a5c9d420,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-rjq2q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rjq2q webserver-deployment-845c8977d9- deployment-217  ea1f32bb-d546-4e23-a67e-3ab57ba41807 46087 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:e1408c0b76631893fca65e07b2ab8a02eab25f8a01477415d40b0dadc7f0f763 cni.projectcalico.org/podIP:172.30.146.15/32 cni.projectcalico.org/podIPs:172.30.146.15/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947037 0xc004947038}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lbhhp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lbhhp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.409: INFO: Pod "webserver-deployment-845c8977d9-sb8wc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sb8wc webserver-deployment-845c8977d9- deployment-217  2c68171b-1d21-44e5-b4ec-9a60b0cfacc7 46040 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947237 0xc004947238}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49hth,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49hth,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.410: INFO: Pod "webserver-deployment-845c8977d9-scfg9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-scfg9 webserver-deployment-845c8977d9- deployment-217  2143c344-f94a-4cd6-bd32-9f32b08035b4 46037 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947407 0xc004947408}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g2xql,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g2xql,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.410: INFO: Pod "webserver-deployment-845c8977d9-t79td" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-t79td webserver-deployment-845c8977d9- deployment-217  44363071-dd08-4e8f-a361-4178e2dd7cf0 45836 0 2022-11-12 00:51:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b96e76ee6b60adcd3f1aa12cd076b180460f21efdb8a69f341d29a20a730f7c5 cni.projectcalico.org/podIP:172.30.188.240/32 cni.projectcalico.org/podIPs:172.30.188.240/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049475d7 0xc0049475d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.240\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7sfp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7sfp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:172.30.188.240,StartTime:2022-11-12 00:51:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://15e38d2b966e2f70e878076f2620d7afd47c474f692234c2c3ee0fa86939266c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.188.240,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.411: INFO: Pod "webserver-deployment-845c8977d9-tqxq8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tqxq8 webserver-deployment-845c8977d9- deployment-217  e7b09d2e-4308-4a7e-ab22-3d15be1f2d3d 46107 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:6ac0d160eb40be618b56d082a606faaf8116d3ccef6f301e2946c9c029e57539 cni.projectcalico.org/podIP:172.30.188.246/32 cni.projectcalico.org/podIPs:172.30.188.246/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049477e7 0xc0049477e8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hnrmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hnrmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.113,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.113,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.411: INFO: Pod "webserver-deployment-845c8977d9-v9bx6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-v9bx6 webserver-deployment-845c8977d9- deployment-217  e360e4a8-ef82-44a6-8f01-f0b5fc151829 46001 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc0049479d7 0xc0049479d8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5cdpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5cdpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.412: INFO: Pod "webserver-deployment-845c8977d9-xtkcp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xtkcp webserver-deployment-845c8977d9- deployment-217  36a884cd-9104-4f60-80b5-ad989ee50be5 46053 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947ba7 0xc004947ba8}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vwpff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vwpff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 00:51:17.412: INFO: Pod "webserver-deployment-845c8977d9-zcc6x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zcc6x webserver-deployment-845c8977d9- deployment-217  72958420-88e4-4b41-8dd4-61cde616d665 46116 0 2022-11-12 00:51:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:afe6c84793605c1465efd7ddfadee757927e9aff6138258454377552bfcc685e cni.projectcalico.org/podIP:172.30.194.119/32 cni.projectcalico.org/podIPs:172.30.194.119/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 aa4eafa2-30d7-45f4-843a-03d6eaf88e8d 0xc004947d77 0xc004947d78}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa4eafa2-30d7-45f4-843a-03d6eaf88e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 00:51:15 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2022-11-12 00:51:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4w5sd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4w5sd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.148.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.148.26,PodIP:,StartTime:2022-11-12 00:51:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 00:51:17.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-217" for this suite. 11/12/22 00:51:17.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:17.521
Nov 12 00:51:17.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename events 11/12/22 00:51:17.524
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:17.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:17.605
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 11/12/22 00:51:17.616
STEP: listing events in all namespaces 11/12/22 00:51:17.638
STEP: listing events in test namespace 11/12/22 00:51:17.662
STEP: listing events with field selection filtering on source 11/12/22 00:51:17.672
STEP: listing events with field selection filtering on reportingController 11/12/22 00:51:17.705
STEP: getting the test event 11/12/22 00:51:17.718
STEP: patching the test event 11/12/22 00:51:17.742
STEP: getting the test event 11/12/22 00:51:17.811
STEP: updating the test event 11/12/22 00:51:17.843
STEP: getting the test event 11/12/22 00:51:17.862
STEP: deleting the test event 11/12/22 00:51:17.876
STEP: listing events in all namespaces 11/12/22 00:51:17.905
STEP: listing events in test namespace 11/12/22 00:51:17.936
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 12 00:51:17.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8910" for this suite. 11/12/22 00:51:17.976
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":322,"skipped":6120,"failed":0}
------------------------------
• [0.476 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:17.521
    Nov 12 00:51:17.521: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename events 11/12/22 00:51:17.524
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:17.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:17.605
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 11/12/22 00:51:17.616
    STEP: listing events in all namespaces 11/12/22 00:51:17.638
    STEP: listing events in test namespace 11/12/22 00:51:17.662
    STEP: listing events with field selection filtering on source 11/12/22 00:51:17.672
    STEP: listing events with field selection filtering on reportingController 11/12/22 00:51:17.705
    STEP: getting the test event 11/12/22 00:51:17.718
    STEP: patching the test event 11/12/22 00:51:17.742
    STEP: getting the test event 11/12/22 00:51:17.811
    STEP: updating the test event 11/12/22 00:51:17.843
    STEP: getting the test event 11/12/22 00:51:17.862
    STEP: deleting the test event 11/12/22 00:51:17.876
    STEP: listing events in all namespaces 11/12/22 00:51:17.905
    STEP: listing events in test namespace 11/12/22 00:51:17.936
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 12 00:51:17.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8910" for this suite. 11/12/22 00:51:17.976
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:18.006
Nov 12 00:51:18.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename container-runtime 11/12/22 00:51:18.01
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:18.062
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:18.071
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 11/12/22 00:51:18.084
STEP: wait for the container to reach Succeeded 11/12/22 00:51:18.163
STEP: get the container status 11/12/22 00:51:24.298
STEP: the container should be terminated 11/12/22 00:51:24.319
STEP: the termination message should be set 11/12/22 00:51:24.32
Nov 12 00:51:24.320: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 11/12/22 00:51:24.32
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 00:51:24.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4673" for this suite. 11/12/22 00:51:24.441
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":323,"skipped":6131,"failed":0}
------------------------------
• [SLOW TEST] [6.456 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:18.006
    Nov 12 00:51:18.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename container-runtime 11/12/22 00:51:18.01
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:18.062
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:18.071
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 11/12/22 00:51:18.084
    STEP: wait for the container to reach Succeeded 11/12/22 00:51:18.163
    STEP: get the container status 11/12/22 00:51:24.298
    STEP: the container should be terminated 11/12/22 00:51:24.319
    STEP: the termination message should be set 11/12/22 00:51:24.32
    Nov 12 00:51:24.320: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 11/12/22 00:51:24.32
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 00:51:24.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4673" for this suite. 11/12/22 00:51:24.441
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:24.462
Nov 12 00:51:24.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 00:51:24.466
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:24.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:24.529
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Nov 12 00:51:24.603: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 12 00:51:29.627: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 00:51:29.627
Nov 12 00:51:29.627: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 12 00:51:31.655: INFO: Creating deployment "test-rollover-deployment"
Nov 12 00:51:31.715: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 12 00:51:33.744: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 12 00:51:33.779: INFO: Ensure that both replica sets have 1 created replica
Nov 12 00:51:33.815: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 12 00:51:33.852: INFO: Updating deployment test-rollover-deployment
Nov 12 00:51:33.852: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 12 00:51:35.905: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 12 00:51:35.935: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 12 00:51:35.966: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 00:51:35.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:38.000: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 00:51:38.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:40.002: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 00:51:40.002: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:42.002: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 00:51:42.002: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:44.001: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 00:51:44.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:46.007: INFO: 
Nov 12 00:51:46.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 00:51:47.995: INFO: 
Nov 12 00:51:47.995: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 00:51:48.039: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3775  93d92967-a071-400b-9318-e88ffd2538b2 46735 2 2022-11-12 00:51:31 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000547fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 00:51:31 +0000 UTC,LastTransitionTime:2022-11-12 00:51:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-12 00:51:46 +0000 UTC,LastTransitionTime:2022-11-12 00:51:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 00:51:48.056: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-3775  37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098 46725 2 2022-11-12 00:51:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a5f7 0xc004e9a5f8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e9a6a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:51:48.057: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 12 00:51:48.057: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3775  6ad7dd11-760e-4f12-b634-1489a92021ca 46734 2 2022-11-12 00:51:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a3a7 0xc004e9a3a8}] [] [{e2e.test Update apps/v1 2022-11-12 00:51:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:46 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004e9a468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:51:48.058: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-3775  62896232-e1cf-4146-bfdb-9149c14c0881 46688 2 2022-11-12 00:51:31 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a4d7 0xc004e9a4d8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e9a588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 00:51:48.074: INFO: Pod "test-rollover-deployment-6d45fd857b-mpflq" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-mpflq test-rollover-deployment-6d45fd857b- deployment-3775  09352233-8a45-4483-8928-233856e594a8 46705 0 2022-11-12 00:51:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:3f4a2b61445d185083dfd2b3d770ea59b4e8ceae34ae3321d06ac51e5841c84f cni.projectcalico.org/podIP:172.30.146.26/32 cni.projectcalico.org/podIPs:172.30.146.26/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098 0xc006471747 0xc006471748}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mk568,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mk568,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.26,StartTime:2022-11-12 00:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://0b26959a9ac0b828b14fcf3740a56bd6bc157ea4e3ac3a3dbac8f446a32d428e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 00:51:48.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3775" for this suite. 11/12/22 00:51:48.096
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":324,"skipped":6131,"failed":0}
------------------------------
• [SLOW TEST] [23.661 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:24.462
    Nov 12 00:51:24.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 00:51:24.466
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:24.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:24.529
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Nov 12 00:51:24.603: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Nov 12 00:51:29.627: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 00:51:29.627
    Nov 12 00:51:29.627: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Nov 12 00:51:31.655: INFO: Creating deployment "test-rollover-deployment"
    Nov 12 00:51:31.715: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Nov 12 00:51:33.744: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Nov 12 00:51:33.779: INFO: Ensure that both replica sets have 1 created replica
    Nov 12 00:51:33.815: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Nov 12 00:51:33.852: INFO: Updating deployment test-rollover-deployment
    Nov 12 00:51:33.852: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Nov 12 00:51:35.905: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Nov 12 00:51:35.935: INFO: Make sure deployment "test-rollover-deployment" is complete
    Nov 12 00:51:35.966: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 00:51:35.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:38.000: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 00:51:38.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:40.002: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 00:51:40.002: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:42.002: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 00:51:42.002: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:44.001: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 00:51:44.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 35, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:46.007: INFO: 
    Nov 12 00:51:46.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 45, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 00:51:47.995: INFO: 
    Nov 12 00:51:47.995: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 00:51:48.039: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-3775  93d92967-a071-400b-9318-e88ffd2538b2 46735 2 2022-11-12 00:51:31 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000547fd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 00:51:31 +0000 UTC,LastTransitionTime:2022-11-12 00:51:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-12 00:51:46 +0000 UTC,LastTransitionTime:2022-11-12 00:51:31 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 00:51:48.056: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-3775  37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098 46725 2 2022-11-12 00:51:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a5f7 0xc004e9a5f8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:45 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e9a6a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:51:48.057: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Nov 12 00:51:48.057: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3775  6ad7dd11-760e-4f12-b634-1489a92021ca 46734 2 2022-11-12 00:51:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a3a7 0xc004e9a3a8}] [] [{e2e.test Update apps/v1 2022-11-12 00:51:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:46 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004e9a468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:51:48.058: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-3775  62896232-e1cf-4146-bfdb-9149c14c0881 46688 2 2022-11-12 00:51:31 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 93d92967-a071-400b-9318-e88ffd2538b2 0xc004e9a4d7 0xc004e9a4d8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"93d92967-a071-400b-9318-e88ffd2538b2\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e9a588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 00:51:48.074: INFO: Pod "test-rollover-deployment-6d45fd857b-mpflq" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-mpflq test-rollover-deployment-6d45fd857b- deployment-3775  09352233-8a45-4483-8928-233856e594a8 46705 0 2022-11-12 00:51:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:3f4a2b61445d185083dfd2b3d770ea59b4e8ceae34ae3321d06ac51e5841c84f cni.projectcalico.org/podIP:172.30.146.26/32 cni.projectcalico.org/podIPs:172.30.146.26/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098 0xc006471747 0xc006471748}] [] [{kube-controller-manager Update v1 2022-11-12 00:51:33 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"37c7e7ab-bb8d-4da1-bef9-1a9d99ea8098\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 00:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 00:51:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mk568,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mk568,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 00:51:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.26,StartTime:2022-11-12 00:51:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 00:51:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://0b26959a9ac0b828b14fcf3740a56bd6bc157ea4e3ac3a3dbac8f446a32d428e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 00:51:48.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3775" for this suite. 11/12/22 00:51:48.096
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:48.129
Nov 12 00:51:48.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename events 11/12/22 00:51:48.131
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:48.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:48.199
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 11/12/22 00:51:48.211
STEP: get a list of Events with a label in the current namespace 11/12/22 00:51:48.269
STEP: delete a list of events 11/12/22 00:51:48.282
Nov 12 00:51:48.282: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/12/22 00:51:48.356
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 12 00:51:48.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8139" for this suite. 11/12/22 00:51:48.39
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":325,"skipped":6170,"failed":0}
------------------------------
• [0.286 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:48.129
    Nov 12 00:51:48.130: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename events 11/12/22 00:51:48.131
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:48.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:48.199
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 11/12/22 00:51:48.211
    STEP: get a list of Events with a label in the current namespace 11/12/22 00:51:48.269
    STEP: delete a list of events 11/12/22 00:51:48.282
    Nov 12 00:51:48.282: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/12/22 00:51:48.356
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 12 00:51:48.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8139" for this suite. 11/12/22 00:51:48.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:48.428
Nov 12 00:51:48.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename webhook 11/12/22 00:51:48.43
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:48.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:48.531
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 00:51:48.591
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:51:49.415
STEP: Deploying the webhook pod 11/12/22 00:51:49.441
STEP: Wait for the deployment to be ready 11/12/22 00:51:49.486
Nov 12 00:51:49.520: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 00:51:51.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:51:53.587
STEP: Verifying the service has paired with the endpoint 11/12/22 00:51:53.624
Nov 12 00:51:54.626: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 11/12/22 00:51:54.846
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 00:51:54.984
STEP: Deleting the collection of validation webhooks 11/12/22 00:51:55.131
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 00:51:55.345
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:51:55.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2606" for this suite. 11/12/22 00:51:55.405
STEP: Destroying namespace "webhook-2606-markers" for this suite. 11/12/22 00:51:55.425
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":326,"skipped":6196,"failed":0}
------------------------------
• [SLOW TEST] [7.152 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:48.428
    Nov 12 00:51:48.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename webhook 11/12/22 00:51:48.43
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:48.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:48.531
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 00:51:48.591
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 00:51:49.415
    STEP: Deploying the webhook pod 11/12/22 00:51:49.441
    STEP: Wait for the deployment to be ready 11/12/22 00:51:49.486
    Nov 12 00:51:49.520: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 00:51:51.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 51, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:51:53.587
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:51:53.624
    Nov 12 00:51:54.626: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 11/12/22 00:51:54.846
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 00:51:54.984
    STEP: Deleting the collection of validation webhooks 11/12/22 00:51:55.131
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 00:51:55.345
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:51:55.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2606" for this suite. 11/12/22 00:51:55.405
    STEP: Destroying namespace "webhook-2606-markers" for this suite. 11/12/22 00:51:55.425
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:51:55.599
Nov 12 00:51:55.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pods 11/12/22 00:51:55.602
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:55.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:55.662
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Nov 12 00:51:55.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: creating the pod 11/12/22 00:51:55.674
STEP: submitting the pod to kubernetes 11/12/22 00:51:55.674
Nov 12 00:51:55.706: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8" in namespace "pods-6222" to be "running and ready"
Nov 12 00:51:55.721: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.34388ms
Nov 12 00:51:55.721: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:51:57.766: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059397665s
Nov 12 00:51:57.766: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:51:59.744: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Running", Reason="", readiness=true. Elapsed: 4.037293546s
Nov 12 00:51:59.744: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Running (Ready = true)
Nov 12 00:51:59.744: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 00:51:59.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6222" for this suite. 11/12/22 00:52:00.004
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":327,"skipped":6241,"failed":0}
------------------------------
• [4.428 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:51:55.599
    Nov 12 00:51:55.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pods 11/12/22 00:51:55.602
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:51:55.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:51:55.662
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Nov 12 00:51:55.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: creating the pod 11/12/22 00:51:55.674
    STEP: submitting the pod to kubernetes 11/12/22 00:51:55.674
    Nov 12 00:51:55.706: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8" in namespace "pods-6222" to be "running and ready"
    Nov 12 00:51:55.721: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.34388ms
    Nov 12 00:51:55.721: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:51:57.766: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059397665s
    Nov 12 00:51:57.766: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:51:59.744: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8": Phase="Running", Reason="", readiness=true. Elapsed: 4.037293546s
    Nov 12 00:51:59.744: INFO: The phase of Pod pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8 is Running (Ready = true)
    Nov 12 00:51:59.744: INFO: Pod "pod-exec-websocket-3f9c46e8-88c4-45f0-b6f7-4c1e09c15dd8" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 00:51:59.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6222" for this suite. 11/12/22 00:52:00.004
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:00.028
Nov 12 00:52:00.028: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename namespaces 11/12/22 00:52:00.032
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:00.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:00.097
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 11/12/22 00:52:00.115
STEP: patching the Namespace 11/12/22 00:52:00.163
STEP: get the Namespace and ensuring it has the label 11/12/22 00:52:00.18
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:52:00.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1019" for this suite. 11/12/22 00:52:00.221
STEP: Destroying namespace "nspatchtest-4c7b25aa-b8d4-400f-9e74-a2d96e289a5c-2510" for this suite. 11/12/22 00:52:00.244
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":328,"skipped":6243,"failed":0}
------------------------------
• [0.245 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:00.028
    Nov 12 00:52:00.028: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename namespaces 11/12/22 00:52:00.032
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:00.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:00.097
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 11/12/22 00:52:00.115
    STEP: patching the Namespace 11/12/22 00:52:00.163
    STEP: get the Namespace and ensuring it has the label 11/12/22 00:52:00.18
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:52:00.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1019" for this suite. 11/12/22 00:52:00.221
    STEP: Destroying namespace "nspatchtest-4c7b25aa-b8d4-400f-9e74-a2d96e289a5c-2510" for this suite. 11/12/22 00:52:00.244
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:00.275
Nov 12 00:52:00.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:52:00.278
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:00.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:00.35
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-a2feff05-538f-4991-ba9c-9a936f54557c 11/12/22 00:52:00.362
STEP: Creating a pod to test consume configMaps 11/12/22 00:52:00.379
Nov 12 00:52:00.436: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0" in namespace "projected-3968" to be "Succeeded or Failed"
Nov 12 00:52:00.454: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.448511ms
Nov 12 00:52:02.476: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039889807s
Nov 12 00:52:04.475: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038569044s
Nov 12 00:52:06.470: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034141327s
STEP: Saw pod success 11/12/22 00:52:06.471
Nov 12 00:52:06.471: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0" satisfied condition "Succeeded or Failed"
Nov 12 00:52:06.508: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:52:06.581
Nov 12 00:52:06.636: INFO: Waiting for pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 to disappear
Nov 12 00:52:06.675: INFO: Pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 00:52:06.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3968" for this suite. 11/12/22 00:52:06.697
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":329,"skipped":6246,"failed":0}
------------------------------
• [SLOW TEST] [6.444 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:00.275
    Nov 12 00:52:00.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:52:00.278
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:00.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:00.35
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-a2feff05-538f-4991-ba9c-9a936f54557c 11/12/22 00:52:00.362
    STEP: Creating a pod to test consume configMaps 11/12/22 00:52:00.379
    Nov 12 00:52:00.436: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0" in namespace "projected-3968" to be "Succeeded or Failed"
    Nov 12 00:52:00.454: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.448511ms
    Nov 12 00:52:02.476: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039889807s
    Nov 12 00:52:04.475: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038569044s
    Nov 12 00:52:06.470: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.034141327s
    STEP: Saw pod success 11/12/22 00:52:06.471
    Nov 12 00:52:06.471: INFO: Pod "pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0" satisfied condition "Succeeded or Failed"
    Nov 12 00:52:06.508: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:52:06.581
    Nov 12 00:52:06.636: INFO: Waiting for pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 to disappear
    Nov 12 00:52:06.675: INFO: Pod pod-projected-configmaps-08619ed4-0b58-4e08-98ef-3642fa269bf0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 00:52:06.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3968" for this suite. 11/12/22 00:52:06.697
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:06.729
Nov 12 00:52:06.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:52:06.731
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:06.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:06.794
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 11/12/22 00:52:06.806
Nov 12 00:52:06.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-760 create -f -'
Nov 12 00:52:07.272: INFO: stderr: ""
Nov 12 00:52:07.272: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 00:52:07.272
Nov 12 00:52:08.288: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:52:08.288: INFO: Found 0 / 1
Nov 12 00:52:09.297: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:52:09.297: INFO: Found 0 / 1
Nov 12 00:52:10.291: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:52:10.291: INFO: Found 1 / 1
Nov 12 00:52:10.291: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 11/12/22 00:52:10.291
Nov 12 00:52:10.309: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:52:10.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 00:52:10.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-760 patch pod agnhost-primary-wgb96 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 12 00:52:10.510: INFO: stderr: ""
Nov 12 00:52:10.510: INFO: stdout: "pod/agnhost-primary-wgb96 patched\n"
STEP: checking annotations 11/12/22 00:52:10.51
Nov 12 00:52:10.525: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:52:10.525: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:52:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-760" for this suite. 11/12/22 00:52:10.545
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":330,"skipped":6247,"failed":0}
------------------------------
• [3.837 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:06.729
    Nov 12 00:52:06.730: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:52:06.731
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:06.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:06.794
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 11/12/22 00:52:06.806
    Nov 12 00:52:06.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-760 create -f -'
    Nov 12 00:52:07.272: INFO: stderr: ""
    Nov 12 00:52:07.272: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 00:52:07.272
    Nov 12 00:52:08.288: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:52:08.288: INFO: Found 0 / 1
    Nov 12 00:52:09.297: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:52:09.297: INFO: Found 0 / 1
    Nov 12 00:52:10.291: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:52:10.291: INFO: Found 1 / 1
    Nov 12 00:52:10.291: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 11/12/22 00:52:10.291
    Nov 12 00:52:10.309: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:52:10.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 00:52:10.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-760 patch pod agnhost-primary-wgb96 -p {"metadata":{"annotations":{"x":"y"}}}'
    Nov 12 00:52:10.510: INFO: stderr: ""
    Nov 12 00:52:10.510: INFO: stdout: "pod/agnhost-primary-wgb96 patched\n"
    STEP: checking annotations 11/12/22 00:52:10.51
    Nov 12 00:52:10.525: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:52:10.525: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:52:10.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-760" for this suite. 11/12/22 00:52:10.545
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:10.568
Nov 12 00:52:10.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-webhook 11/12/22 00:52:10.569
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:10.615
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:10.627
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/12/22 00:52:10.646
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 00:52:11.982
STEP: Deploying the custom resource conversion webhook pod 11/12/22 00:52:12.003
STEP: Wait for the deployment to be ready 11/12/22 00:52:12.045
Nov 12 00:52:12.080: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov 12 00:52:14.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 00:52:16.155
STEP: Verifying the service has paired with the endpoint 11/12/22 00:52:16.192
Nov 12 00:52:17.193: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Nov 12 00:52:17.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Creating a v1 custom resource 11/12/22 00:52:20.212
STEP: Create a v2 custom resource 11/12/22 00:52:20.298
STEP: List CRs in v1 11/12/22 00:52:20.48
STEP: List CRs in v2 11/12/22 00:52:20.505
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:52:21.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8894" for this suite. 11/12/22 00:52:21.107
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":331,"skipped":6250,"failed":0}
------------------------------
• [SLOW TEST] [10.687 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:10.568
    Nov 12 00:52:10.568: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-webhook 11/12/22 00:52:10.569
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:10.615
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:10.627
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/12/22 00:52:10.646
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 00:52:11.982
    STEP: Deploying the custom resource conversion webhook pod 11/12/22 00:52:12.003
    STEP: Wait for the deployment to be ready 11/12/22 00:52:12.045
    Nov 12 00:52:12.080: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Nov 12 00:52:14.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 0, 52, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 00:52:16.155
    STEP: Verifying the service has paired with the endpoint 11/12/22 00:52:16.192
    Nov 12 00:52:17.193: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Nov 12 00:52:17.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Creating a v1 custom resource 11/12/22 00:52:20.212
    STEP: Create a v2 custom resource 11/12/22 00:52:20.298
    STEP: List CRs in v1 11/12/22 00:52:20.48
    STEP: List CRs in v2 11/12/22 00:52:20.505
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:52:21.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-8894" for this suite. 11/12/22 00:52:21.107
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:21.256
Nov 12 00:52:21.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:52:21.259
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.349
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 11/12/22 00:52:21.363
Nov 12 00:52:21.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3223 api-versions'
Nov 12 00:52:21.498: INFO: stderr: ""
Nov 12 00:52:21.498: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:52:21.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3223" for this suite. 11/12/22 00:52:21.548
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":332,"skipped":6258,"failed":0}
------------------------------
• [0.356 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:21.256
    Nov 12 00:52:21.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:52:21.259
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.349
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 11/12/22 00:52:21.363
    Nov 12 00:52:21.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-3223 api-versions'
    Nov 12 00:52:21.498: INFO: stderr: ""
    Nov 12 00:52:21.498: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nibm.com/v1alpha1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:52:21.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3223" for this suite. 11/12/22 00:52:21.548
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:21.612
Nov 12 00:52:21.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:52:21.614
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.697
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-9265-delete-me 11/12/22 00:52:21.726
STEP: Waiting for the RuntimeClass to disappear 11/12/22 00:52:21.749
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 00:52:21.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9265" for this suite. 11/12/22 00:52:21.806
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":333,"skipped":6258,"failed":0}
------------------------------
• [0.242 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:21.612
    Nov 12 00:52:21.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 00:52:21.614
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.697
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-9265-delete-me 11/12/22 00:52:21.726
    STEP: Waiting for the RuntimeClass to disappear 11/12/22 00:52:21.749
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 00:52:21.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9265" for this suite. 11/12/22 00:52:21.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:52:21.859
Nov 12 00:52:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/12/22 00:52:21.862
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.918
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 11/12/22 00:52:21.944
STEP: delete the rc 11/12/22 00:52:27.011
STEP: wait for the rc to be deleted 11/12/22 00:52:27.079
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/12/22 00:52:32.102
STEP: Gathering metrics 11/12/22 00:53:02.188
W1112 00:53:02.301899      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 00:53:02.301: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 12 00:53:02.302: INFO: Deleting pod "simpletest.rc-29lqw" in namespace "gc-10"
Nov 12 00:53:02.365: INFO: Deleting pod "simpletest.rc-2jcdl" in namespace "gc-10"
Nov 12 00:53:02.432: INFO: Deleting pod "simpletest.rc-2svb4" in namespace "gc-10"
Nov 12 00:53:02.486: INFO: Deleting pod "simpletest.rc-2vt2t" in namespace "gc-10"
Nov 12 00:53:02.532: INFO: Deleting pod "simpletest.rc-48x5d" in namespace "gc-10"
Nov 12 00:53:02.587: INFO: Deleting pod "simpletest.rc-4dqhq" in namespace "gc-10"
Nov 12 00:53:02.667: INFO: Deleting pod "simpletest.rc-4drgm" in namespace "gc-10"
Nov 12 00:53:02.720: INFO: Deleting pod "simpletest.rc-4l2jz" in namespace "gc-10"
Nov 12 00:53:02.776: INFO: Deleting pod "simpletest.rc-4qdmj" in namespace "gc-10"
Nov 12 00:53:02.843: INFO: Deleting pod "simpletest.rc-4r2cg" in namespace "gc-10"
Nov 12 00:53:02.939: INFO: Deleting pod "simpletest.rc-54x5g" in namespace "gc-10"
Nov 12 00:53:03.007: INFO: Deleting pod "simpletest.rc-5b949" in namespace "gc-10"
Nov 12 00:53:03.051: INFO: Deleting pod "simpletest.rc-5v67c" in namespace "gc-10"
Nov 12 00:53:03.111: INFO: Deleting pod "simpletest.rc-5wb89" in namespace "gc-10"
Nov 12 00:53:03.169: INFO: Deleting pod "simpletest.rc-64j4t" in namespace "gc-10"
Nov 12 00:53:03.288: INFO: Deleting pod "simpletest.rc-68cnj" in namespace "gc-10"
Nov 12 00:53:03.353: INFO: Deleting pod "simpletest.rc-6g9p5" in namespace "gc-10"
Nov 12 00:53:03.425: INFO: Deleting pod "simpletest.rc-6rdqf" in namespace "gc-10"
Nov 12 00:53:03.500: INFO: Deleting pod "simpletest.rc-6s9xj" in namespace "gc-10"
Nov 12 00:53:03.580: INFO: Deleting pod "simpletest.rc-6sww9" in namespace "gc-10"
Nov 12 00:53:03.653: INFO: Deleting pod "simpletest.rc-72q2d" in namespace "gc-10"
Nov 12 00:53:03.711: INFO: Deleting pod "simpletest.rc-7827t" in namespace "gc-10"
Nov 12 00:53:03.762: INFO: Deleting pod "simpletest.rc-7bgpd" in namespace "gc-10"
Nov 12 00:53:03.839: INFO: Deleting pod "simpletest.rc-7dsnm" in namespace "gc-10"
Nov 12 00:53:03.912: INFO: Deleting pod "simpletest.rc-7f5bn" in namespace "gc-10"
Nov 12 00:53:04.000: INFO: Deleting pod "simpletest.rc-7fn6f" in namespace "gc-10"
Nov 12 00:53:04.085: INFO: Deleting pod "simpletest.rc-7k765" in namespace "gc-10"
Nov 12 00:53:04.145: INFO: Deleting pod "simpletest.rc-7kds8" in namespace "gc-10"
Nov 12 00:53:04.218: INFO: Deleting pod "simpletest.rc-864vm" in namespace "gc-10"
Nov 12 00:53:04.284: INFO: Deleting pod "simpletest.rc-8zgqr" in namespace "gc-10"
Nov 12 00:53:04.329: INFO: Deleting pod "simpletest.rc-99mst" in namespace "gc-10"
Nov 12 00:53:04.380: INFO: Deleting pod "simpletest.rc-99zzv" in namespace "gc-10"
Nov 12 00:53:04.498: INFO: Deleting pod "simpletest.rc-b2q6r" in namespace "gc-10"
Nov 12 00:53:04.555: INFO: Deleting pod "simpletest.rc-bcgt7" in namespace "gc-10"
Nov 12 00:53:04.670: INFO: Deleting pod "simpletest.rc-bwns4" in namespace "gc-10"
Nov 12 00:53:04.805: INFO: Deleting pod "simpletest.rc-c498n" in namespace "gc-10"
Nov 12 00:53:04.910: INFO: Deleting pod "simpletest.rc-cfzk2" in namespace "gc-10"
Nov 12 00:53:04.971: INFO: Deleting pod "simpletest.rc-cnvlp" in namespace "gc-10"
Nov 12 00:53:05.038: INFO: Deleting pod "simpletest.rc-dsbc6" in namespace "gc-10"
Nov 12 00:53:05.142: INFO: Deleting pod "simpletest.rc-dsdxm" in namespace "gc-10"
Nov 12 00:53:05.221: INFO: Deleting pod "simpletest.rc-dvcmh" in namespace "gc-10"
Nov 12 00:53:05.279: INFO: Deleting pod "simpletest.rc-f552m" in namespace "gc-10"
Nov 12 00:53:05.351: INFO: Deleting pod "simpletest.rc-f7nng" in namespace "gc-10"
Nov 12 00:53:05.397: INFO: Deleting pod "simpletest.rc-fcsrp" in namespace "gc-10"
Nov 12 00:53:05.483: INFO: Deleting pod "simpletest.rc-gdgvs" in namespace "gc-10"
Nov 12 00:53:05.595: INFO: Deleting pod "simpletest.rc-gf9kb" in namespace "gc-10"
Nov 12 00:53:05.654: INFO: Deleting pod "simpletest.rc-gh2cr" in namespace "gc-10"
Nov 12 00:53:05.762: INFO: Deleting pod "simpletest.rc-ghqqs" in namespace "gc-10"
Nov 12 00:53:05.816: INFO: Deleting pod "simpletest.rc-gjsnd" in namespace "gc-10"
Nov 12 00:53:05.879: INFO: Deleting pod "simpletest.rc-gnd4q" in namespace "gc-10"
Nov 12 00:53:05.981: INFO: Deleting pod "simpletest.rc-gzn64" in namespace "gc-10"
Nov 12 00:53:06.047: INFO: Deleting pod "simpletest.rc-hd8nh" in namespace "gc-10"
Nov 12 00:53:06.155: INFO: Deleting pod "simpletest.rc-hffnj" in namespace "gc-10"
Nov 12 00:53:06.224: INFO: Deleting pod "simpletest.rc-hj8ts" in namespace "gc-10"
Nov 12 00:53:06.286: INFO: Deleting pod "simpletest.rc-hkx2r" in namespace "gc-10"
Nov 12 00:53:06.459: INFO: Deleting pod "simpletest.rc-j8zgv" in namespace "gc-10"
Nov 12 00:53:06.533: INFO: Deleting pod "simpletest.rc-jhn55" in namespace "gc-10"
Nov 12 00:53:06.604: INFO: Deleting pod "simpletest.rc-jjkkx" in namespace "gc-10"
Nov 12 00:53:06.728: INFO: Deleting pod "simpletest.rc-jk2sq" in namespace "gc-10"
Nov 12 00:53:06.793: INFO: Deleting pod "simpletest.rc-jncb8" in namespace "gc-10"
Nov 12 00:53:06.895: INFO: Deleting pod "simpletest.rc-jsp28" in namespace "gc-10"
Nov 12 00:53:07.013: INFO: Deleting pod "simpletest.rc-k5jwl" in namespace "gc-10"
Nov 12 00:53:07.075: INFO: Deleting pod "simpletest.rc-khssd" in namespace "gc-10"
Nov 12 00:53:07.139: INFO: Deleting pod "simpletest.rc-kv42w" in namespace "gc-10"
Nov 12 00:53:07.261: INFO: Deleting pod "simpletest.rc-kwm9q" in namespace "gc-10"
Nov 12 00:53:07.324: INFO: Deleting pod "simpletest.rc-kz9lr" in namespace "gc-10"
Nov 12 00:53:07.383: INFO: Deleting pod "simpletest.rc-l77xk" in namespace "gc-10"
Nov 12 00:53:07.456: INFO: Deleting pod "simpletest.rc-lfhfm" in namespace "gc-10"
Nov 12 00:53:07.560: INFO: Deleting pod "simpletest.rc-lh2jc" in namespace "gc-10"
Nov 12 00:53:07.677: INFO: Deleting pod "simpletest.rc-lw2vl" in namespace "gc-10"
Nov 12 00:53:07.747: INFO: Deleting pod "simpletest.rc-m6k2v" in namespace "gc-10"
Nov 12 00:53:07.826: INFO: Deleting pod "simpletest.rc-mn94n" in namespace "gc-10"
Nov 12 00:53:07.909: INFO: Deleting pod "simpletest.rc-mwms2" in namespace "gc-10"
Nov 12 00:53:08.000: INFO: Deleting pod "simpletest.rc-n6zzw" in namespace "gc-10"
Nov 12 00:53:08.093: INFO: Deleting pod "simpletest.rc-n9nc8" in namespace "gc-10"
Nov 12 00:53:08.149: INFO: Deleting pod "simpletest.rc-ncm2g" in namespace "gc-10"
Nov 12 00:53:08.221: INFO: Deleting pod "simpletest.rc-q462g" in namespace "gc-10"
Nov 12 00:53:08.328: INFO: Deleting pod "simpletest.rc-qdl7z" in namespace "gc-10"
Nov 12 00:53:08.415: INFO: Deleting pod "simpletest.rc-qdx24" in namespace "gc-10"
Nov 12 00:53:08.473: INFO: Deleting pod "simpletest.rc-qfvnv" in namespace "gc-10"
Nov 12 00:53:08.527: INFO: Deleting pod "simpletest.rc-rbkxz" in namespace "gc-10"
Nov 12 00:53:08.588: INFO: Deleting pod "simpletest.rc-rd5k8" in namespace "gc-10"
Nov 12 00:53:08.657: INFO: Deleting pod "simpletest.rc-rn8cp" in namespace "gc-10"
Nov 12 00:53:08.704: INFO: Deleting pod "simpletest.rc-rnt4d" in namespace "gc-10"
Nov 12 00:53:08.772: INFO: Deleting pod "simpletest.rc-t9j5j" in namespace "gc-10"
Nov 12 00:53:08.865: INFO: Deleting pod "simpletest.rc-tghd8" in namespace "gc-10"
Nov 12 00:53:08.919: INFO: Deleting pod "simpletest.rc-tlgq6" in namespace "gc-10"
Nov 12 00:53:09.003: INFO: Deleting pod "simpletest.rc-tvqtj" in namespace "gc-10"
Nov 12 00:53:09.091: INFO: Deleting pod "simpletest.rc-v48lw" in namespace "gc-10"
Nov 12 00:53:09.193: INFO: Deleting pod "simpletest.rc-vzzrn" in namespace "gc-10"
Nov 12 00:53:09.271: INFO: Deleting pod "simpletest.rc-wj6xr" in namespace "gc-10"
Nov 12 00:53:09.316: INFO: Deleting pod "simpletest.rc-wn5p2" in namespace "gc-10"
Nov 12 00:53:09.374: INFO: Deleting pod "simpletest.rc-x2ljs" in namespace "gc-10"
Nov 12 00:53:09.428: INFO: Deleting pod "simpletest.rc-x96qx" in namespace "gc-10"
Nov 12 00:53:09.509: INFO: Deleting pod "simpletest.rc-xs987" in namespace "gc-10"
Nov 12 00:53:09.560: INFO: Deleting pod "simpletest.rc-z6s5j" in namespace "gc-10"
Nov 12 00:53:09.643: INFO: Deleting pod "simpletest.rc-z7vnr" in namespace "gc-10"
Nov 12 00:53:09.703: INFO: Deleting pod "simpletest.rc-zgktd" in namespace "gc-10"
Nov 12 00:53:09.765: INFO: Deleting pod "simpletest.rc-zmkdl" in namespace "gc-10"
Nov 12 00:53:09.858: INFO: Deleting pod "simpletest.rc-zp9fp" in namespace "gc-10"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 00:53:09.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-10" for this suite. 11/12/22 00:53:10.043
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":334,"skipped":6264,"failed":0}
------------------------------
• [SLOW TEST] [48.234 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:52:21.859
    Nov 12 00:52:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/12/22 00:52:21.862
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:52:21.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:52:21.918
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 11/12/22 00:52:21.944
    STEP: delete the rc 11/12/22 00:52:27.011
    STEP: wait for the rc to be deleted 11/12/22 00:52:27.079
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/12/22 00:52:32.102
    STEP: Gathering metrics 11/12/22 00:53:02.188
    W1112 00:53:02.301899      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 00:53:02.301: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 12 00:53:02.302: INFO: Deleting pod "simpletest.rc-29lqw" in namespace "gc-10"
    Nov 12 00:53:02.365: INFO: Deleting pod "simpletest.rc-2jcdl" in namespace "gc-10"
    Nov 12 00:53:02.432: INFO: Deleting pod "simpletest.rc-2svb4" in namespace "gc-10"
    Nov 12 00:53:02.486: INFO: Deleting pod "simpletest.rc-2vt2t" in namespace "gc-10"
    Nov 12 00:53:02.532: INFO: Deleting pod "simpletest.rc-48x5d" in namespace "gc-10"
    Nov 12 00:53:02.587: INFO: Deleting pod "simpletest.rc-4dqhq" in namespace "gc-10"
    Nov 12 00:53:02.667: INFO: Deleting pod "simpletest.rc-4drgm" in namespace "gc-10"
    Nov 12 00:53:02.720: INFO: Deleting pod "simpletest.rc-4l2jz" in namespace "gc-10"
    Nov 12 00:53:02.776: INFO: Deleting pod "simpletest.rc-4qdmj" in namespace "gc-10"
    Nov 12 00:53:02.843: INFO: Deleting pod "simpletest.rc-4r2cg" in namespace "gc-10"
    Nov 12 00:53:02.939: INFO: Deleting pod "simpletest.rc-54x5g" in namespace "gc-10"
    Nov 12 00:53:03.007: INFO: Deleting pod "simpletest.rc-5b949" in namespace "gc-10"
    Nov 12 00:53:03.051: INFO: Deleting pod "simpletest.rc-5v67c" in namespace "gc-10"
    Nov 12 00:53:03.111: INFO: Deleting pod "simpletest.rc-5wb89" in namespace "gc-10"
    Nov 12 00:53:03.169: INFO: Deleting pod "simpletest.rc-64j4t" in namespace "gc-10"
    Nov 12 00:53:03.288: INFO: Deleting pod "simpletest.rc-68cnj" in namespace "gc-10"
    Nov 12 00:53:03.353: INFO: Deleting pod "simpletest.rc-6g9p5" in namespace "gc-10"
    Nov 12 00:53:03.425: INFO: Deleting pod "simpletest.rc-6rdqf" in namespace "gc-10"
    Nov 12 00:53:03.500: INFO: Deleting pod "simpletest.rc-6s9xj" in namespace "gc-10"
    Nov 12 00:53:03.580: INFO: Deleting pod "simpletest.rc-6sww9" in namespace "gc-10"
    Nov 12 00:53:03.653: INFO: Deleting pod "simpletest.rc-72q2d" in namespace "gc-10"
    Nov 12 00:53:03.711: INFO: Deleting pod "simpletest.rc-7827t" in namespace "gc-10"
    Nov 12 00:53:03.762: INFO: Deleting pod "simpletest.rc-7bgpd" in namespace "gc-10"
    Nov 12 00:53:03.839: INFO: Deleting pod "simpletest.rc-7dsnm" in namespace "gc-10"
    Nov 12 00:53:03.912: INFO: Deleting pod "simpletest.rc-7f5bn" in namespace "gc-10"
    Nov 12 00:53:04.000: INFO: Deleting pod "simpletest.rc-7fn6f" in namespace "gc-10"
    Nov 12 00:53:04.085: INFO: Deleting pod "simpletest.rc-7k765" in namespace "gc-10"
    Nov 12 00:53:04.145: INFO: Deleting pod "simpletest.rc-7kds8" in namespace "gc-10"
    Nov 12 00:53:04.218: INFO: Deleting pod "simpletest.rc-864vm" in namespace "gc-10"
    Nov 12 00:53:04.284: INFO: Deleting pod "simpletest.rc-8zgqr" in namespace "gc-10"
    Nov 12 00:53:04.329: INFO: Deleting pod "simpletest.rc-99mst" in namespace "gc-10"
    Nov 12 00:53:04.380: INFO: Deleting pod "simpletest.rc-99zzv" in namespace "gc-10"
    Nov 12 00:53:04.498: INFO: Deleting pod "simpletest.rc-b2q6r" in namespace "gc-10"
    Nov 12 00:53:04.555: INFO: Deleting pod "simpletest.rc-bcgt7" in namespace "gc-10"
    Nov 12 00:53:04.670: INFO: Deleting pod "simpletest.rc-bwns4" in namespace "gc-10"
    Nov 12 00:53:04.805: INFO: Deleting pod "simpletest.rc-c498n" in namespace "gc-10"
    Nov 12 00:53:04.910: INFO: Deleting pod "simpletest.rc-cfzk2" in namespace "gc-10"
    Nov 12 00:53:04.971: INFO: Deleting pod "simpletest.rc-cnvlp" in namespace "gc-10"
    Nov 12 00:53:05.038: INFO: Deleting pod "simpletest.rc-dsbc6" in namespace "gc-10"
    Nov 12 00:53:05.142: INFO: Deleting pod "simpletest.rc-dsdxm" in namespace "gc-10"
    Nov 12 00:53:05.221: INFO: Deleting pod "simpletest.rc-dvcmh" in namespace "gc-10"
    Nov 12 00:53:05.279: INFO: Deleting pod "simpletest.rc-f552m" in namespace "gc-10"
    Nov 12 00:53:05.351: INFO: Deleting pod "simpletest.rc-f7nng" in namespace "gc-10"
    Nov 12 00:53:05.397: INFO: Deleting pod "simpletest.rc-fcsrp" in namespace "gc-10"
    Nov 12 00:53:05.483: INFO: Deleting pod "simpletest.rc-gdgvs" in namespace "gc-10"
    Nov 12 00:53:05.595: INFO: Deleting pod "simpletest.rc-gf9kb" in namespace "gc-10"
    Nov 12 00:53:05.654: INFO: Deleting pod "simpletest.rc-gh2cr" in namespace "gc-10"
    Nov 12 00:53:05.762: INFO: Deleting pod "simpletest.rc-ghqqs" in namespace "gc-10"
    Nov 12 00:53:05.816: INFO: Deleting pod "simpletest.rc-gjsnd" in namespace "gc-10"
    Nov 12 00:53:05.879: INFO: Deleting pod "simpletest.rc-gnd4q" in namespace "gc-10"
    Nov 12 00:53:05.981: INFO: Deleting pod "simpletest.rc-gzn64" in namespace "gc-10"
    Nov 12 00:53:06.047: INFO: Deleting pod "simpletest.rc-hd8nh" in namespace "gc-10"
    Nov 12 00:53:06.155: INFO: Deleting pod "simpletest.rc-hffnj" in namespace "gc-10"
    Nov 12 00:53:06.224: INFO: Deleting pod "simpletest.rc-hj8ts" in namespace "gc-10"
    Nov 12 00:53:06.286: INFO: Deleting pod "simpletest.rc-hkx2r" in namespace "gc-10"
    Nov 12 00:53:06.459: INFO: Deleting pod "simpletest.rc-j8zgv" in namespace "gc-10"
    Nov 12 00:53:06.533: INFO: Deleting pod "simpletest.rc-jhn55" in namespace "gc-10"
    Nov 12 00:53:06.604: INFO: Deleting pod "simpletest.rc-jjkkx" in namespace "gc-10"
    Nov 12 00:53:06.728: INFO: Deleting pod "simpletest.rc-jk2sq" in namespace "gc-10"
    Nov 12 00:53:06.793: INFO: Deleting pod "simpletest.rc-jncb8" in namespace "gc-10"
    Nov 12 00:53:06.895: INFO: Deleting pod "simpletest.rc-jsp28" in namespace "gc-10"
    Nov 12 00:53:07.013: INFO: Deleting pod "simpletest.rc-k5jwl" in namespace "gc-10"
    Nov 12 00:53:07.075: INFO: Deleting pod "simpletest.rc-khssd" in namespace "gc-10"
    Nov 12 00:53:07.139: INFO: Deleting pod "simpletest.rc-kv42w" in namespace "gc-10"
    Nov 12 00:53:07.261: INFO: Deleting pod "simpletest.rc-kwm9q" in namespace "gc-10"
    Nov 12 00:53:07.324: INFO: Deleting pod "simpletest.rc-kz9lr" in namespace "gc-10"
    Nov 12 00:53:07.383: INFO: Deleting pod "simpletest.rc-l77xk" in namespace "gc-10"
    Nov 12 00:53:07.456: INFO: Deleting pod "simpletest.rc-lfhfm" in namespace "gc-10"
    Nov 12 00:53:07.560: INFO: Deleting pod "simpletest.rc-lh2jc" in namespace "gc-10"
    Nov 12 00:53:07.677: INFO: Deleting pod "simpletest.rc-lw2vl" in namespace "gc-10"
    Nov 12 00:53:07.747: INFO: Deleting pod "simpletest.rc-m6k2v" in namespace "gc-10"
    Nov 12 00:53:07.826: INFO: Deleting pod "simpletest.rc-mn94n" in namespace "gc-10"
    Nov 12 00:53:07.909: INFO: Deleting pod "simpletest.rc-mwms2" in namespace "gc-10"
    Nov 12 00:53:08.000: INFO: Deleting pod "simpletest.rc-n6zzw" in namespace "gc-10"
    Nov 12 00:53:08.093: INFO: Deleting pod "simpletest.rc-n9nc8" in namespace "gc-10"
    Nov 12 00:53:08.149: INFO: Deleting pod "simpletest.rc-ncm2g" in namespace "gc-10"
    Nov 12 00:53:08.221: INFO: Deleting pod "simpletest.rc-q462g" in namespace "gc-10"
    Nov 12 00:53:08.328: INFO: Deleting pod "simpletest.rc-qdl7z" in namespace "gc-10"
    Nov 12 00:53:08.415: INFO: Deleting pod "simpletest.rc-qdx24" in namespace "gc-10"
    Nov 12 00:53:08.473: INFO: Deleting pod "simpletest.rc-qfvnv" in namespace "gc-10"
    Nov 12 00:53:08.527: INFO: Deleting pod "simpletest.rc-rbkxz" in namespace "gc-10"
    Nov 12 00:53:08.588: INFO: Deleting pod "simpletest.rc-rd5k8" in namespace "gc-10"
    Nov 12 00:53:08.657: INFO: Deleting pod "simpletest.rc-rn8cp" in namespace "gc-10"
    Nov 12 00:53:08.704: INFO: Deleting pod "simpletest.rc-rnt4d" in namespace "gc-10"
    Nov 12 00:53:08.772: INFO: Deleting pod "simpletest.rc-t9j5j" in namespace "gc-10"
    Nov 12 00:53:08.865: INFO: Deleting pod "simpletest.rc-tghd8" in namespace "gc-10"
    Nov 12 00:53:08.919: INFO: Deleting pod "simpletest.rc-tlgq6" in namespace "gc-10"
    Nov 12 00:53:09.003: INFO: Deleting pod "simpletest.rc-tvqtj" in namespace "gc-10"
    Nov 12 00:53:09.091: INFO: Deleting pod "simpletest.rc-v48lw" in namespace "gc-10"
    Nov 12 00:53:09.193: INFO: Deleting pod "simpletest.rc-vzzrn" in namespace "gc-10"
    Nov 12 00:53:09.271: INFO: Deleting pod "simpletest.rc-wj6xr" in namespace "gc-10"
    Nov 12 00:53:09.316: INFO: Deleting pod "simpletest.rc-wn5p2" in namespace "gc-10"
    Nov 12 00:53:09.374: INFO: Deleting pod "simpletest.rc-x2ljs" in namespace "gc-10"
    Nov 12 00:53:09.428: INFO: Deleting pod "simpletest.rc-x96qx" in namespace "gc-10"
    Nov 12 00:53:09.509: INFO: Deleting pod "simpletest.rc-xs987" in namespace "gc-10"
    Nov 12 00:53:09.560: INFO: Deleting pod "simpletest.rc-z6s5j" in namespace "gc-10"
    Nov 12 00:53:09.643: INFO: Deleting pod "simpletest.rc-z7vnr" in namespace "gc-10"
    Nov 12 00:53:09.703: INFO: Deleting pod "simpletest.rc-zgktd" in namespace "gc-10"
    Nov 12 00:53:09.765: INFO: Deleting pod "simpletest.rc-zmkdl" in namespace "gc-10"
    Nov 12 00:53:09.858: INFO: Deleting pod "simpletest.rc-zp9fp" in namespace "gc-10"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 00:53:09.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-10" for this suite. 11/12/22 00:53:10.043
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:53:10.095
Nov 12 00:53:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:53:10.1
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:53:10.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:53:10.165
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 11/12/22 00:53:10.207
STEP: Counting existing ResourceQuota 11/12/22 00:53:15.227
STEP: Creating a ResourceQuota 11/12/22 00:53:20.247
STEP: Ensuring resource quota status is calculated 11/12/22 00:53:20.271
STEP: Creating a Secret 11/12/22 00:53:22.292
STEP: Ensuring resource quota status captures secret creation 11/12/22 00:53:22.34
STEP: Deleting a secret 11/12/22 00:53:24.361
STEP: Ensuring resource quota status released usage 11/12/22 00:53:24.387
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:53:26.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7809" for this suite. 11/12/22 00:53:26.426
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":335,"skipped":6276,"failed":0}
------------------------------
• [SLOW TEST] [16.352 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:53:10.095
    Nov 12 00:53:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:53:10.1
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:53:10.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:53:10.165
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 11/12/22 00:53:10.207
    STEP: Counting existing ResourceQuota 11/12/22 00:53:15.227
    STEP: Creating a ResourceQuota 11/12/22 00:53:20.247
    STEP: Ensuring resource quota status is calculated 11/12/22 00:53:20.271
    STEP: Creating a Secret 11/12/22 00:53:22.292
    STEP: Ensuring resource quota status captures secret creation 11/12/22 00:53:22.34
    STEP: Deleting a secret 11/12/22 00:53:24.361
    STEP: Ensuring resource quota status released usage 11/12/22 00:53:24.387
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:53:26.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7809" for this suite. 11/12/22 00:53:26.426
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:53:26.45
Nov 12 00:53:26.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename sched-preemption 11/12/22 00:53:26.452
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:53:26.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:53:26.519
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 00:53:26.604: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 00:54:26.751: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 11/12/22 00:54:26.765
Nov 12 00:54:26.846: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 12 00:54:26.871: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 12 00:54:26.929: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 12 00:54:26.951: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 12 00:54:27.040: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 12 00:54:27.071: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/12/22 00:54:27.071
Nov 12 00:54:27.072: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:27.089: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 16.782439ms
Nov 12 00:54:29.110: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038040633s
Nov 12 00:54:31.108: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.036503407s
Nov 12 00:54:31.108: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 12 00:54:31.108: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.124: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.146119ms
Nov 12 00:54:31.125: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:54:31.125: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.139: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 14.254662ms
Nov 12 00:54:31.139: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:54:31.139: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.154: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 14.848611ms
Nov 12 00:54:31.154: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:54:31.154: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.177: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 22.552818ms
Nov 12 00:54:31.177: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 00:54:31.177: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.194: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.451993ms
Nov 12 00:54:31.194: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/12/22 00:54:31.194
Nov 12 00:54:31.214: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7804" to be "running"
Nov 12 00:54:31.262: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 48.596093ms
Nov 12 00:54:33.284: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070581975s
Nov 12 00:54:35.290: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076553504s
Nov 12 00:54:37.280: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.06635558s
Nov 12 00:54:37.280: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:54:37.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7804" for this suite. 11/12/22 00:54:37.468
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":336,"skipped":6300,"failed":0}
------------------------------
• [SLOW TEST] [71.214 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:53:26.45
    Nov 12 00:53:26.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 00:53:26.452
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:53:26.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:53:26.519
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 00:53:26.604: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 00:54:26.751: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 11/12/22 00:54:26.765
    Nov 12 00:54:26.846: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 12 00:54:26.871: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 12 00:54:26.929: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 12 00:54:26.951: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 12 00:54:27.040: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 12 00:54:27.071: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/12/22 00:54:27.071
    Nov 12 00:54:27.072: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:27.089: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 16.782439ms
    Nov 12 00:54:29.110: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038040633s
    Nov 12 00:54:31.108: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.036503407s
    Nov 12 00:54:31.108: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 12 00:54:31.108: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.124: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.146119ms
    Nov 12 00:54:31.125: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:54:31.125: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.139: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 14.254662ms
    Nov 12 00:54:31.139: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:54:31.139: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.154: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 14.848611ms
    Nov 12 00:54:31.154: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:54:31.154: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.177: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 22.552818ms
    Nov 12 00:54:31.177: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 00:54:31.177: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.194: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.451993ms
    Nov 12 00:54:31.194: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/12/22 00:54:31.194
    Nov 12 00:54:31.214: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7804" to be "running"
    Nov 12 00:54:31.262: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 48.596093ms
    Nov 12 00:54:33.284: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070581975s
    Nov 12 00:54:35.290: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076553504s
    Nov 12 00:54:37.280: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.06635558s
    Nov 12 00:54:37.280: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:54:37.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7804" for this suite. 11/12/22 00:54:37.468
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:54:37.665
Nov 12 00:54:37.665: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename containers 11/12/22 00:54:37.668
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:37.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:37.733
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Nov 12 00:54:37.782: INFO: Waiting up to 5m0s for pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd" in namespace "containers-8423" to be "running"
Nov 12 00:54:37.796: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.791247ms
Nov 12 00:54:39.831: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049330895s
Nov 12 00:54:41.813: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Running", Reason="", readiness=true. Elapsed: 4.0316795s
Nov 12 00:54:41.814: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 00:54:41.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8423" for this suite. 11/12/22 00:54:41.98
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":337,"skipped":6300,"failed":0}
------------------------------
• [4.339 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:54:37.665
    Nov 12 00:54:37.665: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename containers 11/12/22 00:54:37.668
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:37.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:37.733
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Nov 12 00:54:37.782: INFO: Waiting up to 5m0s for pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd" in namespace "containers-8423" to be "running"
    Nov 12 00:54:37.796: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.791247ms
    Nov 12 00:54:39.831: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049330895s
    Nov 12 00:54:41.813: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd": Phase="Running", Reason="", readiness=true. Elapsed: 4.0316795s
    Nov 12 00:54:41.814: INFO: Pod "client-containers-f76e14fe-aa4c-441a-8d44-9fe04b3fc0bd" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 00:54:41.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8423" for this suite. 11/12/22 00:54:41.98
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:54:42.005
Nov 12 00:54:42.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:54:42.008
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:42.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:42.061
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-7b66cd1c-b1c6-43ef-9fe3-7b39daa4af96 11/12/22 00:54:42.072
STEP: Creating a pod to test consume secrets 11/12/22 00:54:42.09
Nov 12 00:54:42.125: INFO: Waiting up to 5m0s for pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187" in namespace "secrets-5684" to be "Succeeded or Failed"
Nov 12 00:54:42.147: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 21.810848ms
Nov 12 00:54:44.165: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039379095s
Nov 12 00:54:46.195: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069608483s
Nov 12 00:54:48.168: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042647461s
STEP: Saw pod success 11/12/22 00:54:48.168
Nov 12 00:54:48.168: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187" satisfied condition "Succeeded or Failed"
Nov 12 00:54:48.184: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 container secret-env-test: <nil>
STEP: delete the pod 11/12/22 00:54:48.239
Nov 12 00:54:48.309: INFO: Waiting for pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 to disappear
Nov 12 00:54:48.349: INFO: Pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:54:48.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5684" for this suite. 11/12/22 00:54:48.365
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":338,"skipped":6313,"failed":0}
------------------------------
• [SLOW TEST] [6.383 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:54:42.005
    Nov 12 00:54:42.005: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:54:42.008
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:42.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:42.061
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-7b66cd1c-b1c6-43ef-9fe3-7b39daa4af96 11/12/22 00:54:42.072
    STEP: Creating a pod to test consume secrets 11/12/22 00:54:42.09
    Nov 12 00:54:42.125: INFO: Waiting up to 5m0s for pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187" in namespace "secrets-5684" to be "Succeeded or Failed"
    Nov 12 00:54:42.147: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 21.810848ms
    Nov 12 00:54:44.165: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039379095s
    Nov 12 00:54:46.195: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069608483s
    Nov 12 00:54:48.168: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042647461s
    STEP: Saw pod success 11/12/22 00:54:48.168
    Nov 12 00:54:48.168: INFO: Pod "pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187" satisfied condition "Succeeded or Failed"
    Nov 12 00:54:48.184: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 container secret-env-test: <nil>
    STEP: delete the pod 11/12/22 00:54:48.239
    Nov 12 00:54:48.309: INFO: Waiting for pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 to disappear
    Nov 12 00:54:48.349: INFO: Pod pod-secrets-d7bae342-0615-4d1e-bdb6-5fad8a3a2187 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:54:48.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5684" for this suite. 11/12/22 00:54:48.365
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:54:48.395
Nov 12 00:54:48.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:54:48.397
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:48.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:48.456
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 00:54:48.466
Nov 12 00:54:48.499: INFO: Waiting up to 5m0s for pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc" in namespace "emptydir-7374" to be "Succeeded or Failed"
Nov 12 00:54:48.515: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.487844ms
Nov 12 00:54:50.532: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033473275s
Nov 12 00:54:52.536: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037253653s
Nov 12 00:54:54.534: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035220467s
STEP: Saw pod success 11/12/22 00:54:54.534
Nov 12 00:54:54.535: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc" satisfied condition "Succeeded or Failed"
Nov 12 00:54:54.551: INFO: Trying to get logs from node 10.184.98.55 pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc container test-container: <nil>
STEP: delete the pod 11/12/22 00:54:54.584
Nov 12 00:54:54.629: INFO: Waiting for pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc to disappear
Nov 12 00:54:54.644: INFO: Pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:54:54.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7374" for this suite. 11/12/22 00:54:54.66
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":339,"skipped":6361,"failed":0}
------------------------------
• [SLOW TEST] [6.284 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:54:48.395
    Nov 12 00:54:48.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:54:48.397
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:48.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:48.456
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 00:54:48.466
    Nov 12 00:54:48.499: INFO: Waiting up to 5m0s for pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc" in namespace "emptydir-7374" to be "Succeeded or Failed"
    Nov 12 00:54:48.515: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.487844ms
    Nov 12 00:54:50.532: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033473275s
    Nov 12 00:54:52.536: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037253653s
    Nov 12 00:54:54.534: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035220467s
    STEP: Saw pod success 11/12/22 00:54:54.534
    Nov 12 00:54:54.535: INFO: Pod "pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc" satisfied condition "Succeeded or Failed"
    Nov 12 00:54:54.551: INFO: Trying to get logs from node 10.184.98.55 pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc container test-container: <nil>
    STEP: delete the pod 11/12/22 00:54:54.584
    Nov 12 00:54:54.629: INFO: Waiting for pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc to disappear
    Nov 12 00:54:54.644: INFO: Pod pod-fb3d1ab8-c89e-47d8-b21c-48b7f28f7cfc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:54:54.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7374" for this suite. 11/12/22 00:54:54.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:54:54.686
Nov 12 00:54:54.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption 11/12/22 00:54:54.687
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:54.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:54.747
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 11/12/22 00:54:54.759
STEP: Waiting for the pdb to be processed 11/12/22 00:54:54.776
STEP: First trying to evict a pod which shouldn't be evictable 11/12/22 00:54:56.833
STEP: Waiting for all pods to be running 11/12/22 00:54:56.833
Nov 12 00:54:56.852: INFO: pods: 0 < 3
Nov 12 00:54:58.868: INFO: running pods: 0 < 3
STEP: locating a running pod 11/12/22 00:55:00.871
STEP: Updating the pdb to allow a pod to be evicted 11/12/22 00:55:00.922
STEP: Waiting for the pdb to be processed 11/12/22 00:55:00.955
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 00:55:00.967
STEP: Waiting for all pods to be running 11/12/22 00:55:00.967
STEP: Waiting for the pdb to observed all healthy pods 11/12/22 00:55:00.983
STEP: Patching the pdb to disallow a pod to be evicted 11/12/22 00:55:01.092
STEP: Waiting for the pdb to be processed 11/12/22 00:55:01.135
STEP: Waiting for all pods to be running 11/12/22 00:55:01.151
Nov 12 00:55:01.166: INFO: running pods: 2 < 3
Nov 12 00:55:03.188: INFO: running pods: 2 < 3
STEP: locating a running pod 11/12/22 00:55:05.187
STEP: Deleting the pdb to allow a pod to be evicted 11/12/22 00:55:05.264
STEP: Waiting for the pdb to be deleted 11/12/22 00:55:05.288
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 00:55:05.303
STEP: Waiting for all pods to be running 11/12/22 00:55:05.303
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 00:55:05.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9965" for this suite. 11/12/22 00:55:05.423
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":340,"skipped":6366,"failed":0}
------------------------------
• [SLOW TEST] [10.760 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:54:54.686
    Nov 12 00:54:54.686: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption 11/12/22 00:54:54.687
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:54:54.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:54:54.747
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 11/12/22 00:54:54.759
    STEP: Waiting for the pdb to be processed 11/12/22 00:54:54.776
    STEP: First trying to evict a pod which shouldn't be evictable 11/12/22 00:54:56.833
    STEP: Waiting for all pods to be running 11/12/22 00:54:56.833
    Nov 12 00:54:56.852: INFO: pods: 0 < 3
    Nov 12 00:54:58.868: INFO: running pods: 0 < 3
    STEP: locating a running pod 11/12/22 00:55:00.871
    STEP: Updating the pdb to allow a pod to be evicted 11/12/22 00:55:00.922
    STEP: Waiting for the pdb to be processed 11/12/22 00:55:00.955
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 00:55:00.967
    STEP: Waiting for all pods to be running 11/12/22 00:55:00.967
    STEP: Waiting for the pdb to observed all healthy pods 11/12/22 00:55:00.983
    STEP: Patching the pdb to disallow a pod to be evicted 11/12/22 00:55:01.092
    STEP: Waiting for the pdb to be processed 11/12/22 00:55:01.135
    STEP: Waiting for all pods to be running 11/12/22 00:55:01.151
    Nov 12 00:55:01.166: INFO: running pods: 2 < 3
    Nov 12 00:55:03.188: INFO: running pods: 2 < 3
    STEP: locating a running pod 11/12/22 00:55:05.187
    STEP: Deleting the pdb to allow a pod to be evicted 11/12/22 00:55:05.264
    STEP: Waiting for the pdb to be deleted 11/12/22 00:55:05.288
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 00:55:05.303
    STEP: Waiting for all pods to be running 11/12/22 00:55:05.303
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 00:55:05.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9965" for this suite. 11/12/22 00:55:05.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:05.461
Nov 12 00:55:05.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename kubectl 11/12/22 00:55:05.463
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:05.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:05.518
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 11/12/22 00:55:05.526
Nov 12 00:55:05.526: INFO: namespace kubectl-8260
Nov 12 00:55:05.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 create -f -'
Nov 12 00:55:06.627: INFO: stderr: ""
Nov 12 00:55:06.627: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 00:55:06.627
Nov 12 00:55:07.642: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:55:07.642: INFO: Found 0 / 1
Nov 12 00:55:08.642: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:55:08.642: INFO: Found 0 / 1
Nov 12 00:55:09.643: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:55:09.643: INFO: Found 1 / 1
Nov 12 00:55:09.643: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 12 00:55:09.687: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 00:55:09.687: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 00:55:09.687: INFO: wait on agnhost-primary startup in kubectl-8260 
Nov 12 00:55:09.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 logs agnhost-primary-xnfjr agnhost-primary'
Nov 12 00:55:09.899: INFO: stderr: ""
Nov 12 00:55:09.899: INFO: stdout: "Paused\n"
STEP: exposing RC 11/12/22 00:55:09.899
Nov 12 00:55:09.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Nov 12 00:55:10.210: INFO: stderr: ""
Nov 12 00:55:10.210: INFO: stdout: "service/rm2 exposed\n"
Nov 12 00:55:10.224: INFO: Service rm2 in namespace kubectl-8260 found.
STEP: exposing service 11/12/22 00:55:12.253
Nov 12 00:55:12.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Nov 12 00:55:12.551: INFO: stderr: ""
Nov 12 00:55:12.551: INFO: stdout: "service/rm3 exposed\n"
Nov 12 00:55:12.567: INFO: Service rm3 in namespace kubectl-8260 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 00:55:14.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8260" for this suite. 11/12/22 00:55:14.607
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":341,"skipped":6423,"failed":0}
------------------------------
• [SLOW TEST] [9.167 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:05.461
    Nov 12 00:55:05.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename kubectl 11/12/22 00:55:05.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:05.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:05.518
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 11/12/22 00:55:05.526
    Nov 12 00:55:05.526: INFO: namespace kubectl-8260
    Nov 12 00:55:05.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 create -f -'
    Nov 12 00:55:06.627: INFO: stderr: ""
    Nov 12 00:55:06.627: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 00:55:06.627
    Nov 12 00:55:07.642: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:55:07.642: INFO: Found 0 / 1
    Nov 12 00:55:08.642: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:55:08.642: INFO: Found 0 / 1
    Nov 12 00:55:09.643: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:55:09.643: INFO: Found 1 / 1
    Nov 12 00:55:09.643: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 12 00:55:09.687: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 00:55:09.687: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 00:55:09.687: INFO: wait on agnhost-primary startup in kubectl-8260 
    Nov 12 00:55:09.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 logs agnhost-primary-xnfjr agnhost-primary'
    Nov 12 00:55:09.899: INFO: stderr: ""
    Nov 12 00:55:09.899: INFO: stdout: "Paused\n"
    STEP: exposing RC 11/12/22 00:55:09.899
    Nov 12 00:55:09.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Nov 12 00:55:10.210: INFO: stderr: ""
    Nov 12 00:55:10.210: INFO: stdout: "service/rm2 exposed\n"
    Nov 12 00:55:10.224: INFO: Service rm2 in namespace kubectl-8260 found.
    STEP: exposing service 11/12/22 00:55:12.253
    Nov 12 00:55:12.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=kubectl-8260 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Nov 12 00:55:12.551: INFO: stderr: ""
    Nov 12 00:55:12.551: INFO: stdout: "service/rm3 exposed\n"
    Nov 12 00:55:12.567: INFO: Service rm3 in namespace kubectl-8260 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 00:55:14.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8260" for this suite. 11/12/22 00:55:14.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:14.63
Nov 12 00:55:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename containers 11/12/22 00:55:14.632
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:14.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:14.698
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 11/12/22 00:55:14.705
Nov 12 00:55:14.736: INFO: Waiting up to 5m0s for pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760" in namespace "containers-3346" to be "Succeeded or Failed"
Nov 12 00:55:14.752: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 16.400638ms
Nov 12 00:55:16.769: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033631535s
Nov 12 00:55:18.808: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072482982s
Nov 12 00:55:20.769: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033001128s
STEP: Saw pod success 11/12/22 00:55:20.769
Nov 12 00:55:20.770: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760" satisfied condition "Succeeded or Failed"
Nov 12 00:55:20.802: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:55:20.838
Nov 12 00:55:20.914: INFO: Waiting for pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 to disappear
Nov 12 00:55:20.930: INFO: Pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 00:55:20.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3346" for this suite. 11/12/22 00:55:20.947
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":342,"skipped":6437,"failed":0}
------------------------------
• [SLOW TEST] [6.340 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:14.63
    Nov 12 00:55:14.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename containers 11/12/22 00:55:14.632
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:14.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:14.698
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 11/12/22 00:55:14.705
    Nov 12 00:55:14.736: INFO: Waiting up to 5m0s for pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760" in namespace "containers-3346" to be "Succeeded or Failed"
    Nov 12 00:55:14.752: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 16.400638ms
    Nov 12 00:55:16.769: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033631535s
    Nov 12 00:55:18.808: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072482982s
    Nov 12 00:55:20.769: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.033001128s
    STEP: Saw pod success 11/12/22 00:55:20.769
    Nov 12 00:55:20.770: INFO: Pod "client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760" satisfied condition "Succeeded or Failed"
    Nov 12 00:55:20.802: INFO: Trying to get logs from node 10.184.98.55 pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:55:20.838
    Nov 12 00:55:20.914: INFO: Waiting for pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 to disappear
    Nov 12 00:55:20.930: INFO: Pod client-containers-1e437e89-77af-4b8b-94c2-28df97cdb760 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 00:55:20.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3346" for this suite. 11/12/22 00:55:20.947
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:20.971
Nov 12 00:55:20.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:55:20.974
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:21.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:21.031
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-250e9c0d-f82d-40da-a2c0-725d31c18b18 11/12/22 00:55:21.13
STEP: Creating a pod to test consume secrets 11/12/22 00:55:21.151
Nov 12 00:55:21.212: INFO: Waiting up to 5m0s for pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86" in namespace "secrets-2020" to be "Succeeded or Failed"
Nov 12 00:55:21.248: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 35.709307ms
Nov 12 00:55:23.266: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053723817s
Nov 12 00:55:25.271: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058180018s
Nov 12 00:55:27.269: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056342651s
STEP: Saw pod success 11/12/22 00:55:27.269
Nov 12 00:55:27.269: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86" satisfied condition "Succeeded or Failed"
Nov 12 00:55:27.285: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:55:27.32
Nov 12 00:55:27.368: INFO: Waiting for pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 to disappear
Nov 12 00:55:27.383: INFO: Pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:55:27.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2020" for this suite. 11/12/22 00:55:27.404
STEP: Destroying namespace "secret-namespace-7803" for this suite. 11/12/22 00:55:27.425
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":343,"skipped":6439,"failed":0}
------------------------------
• [SLOW TEST] [6.474 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:20.971
    Nov 12 00:55:20.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:55:20.974
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:21.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:21.031
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-250e9c0d-f82d-40da-a2c0-725d31c18b18 11/12/22 00:55:21.13
    STEP: Creating a pod to test consume secrets 11/12/22 00:55:21.151
    Nov 12 00:55:21.212: INFO: Waiting up to 5m0s for pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86" in namespace "secrets-2020" to be "Succeeded or Failed"
    Nov 12 00:55:21.248: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 35.709307ms
    Nov 12 00:55:23.266: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053723817s
    Nov 12 00:55:25.271: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058180018s
    Nov 12 00:55:27.269: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056342651s
    STEP: Saw pod success 11/12/22 00:55:27.269
    Nov 12 00:55:27.269: INFO: Pod "pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86" satisfied condition "Succeeded or Failed"
    Nov 12 00:55:27.285: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:55:27.32
    Nov 12 00:55:27.368: INFO: Waiting for pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 to disappear
    Nov 12 00:55:27.383: INFO: Pod pod-secrets-33e51f51-747a-49b7-80e9-f926c0cd5f86 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:55:27.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2020" for this suite. 11/12/22 00:55:27.404
    STEP: Destroying namespace "secret-namespace-7803" for this suite. 11/12/22 00:55:27.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:27.451
Nov 12 00:55:27.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename emptydir 11/12/22 00:55:27.453
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:27.502
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:27.515
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 00:55:27.532
Nov 12 00:55:27.569: INFO: Waiting up to 5m0s for pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063" in namespace "emptydir-5771" to be "Succeeded or Failed"
Nov 12 00:55:27.589: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Pending", Reason="", readiness=false. Elapsed: 19.844219ms
Nov 12 00:55:29.607: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Running", Reason="", readiness=true. Elapsed: 2.037292964s
Nov 12 00:55:31.606: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Running", Reason="", readiness=false. Elapsed: 4.036296246s
Nov 12 00:55:33.612: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042928685s
STEP: Saw pod success 11/12/22 00:55:33.612
Nov 12 00:55:33.613: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063" satisfied condition "Succeeded or Failed"
Nov 12 00:55:33.629: INFO: Trying to get logs from node 10.184.98.55 pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 container test-container: <nil>
STEP: delete the pod 11/12/22 00:55:33.683
Nov 12 00:55:33.727: INFO: Waiting for pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 to disappear
Nov 12 00:55:33.742: INFO: Pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 00:55:33.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5771" for this suite. 11/12/22 00:55:33.76
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":344,"skipped":6447,"failed":0}
------------------------------
• [SLOW TEST] [6.336 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:27.451
    Nov 12 00:55:27.451: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename emptydir 11/12/22 00:55:27.453
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:27.502
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:27.515
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 00:55:27.532
    Nov 12 00:55:27.569: INFO: Waiting up to 5m0s for pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063" in namespace "emptydir-5771" to be "Succeeded or Failed"
    Nov 12 00:55:27.589: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Pending", Reason="", readiness=false. Elapsed: 19.844219ms
    Nov 12 00:55:29.607: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Running", Reason="", readiness=true. Elapsed: 2.037292964s
    Nov 12 00:55:31.606: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Running", Reason="", readiness=false. Elapsed: 4.036296246s
    Nov 12 00:55:33.612: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042928685s
    STEP: Saw pod success 11/12/22 00:55:33.612
    Nov 12 00:55:33.613: INFO: Pod "pod-1899acad-6a1a-4069-858e-735a0c5c4063" satisfied condition "Succeeded or Failed"
    Nov 12 00:55:33.629: INFO: Trying to get logs from node 10.184.98.55 pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 container test-container: <nil>
    STEP: delete the pod 11/12/22 00:55:33.683
    Nov 12 00:55:33.727: INFO: Waiting for pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 to disappear
    Nov 12 00:55:33.742: INFO: Pod pod-1899acad-6a1a-4069-858e-735a0c5c4063 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 00:55:33.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5771" for this suite. 11/12/22 00:55:33.76
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:33.79
Nov 12 00:55:33.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename downward-api 11/12/22 00:55:33.792
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:33.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:33.858
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 11/12/22 00:55:33.869
Nov 12 00:55:33.908: INFO: Waiting up to 5m0s for pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33" in namespace "downward-api-7507" to be "running and ready"
Nov 12 00:55:33.927: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Pending", Reason="", readiness=false. Elapsed: 18.634358ms
Nov 12 00:55:33.927: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:55:35.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038451953s
Nov 12 00:55:35.947: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:55:37.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Running", Reason="", readiness=true. Elapsed: 4.039060384s
Nov 12 00:55:37.947: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Running (Ready = true)
Nov 12 00:55:37.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33" satisfied condition "running and ready"
Nov 12 00:55:38.549: INFO: Successfully updated pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 00:55:40.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7507" for this suite. 11/12/22 00:55:40.658
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":345,"skipped":6451,"failed":0}
------------------------------
• [SLOW TEST] [6.891 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:33.79
    Nov 12 00:55:33.790: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename downward-api 11/12/22 00:55:33.792
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:33.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:33.858
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 11/12/22 00:55:33.869
    Nov 12 00:55:33.908: INFO: Waiting up to 5m0s for pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33" in namespace "downward-api-7507" to be "running and ready"
    Nov 12 00:55:33.927: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Pending", Reason="", readiness=false. Elapsed: 18.634358ms
    Nov 12 00:55:33.927: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:55:35.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038451953s
    Nov 12 00:55:35.947: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:55:37.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33": Phase="Running", Reason="", readiness=true. Elapsed: 4.039060384s
    Nov 12 00:55:37.947: INFO: The phase of Pod annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33 is Running (Ready = true)
    Nov 12 00:55:37.947: INFO: Pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33" satisfied condition "running and ready"
    Nov 12 00:55:38.549: INFO: Successfully updated pod "annotationupdateeca822cd-bec1-4799-a55f-2aabe3a09a33"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 00:55:40.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7507" for this suite. 11/12/22 00:55:40.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:40.682
Nov 12 00:55:40.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename daemonsets 11/12/22 00:55:40.685
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:40.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:40.744
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 11/12/22 00:55:40.828
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:55:40.848
Nov 12 00:55:40.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:55:40.882: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:55:41.931: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:55:41.932: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:55:42.926: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 00:55:42.926: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:55:43.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 00:55:43.922: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 11/12/22 00:55:43.934
STEP: DeleteCollection of the DaemonSets 11/12/22 00:55:43.958
STEP: Verify that ReplicaSets have been deleted 11/12/22 00:55:44.015
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Nov 12 00:55:44.060: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"50395"},"items":null}

Nov 12 00:55:44.097: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"50395"},"items":[{"metadata":{"name":"daemon-set-78n8v","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"168dcfd2-cd89-48be-8396-1a1672ab2cec","resourceVersion":"50388","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"812e550567df8899752d667908a6ded29c21d7104024a3a78a588153e605bdb6","cni.projectcalico.org/podIP":"172.30.194.108/32","cni.projectcalico.org/podIPs":"172.30.194.108/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.108\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cj45v","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cj45v","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.241.148.26","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.241.148.26"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.241.148.26","podIP":"172.30.194.108","podIPs":[{"ip":"172.30.194.108"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7beeb52092ff85085d939083b0170779c59db7987bf3a7fb6c6ca4fce9d3aa5a","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qb56b","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"c528555b-4cd5-40a1-9079-cbecb62490a3","resourceVersion":"50389","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"5729a81f645a077542490e1a42a4f7cfaf26eb43fd0167f9034fdecff53576de","cni.projectcalico.org/podIP":"172.30.188.225/32","cni.projectcalico.org/podIPs":"172.30.188.225/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6pfhv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6pfhv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.241.148.113","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.241.148.113"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.241.148.113","podIP":"172.30.188.225","podIPs":[{"ip":"172.30.188.225"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://5a86c12b53644440a759fbd1817e47164d14f10a03410778a3c753d2ff2123db","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-ss5mh","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"ec003cbe-da30-4e60-99bd-6369f4e46005","resourceVersion":"50393","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f723b10a101b273783ceae45f09a09a94f2617aca80d420f5b595d3db89c41f1","cni.projectcalico.org/podIP":"172.30.146.60/32","cni.projectcalico.org/podIPs":"172.30.146.60/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-q7rsd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-q7rsd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.184.98.55","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.184.98.55"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.184.98.55","podIP":"172.30.146.60","podIPs":[{"ip":"172.30.146.60"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1ebf77ae74d02d4a6557420b1f4e90b9a624354becd3990194027cb296c170f7","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:55:44.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8028" for this suite. 11/12/22 00:55:44.174
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":346,"skipped":6458,"failed":0}
------------------------------
• [3.512 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:40.682
    Nov 12 00:55:40.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename daemonsets 11/12/22 00:55:40.685
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:40.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:40.744
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 11/12/22 00:55:40.828
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:55:40.848
    Nov 12 00:55:40.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:55:40.882: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:55:41.931: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:55:41.932: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:55:42.926: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 00:55:42.926: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:55:43.922: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 00:55:43.922: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 11/12/22 00:55:43.934
    STEP: DeleteCollection of the DaemonSets 11/12/22 00:55:43.958
    STEP: Verify that ReplicaSets have been deleted 11/12/22 00:55:44.015
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Nov 12 00:55:44.060: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"50395"},"items":null}

    Nov 12 00:55:44.097: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"50395"},"items":[{"metadata":{"name":"daemon-set-78n8v","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"168dcfd2-cd89-48be-8396-1a1672ab2cec","resourceVersion":"50388","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"812e550567df8899752d667908a6ded29c21d7104024a3a78a588153e605bdb6","cni.projectcalico.org/podIP":"172.30.194.108/32","cni.projectcalico.org/podIPs":"172.30.194.108/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.194.108\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-cj45v","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-cj45v","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.241.148.26","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.241.148.26"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.241.148.26","podIP":"172.30.194.108","podIPs":[{"ip":"172.30.194.108"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7beeb52092ff85085d939083b0170779c59db7987bf3a7fb6c6ca4fce9d3aa5a","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-qb56b","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"c528555b-4cd5-40a1-9079-cbecb62490a3","resourceVersion":"50389","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"5729a81f645a077542490e1a42a4f7cfaf26eb43fd0167f9034fdecff53576de","cni.projectcalico.org/podIP":"172.30.188.225/32","cni.projectcalico.org/podIPs":"172.30.188.225/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.188.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6pfhv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6pfhv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.241.148.113","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.241.148.113"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.241.148.113","podIP":"172.30.188.225","podIPs":[{"ip":"172.30.188.225"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://5a86c12b53644440a759fbd1817e47164d14f10a03410778a3c753d2ff2123db","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-ss5mh","generateName":"daemon-set-","namespace":"daemonsets-8028","uid":"ec003cbe-da30-4e60-99bd-6369f4e46005","resourceVersion":"50393","creationTimestamp":"2022-11-12T00:55:40Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f723b10a101b273783ceae45f09a09a94f2617aca80d420f5b595d3db89c41f1","cni.projectcalico.org/podIP":"172.30.146.60/32","cni.projectcalico.org/podIPs":"172.30.146.60/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8c2c300e-7815-4306-81aa-26a9a1f3fba0","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:40Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c2c300e-7815-4306-81aa-26a9a1f3fba0\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:42Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T00:55:43Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.60\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-q7rsd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-q7rsd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"10.184.98.55","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["10.184.98.55"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:43Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T00:55:40Z"}],"hostIP":"10.184.98.55","podIP":"172.30.146.60","podIPs":[{"ip":"172.30.146.60"}],"startTime":"2022-11-12T00:55:40Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T00:55:42Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://1ebf77ae74d02d4a6557420b1f4e90b9a624354becd3990194027cb296c170f7","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:55:44.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8028" for this suite. 11/12/22 00:55:44.174
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:44.195
Nov 12 00:55:44.195: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename services 11/12/22 00:55:44.198
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:44.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:44.257
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5889 11/12/22 00:55:44.27
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[] 11/12/22 00:55:44.303
Nov 12 00:55:44.335: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5889 11/12/22 00:55:44.335
Nov 12 00:55:44.371: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5889" to be "running and ready"
Nov 12 00:55:44.388: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.000482ms
Nov 12 00:55:44.388: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:55:46.403: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031545488s
Nov 12 00:55:46.403: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:55:48.408: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.03646394s
Nov 12 00:55:48.408: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 12 00:55:48.408: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod1:[100]] 11/12/22 00:55:48.426
Nov 12 00:55:48.479: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5889 11/12/22 00:55:48.479
Nov 12 00:55:48.504: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5889" to be "running and ready"
Nov 12 00:55:48.520: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.868294ms
Nov 12 00:55:48.520: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:55:50.539: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.035228688s
Nov 12 00:55:50.539: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 12 00:55:50.539: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod1:[100] pod2:[101]] 11/12/22 00:55:50.557
Nov 12 00:55:50.623: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 11/12/22 00:55:50.623
Nov 12 00:55:50.624: INFO: Creating new exec pod
Nov 12 00:55:50.644: INFO: Waiting up to 5m0s for pod "execpodzccg2" in namespace "services-5889" to be "running"
Nov 12 00:55:50.660: INFO: Pod "execpodzccg2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.080293ms
Nov 12 00:55:52.679: INFO: Pod "execpodzccg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035182987s
Nov 12 00:55:54.676: INFO: Pod "execpodzccg2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032356706s
Nov 12 00:55:54.676: INFO: Pod "execpodzccg2" satisfied condition "running"
Nov 12 00:55:55.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Nov 12 00:55:56.155: INFO: stderr: "+ + echonc -v -t -w hostName 2 multi-endpoint-test\n 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Nov 12 00:55:56.156: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:55:56.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.74.150 80'
Nov 12 00:55:56.586: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.74.150 80\nConnection to 172.21.74.150 80 port [tcp/http] succeeded!\n"
Nov 12 00:55:56.586: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:55:56.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Nov 12 00:55:57.010: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Nov 12 00:55:57.010: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 00:55:57.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.74.150 81'
Nov 12 00:55:57.404: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.74.150 81\nConnection to 172.21.74.150 81 port [tcp/*] succeeded!\n"
Nov 12 00:55:57.404: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5889 11/12/22 00:55:57.404
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod2:[101]] 11/12/22 00:55:57.445
Nov 12 00:55:57.499: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5889 11/12/22 00:55:57.499
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[] 11/12/22 00:55:57.549
Nov 12 00:55:57.596: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 00:55:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5889" for this suite. 11/12/22 00:55:57.669
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":347,"skipped":6459,"failed":0}
------------------------------
• [SLOW TEST] [13.495 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:44.195
    Nov 12 00:55:44.195: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename services 11/12/22 00:55:44.198
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:44.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:44.257
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5889 11/12/22 00:55:44.27
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[] 11/12/22 00:55:44.303
    Nov 12 00:55:44.335: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5889 11/12/22 00:55:44.335
    Nov 12 00:55:44.371: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5889" to be "running and ready"
    Nov 12 00:55:44.388: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.000482ms
    Nov 12 00:55:44.388: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:55:46.403: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031545488s
    Nov 12 00:55:46.403: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:55:48.408: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.03646394s
    Nov 12 00:55:48.408: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 12 00:55:48.408: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod1:[100]] 11/12/22 00:55:48.426
    Nov 12 00:55:48.479: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5889 11/12/22 00:55:48.479
    Nov 12 00:55:48.504: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5889" to be "running and ready"
    Nov 12 00:55:48.520: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.868294ms
    Nov 12 00:55:48.520: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:55:50.539: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.035228688s
    Nov 12 00:55:50.539: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 12 00:55:50.539: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod1:[100] pod2:[101]] 11/12/22 00:55:50.557
    Nov 12 00:55:50.623: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 11/12/22 00:55:50.623
    Nov 12 00:55:50.624: INFO: Creating new exec pod
    Nov 12 00:55:50.644: INFO: Waiting up to 5m0s for pod "execpodzccg2" in namespace "services-5889" to be "running"
    Nov 12 00:55:50.660: INFO: Pod "execpodzccg2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.080293ms
    Nov 12 00:55:52.679: INFO: Pod "execpodzccg2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035182987s
    Nov 12 00:55:54.676: INFO: Pod "execpodzccg2": Phase="Running", Reason="", readiness=true. Elapsed: 4.032356706s
    Nov 12 00:55:54.676: INFO: Pod "execpodzccg2" satisfied condition "running"
    Nov 12 00:55:55.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Nov 12 00:55:56.155: INFO: stderr: "+ + echonc -v -t -w hostName 2 multi-endpoint-test\n 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Nov 12 00:55:56.156: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:55:56.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.74.150 80'
    Nov 12 00:55:56.586: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.74.150 80\nConnection to 172.21.74.150 80 port [tcp/http] succeeded!\n"
    Nov 12 00:55:56.586: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:55:56.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Nov 12 00:55:57.010: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Nov 12 00:55:57.010: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 00:55:57.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2417746661 --namespace=services-5889 exec execpodzccg2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.21.74.150 81'
    Nov 12 00:55:57.404: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.21.74.150 81\nConnection to 172.21.74.150 81 port [tcp/*] succeeded!\n"
    Nov 12 00:55:57.404: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5889 11/12/22 00:55:57.404
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[pod2:[101]] 11/12/22 00:55:57.445
    Nov 12 00:55:57.499: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5889 11/12/22 00:55:57.499
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5889 to expose endpoints map[] 11/12/22 00:55:57.549
    Nov 12 00:55:57.596: INFO: successfully validated that service multi-endpoint-test in namespace services-5889 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 00:55:57.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5889" for this suite. 11/12/22 00:55:57.669
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:57.694
Nov 12 00:55:57.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename server-version 11/12/22 00:55:57.696
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:57.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:57.765
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 11/12/22 00:55:57.776
STEP: Confirm major version 11/12/22 00:55:57.781
Nov 12 00:55:57.781: INFO: Major version: 1
STEP: Confirm minor version 11/12/22 00:55:57.781
Nov 12 00:55:57.781: INFO: cleanMinorVersion: 25
Nov 12 00:55:57.781: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Nov 12 00:55:57.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7261" for this suite. 11/12/22 00:55:57.796
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":348,"skipped":6468,"failed":0}
------------------------------
• [0.137 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:57.694
    Nov 12 00:55:57.694: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename server-version 11/12/22 00:55:57.696
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:57.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:57.765
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 11/12/22 00:55:57.776
    STEP: Confirm major version 11/12/22 00:55:57.781
    Nov 12 00:55:57.781: INFO: Major version: 1
    STEP: Confirm minor version 11/12/22 00:55:57.781
    Nov 12 00:55:57.781: INFO: cleanMinorVersion: 25
    Nov 12 00:55:57.781: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Nov 12 00:55:57.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-7261" for this suite. 11/12/22 00:55:57.796
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:55:57.842
Nov 12 00:55:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 00:55:57.845
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:57.892
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:57.907
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-09e02281-71e3-49d0-b7fc-27e604c283f2 11/12/22 00:55:57.919
STEP: Creating a pod to test consume configMaps 11/12/22 00:55:57.939
Nov 12 00:55:57.980: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d" in namespace "projected-8931" to be "Succeeded or Failed"
Nov 12 00:55:57.998: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.232479ms
Nov 12 00:56:00.022: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041860494s
Nov 12 00:56:02.018: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037984545s
Nov 12 00:56:04.017: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037320969s
STEP: Saw pod success 11/12/22 00:56:04.017
Nov 12 00:56:04.018: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d" satisfied condition "Succeeded or Failed"
Nov 12 00:56:04.035: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d container agnhost-container: <nil>
STEP: delete the pod 11/12/22 00:56:04.075
Nov 12 00:56:04.131: INFO: Waiting for pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d to disappear
Nov 12 00:56:04.147: INFO: Pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 00:56:04.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8931" for this suite. 11/12/22 00:56:04.168
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":349,"skipped":6496,"failed":0}
------------------------------
• [SLOW TEST] [6.348 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:55:57.842
    Nov 12 00:55:57.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 00:55:57.845
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:55:57.892
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:55:57.907
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-09e02281-71e3-49d0-b7fc-27e604c283f2 11/12/22 00:55:57.919
    STEP: Creating a pod to test consume configMaps 11/12/22 00:55:57.939
    Nov 12 00:55:57.980: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d" in namespace "projected-8931" to be "Succeeded or Failed"
    Nov 12 00:55:57.998: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.232479ms
    Nov 12 00:56:00.022: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041860494s
    Nov 12 00:56:02.018: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037984545s
    Nov 12 00:56:04.017: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037320969s
    STEP: Saw pod success 11/12/22 00:56:04.017
    Nov 12 00:56:04.018: INFO: Pod "pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d" satisfied condition "Succeeded or Failed"
    Nov 12 00:56:04.035: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 00:56:04.075
    Nov 12 00:56:04.131: INFO: Waiting for pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d to disappear
    Nov 12 00:56:04.147: INFO: Pod pod-projected-configmaps-eec78ee7-6620-45a7-89e0-4e6f43ff8f1d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 00:56:04.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8931" for this suite. 11/12/22 00:56:04.168
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:04.192
Nov 12 00:56:04.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename secrets 11/12/22 00:56:04.195
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:04.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:04.258
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-5298c235-44b7-45e6-aedb-8e72b13a4e82 11/12/22 00:56:04.27
STEP: Creating a pod to test consume secrets 11/12/22 00:56:04.29
Nov 12 00:56:04.328: INFO: Waiting up to 5m0s for pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92" in namespace "secrets-2737" to be "Succeeded or Failed"
Nov 12 00:56:04.345: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 17.284729ms
Nov 12 00:56:06.364: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035578843s
Nov 12 00:56:08.361: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033483682s
Nov 12 00:56:10.372: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043817728s
STEP: Saw pod success 11/12/22 00:56:10.372
Nov 12 00:56:10.372: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92" satisfied condition "Succeeded or Failed"
Nov 12 00:56:10.389: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 00:56:10.422
Nov 12 00:56:10.492: INFO: Waiting for pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 to disappear
Nov 12 00:56:10.534: INFO: Pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 00:56:10.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2737" for this suite. 11/12/22 00:56:10.582
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":350,"skipped":6497,"failed":0}
------------------------------
• [SLOW TEST] [6.411 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:04.192
    Nov 12 00:56:04.192: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename secrets 11/12/22 00:56:04.195
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:04.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:04.258
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-5298c235-44b7-45e6-aedb-8e72b13a4e82 11/12/22 00:56:04.27
    STEP: Creating a pod to test consume secrets 11/12/22 00:56:04.29
    Nov 12 00:56:04.328: INFO: Waiting up to 5m0s for pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92" in namespace "secrets-2737" to be "Succeeded or Failed"
    Nov 12 00:56:04.345: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 17.284729ms
    Nov 12 00:56:06.364: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035578843s
    Nov 12 00:56:08.361: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033483682s
    Nov 12 00:56:10.372: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043817728s
    STEP: Saw pod success 11/12/22 00:56:10.372
    Nov 12 00:56:10.372: INFO: Pod "pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92" satisfied condition "Succeeded or Failed"
    Nov 12 00:56:10.389: INFO: Trying to get logs from node 10.184.98.55 pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 00:56:10.422
    Nov 12 00:56:10.492: INFO: Waiting for pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 to disappear
    Nov 12 00:56:10.534: INFO: Pod pod-secrets-b61e9d73-ca50-4a65-8c38-d69cb3e9ea92 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 00:56:10.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2737" for this suite. 11/12/22 00:56:10.582
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:10.603
Nov 12 00:56:10.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename disruption 11/12/22 00:56:10.605
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:10.676
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:10.695
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 11/12/22 00:56:10.724
STEP: Waiting for all pods to be running 11/12/22 00:56:10.902
Nov 12 00:56:10.930: INFO: running pods: 0 < 3
Nov 12 00:56:12.952: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 00:56:14.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9054" for this suite. 11/12/22 00:56:14.982
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":351,"skipped":6501,"failed":0}
------------------------------
• [4.402 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:10.603
    Nov 12 00:56:10.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename disruption 11/12/22 00:56:10.605
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:10.676
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:10.695
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 11/12/22 00:56:10.724
    STEP: Waiting for all pods to be running 11/12/22 00:56:10.902
    Nov 12 00:56:10.930: INFO: running pods: 0 < 3
    Nov 12 00:56:12.952: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 00:56:14.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9054" for this suite. 11/12/22 00:56:14.982
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:15.007
Nov 12 00:56:15.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename configmap 11/12/22 00:56:15.01
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:15.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:15.08
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 11/12/22 00:56:15.099
STEP: fetching the ConfigMap 11/12/22 00:56:15.116
STEP: patching the ConfigMap 11/12/22 00:56:15.132
STEP: listing all ConfigMaps in all namespaces with a label selector 11/12/22 00:56:15.149
STEP: deleting the ConfigMap by collection with a label selector 11/12/22 00:56:15.171
STEP: listing all ConfigMaps in test namespace 11/12/22 00:56:15.2
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 00:56:15.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1554" for this suite. 11/12/22 00:56:15.232
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":352,"skipped":6511,"failed":0}
------------------------------
• [0.248 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:15.007
    Nov 12 00:56:15.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename configmap 11/12/22 00:56:15.01
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:15.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:15.08
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 11/12/22 00:56:15.099
    STEP: fetching the ConfigMap 11/12/22 00:56:15.116
    STEP: patching the ConfigMap 11/12/22 00:56:15.132
    STEP: listing all ConfigMaps in all namespaces with a label selector 11/12/22 00:56:15.149
    STEP: deleting the ConfigMap by collection with a label selector 11/12/22 00:56:15.171
    STEP: listing all ConfigMaps in test namespace 11/12/22 00:56:15.2
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 00:56:15.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1554" for this suite. 11/12/22 00:56:15.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:15.271
Nov 12 00:56:15.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:56:15.272
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:15.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:15.336
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Nov 12 00:56:15.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:56:18.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2200" for this suite. 11/12/22 00:56:18.723
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":353,"skipped":6572,"failed":0}
------------------------------
• [3.471 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:15.271
    Nov 12 00:56:15.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 00:56:15.272
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:15.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:15.336
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Nov 12 00:56:15.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:56:18.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2200" for this suite. 11/12/22 00:56:18.723
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:18.746
Nov 12 00:56:18.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename gc 11/12/22 00:56:18.748
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:18.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:18.833
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 11/12/22 00:56:18.844
STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 00:56:18.866
STEP: delete the deployment 11/12/22 00:56:19.418
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/12/22 00:56:19.447
STEP: Gathering metrics 11/12/22 00:56:20.097
W1112 00:56:20.175137      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 00:56:20.175: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 00:56:20.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-589" for this suite. 11/12/22 00:56:20.193
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":354,"skipped":6594,"failed":0}
------------------------------
• [1.479 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:18.746
    Nov 12 00:56:18.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename gc 11/12/22 00:56:18.748
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:18.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:18.833
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 11/12/22 00:56:18.844
    STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 00:56:18.866
    STEP: delete the deployment 11/12/22 00:56:19.418
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/12/22 00:56:19.447
    STEP: Gathering metrics 11/12/22 00:56:20.097
    W1112 00:56:20.175137      21 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 00:56:20.175: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 00:56:20.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-589" for this suite. 11/12/22 00:56:20.193
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:20.228
Nov 12 00:56:20.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename resourcequota 11/12/22 00:56:20.23
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:20.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:20.291
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 11/12/22 00:56:20.307
STEP: Creating a ResourceQuota 11/12/22 00:56:25.325
STEP: Ensuring resource quota status is calculated 11/12/22 00:56:25.346
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 00:56:27.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6805" for this suite. 11/12/22 00:56:27.382
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":355,"skipped":6609,"failed":0}
------------------------------
• [SLOW TEST] [7.174 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:20.228
    Nov 12 00:56:20.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename resourcequota 11/12/22 00:56:20.23
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:20.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:20.291
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 11/12/22 00:56:20.307
    STEP: Creating a ResourceQuota 11/12/22 00:56:25.325
    STEP: Ensuring resource quota status is calculated 11/12/22 00:56:25.346
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 00:56:27.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6805" for this suite. 11/12/22 00:56:27.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:56:27.406
Nov 12 00:56:27.406: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename crd-watch 11/12/22 00:56:27.408
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:27.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:27.47
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Nov 12 00:56:27.483: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Creating first CR  11/12/22 00:56:30.138
Nov 12 00:56:30.157: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:30Z]] name:name1 resourceVersion:50866 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 11/12/22 00:56:40.158
Nov 12 00:56:40.179: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:40Z]] name:name2 resourceVersion:50882 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 11/12/22 00:56:50.18
Nov 12 00:56:50.202: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:50Z]] name:name1 resourceVersion:50894 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 11/12/22 00:57:00.203
Nov 12 00:57:00.225: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:57:00Z]] name:name2 resourceVersion:50905 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 11/12/22 00:57:10.227
Nov 12 00:57:10.256: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:50Z]] name:name1 resourceVersion:50918 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 11/12/22 00:57:20.257
Nov 12 00:57:20.283: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:57:00Z]] name:name2 resourceVersion:50929 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 00:57:30.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9954" for this suite. 11/12/22 00:57:30.859
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":356,"skipped":6619,"failed":0}
------------------------------
• [SLOW TEST] [63.484 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:56:27.406
    Nov 12 00:56:27.406: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename crd-watch 11/12/22 00:56:27.408
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:56:27.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:56:27.47
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Nov 12 00:56:27.483: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Creating first CR  11/12/22 00:56:30.138
    Nov 12 00:56:30.157: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:30Z]] name:name1 resourceVersion:50866 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 11/12/22 00:56:40.158
    Nov 12 00:56:40.179: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:40Z]] name:name2 resourceVersion:50882 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 11/12/22 00:56:50.18
    Nov 12 00:56:50.202: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:50Z]] name:name1 resourceVersion:50894 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 11/12/22 00:57:00.203
    Nov 12 00:57:00.225: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:57:00Z]] name:name2 resourceVersion:50905 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 11/12/22 00:57:10.227
    Nov 12 00:57:10.256: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:30Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:56:50Z]] name:name1 resourceVersion:50918 uid:1fc83697-5f09-4492-aacf-da43235234f8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 11/12/22 00:57:20.257
    Nov 12 00:57:20.283: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T00:56:40Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T00:57:00Z]] name:name2 resourceVersion:50929 uid:e71818d6-0a46-4629-a718-25a20b4204e0] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 00:57:30.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-9954" for this suite. 11/12/22 00:57:30.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:57:30.909
Nov 12 00:57:30.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename controllerrevisions 11/12/22 00:57:30.911
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:57:30.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:57:30.975
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-n55qw-daemon-set" 11/12/22 00:57:31.086
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:57:31.102
Nov 12 00:57:31.141: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
Nov 12 00:57:31.141: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:57:32.184: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
Nov 12 00:57:32.184: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:57:33.180: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 1
Nov 12 00:57:33.180: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
Nov 12 00:57:34.179: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 3
Nov 12 00:57:34.179: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-n55qw-daemon-set
STEP: Confirm DaemonSet "e2e-n55qw-daemon-set" successfully created with "daemonset-name=e2e-n55qw-daemon-set" label 11/12/22 00:57:34.193
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-n55qw-daemon-set" 11/12/22 00:57:34.241
Nov 12 00:57:34.263: INFO: Located ControllerRevision: "e2e-n55qw-daemon-set-64f859b6f5"
STEP: Patching ControllerRevision "e2e-n55qw-daemon-set-64f859b6f5" 11/12/22 00:57:34.279
Nov 12 00:57:34.303: INFO: e2e-n55qw-daemon-set-64f859b6f5 has been patched
STEP: Create a new ControllerRevision 11/12/22 00:57:34.303
Nov 12 00:57:34.325: INFO: Created ControllerRevision: e2e-n55qw-daemon-set-6dccdb4c99
STEP: Confirm that there are two ControllerRevisions 11/12/22 00:57:34.325
Nov 12 00:57:34.326: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 00:57:34.342: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-n55qw-daemon-set-64f859b6f5" 11/12/22 00:57:34.342
STEP: Confirm that there is only one ControllerRevision 11/12/22 00:57:34.372
Nov 12 00:57:34.372: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 00:57:34.390: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-n55qw-daemon-set-6dccdb4c99" 11/12/22 00:57:34.406
Nov 12 00:57:34.444: INFO: e2e-n55qw-daemon-set-6dccdb4c99 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 11/12/22 00:57:34.444
W1112 00:57:34.469502      21 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 11/12/22 00:57:34.469
Nov 12 00:57:34.470: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 00:57:35.487: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 00:57:35.504: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-n55qw-daemon-set-6dccdb4c99=updated" 11/12/22 00:57:35.504
STEP: Confirm that there is only one ControllerRevision 11/12/22 00:57:35.546
Nov 12 00:57:35.547: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 00:57:35.563: INFO: Found 1 ControllerRevisions
Nov 12 00:57:35.579: INFO: ControllerRevision "e2e-n55qw-daemon-set-7cbd6c7dc8" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-n55qw-daemon-set" 11/12/22 00:57:35.593
STEP: deleting DaemonSet.extensions e2e-n55qw-daemon-set in namespace controllerrevisions-4527, will wait for the garbage collector to delete the pods 11/12/22 00:57:35.593
Nov 12 00:57:35.680: INFO: Deleting DaemonSet.extensions e2e-n55qw-daemon-set took: 22.748991ms
Nov 12 00:57:35.781: INFO: Terminating DaemonSet.extensions e2e-n55qw-daemon-set pods took: 100.738764ms
Nov 12 00:57:37.398: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
Nov 12 00:57:37.398: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-n55qw-daemon-set
Nov 12 00:57:37.410: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"51044"},"items":null}

Nov 12 00:57:37.427: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"51044"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Nov 12 00:57:37.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-4527" for this suite. 11/12/22 00:57:37.501
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":357,"skipped":6653,"failed":0}
------------------------------
• [SLOW TEST] [6.614 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:57:30.909
    Nov 12 00:57:30.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename controllerrevisions 11/12/22 00:57:30.911
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:57:30.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:57:30.975
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-n55qw-daemon-set" 11/12/22 00:57:31.086
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 00:57:31.102
    Nov 12 00:57:31.141: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
    Nov 12 00:57:31.141: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:57:32.184: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
    Nov 12 00:57:32.184: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:57:33.180: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 1
    Nov 12 00:57:33.180: INFO: Node 10.184.98.55 is running 0 daemon pod, expected 1
    Nov 12 00:57:34.179: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 3
    Nov 12 00:57:34.179: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-n55qw-daemon-set
    STEP: Confirm DaemonSet "e2e-n55qw-daemon-set" successfully created with "daemonset-name=e2e-n55qw-daemon-set" label 11/12/22 00:57:34.193
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-n55qw-daemon-set" 11/12/22 00:57:34.241
    Nov 12 00:57:34.263: INFO: Located ControllerRevision: "e2e-n55qw-daemon-set-64f859b6f5"
    STEP: Patching ControllerRevision "e2e-n55qw-daemon-set-64f859b6f5" 11/12/22 00:57:34.279
    Nov 12 00:57:34.303: INFO: e2e-n55qw-daemon-set-64f859b6f5 has been patched
    STEP: Create a new ControllerRevision 11/12/22 00:57:34.303
    Nov 12 00:57:34.325: INFO: Created ControllerRevision: e2e-n55qw-daemon-set-6dccdb4c99
    STEP: Confirm that there are two ControllerRevisions 11/12/22 00:57:34.325
    Nov 12 00:57:34.326: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 00:57:34.342: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-n55qw-daemon-set-64f859b6f5" 11/12/22 00:57:34.342
    STEP: Confirm that there is only one ControllerRevision 11/12/22 00:57:34.372
    Nov 12 00:57:34.372: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 00:57:34.390: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-n55qw-daemon-set-6dccdb4c99" 11/12/22 00:57:34.406
    Nov 12 00:57:34.444: INFO: e2e-n55qw-daemon-set-6dccdb4c99 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 11/12/22 00:57:34.444
    W1112 00:57:34.469502      21 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 11/12/22 00:57:34.469
    Nov 12 00:57:34.470: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 00:57:35.487: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 00:57:35.504: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-n55qw-daemon-set-6dccdb4c99=updated" 11/12/22 00:57:35.504
    STEP: Confirm that there is only one ControllerRevision 11/12/22 00:57:35.546
    Nov 12 00:57:35.547: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 00:57:35.563: INFO: Found 1 ControllerRevisions
    Nov 12 00:57:35.579: INFO: ControllerRevision "e2e-n55qw-daemon-set-7cbd6c7dc8" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-n55qw-daemon-set" 11/12/22 00:57:35.593
    STEP: deleting DaemonSet.extensions e2e-n55qw-daemon-set in namespace controllerrevisions-4527, will wait for the garbage collector to delete the pods 11/12/22 00:57:35.593
    Nov 12 00:57:35.680: INFO: Deleting DaemonSet.extensions e2e-n55qw-daemon-set took: 22.748991ms
    Nov 12 00:57:35.781: INFO: Terminating DaemonSet.extensions e2e-n55qw-daemon-set pods took: 100.738764ms
    Nov 12 00:57:37.398: INFO: Number of nodes with available pods controlled by daemonset e2e-n55qw-daemon-set: 0
    Nov 12 00:57:37.398: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-n55qw-daemon-set
    Nov 12 00:57:37.410: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"51044"},"items":null}

    Nov 12 00:57:37.427: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"51044"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 00:57:37.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-4527" for this suite. 11/12/22 00:57:37.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:57:37.533
Nov 12 00:57:37.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:57:37.535
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:57:37.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:57:37.596
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-9280 11/12/22 00:57:37.608
STEP: creating a selector 11/12/22 00:57:37.608
STEP: Creating the service pods in kubernetes 11/12/22 00:57:37.608
Nov 12 00:57:37.609: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 00:57:37.712: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9280" to be "running and ready"
Nov 12 00:57:37.735: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 23.029215ms
Nov 12 00:57:37.735: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:57:39.751: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038953748s
Nov 12 00:57:39.751: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 00:57:41.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.040284362s
Nov 12 00:57:41.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:43.755: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.043208125s
Nov 12 00:57:43.755: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:45.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.042474961s
Nov 12 00:57:45.754: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:47.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.03992177s
Nov 12 00:57:47.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:49.753: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.040918641s
Nov 12 00:57:49.753: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:51.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.041937949s
Nov 12 00:57:51.754: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:53.756: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.044809716s
Nov 12 00:57:53.756: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:55.758: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.046674283s
Nov 12 00:57:55.758: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:57.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.040341724s
Nov 12 00:57:57.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 00:57:59.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.040047616s
Nov 12 00:57:59.752: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 00:57:59.752: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 00:57:59.773: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9280" to be "running and ready"
Nov 12 00:57:59.791: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 17.684772ms
Nov 12 00:57:59.791: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 00:57:59.791: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 00:57:59.807: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9280" to be "running and ready"
Nov 12 00:57:59.825: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 18.016159ms
Nov 12 00:57:59.826: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 00:57:59.826: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 00:57:59.844
Nov 12 00:57:59.891: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9280" to be "running"
Nov 12 00:57:59.910: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.217514ms
Nov 12 00:58:01.928: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036542827s
Nov 12 00:58:03.930: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.038598116s
Nov 12 00:58:03.930: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 00:58:03.945: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9280" to be "running"
Nov 12 00:58:03.959: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.330745ms
Nov 12 00:58:03.959: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 12 00:58:03.976: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 00:58:03.976: INFO: Going to poll 172.30.146.6 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:58:03.992: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.146.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:58:03.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:58:03.994: INFO: ExecWithOptions: Clientset creation
Nov 12 00:58:03.994: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.146.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:58:05.250: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 12 00:58:05.250: INFO: Going to poll 172.30.188.224 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:58:05.268: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.188.224 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:58:05.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:58:05.270: INFO: ExecWithOptions: Clientset creation
Nov 12 00:58:05.270: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.188.224+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:58:06.557: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 12 00:58:06.557: INFO: Going to poll 172.30.194.113 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 00:58:06.573: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.194.113 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 00:58:06.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
Nov 12 00:58:06.574: INFO: ExecWithOptions: Clientset creation
Nov 12 00:58:06.574: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.194.113+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 00:58:07.818: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 00:58:07.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9280" for this suite. 11/12/22 00:58:07.839
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":358,"skipped":6670,"failed":0}
------------------------------
• [SLOW TEST] [30.328 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:57:37.533
    Nov 12 00:57:37.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 00:57:37.535
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:57:37.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:57:37.596
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-9280 11/12/22 00:57:37.608
    STEP: creating a selector 11/12/22 00:57:37.608
    STEP: Creating the service pods in kubernetes 11/12/22 00:57:37.608
    Nov 12 00:57:37.609: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 00:57:37.712: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9280" to be "running and ready"
    Nov 12 00:57:37.735: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 23.029215ms
    Nov 12 00:57:37.735: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:57:39.751: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038953748s
    Nov 12 00:57:39.751: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 00:57:41.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.040284362s
    Nov 12 00:57:41.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:43.755: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.043208125s
    Nov 12 00:57:43.755: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:45.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.042474961s
    Nov 12 00:57:45.754: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:47.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.03992177s
    Nov 12 00:57:47.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:49.753: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.040918641s
    Nov 12 00:57:49.753: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:51.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.041937949s
    Nov 12 00:57:51.754: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:53.756: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.044809716s
    Nov 12 00:57:53.756: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:55.758: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.046674283s
    Nov 12 00:57:55.758: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:57.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.040341724s
    Nov 12 00:57:57.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 00:57:59.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.040047616s
    Nov 12 00:57:59.752: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 00:57:59.752: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 00:57:59.773: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9280" to be "running and ready"
    Nov 12 00:57:59.791: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 17.684772ms
    Nov 12 00:57:59.791: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 00:57:59.791: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 00:57:59.807: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9280" to be "running and ready"
    Nov 12 00:57:59.825: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 18.016159ms
    Nov 12 00:57:59.826: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 00:57:59.826: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 00:57:59.844
    Nov 12 00:57:59.891: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9280" to be "running"
    Nov 12 00:57:59.910: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 19.217514ms
    Nov 12 00:58:01.928: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036542827s
    Nov 12 00:58:03.930: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.038598116s
    Nov 12 00:58:03.930: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 00:58:03.945: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9280" to be "running"
    Nov 12 00:58:03.959: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 14.330745ms
    Nov 12 00:58:03.959: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 12 00:58:03.976: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 00:58:03.976: INFO: Going to poll 172.30.146.6 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:58:03.992: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.146.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:58:03.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:58:03.994: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:58:03.994: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.146.6+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:58:05.250: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 12 00:58:05.250: INFO: Going to poll 172.30.188.224 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:58:05.268: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.188.224 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:58:05.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:58:05.270: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:58:05.270: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.188.224+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:58:06.557: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 12 00:58:06.557: INFO: Going to poll 172.30.194.113 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 00:58:06.573: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.194.113 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9280 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 00:58:06.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    Nov 12 00:58:06.574: INFO: ExecWithOptions: Clientset creation
    Nov 12 00:58:06.574: INFO: ExecWithOptions: execute(POST https://172.21.0.1:443/api/v1/namespaces/pod-network-test-9280/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.30.194.113+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 00:58:07.818: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 00:58:07.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9280" for this suite. 11/12/22 00:58:07.839
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 00:58:07.862
Nov 12 00:58:07.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename cronjob 11/12/22 00:58:07.865
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:58:07.913
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:58:07.923
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 11/12/22 00:58:07.936
STEP: Ensuring more than one job is running at a time 11/12/22 00:58:07.955
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/12/22 01:00:01.973
STEP: Removing cronjob 11/12/22 01:00:01.995
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 01:00:02.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5582" for this suite. 11/12/22 01:00:02.061
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":359,"skipped":6671,"failed":0}
------------------------------
• [SLOW TEST] [114.225 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 00:58:07.862
    Nov 12 00:58:07.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename cronjob 11/12/22 00:58:07.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 00:58:07.913
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 00:58:07.923
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 11/12/22 00:58:07.936
    STEP: Ensuring more than one job is running at a time 11/12/22 00:58:07.955
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/12/22 01:00:01.973
    STEP: Removing cronjob 11/12/22 01:00:01.995
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 01:00:02.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5582" for this suite. 11/12/22 01:00:02.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 01:00:02.093
Nov 12 01:00:02.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename deployment 11/12/22 01:00:02.096
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:02.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:02.165
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Nov 12 01:00:02.218: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 12 01:00:07.237: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 01:00:07.238
Nov 12 01:00:07.238: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/12/22 01:00:07.278
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 01:00:11.368: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7653  f0828a4a-c5c3-4cf0-92d4-ae72a7522a76 51462 1 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 01:00:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004947da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 01:00:07 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-12 01:00:10 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 01:00:11.386: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7653  46e9bd31-6fa5-4d64-87e9-d0f67a61baac 51452 1 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment f0828a4a-c5c3-4cf0-92d4-ae72a7522a76 0xc004e625c7 0xc004e625c8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f0828a4a-c5c3-4cf0-92d4-ae72a7522a76\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 01:00:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e62678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 01:00:11.402: INFO: Pod "test-cleanup-deployment-69cb9c5497-d9d4d" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-d9d4d test-cleanup-deployment-69cb9c5497- deployment-7653  e2ba4bd1-6d32-42b8-801a-a62fef96e765 51451 0 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:422281fef685d1b25fef1faa8be752bbee91c7fa692cadb7bcf39b03c108a377 cni.projectcalico.org/podIP:172.30.146.40/32 cni.projectcalico.org/podIPs:172.30.146.40/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 46e9bd31-6fa5-4d64-87e9-d0f67a61baac 0xc004e62a47 0xc004e62a48}] [] [{kube-controller-manager Update v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"46e9bd31-6fa5-4d64-87e9-d0f67a61baac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 01:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 01:00:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92xjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92xjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.40,StartTime:2022-11-12 01:00:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 01:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://b6463af86d70dee99f63921acb760092301fd366f7632f1e09e15e0cc48375c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 01:00:11.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7653" for this suite. 11/12/22 01:00:11.423
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":360,"skipped":6677,"failed":0}
------------------------------
• [SLOW TEST] [9.351 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 01:00:02.093
    Nov 12 01:00:02.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename deployment 11/12/22 01:00:02.096
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:02.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:02.165
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Nov 12 01:00:02.218: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Nov 12 01:00:07.237: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 01:00:07.238
    Nov 12 01:00:07.238: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/12/22 01:00:07.278
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 01:00:11.368: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-7653  f0828a4a-c5c3-4cf0-92d4-ae72a7522a76 51462 1 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 01:00:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004947da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 01:00:07 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-12 01:00:10 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 01:00:11.386: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-7653  46e9bd31-6fa5-4d64-87e9-d0f67a61baac 51452 1 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment f0828a4a-c5c3-4cf0-92d4-ae72a7522a76 0xc004e625c7 0xc004e625c8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f0828a4a-c5c3-4cf0-92d4-ae72a7522a76\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 01:00:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e62678 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 01:00:11.402: INFO: Pod "test-cleanup-deployment-69cb9c5497-d9d4d" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-d9d4d test-cleanup-deployment-69cb9c5497- deployment-7653  e2ba4bd1-6d32-42b8-801a-a62fef96e765 51451 0 2022-11-12 01:00:07 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:422281fef685d1b25fef1faa8be752bbee91c7fa692cadb7bcf39b03c108a377 cni.projectcalico.org/podIP:172.30.146.40/32 cni.projectcalico.org/podIPs:172.30.146.40/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 46e9bd31-6fa5-4d64-87e9-d0f67a61baac 0xc004e62a47 0xc004e62a48}] [] [{kube-controller-manager Update v1 2022-11-12 01:00:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"46e9bd31-6fa5-4d64-87e9-d0f67a61baac\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2022-11-12 01:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2022-11-12 01:00:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.30.146.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-92xjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-92xjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.98.55,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 01:00:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.98.55,PodIP:172.30.146.40,StartTime:2022-11-12 01:00:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 01:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://b6463af86d70dee99f63921acb760092301fd366f7632f1e09e15e0cc48375c7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.146.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 01:00:11.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7653" for this suite. 11/12/22 01:00:11.423
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 01:00:11.448
Nov 12 01:00:11.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename security-context-test 11/12/22 01:00:11.45
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:11.499
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:11.514
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Nov 12 01:00:11.570: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63" in namespace "security-context-test-3172" to be "Succeeded or Failed"
Nov 12 01:00:11.588: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 17.716316ms
Nov 12 01:00:13.607: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037106379s
Nov 12 01:00:15.607: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036530708s
Nov 12 01:00:17.605: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035021553s
Nov 12 01:00:17.605: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 01:00:17.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3172" for this suite. 11/12/22 01:00:17.64
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":361,"skipped":6681,"failed":0}
------------------------------
• [SLOW TEST] [6.216 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 01:00:11.448
    Nov 12 01:00:11.448: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename security-context-test 11/12/22 01:00:11.45
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:11.499
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:11.514
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Nov 12 01:00:11.570: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63" in namespace "security-context-test-3172" to be "Succeeded or Failed"
    Nov 12 01:00:11.588: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 17.716316ms
    Nov 12 01:00:13.607: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037106379s
    Nov 12 01:00:15.607: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036530708s
    Nov 12 01:00:17.605: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.035021553s
    Nov 12 01:00:17.605: INFO: Pod "busybox-readonly-false-ff3f07a0-0d1c-4219-ba1b-c995e3b12b63" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 01:00:17.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-3172" for this suite. 11/12/22 01:00:17.64
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 01:00:17.666
Nov 12 01:00:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
STEP: Building a namespace api object, basename projected 11/12/22 01:00:17.669
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:17.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:17.745
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-85dde906-0dbe-4b09-b625-e9240e495893 11/12/22 01:00:17.757
STEP: Creating a pod to test consume configMaps 11/12/22 01:00:17.772
Nov 12 01:00:17.809: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d" in namespace "projected-2461" to be "Succeeded or Failed"
Nov 12 01:00:17.826: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.683453ms
Nov 12 01:00:19.845: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035226327s
Nov 12 01:00:21.844: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Running", Reason="", readiness=false. Elapsed: 4.034232373s
Nov 12 01:00:23.846: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036215329s
STEP: Saw pod success 11/12/22 01:00:23.846
Nov 12 01:00:23.847: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d" satisfied condition "Succeeded or Failed"
Nov 12 01:00:23.865: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d container agnhost-container: <nil>
STEP: delete the pod 11/12/22 01:00:23.976
Nov 12 01:00:24.020: INFO: Waiting for pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d to disappear
Nov 12 01:00:24.036: INFO: Pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 01:00:24.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2461" for this suite. 11/12/22 01:00:24.057
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":362,"skipped":6695,"failed":0}
------------------------------
• [SLOW TEST] [6.411 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 01:00:17.666
    Nov 12 01:00:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2417746661
    STEP: Building a namespace api object, basename projected 11/12/22 01:00:17.669
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 01:00:17.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 01:00:17.745
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-85dde906-0dbe-4b09-b625-e9240e495893 11/12/22 01:00:17.757
    STEP: Creating a pod to test consume configMaps 11/12/22 01:00:17.772
    Nov 12 01:00:17.809: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d" in namespace "projected-2461" to be "Succeeded or Failed"
    Nov 12 01:00:17.826: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.683453ms
    Nov 12 01:00:19.845: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035226327s
    Nov 12 01:00:21.844: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Running", Reason="", readiness=false. Elapsed: 4.034232373s
    Nov 12 01:00:23.846: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036215329s
    STEP: Saw pod success 11/12/22 01:00:23.846
    Nov 12 01:00:23.847: INFO: Pod "pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d" satisfied condition "Succeeded or Failed"
    Nov 12 01:00:23.865: INFO: Trying to get logs from node 10.184.98.55 pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 01:00:23.976
    Nov 12 01:00:24.020: INFO: Waiting for pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d to disappear
    Nov 12 01:00:24.036: INFO: Pod pod-projected-configmaps-5b2803e9-af12-4e1f-9b30-479d542cec1d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 01:00:24.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2461" for this suite. 11/12/22 01:00:24.057
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Nov 12 01:00:24.082: INFO: Running AfterSuite actions on all nodes
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Nov 12 01:00:24.082: INFO: Running AfterSuite actions on node 1
Nov 12 01:00:24.082: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 12 01:00:24.082: INFO: Running AfterSuite actions on all nodes
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Nov 12 01:00:24.082: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 12 01:00:24.082: INFO: Running AfterSuite actions on node 1
    Nov 12 01:00:24.082: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.128 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 6685.896 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h51m26.593678837s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

